{"version":3,"file":"brain-browser.min.js","sources":["../../src/activation/relu.ts","../../src/activation/sigmoid.ts","../../src/activation/tanh.ts","../../src/activation/leaky-relu.ts","../../src/cross-validate.ts","../../src/utilities/kernel.ts","../../src/estimator/mean-squared-error.ts","../../src/layer/base-layer.ts","../../src/utilities/zeros.ts","../../src/utilities/zeros-2d.ts","../../src/utilities/zeros-3d.ts","../../src/layer/activation.ts","../../src/layer/filter.ts","../../src/layer/internal.ts","../../src/layer/modifier.ts","../../src/layer/operator.ts","../../src/layer/target.ts","../../src/layer/types.ts","../../src/lookup.ts","../../src/praxis/base-praxis.ts","../../src/praxis/arthur-deviation-biases.ts","../../src/praxis/arthur-deviation-weights.ts","../../src/praxis/momentum-root-mean-squared-propagation.ts","../../src/utilities/traverse-layers-from.ts","../../src/utilities/flatten-layers.ts","../../src/utilities/layer-size.ts","../../src/layer/add.ts","../../src/utilities/random-weight.ts","../../src/utilities/random.ts","../../src/utilities/randos.ts","../../src/layer/random.ts","../../src/layer/multiply.ts","../../src/layer/sigmoid.ts","../../src/utilities/layer-setup.ts","../../src/utilities/values.ts","../../src/layer/convolution.ts","../../src/layer/dropout.ts","../../src/layer/fully-connected.ts","../../src/layer/negative.ts","../../src/layer/multiply-element.ts","../../src/utilities/ones.ts","../../src/layer/ones.ts","../../src/layer/tanh.ts","../../src/layer/zeros.ts","../../src/layer/input.ts","../../src/layer/leaky-relu.ts","../../src/layer/pool.ts","../../src/layer/recurrent-input.ts","../../src/layer/recurrent-zeros.ts","../../src/layer/relu.ts","../../src/layer/regression.ts","../../src/layer/soft-max.ts","../../src/layer/svm.ts","../../src/layer/transpose.ts","../../src/layer/index.ts","../../src/layer/arthur-feed-forward.ts","../../src/layer/feed-forward.ts","../../src/layer/gru.ts","../../src/layer/lstm-cell.ts","../../src/layer/output.ts","../../src/layer/rnn-cell.ts","../../src/utilities/layer-from-json.ts","../../src/utilities/lookup-table.ts","../../src/feed-forward.ts","../node_modules/thaw.js/browser.js","../../src/utilities/cast.ts","../../src/utilities/max.ts","../../src/utilities/mse.ts","../../src/neural-network.ts","../../src/neural-network-gpu.ts","../../src/layer/recurrent-connection.ts","../../src/recurrent.ts","../../src/recurrent/matrix/index.ts","../../src/recurrent/matrix/random-matrix.ts","../../src/utilities/data-formatter.ts","../../src/recurrent/matrix/add.ts","../../src/recurrent/matrix/add-b.ts","../../src/recurrent/matrix/all-ones.ts","../../src/recurrent/matrix/clone-negative.ts","../../src/recurrent/matrix/multiply.ts","../../src/recurrent/matrix/multiply-b.ts","../../src/recurrent/matrix/multiply-element.ts","../../src/recurrent/matrix/multiply-element-b.ts","../../src/recurrent/matrix/relu.ts","../../src/recurrent/matrix/relu-b.ts","../../src/recurrent/matrix/row-pluck.ts","../../src/recurrent/matrix/row-pluck-b.ts","../../src/recurrent/matrix/sigmoid.ts","../../src/recurrent/matrix/sigmoid-b.ts","../../src/recurrent/matrix/softmax.ts","../../src/recurrent/matrix/tanh.ts","../../src/recurrent/matrix/tanh-b.ts","../../src/recurrent/matrix/equation.ts","../../src/recurrent/matrix/max-i.ts","../../src/recurrent/matrix/sample-i.ts","../../src/recurrent/rnn.ts","../../src/recurrent/matrix/copy.ts","../../src/recurrent/gru.ts","../../src/utilities/array-lookup-table.ts","../../src/recurrent/rnn-time-step.ts","../../src/recurrent/gru-time-step.ts","../../src/recurrent/lstm.ts","../../src/recurrent/lstm-time-step.ts","../../src/utilities/to-svg.ts","../../src/browser-index.ts","../../src/utilities/range.ts","../../src/utilities/to-array.ts","../../src/likely.ts"],"sourcesContent":["/**\n * Relu Activation, aka Rectified Linear Unit Activation\n * @description https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n */\nexport function activate(weight: number): number {\n  return Math.max(0, weight);\n}\n\n/**\n * Relu derivative\n */\nexport function measure(weight: number, delta: number): number {\n  if (weight <= 0) {\n    return 0;\n  }\n  return delta;\n}\n","/**\n * sigmoid activation\n */\nexport function activate(value: number): number {\n  return 1 / (1 + Math.exp(-value));\n}\n\n/**\n * sigmoid derivative\n */\nexport function measure(weight: number, error: number): number {\n  return weight * (1 - weight) * error;\n}\n","/**\n * Hyperbolic tan\n */\nexport function activate(weight: number): number {\n  return Math.tanh(weight);\n}\n\n/**\n * @description grad for z = tanh(x) is (1 - z^2)\n */\nexport function measure(weight: number, error: number): number {\n  return (1 - weight * weight) * error;\n}\n","/**\n * Leaky Relu Activation, aka Leaky Rectified Linear Unit Activation\n * @description https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\n */\nexport function activate(weight: number): number {\n  return weight > 0 ? weight : 0.01 * weight;\n}\n\n/**\n * Leaky Relu derivative\n */\nexport function measure(weight: number, error: number): number {\n  return weight > 0 ? error : 0.01 * error;\n}\n","import {\n  INeuralNetworkBinaryTestResult,\n  INeuralNetworkState,\n  INeuralNetworkTestResult,\n} from './neural-network-types';\n\nexport type InitClassifier<\n  TrainOptsType,\n  JsonType,\n  DatumType\n> = () => IClassifier<TrainOptsType, JsonType, DatumType>;\n\nexport interface IClassifier<TrainOptsType, JsonType, DatumType> {\n  trainOpts: TrainOptsType;\n  toJSON: () => JsonType;\n  fromJSON: (json: JsonType) => this;\n  train: (\n    data: DatumType[],\n    options?: Partial<TrainOptsType>\n  ) => INeuralNetworkState;\n  test: (\n    data: DatumType[]\n  ) => INeuralNetworkTestResult | INeuralNetworkBinaryTestResult;\n  initialize: () => void;\n}\n\nexport type ICrossValidateJSON<JsonType> =\n  | ICrossValidateStats<JsonType>\n  | ICrossValidateBinaryStats<JsonType>;\n\nexport interface ICrossValidateStatsAverages {\n  trainTime: number;\n  testTime: number;\n  iterations: number;\n  error: number;\n}\n\nexport interface ICrossValidateStats<JsonType> {\n  avgs: ICrossValidateStatsAverages;\n  stats: ICrossValidateStatsResultStats;\n  sets: Array<ICrossValidationTestPartitionResults<JsonType>>;\n}\n\nexport interface ICrossValidateBinaryStats<NetworkType> {\n  avgs: ICrossValidateStatsAverages;\n  stats: ICrossValidateStatsResultBinaryStats;\n  sets: Array<ICrossValidationTestPartitionBinaryResults<NetworkType>>;\n}\n\nexport interface ICrossValidateStatsResultStats {\n  total: number;\n  testSize: number;\n  trainSize: number;\n}\n\nexport interface ICrossValidateStatsResultBinaryStats\n  extends ICrossValidateStatsResultStats {\n  total: number;\n  truePos: number;\n  trueNeg: number;\n  falsePos: number;\n  falseNeg: number;\n  precision: number;\n  recall: number;\n  accuracy: number;\n}\n\nexport interface ICrossValidationTestPartitionResults<JsonType>\n  extends INeuralNetworkTestResult {\n  trainTime: number;\n  testTime: number;\n  iterations: number;\n  network: JsonType;\n  total: number;\n}\n\nexport type ICrossValidationTestPartitionBinaryResults<\n  JsonType\n> = INeuralNetworkBinaryTestResult &\n  ICrossValidationTestPartitionResults<JsonType>;\n\nexport default class CrossValidate<\n  InitClassifierType extends InitClassifier<\n    ReturnType<InitClassifierType>['trainOpts'],\n    ReturnType<ReturnType<InitClassifierType>['toJSON']>,\n    Parameters<ReturnType<InitClassifierType>['train']>[0][0]\n  >\n> {\n  initClassifier: InitClassifierType;\n  json: ICrossValidateJSON<\n    ReturnType<ReturnType<InitClassifierType>['toJSON']>\n  > = {\n    avgs: {\n      error: 0,\n      iterations: 0,\n      testTime: 0,\n      trainTime: 0,\n    },\n    stats: {\n      total: 0,\n      testSize: 0,\n      trainSize: 0,\n    },\n    sets: [],\n  };\n\n  constructor(initClassifier: InitClassifierType) {\n    this.initClassifier = initClassifier;\n  }\n\n  testPartition(\n    trainOpts: Parameters<ReturnType<InitClassifierType>['train']>[1],\n    trainSet: Parameters<ReturnType<InitClassifierType>['train']>[0],\n    testSet: Parameters<ReturnType<InitClassifierType>['train']>[0]\n  ):\n    | ICrossValidationTestPartitionResults<\n        ReturnType<ReturnType<InitClassifierType>['toJSON']>\n      >\n    | ICrossValidationTestPartitionBinaryResults<\n        ReturnType<ReturnType<InitClassifierType>['toJSON']>\n      > {\n    const classifier = this.initClassifier();\n    const beginTrain = Date.now();\n    const trainingStats = classifier.train(trainSet, trainOpts);\n    const beginTest = Date.now();\n    const testStats:\n      | INeuralNetworkTestResult\n      | INeuralNetworkBinaryTestResult = classifier.test(testSet);\n    const endTest = Date.now();\n    return {\n      ...testStats,\n      trainTime: beginTest - beginTrain,\n      testTime: endTest - beginTest,\n      iterations: trainingStats.iterations,\n      error: trainingStats.error,\n      total: testStats.total,\n      network: (classifier as {\n        toJSON: () => ReturnType<ReturnType<InitClassifierType>['toJSON']>;\n      }).toJSON(),\n    };\n  }\n\n  /**\n   * Randomize array element order in-place.\n   * Using Durstenfeld shuffle algorithm.\n   * source: http://stackoverflow.com/a/12646864/1324039\n   */\n  shuffleArray<K>(array: K[]): K[] {\n    for (let i = array.length - 1; i > 0; i--) {\n      const j = Math.floor(Math.random() * (i + 1));\n      const temp = array[i];\n      array[i] = array[j];\n      array[j] = temp;\n    }\n    return array;\n  }\n\n  static isBinaryStats = (\n    stats: ICrossValidateStatsResultStats | ICrossValidateStatsResultBinaryStats\n  ): stats is ICrossValidateStatsResultBinaryStats => {\n    return (\n      (stats as ICrossValidateStatsResultBinaryStats).accuracy !== undefined\n    );\n  };\n\n  static isBinaryResults = <JsonType>(\n    stats: ICrossValidateStats<JsonType> | ICrossValidateBinaryStats<JsonType>\n  ): stats is ICrossValidateBinaryStats<JsonType> =>\n    (stats as ICrossValidateBinaryStats<JsonType>).stats.accuracy !== undefined;\n\n  static isBinaryPartitionResults = <JsonType>(\n    stats:\n      | ICrossValidationTestPartitionResults<JsonType>\n      | ICrossValidationTestPartitionBinaryResults<JsonType>\n  ): stats is ICrossValidationTestPartitionBinaryResults<JsonType> =>\n    (stats as ICrossValidationTestPartitionBinaryResults<JsonType>).accuracy !==\n    undefined;\n\n  train(\n    data: Array<Parameters<ReturnType<InitClassifierType>['train']>[0][0]>,\n    trainOpts: Partial<\n      Parameters<ReturnType<InitClassifierType>['train']>[1]\n    > = {},\n    k = 4\n  ): ICrossValidateStats<ReturnType<InitClassifierType>['toJSON']> {\n    if (data.length < k) {\n      throw new Error(\n        `Training set size is too small for ${data.length} k folds of ${k}`\n      );\n    }\n    this.shuffleArray<unknown>(data);\n    const size = data.length / k;\n\n    const avgs: ICrossValidateStatsAverages = {\n      trainTime: 0,\n      testTime: 0,\n      iterations: 0,\n      error: 0,\n    };\n\n    const stats:\n      | ICrossValidateStatsResultStats\n      | ICrossValidateStatsResultBinaryStats = {\n      total: 0,\n      testSize: 0,\n      trainSize: 0,\n    };\n\n    const binaryStats: ICrossValidateStatsResultBinaryStats = {\n      total: 0,\n      testSize: 0,\n      trainSize: 0,\n      truePos: 0,\n      trueNeg: 0,\n      falsePos: 0,\n      falseNeg: 0,\n      precision: 0,\n      recall: 0,\n      accuracy: 0,\n    };\n\n    const results = [];\n    let isBinary = null;\n\n    for (let i = 0; i < k; i++) {\n      const dclone = data.slice(0);\n      const testSet = dclone.splice(i * size, size);\n      const trainSet = dclone;\n      const result = this.testPartition(trainOpts, trainSet, testSet);\n\n      if (isBinary === null) {\n        isBinary =\n          result.hasOwnProperty('falseNeg') &&\n          result.hasOwnProperty('falsePos') &&\n          result.hasOwnProperty('trueNeg') &&\n          result.hasOwnProperty('truePos');\n        if (isBinary) {\n          Object.assign(stats, binaryStats);\n        }\n      }\n\n      avgs.iterations += result.iterations;\n      avgs.testTime += result.testTime;\n      avgs.trainTime += result.trainTime;\n      avgs.error += result.error;\n      stats.total += result.total;\n      if (\n        CrossValidate.isBinaryStats(stats) &&\n        CrossValidate.isBinaryPartitionResults(result)\n      ) {\n        stats.accuracy += result.accuracy;\n        stats.falseNeg += result.falseNeg;\n        stats.falsePos += result.falsePos;\n        stats.precision += result.precision;\n        stats.recall += result.recall;\n        stats.trueNeg += result.trueNeg;\n        stats.truePos += result.truePos;\n      }\n\n      results.push(result);\n    }\n    avgs.error /= k;\n    avgs.iterations /= k;\n    avgs.testTime /= k;\n    avgs.trainTime /= k;\n\n    if (CrossValidate.isBinaryStats(stats)) {\n      stats.precision = stats.truePos / (stats.truePos + stats.falsePos);\n      stats.recall = stats.truePos / (stats.truePos + stats.falseNeg);\n      stats.accuracy = (stats.trueNeg + stats.truePos) / stats.total;\n    }\n\n    stats.testSize = size;\n    stats.trainSize = data.length - size;\n\n    this.json = {\n      avgs: avgs,\n      stats: stats,\n      sets: results,\n    };\n    return this.json;\n  }\n\n  toNeuralNetwork(): ReturnType<InitClassifierType> {\n    return this.fromJSON(this.json);\n  }\n\n  toJSON(): ICrossValidateJSON<\n    ReturnType<ReturnType<InitClassifierType>['toJSON']>\n  > | null {\n    return this.json;\n  }\n\n  fromJSON(\n    crossValidateJson: ICrossValidateJSON<\n      ReturnType<ReturnType<InitClassifierType>['toJSON']>\n    >\n  ): ReturnType<InitClassifierType> {\n    const winningJSON:\n      | ICrossValidationTestPartitionResults<\n          ReturnType<ReturnType<InitClassifierType>['toJSON']>\n        >\n      | ICrossValidationTestPartitionBinaryResults<\n          ReturnType<ReturnType<InitClassifierType>['toJSON']>\n        > = (crossValidateJson as ICrossValidateStats<\n      ReturnType<ReturnType<InitClassifierType>['toJSON']>\n    >).sets.reduce((prev, cur) => (prev.error < cur.error ? prev : cur));\n    return (this.initClassifier() as ReturnType<InitClassifierType>).fromJSON(\n      winningJSON.network\n    );\n  }\n}\n","import {\n  GPU,\n  IConstantsThis,\n  IGPUKernelSettings,\n  IKernelMapRunShortcut,\n  IKernelRunShortcut,\n  Input,\n  ISubKernelObject,\n  KernelFunction,\n  KernelOutput,\n  OutputDimensions,\n  Texture,\n  ThreadFunction,\n  ThreadKernelVariable,\n} from 'gpu.js';\n\nlet gpuInstance: GPU | null = null;\n\n/**\n * Sets up the gpu.js instance\n */\nexport function setup(value: GPU): void {\n  gpuInstance = value;\n}\n\n/**\n * Destroys any existing gpu.js instance\n */\nexport function teardown(): void {\n  if (gpuInstance !== null) {\n    gpuInstance.destroy().catch(console.log);\n  }\n  gpuInstance = null;\n}\n\nexport function makeKernel<\n  ArgTypes extends ThreadKernelVariable[] = ThreadKernelVariable[],\n  ConstantsTypes extends IConstantsThis = IConstantsThis\n>(\n  fn: KernelFunction<ArgTypes, ConstantsTypes>,\n  settings: IGPUKernelSettings\n): IKernelRunShortcut {\n  let _gpuInstance: GPU = gpuInstance as GPU;\n  if (_gpuInstance === null) {\n    _gpuInstance = new GPU({ mode: 'gpu' });\n    setup(_gpuInstance);\n  }\n\n  return _gpuInstance\n    .createKernel<ArgTypes, ConstantsTypes>(fn, settings)\n    .setPipeline(true);\n}\n\nexport function makeKernelMap<\n  ArgTypes extends ThreadKernelVariable[],\n  ConstantsTypes extends IConstantsThis\n>(\n  map: ISubKernelObject,\n  fn: ThreadFunction<ArgTypes, ConstantsTypes>,\n  settings: IGPUKernelSettings\n): IKernelMapRunShortcut<ISubKernelObject> {\n  let _gpuInstance: GPU = gpuInstance as GPU;\n  if (_gpuInstance === null) {\n    _gpuInstance = new GPU({ mode: 'gpu' });\n    setup(_gpuInstance);\n  }\n\n  return _gpuInstance\n    .createKernelMap<ArgTypes, ConstantsTypes>(map, fn, settings)\n    .setPipeline(true);\n}\n\n/**\n * Compiles a function into a gpu.js dev mode kernel\n */\n// export function makeDevKernel(\n//   fn: ThreadFunction,\n//   settings: makeKernelSettings\n// ): IKernelRunShortcut {\n//   if ('map' in settings) {\n//     throw new Error('map kernels are not supported by dev kernels');\n//   }\n//   const gpu = new GPU({ mode: 'dev' });\n//   return gpu.createKernel(fn, settings);\n// }\n\nexport function kernelInput(value: number[], size: OutputDimensions): Input {\n  return new Input(value, size);\n}\n\n/**\n * Deletes a gpu.js texture and frees VRAM\n */\nexport function release(possibleTexture: KernelOutput | Input): void {\n  if (possibleTexture instanceof Texture) {\n    possibleTexture.delete();\n  }\n}\n\n/**\n * Cleans ie sets all elements to 0 of a Texture or a js array\n */\nexport function clear(value: KernelOutput): void {\n  if (value instanceof Texture) {\n    value.clear();\n    return;\n  }\n\n  // array\n  if (Array.isArray(value)) {\n    if (typeof value[0] === 'number') {\n      (value as number[]).fill(0);\n    } else if (typeof value[0][0] === 'number') {\n      for (let x = 0; x < value.length; x++) {\n        (value[x] as number[]).fill(0);\n      }\n      return;\n    } else if (typeof value[0][0][0] === 'number') {\n      // cube\n      for (let y = 0; y < value.length; y++) {\n        const row: number[][] = value[y] as number[][];\n        for (let x = 0; x < row.length; x++) {\n          row[x].fill(0);\n        }\n      }\n      return;\n    }\n  }\n  throw new Error('unhandled value');\n}\n\n/**\n * Clones a value\n */\nexport function clone(value: KernelOutput): KernelOutput {\n  if (value instanceof Texture) {\n    return value.clone();\n  }\n  if (value instanceof Float32Array) {\n    return value.slice(0);\n  }\n  if (Array.isArray(value)) {\n    if (typeof value[0] === 'number') {\n      return value.slice(0);\n    } else if (typeof value[0][0] === 'number') {\n      const matrix = new Array(value.length);\n      for (let x = 0; x < value.length; x++) {\n        matrix[x] = (value[x] as Float32Array).slice(0);\n      }\n      return matrix;\n    } else if (typeof value[0][0][0] === 'number') {\n      const cube = new Array(value.length);\n      for (let y = 0; y < value.length; y++) {\n        const row = value[y] as number[][];\n        const matrix = new Array(row.length);\n        for (let x = 0; x < row.length; x++) {\n          matrix[x] = row[x].slice(0);\n        }\n      }\n      return cube;\n    }\n  }\n  throw new Error('unhandled value');\n}\n","import { IKernelRunShortcut, IKernelFunctionThis } from 'gpu.js';\nimport { makeKernel } from '../utilities/kernel';\n\ninterface mse2dThis extends IKernelFunctionThis {\n  constants: { height: number; width: number; length: number };\n}\n\n/**\n * 2D Mean Squared Error\n */\nexport function mse2d(\n  this: mse2dThis,\n  errors: Array<[number, number]>\n): number {\n  let sum = 0;\n  for (let y = 0; y < this.constants.height; y++) {\n    for (let x = 0; x < this.constants.width; x++) {\n      sum += errors[y][x] ** 2;\n    }\n  }\n  return sum / this.constants.length;\n}\n\nexport class MeanSquaredError {\n  /** Calculate the mean squared error given an array of errors */\n  calculate: IKernelRunShortcut;\n  /** Returns the sum of absolute values of previuous error and previous layer errors */\n  addAbsolute: IKernelRunShortcut;\n  /** Adds two erros */\n  add: IKernelRunShortcut;\n  /** Returns the ratio of sum of errors and length (ie the average) */\n  divide: IKernelRunShortcut;\n\n  constructor({ width, height }: { width: number; height: number }) {\n    this.calculate = makeKernel(mse2d, {\n      output: [1],\n      constants: {\n        width,\n        height,\n        length: width * height,\n      },\n      immutable: true,\n    });\n\n    this.addAbsolute = makeKernel(\n      function (prevError: number[], prevLayerErrors: number[][]) {\n        return prevError[0] + Math.abs(prevLayerErrors[0][0]);\n      },\n      {\n        output: [1],\n        immutable: true,\n      }\n    );\n\n    this.add = makeKernel(\n      function (value1: number[], value2: number[]) {\n        return value1[0] + value2[0];\n      },\n      {\n        output: [1],\n        immutable: true,\n      }\n    );\n\n    this.divide = makeKernel(\n      function (length: number, mseSum: number[]) {\n        const value = mseSum[0];\n        if (value > 0) {\n          return value / length;\n        }\n        return 0;\n      },\n      {\n        output: [1],\n        immutable: true,\n      }\n    );\n  }\n}\n","import {\n  IKernelRunShortcut,\n  Input,\n  Kernel,\n  KernelOutput,\n  Texture,\n  TextureArrayOutput,\n} from 'gpu.js';\nimport { IPraxis, IPraxisSettings } from '../praxis/base-praxis';\nimport { clear, release } from '../utilities/kernel';\n\nexport interface ILayerJSON {\n  width?: number;\n  height?: number;\n  depth?: number;\n  weights?: number[] | number[][] | number[][][] | null;\n  type: string;\n  inputLayerIndex?: number;\n  inputLayer1Index?: number;\n  inputLayer2Index?: number;\n  praxisOpts?: Partial<IPraxisSettings> | null;\n}\n\nexport interface ILayer {\n  width: number;\n  height: number;\n  depth: number;\n  weights: KernelOutput | Input;\n  deltas: KernelOutput;\n  praxis: IPraxis | null;\n  errors?: KernelOutput | null;\n  setupKernels: (training?: boolean) => void;\n  predictKernel: IKernelRunShortcut | null;\n  compareKernel: IKernelRunShortcut | null;\n  settings: Partial<ILayerSettings>;\n  reuseKernels: (layer: ILayer) => void;\n  predict: (inputs?: KernelOutput) => void;\n  compare: (targetValues?: KernelOutput) => void;\n  learn: ((learningRate?: number) => void) | ((learningRate: number) => void);\n  toJSON: () => Partial<ILayerJSON>;\n  inputLayer?: ILayer;\n  inputLayer1?: ILayer;\n  inputLayer2?: ILayer;\n  index?: number;\n  id?: string;\n}\n\nexport interface ILayerSettings {\n  width?: number | null;\n  height?: number | null;\n  depth?: number | null;\n  weights?: KernelOutput | null;\n  deltas?: KernelOutput | null;\n  id?: string;\n  praxis?: IPraxis | null;\n  praxisOpts?: Partial<IPraxisSettings> | null;\n  initPraxis?:\n    | ((layerTemplate: ILayer, settings?: IPraxisSettings) => IPraxis)\n    | null;\n}\n\nexport const baseLayerDefaultSettings: ILayerSettings = {\n  width: 1,\n  height: 1,\n  depth: null,\n  weights: null,\n  deltas: null,\n  praxis: null,\n  praxisOpts: null,\n};\n\nexport type BaseLayerType = new (settings?: Partial<ILayerSettings>) => ILayer;\n\nexport class BaseLayer implements ILayer {\n  praxis: IPraxis | null = null;\n  predictKernel: IKernelRunShortcut | null = null;\n  compareKernel: IKernelRunShortcut | null = null;\n  settings: Partial<ILayerSettings>;\n\n  get width(): number {\n    return this.settings.width ?? 0;\n  }\n\n  get height(): number {\n    return this.settings.height ?? 0;\n  }\n\n  get depth(): number {\n    return this.settings.depth ?? 0;\n  }\n\n  get weights(): KernelOutput | Input {\n    return this.settings.weights as KernelOutput;\n  }\n\n  set weights(weights: KernelOutput | Input) {\n    this.settings.weights = weights as KernelOutput;\n  }\n\n  get deltas(): KernelOutput {\n    return this.settings.deltas as KernelOutput;\n  }\n\n  set deltas(deltas: KernelOutput) {\n    this.settings.deltas = deltas;\n  }\n\n  get id(): string {\n    return this.settings.id ?? '';\n  }\n\n  set id(title: string) {\n    this.settings.id = title;\n  }\n\n  constructor(settings?: Partial<ILayerSettings>) {\n    if (settings) {\n      this.settings = { ...baseLayerDefaultSettings, ...settings };\n    } else {\n      this.settings = { ...baseLayerDefaultSettings };\n    }\n    this.setupPraxis();\n  }\n\n  setupPraxis(): void {\n    const { initPraxis, praxis, praxisOpts } = this.settings;\n    if (!this.praxis) {\n      if (initPraxis) {\n        if (praxisOpts) {\n          this.praxis = initPraxis(this, praxisOpts);\n        } else {\n          this.praxis = initPraxis(this);\n        }\n      } else if (praxis) {\n        this.praxis = praxis;\n      }\n    }\n  }\n\n  /*\n  get weights() {\n    return this._weights;\n  }\n\n  set weights(value) {\n    if (value) {\n      if (value.dimensions) {\n        if (value.dimensions[0] !== this.width) {\n          throw new Error(`${this.constructor.name}.weights being set with improper value width`);\n        }\n        if (value.dimensions[1] !== this.height) {\n          throw new Error(`${this.constructor.name}.weights being set with improper value height`);\n        }\n      } else {\n        if (value[0].length !== this.width) {\n          throw new Error(`${this.constructor.name}.weights being set with improper value width`);\n        }\n        if (value.length !== this.height) {\n          throw new Error(`${this.constructor.name}.weights being set with improper value height`);\n        }\n      }\n    }\n    this._weights = value;\n  }\n\n  get deltas() {\n    return this._deltas;\n  }\n\n  set deltas(value) {\n    if (value) {\n      if (value.dimensions) {\n        if (value.dimensions[0] !== this.width) {\n          throw new Error(`${this.constructor.name}.deltas being set with improper value width`);\n        }\n        if (value.dimensions[1] !== this.height) {\n          throw new Error(`${this.constructor.name}.deltas being set with improper value height`);\n        }\n      } else {\n        if (value[0].length !== this.width) {\n          throw new Error(`${this.constructor.name}.deltas being set with improper value width`);\n        }\n        if (value.length !== this.height) {\n          throw new Error(`${this.constructor.name}.deltas being set with improper value height`);\n        }\n      }\n    }\n    this._deltas = value;\n  } */\n\n  validate(): void {\n    if (Number.isNaN(this.height)) {\n      throw new Error(`${this.constructor.name} layer height is not a number`);\n    }\n    if (Number.isNaN(this.width)) {\n      throw new Error(`${this.constructor.name} layer width is not a number`);\n    }\n    if (this.height < 1) {\n      throw new Error(`${this.constructor.name} layer height is less than 1`);\n    }\n    if (this.width < 1) {\n      throw new Error(`${this.constructor.name} layer width is less than 1`);\n    }\n  }\n\n  setupKernels(isTraining?: boolean): void {}\n\n  reuseKernels(layer: ILayer): void {\n    if (layer.width !== this.width) {\n      throw new Error(\n        `${this.constructor.name} kernel width mismatch ${layer.width} is not ${this.width}`\n      );\n    }\n    if (layer.height !== this.height) {\n      throw new Error(\n        `${this.constructor.name} kernel width mismatch ${layer.height} is not ${this.height}`\n      );\n    }\n    if (layer.hasOwnProperty('predictKernel') && layer.predictKernel !== null) {\n      if (!(layer.predictKernel as Kernel).immutable) {\n        throw new Error(\n          `${layer.constructor.name}.predictKernel is not reusable, set kernel.immutable = true`\n        );\n      }\n      this.predictKernel = layer.predictKernel;\n    }\n    if (layer.hasOwnProperty('compareKernel') && layer.compareKernel !== null) {\n      if (!(layer.compareKernel as Kernel).immutable) {\n        throw new Error(\n          `${layer.constructor.name}.compareKernel is not reusable, set kernel.immutable = true`\n        );\n      }\n      this.compareKernel = layer.compareKernel;\n    }\n    this.praxis = layer.praxis;\n  }\n\n  predict(inputs?: KernelOutput): void {}\n\n  compare(targetValues?: KernelOutput): void {}\n\n  learn(learningRate?: number): void {\n    // TODO: do we need to release here?\n    const { weights: oldWeights } = this;\n    if (!this.praxis) throw new Error('this.praxis not defined');\n    this.weights = this.praxis.run(this, learningRate as number);\n    release(oldWeights);\n    clear(this.deltas);\n  }\n\n  toArray(): TextureArrayOutput {\n    return Array.isArray(this.weights)\n      ? this.weights\n      : (this.weights as Texture).toArray();\n  }\n\n  toJSON(): Partial<ILayerJSON> {\n    return BaseLayer.toJSON(this);\n  }\n\n  static toJSON(layer: ILayer): Partial<ILayerJSON> {\n    const { weights } = layer;\n    return {\n      width: layer.width,\n      height: layer.height,\n      depth: layer.depth,\n      weights: toUntypedArray(\n        (weights && weights instanceof Texture\n          ? weights.toArray()\n          : weights) as\n          | Float32Array\n          | Float32Array[]\n          | Float32Array[][]\n          | number[]\n          | number[][]\n          | number[][][]\n          | null\n      ),\n      type: layer.constructor.name,\n      praxisOpts: layer.praxis ? layer.praxis.toJSON() : null,\n    };\n  }\n}\n\nfunction toUntypedArray(\n  weights:\n    | Float32Array\n    | Float32Array[]\n    | Float32Array[][]\n    | number[]\n    | number[][]\n    | number[][][]\n    | null\n): number[][][] | number[][] | number[] | null {\n  if (weights === null) return null;\n  if (Array.isArray(weights)) {\n    if (typeof weights[0] === 'number') {\n      return weights as number[];\n    } else if (Array.isArray(weights[0]) && typeof weights[0][0] === 'number') {\n      return weights as number[][];\n    } else if (\n      Array.isArray(weights[0][0]) &&\n      typeof weights[0][0][0] === 'number'\n    ) {\n      return weights as number[][][];\n    } else if (weights[0] instanceof Float32Array) {\n      const matrix = weights as Float32Array[];\n      return matrix.map((row: Float32Array) => {\n        return Array.from(row);\n      });\n    } else if (weights[0][0] instanceof Float32Array) {\n      const cube = weights as Float32Array[][];\n      return cube.map((matrix: Float32Array[]): number[][] => {\n        return matrix.map((row: Float32Array): number[] => {\n          return Array.from(row);\n        });\n      });\n    }\n  } else if (weights) {\n    return Array.from(weights);\n  }\n  throw new Error('unexpected value');\n}\n","/**\n * Returns an array of zeros\n */\nexport function zeros(size: number): Float32Array {\n  return new Float32Array(size);\n}\n","import { zeros } from './zeros';\n\n/**\n * Returns a 2D tensor(matrix) of zeros\n */\nexport function zeros2D(width: number, height: number): Float32Array[] {\n  const result: Float32Array[] = new Array(height);\n  for (let y = 0; y < height; y++) {\n    result[y] = zeros(width);\n  }\n  return result;\n}\n","import { zeros2D } from './zeros-2d';\n\n/**\n * Returns a 3D tensor of arrays\n */\nexport function zeros3D(\n  width: number,\n  height: number,\n  depth: number\n): Float32Array[][] {\n  const result: Float32Array[][] = new Array(depth);\n  for (let z = 0; z < depth; z++) {\n    result[z] = zeros2D(width, height);\n  }\n  return result;\n}\n","import { BaseLayer, ILayerSettings, ILayer } from './base-layer';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { zeros3D } from '../utilities/zeros-3d';\n\nexport type ActivationType = new (\n  inputLayer: ILayer,\n  settings: Partial<ILayerSettings>\n) => ILayer;\n\nexport class Activation extends BaseLayer {\n  inputLayer: ILayer;\n\n  get width(): number {\n    return this.inputLayer.width;\n  }\n\n  get height(): number {\n    return this.inputLayer.height;\n  }\n\n  get depth(): number {\n    return this.inputLayer.depth;\n  }\n\n  constructor(inputLayer: ILayer, settings?: Partial<ILayerSettings>) {\n    super(settings);\n    this.inputLayer = inputLayer;\n    const { width, height, depth } = this;\n    this.predictKernel = null;\n    this.compareKernel = null;\n    this.validate();\n    if (depth > 0) {\n      this.weights = zeros3D(width, height, depth);\n      this.deltas = zeros3D(width, height, depth);\n    } else if (height > 0) {\n      this.weights = zeros2D(width, height);\n      this.deltas = zeros2D(width, height);\n    }\n    this.setupPraxis();\n  }\n}\n","import { KernelOutput } from 'gpu.js';\nimport { BaseLayer, ILayer, ILayerSettings } from './base-layer';\n\nexport interface IFilterSettings extends ILayerSettings {\n  filterCount: number;\n  filterWidth: number;\n  filterHeight: number;\n  filters?: KernelOutput;\n  filterDeltas?: KernelOutput;\n}\n\nexport type FilterType = new (\n  settings: Partial<IFilterSettings>,\n  inputLayer: ILayer\n) => ILayer;\n\nexport class Filter extends BaseLayer {\n  get width(): number {\n    return this.inputLayer.width;\n  }\n\n  get height(): number {\n    return this.inputLayer.height;\n  }\n\n  get depth(): number {\n    return this.inputLayer.depth;\n  }\n\n  get filterCount(): number {\n    return this.settings.filterCount as number;\n  }\n\n  get filterWidth(): number {\n    return this.settings.filterWidth as number;\n  }\n\n  get filterHeight(): number {\n    return this.settings.filterHeight as number;\n  }\n\n  get filters(): KernelOutput {\n    return this.settings.filters;\n  }\n\n  set filters(filters: KernelOutput) {\n    this.settings.filters = filters;\n  }\n\n  get filterDeltas(): KernelOutput {\n    return this.settings.filterDeltas;\n  }\n\n  set filterDeltas(filterDeltas: KernelOutput) {\n    this.settings.filterDeltas = filterDeltas;\n  }\n\n  settings: Partial<IFilterSettings>;\n  inputLayer: ILayer;\n  constructor(settings: Partial<IFilterSettings>, inputLayer: ILayer) {\n    super();\n    this.settings = settings;\n    this.inputLayer = inputLayer;\n  }\n}\n","import { BaseLayer, ILayer, ILayerJSON, ILayerSettings } from './base-layer';\nimport { IKernelRunShortcut, Input, KernelOutput } from 'gpu.js';\nimport { IPraxis } from '../praxis/base-praxis';\n\nexport type InternalType = new (settings: Partial<ILayerSettings>) => ILayer;\n\nexport abstract class Internal implements ILayer {\n  abstract settings: ILayerSettings;\n  abstract predict(inputs?: KernelOutput): void;\n  abstract compare(targetValues?: KernelOutput): void;\n  abstract learn(learningRate?: number): void;\n  abstract setupKernels(training?: boolean): void;\n  predictKernel: IKernelRunShortcut | null = null;\n  compareKernel: IKernelRunShortcut | null = null;\n  praxis: IPraxis | null = null;\n\n  get width(): number {\n    return this.settings.width as number;\n  }\n\n  get height(): number {\n    return this.settings.height as number;\n  }\n\n  get depth(): number {\n    return this.settings.depth as number;\n  }\n\n  get weights(): KernelOutput | Input {\n    return this.settings.weights as KernelOutput;\n  }\n\n  set weights(weights: KernelOutput | Input) {\n    this.settings.weights = weights as KernelOutput;\n  }\n\n  get deltas(): KernelOutput {\n    return this.settings.deltas as KernelOutput;\n  }\n\n  set deltas(deltas: KernelOutput) {\n    this.settings.deltas = deltas;\n  }\n\n  toJSON(): Partial<ILayerJSON> {\n    return BaseLayer.toJSON(this);\n  }\n\n  abstract reuseKernels(layer: ILayer): void;\n}\n","import { BaseLayer, ILayer, ILayerSettings } from './base-layer';\n\nexport type ModifierType = new (\n  inputLayer: ILayer,\n  settings?: Partial<ILayerSettings>\n) => ILayer;\n\nexport class Modifier extends BaseLayer {\n  inputLayer: ILayer;\n  constructor(inputLayer: ILayer, settings?: Partial<ILayerSettings>) {\n    super({\n      ...settings,\n      width: inputLayer.width,\n      height: inputLayer.height,\n      depth: inputLayer.depth,\n    });\n    this.inputLayer = inputLayer;\n  }\n\n  validate(): void {\n    super.validate();\n\n    if (this.width !== this.inputLayer.width) {\n      throw new Error(\n        `width of ${this.width} does not match inputLayer.width of ${this.inputLayer.width}`\n      );\n    }\n\n    if (this.height !== this.inputLayer.height) {\n      throw new Error(\n        `height of ${this.height} does not match inputLayer.height of ${this.inputLayer.height}`\n      );\n    }\n\n    if (this.depth !== (this.inputLayer.depth ?? 0)) {\n      throw new Error(\n        `depth of ${this.depth} does not match inputLayer.depth of ${this.inputLayer.depth}`\n      );\n    }\n  }\n}\n","import { BaseLayer, ILayerSettings, ILayer } from './base-layer';\nimport { zeros2D } from '../utilities/zeros-2d';\n\nexport type OperatorType = new (\n  inputLayer1: ILayer,\n  inputLayer2: ILayer,\n  settings?: Partial<ILayerSettings>\n) => ILayer;\n\nexport abstract class Operator extends BaseLayer {\n  inputLayer1: ILayer;\n  inputLayer2: ILayer;\n  constructor(\n    inputLayer1: ILayer,\n    inputLayer2: ILayer,\n    settings?: Partial<ILayerSettings>\n  ) {\n    super(settings);\n    this.inputLayer1 = inputLayer1;\n    this.inputLayer2 = inputLayer2;\n    this.validate();\n    this.weights = zeros2D(this.width, this.height);\n    this.deltas = zeros2D(this.width, this.height);\n    this.setupPraxis();\n  }\n}\n","import { IKernelFunctionThis, IKernelRunShortcut, KernelOutput } from 'gpu.js';\n\nimport { makeKernel, release, clone, clear } from '../utilities/kernel';\nimport { zeros } from '../utilities/zeros';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { BaseLayer, ILayer, ILayerSettings } from './base-layer';\n\nexport function compare1D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  targetValues: number[]\n): number {\n  return weights[this.thread.y][this.thread.x] - targetValues[this.thread.x];\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  targetValues: number[][]\n): number {\n  return (\n    weights[this.thread.y][this.thread.x] -\n    targetValues[this.thread.y][this.thread.x]\n  );\n}\n\nexport type TargetType = new (\n  settings: Partial<ILayerSettings>,\n  inputLayer: ILayer\n) => ILayer;\n\nexport class Target extends BaseLayer {\n  errors: KernelOutput;\n  inputLayer: ILayer;\n  constructor(settings: Partial<ILayerSettings>, inputLayer: ILayer) {\n    super(settings);\n    this.inputLayer = inputLayer;\n    this.validate();\n    if (this.depth) {\n      throw new Error('Target layer not implemented for depth');\n    } else if (this.height) {\n      this.weights = zeros2D(this.width, this.height);\n      this.deltas = zeros2D(this.width, this.height);\n      this.errors = zeros2D(this.width, this.height);\n    } else {\n      this.weights = zeros(this.width);\n      this.deltas = zeros(this.width);\n      this.errors = zeros(this.width);\n    }\n  }\n\n  setupKernels(): void {\n    if (this.width === 1) {\n      this.compareKernel = makeKernel(compare1D, {\n        output: [this.width, this.height],\n        immutable: true,\n      });\n    } else {\n      this.compareKernel = makeKernel(compare2D, {\n        output: [this.width, this.height],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    // TODO: should we clone here?\n    // NOTE: this looks like it shouldn't be, but the weights are immutable, and this is where they are reused.\n    release(this.weights);\n    this.weights = clone(this.inputLayer.weights as KernelOutput);\n    clear(this.deltas);\n  }\n\n  compare(targetValues: KernelOutput): void {\n    // this is where weights attach to deltas\n    // deltas will be zero on learn, so save it in error for comparing to mse later\n    release(this.deltas);\n    release(this.errors);\n    release(this.inputLayer.deltas);\n    this.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.weights,\n      targetValues\n    );\n    this.inputLayer.deltas = clone(this.deltas);\n    this.errors = clone(this.deltas);\n  }\n\n  setupPraxis(): void {}\n}\n\nexport function target(settings: ILayerSettings, inputLayer: ILayer): Target {\n  return new Target(settings, inputLayer);\n}\n","import { BaseLayer, ILayer, ILayerSettings } from './base-layer';\n\nexport { Activation } from './activation';\nexport { Filter } from './filter';\nexport { Internal } from './internal';\nexport { Modifier } from './modifier';\nexport { Operator } from './operator';\nexport { Target } from './target';\n\n// eslint-disable-next-line @typescript-eslint/no-extraneous-class\nexport class InternalModel {}\n\nexport type EntryPointType = new (settings: Partial<ILayerSettings>) => ILayer;\n// eslint-disable-next-line @typescript-eslint/no-extraneous-class\nexport class EntryPoint extends BaseLayer {}\n\n// eslint-disable-next-line @typescript-eslint/no-extraneous-class\nexport class Model extends BaseLayer {}\n","import { KernelOutput } from 'gpu.js';\n\nexport interface INumberHash {\n  [character: string]: number;\n}\n\nexport interface INumberArray {\n  length: number;\n  buffer?: ArrayBuffer;\n  [index: number]: number;\n}\n\nexport type InputOutputValue = INumberArray | Partial<INumberHash>;\n\nexport interface ITrainingDatum {\n  input: InputOutputValue | InputOutputValue[] | KernelOutput;\n  output: InputOutputValue | InputOutputValue[] | KernelOutput;\n}\n\nexport type FormattableData =\n  | number\n  | ITrainingDatum\n  | InputOutputValue\n  | InputOutputValue[];\n\n/* Functions for turning sparse hashes into arrays and vice versa */\nexport const lookup = {\n  /**\n   * Performs `[{a: 1}, {b: 6, c: 7}] -> {a: 0, b: 1, c: 2}`\n   * @param {Object} hashes\n   * @returns {Object}\n   */\n  toTable(hashes: INumberHash[]): INumberHash {\n    const hash = hashes.reduce((memo, hash) => {\n      return Object.assign(memo, hash);\n    }, {});\n\n    return lookup.toHash(hash);\n  },\n\n  /**\n   * Performs `[{a: 1}, {b: 6, c: 7}] -> {a: 0, b: 1, c: 2}`\n   */\n  toTable2D(objects2D: INumberHash[][]): INumberHash {\n    const table: INumberHash = {};\n    let valueIndex = 0;\n    for (let i = 0; i < objects2D.length; i++) {\n      const objects = objects2D[i];\n      for (let j = 0; j < objects.length; j++) {\n        const object = objects[j];\n        for (const p in object) {\n          if (object.hasOwnProperty(p) && !table.hasOwnProperty(p)) {\n            table[p] = valueIndex++;\n          }\n        }\n      }\n    }\n    return table;\n  },\n\n  toInputTable2D(\n    data: Array<{ input: Array<{ [key: string]: number }> }>\n  ): INumberHash {\n    const table: INumberHash = {};\n    let tableIndex = 0;\n    for (let dataIndex = 0; dataIndex < data.length; dataIndex++) {\n      const input = data[dataIndex].input;\n      for (let i = 0; i < input.length; i++) {\n        const object = input[i];\n        for (const p in object) {\n          if (!object.hasOwnProperty(p)) continue;\n          if (!table.hasOwnProperty(p)) {\n            table[p] = tableIndex++;\n          }\n        }\n      }\n    }\n    return table;\n  },\n\n  toOutputTable2D(\n    data: Array<{ output: Array<{ [key: string]: number }> }>\n  ): INumberHash {\n    const table: INumberHash = {};\n    let tableIndex = 0;\n    for (let dataIndex = 0; dataIndex < data.length; dataIndex++) {\n      const output = data[dataIndex].output;\n      for (let i = 0; i < output.length; i++) {\n        const object = output[i];\n        for (const p in object) {\n          if (!object.hasOwnProperty(p)) continue;\n          if (!table.hasOwnProperty(p)) {\n            table[p] = tableIndex++;\n          }\n        }\n      }\n    }\n    return table;\n  },\n\n  /**\n   * performs `{a: 6, b: 7} -> {a: 0, b: 1}`\n   */\n  toHash(hash: INumberHash): INumberHash {\n    const lookup: INumberHash = {};\n    let index = 0;\n    const keys = Object.keys(hash);\n    for (let i = 0; i < keys.length; i++) {\n      lookup[keys[i]] = index++;\n    }\n    return lookup;\n  },\n\n  /**\n   * performs `{a: 0, b: 1}, {a: 6} -> [6, 0]`\n   */\n  toArray(\n    lookup: INumberHash,\n    object: INumberHash,\n    arrayLength: number\n  ): Float32Array {\n    const result = new Float32Array(arrayLength);\n    for (const p in lookup) {\n      if (!lookup.hasOwnProperty(p)) continue;\n      result[lookup[p]] = object.hasOwnProperty(p) ? object[p] : 0;\n    }\n    return result;\n  },\n\n  toArrayShort(lookup: INumberHash, object: INumberHash): Float32Array {\n    const result = [];\n    for (const p in lookup) {\n      if (!lookup.hasOwnProperty(p)) continue;\n      if (!object.hasOwnProperty(p)) break;\n      result[lookup[p]] = object[p];\n    }\n    return Float32Array.from(result);\n  },\n\n  toArrays(\n    lookup: INumberHash,\n    objects: INumberHash[],\n    arrayLength: number\n  ): Float32Array[] {\n    const result = [];\n    for (let i = 0; i < objects.length; i++) {\n      result.push(this.toArray(lookup, objects[i], arrayLength));\n    }\n    return result;\n  },\n\n  /**\n   * performs `{a: 0, b: 1}, [6, 7] -> {a: 6, b: 7}`\n   * @param {Object} lookup\n   * @param {Array} array\n   * @returns {Object}\n   */\n  toObject(lookup: INumberHash, array: number[] | Float32Array): INumberHash {\n    const object: INumberHash = {};\n    for (const p in lookup) {\n      if (!lookup.hasOwnProperty(p)) continue;\n      object[p] = array[lookup[p]];\n    }\n    return object;\n  },\n\n  toObjectPartial(\n    lookup: INumberHash,\n    array: number[] | Float32Array,\n    offset = 0,\n    limit = 0\n  ): INumberHash {\n    const object: INumberHash = {};\n    let i = 0;\n    for (const p in lookup) {\n      if (!lookup.hasOwnProperty(p)) continue;\n      if (offset > 0) {\n        if (i++ < offset) continue;\n      }\n      if (limit > 0) {\n        if (i++ >= limit) continue;\n      }\n      object[p] = array[lookup[p] - offset];\n    }\n    return object;\n  },\n\n  dataShape(data: FormattableData[] | FormattableData): string[] {\n    const shape = [];\n    let lastData;\n    if (data.hasOwnProperty('input')) {\n      shape.push('datum');\n      lastData = (data as ITrainingDatum).input;\n    } else if (Array.isArray(data)) {\n      if (\n        (data as ITrainingDatum[])[0] &&\n        (data as ITrainingDatum[])[0].input\n      ) {\n        shape.push('array', 'datum');\n        lastData = (data as ITrainingDatum[])[0].input;\n      } else if (Array.isArray(data[0])) {\n        shape.push('array');\n        lastData = data[0];\n      } else {\n        lastData = data as\n          | InputOutputValue\n          | InputOutputValue[]\n          | InputOutputValue[][];\n      }\n    } else {\n      lastData = data as\n        | InputOutputValue\n        | InputOutputValue[]\n        | InputOutputValue[][];\n    }\n\n    let p;\n    while (lastData) {\n      p = Object.keys(lastData)[0];\n      if (\n        Array.isArray(lastData) ||\n        typeof (lastData as Float32Array).buffer === 'object'\n      ) {\n        shape.push('array');\n        const possibleNumber:\n          | number\n          | INumberArray = (lastData as INumberArray[])[parseInt(p)];\n        if (typeof possibleNumber === 'number') {\n          shape.push('number');\n          break;\n        } else {\n          lastData = possibleNumber;\n        }\n      } else if (\n        typeof lastData === 'object' &&\n        typeof (lastData as Float32Array).buffer !== 'object'\n      ) {\n        shape.push('object');\n        const possibleNumber: number | INumberHash = (lastData as INumberHash)[\n          p\n        ];\n        if (typeof possibleNumber === 'number') {\n          shape.push('number');\n          break;\n        } else {\n          lastData = possibleNumber;\n        }\n      } else {\n        throw new Error('unhandled signature');\n      }\n    }\n    return shape;\n  },\n\n  addKeys(value: number[] | INumberHash, table: INumberHash): INumberHash {\n    if (Array.isArray(value)) return table;\n    let i = Object.keys(table).length;\n    for (const p in value) {\n      if (!value.hasOwnProperty(p)) continue;\n      if (table.hasOwnProperty(p)) continue;\n      table[p] = i++;\n    }\n    return table;\n  },\n};\n","import { ILayer } from '../layer';\nimport { IKernelRunShortcut, KernelOutput } from 'gpu.js';\n\nexport interface ILayerTemplate {\n  width: number;\n  height: number;\n  depth: number;\n}\n\nexport interface IPraxisJSON {\n  width: number;\n  height: number;\n  depth: number;\n}\n\nexport interface IPraxisSettings {\n  width?: number;\n  height?: number;\n  depth?: number;\n  kernel?: IKernelRunShortcut | null;\n}\n\nexport interface IPraxis {\n  layerTemplate: ILayerTemplate | null;\n  kernel: IKernelRunShortcut | null;\n  settings: Partial<IPraxisSettings>;\n  setupKernels: () => void;\n  width: number;\n  height: number;\n  depth: number;\n  run:\n    | ((layer: ILayer, learningRate: number) => KernelOutput)\n    | ((layer: ILayer, learningRate?: number) => KernelOutput);\n  toJSON: () => Partial<IPraxisSettings>;\n}\n\nexport abstract class BasePraxis implements IPraxis {\n  layerTemplate: ILayerTemplate;\n  kernel: IKernelRunShortcut | null;\n  settings: Partial<IPraxisSettings>;\n\n  get width(): number {\n    return this.layerTemplate.width;\n  }\n\n  get height(): number {\n    return this.layerTemplate.height;\n  }\n\n  get depth(): number {\n    return this.layerTemplate.depth;\n  }\n\n  constructor(\n    layerTemplate: ILayerTemplate,\n    settings: Partial<IPraxisSettings> = {}\n  ) {\n    this.layerTemplate = layerTemplate;\n    this.settings = { ...settings };\n    this.kernel = null;\n  }\n\n  setupKernels(): void {}\n\n  reuseKernels(praxis: IPraxis): void {\n    if (praxis.width !== this.width) {\n      throw new Error(\n        `${this.constructor.name} kernel width mismatch ${praxis.width} is not ${this.width}`\n      );\n    }\n    if (praxis.height !== this.height) {\n      throw new Error(\n        `${this.constructor.name} kernel width mismatch ${praxis.height} is not ${this.height}`\n      );\n    }\n    if (praxis.hasOwnProperty('kernel')) {\n      this.kernel = praxis.kernel;\n    }\n  }\n\n  abstract run(layer: ILayer, learningRate?: number): KernelOutput;\n\n  toJSON(): Partial<IPraxisSettings> {\n    return { ...this.settings };\n  }\n}\n","import { makeKernel } from '../utilities/kernel';\nimport { BasePraxis, IPraxisSettings } from './base-praxis';\nimport { ILayer } from '../layer/base-layer';\nimport { IKernelFunctionThis, IKernelRunShortcut, KernelOutput } from 'gpu.js';\n\nexport interface IUpdateThis extends IKernelFunctionThis {\n  constants: {\n    learningRate: number;\n  };\n}\n\nexport function update(\n  this: IUpdateThis,\n  weights: number[][],\n  deltas: number[][]\n): number {\n  return (\n    weights[this.thread.y][this.thread.x] +\n    this.constants.learningRate * deltas[this.thread.y][this.thread.x]\n  );\n}\n\nexport interface IArthurDeviationBiasesSettings extends IPraxisSettings {\n  learningRate?: number;\n}\n\nexport const defaultSettings = {\n  learningRate: 0.3,\n};\n\nexport class ArthurDeviationBiases extends BasePraxis {\n  settings: IArthurDeviationBiasesSettings;\n  kernel: IKernelRunShortcut | null;\n  constructor(layer: ILayer, settings?: IArthurDeviationBiasesSettings) {\n    super(layer);\n    this.settings = { ...defaultSettings, ...settings };\n    this.kernel = null;\n  }\n\n  run(layer: ILayer): KernelOutput {\n    return (this.kernel as IKernelRunShortcut)(layer.weights, layer.deltas);\n  }\n\n  setupKernels(): void {\n    this.kernel = makeKernel(update, {\n      output: [this.width, this.height],\n      constants: {\n        learningRate: this.settings.learningRate,\n      },\n    });\n  }\n}\n\nexport function arthurDeviationBiases(\n  layer: ILayer,\n  settings?: Partial<IArthurDeviationBiasesSettings>\n): ArthurDeviationBiases {\n  return new ArthurDeviationBiases(layer, settings);\n}\n","import { makeKernelMap } from '../utilities/kernel';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { BasePraxis, IPraxisSettings } from './base-praxis';\nimport { ILayer } from '../layer/base-layer';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelMapRunShortcut,\n  ISubKernelObject,\n  ISubKernelsResults,\n  KernelOutput,\n} from 'gpu.js';\n\nexport function updateChange(value: number): number {\n  return value;\n}\n\nexport interface IUpdateConstants extends IConstantsThis {\n  learningRate: number;\n  momentum: number;\n}\n\nexport function update(\n  this: IKernelFunctionThis<IUpdateConstants>,\n  changes: number[][],\n  weights: number[][],\n  incomingWeights: number[][],\n  inputDeltas: number[][]\n): number {\n  const lastChange: number = changes[this.thread.y][this.thread.x];\n  const inputDelta: number = inputDeltas[this.thread.y][0];\n  const weight: number = weights[this.thread.y][this.thread.x];\n  const incoming: number = incomingWeights[this.thread.x][0];\n\n  const change =\n    this.constants.learningRate * inputDelta * incoming +\n    this.constants.momentum * lastChange;\n  updateChange(change);\n  return weight + change;\n}\n\nexport interface IArthurDeviationWeightsSettings extends IPraxisSettings {\n  learningRate?: number;\n  momentum?: number;\n  weightsLayer?: ILayer | null;\n  incomingLayer?: ILayer | null;\n  deltaLayer?: ILayer | null;\n}\n\nexport interface IKernelMapResults extends ISubKernelsResults {\n  changes: KernelOutput;\n}\n\nexport const defaultSettings: IArthurDeviationWeightsSettings = {\n  learningRate: 0.3,\n  momentum: 0.1,\n  weightsLayer: null,\n  incomingLayer: null,\n  deltaLayer: null,\n};\n\nexport class ArthurDeviationWeights extends BasePraxis {\n  changes: KernelOutput;\n  kernelMap: IKernelMapRunShortcut<ISubKernelObject> | null = null;\n  settings: IArthurDeviationWeightsSettings;\n  get learningRate(): number {\n    return this.settings.learningRate as number;\n  }\n\n  get momentum(): number {\n    return this.settings.momentum as number;\n  }\n\n  get weightsLayer(): ILayer {\n    return this.settings.weightsLayer as ILayer;\n  }\n\n  set weightsLayer(layer: ILayer) {\n    this.settings.weightsLayer = layer;\n  }\n\n  get deltaLayer(): ILayer {\n    return this.settings.deltaLayer as ILayer;\n  }\n\n  set deltaLayer(layer: ILayer) {\n    this.settings.deltaLayer = layer;\n  }\n\n  get incomingLayer(): ILayer {\n    return this.settings.incomingLayer as ILayer;\n  }\n\n  set incomingLayer(layer: ILayer) {\n    this.settings.incomingLayer = layer;\n  }\n\n  constructor(layer: ILayer, settings?: IArthurDeviationWeightsSettings) {\n    super(layer);\n    this.settings = { ...defaultSettings, ...settings };\n    this.changes = zeros2D(layer.width, layer.height);\n  }\n\n  run(): KernelOutput {\n    const output = (this.kernelMap as IKernelMapRunShortcut<IKernelMapResults>)(\n      this.changes,\n      this.weightsLayer.weights,\n      this.incomingLayer.weights,\n      this.deltaLayer.deltas\n    );\n    this.changes = output.changes;\n    return output.result;\n  }\n\n  setupKernels(): void {\n    this.kernelMap = makeKernelMap<Parameters<typeof update>, IUpdateConstants>(\n      {\n        changes: updateChange,\n      },\n      update,\n      {\n        output: [this.width, this.height],\n        constants: {\n          learningRate: this.learningRate,\n          momentum: this.momentum,\n        },\n      }\n    );\n  }\n}\n\nexport function arthurDeviationWeights(\n  layer: ILayer,\n  settings?: Partial<IArthurDeviationWeightsSettings>\n): ArthurDeviationWeights {\n  return new ArthurDeviationWeights(layer, settings);\n}\n","import { BasePraxis, ILayerTemplate, IPraxisSettings } from './base-praxis';\n\nimport { makeKernelMap, release } from '../utilities/kernel';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelMapRunShortcut,\n  ISubKernelObject,\n  KernelOutput,\n} from 'gpu.js';\nimport { ILayer } from '../layer';\n\nexport function getMomentum(\n  delta: number,\n  decay: number,\n  previousMomentum: number\n): number {\n  return previousMomentum * decay + (1 - decay) * delta * delta;\n}\n\nexport function clipByValue(value: number, max: number, min: number): number {\n  if (value > max) {\n    return max;\n  }\n  if (value < min) {\n    return min;\n  }\n  return value;\n}\n\ninterface IUpdate extends IConstantsThis {\n  clipValue: number;\n  decayRate: number;\n  smoothEps: number;\n  regularizationStrength: number;\n}\n/**\n * @description Momentum Root Mean Square Propagation Function\n */\nexport function update(\n  this: IKernelFunctionThis<IUpdate>,\n  weights: number[][],\n  deltas: number[][],\n  previousMomenta: number[][]\n): number {\n  const delta = deltas[this.thread.y][this.thread.x];\n  const clippedDelta = clipByValue(\n    delta,\n    this.constants.clipValue,\n    -this.constants.clipValue\n  );\n  const weight = weights[this.thread.y][this.thread.x];\n  const previousMomentum = previousMomenta[this.thread.y][this.thread.x];\n  const momentum = getMomentum(\n    delta,\n    this.constants.decayRate,\n    previousMomentum\n  );\n  return (\n    weight +\n    (-this.constants.learningRate * clippedDelta) /\n      Math.sqrt(momentum + this.constants.smoothEps) -\n    this.constants.regularizationStrength * weight\n  );\n}\n\nexport function isClippedByValue(\n  value: number,\n  max: number,\n  min: number\n): number {\n  if (value > max) {\n    return 1;\n  }\n  if (value < min) {\n    return 1;\n  }\n  return 0;\n}\n\nexport interface IMomentumRootMeanSquaredPropagationSettings\n  extends IPraxisSettings {\n  decayRate?: number;\n  regularizationStrength?: number;\n  learningRate?: number;\n  smoothEps: number;\n  clipValue: number;\n}\n\nexport const defaults: IMomentumRootMeanSquaredPropagationSettings = {\n  decayRate: 0.999,\n  regularizationStrength: 0.0001,\n  learningRate: 0.01,\n  smoothEps: 1e-8,\n  clipValue: 5,\n};\n\nexport class MomentumRootMeanSquaredPropagation extends BasePraxis {\n  momenta: KernelOutput;\n  kernelMap: IKernelMapRunShortcut<ISubKernelObject> | null = null;\n  settings: Partial<IMomentumRootMeanSquaredPropagationSettings>;\n\n  get clipValue(): number {\n    return this.settings.clipValue as number;\n  }\n\n  get decayRate(): number {\n    return this.settings.decayRate as number;\n  }\n\n  get learningRate(): number {\n    return this.settings.learningRate as number;\n  }\n\n  get regularizationStrength(): number {\n    return this.settings.regularizationStrength as number;\n  }\n\n  get smoothEps(): number {\n    return this.settings.smoothEps as number;\n  }\n\n  constructor(\n    layerTemplate: ILayerTemplate,\n    settings: Partial<IMomentumRootMeanSquaredPropagationSettings> = {}\n  ) {\n    super(layerTemplate);\n    this.settings = { ...defaults, ...settings };\n    this.momenta = zeros2D(layerTemplate.width, layerTemplate.height);\n  }\n\n  run(layer: ILayer): KernelOutput {\n    const { momenta, result } = (this.kernelMap as IKernelMapRunShortcut<\n      ISubKernelObject\n    >)(layer.weights, layer.deltas, this.momenta);\n    release(this.momenta);\n    this.momenta = momenta;\n    return result;\n  }\n\n  setupKernels(): void {\n    this.kernelMap = makeKernelMap(\n      {\n        momenta: getMomentum,\n      },\n      update,\n      {\n        output: [this.width, this.height],\n        constants: {\n          clipValue: this.clipValue,\n          decayRate: this.decayRate,\n          learningRate: this.learningRate,\n          regularizationStrength: this.regularizationStrength,\n          smoothEps: this.smoothEps,\n        },\n        functions: [clipByValue],\n        immutable: true,\n      }\n    );\n  }\n}\n\nexport function momentumRootMeanSquaredPropagation(\n  layer: ILayer,\n  settings: Partial<IMomentumRootMeanSquaredPropagationSettings>\n): MomentumRootMeanSquaredPropagation {\n  return new MomentumRootMeanSquaredPropagation(layer, settings);\n}\n\n/**\n * @description Mathematician friendly name of MomentumRootMeanSquaredPropagation class. For those that are not mere mortals\n */\nexport const MRmsProp = MomentumRootMeanSquaredPropagation;\nexport const mRmsProp = momentumRootMeanSquaredPropagation;\n","import { ILayer } from '../layer/base-layer';\n\nexport function traverseLayersFrom(\n  layer: ILayer,\n  cb: (layer: ILayer) => void\n): void {\n  if (layer.hasOwnProperty('inputLayer')) {\n    traverseLayersFrom(\n      (layer as ILayer & { inputLayer: ILayer }).inputLayer,\n      cb\n    );\n  } else {\n    if (layer.hasOwnProperty('inputLayer1')) {\n      traverseLayersFrom(\n        (layer as ILayer & { inputLayer1: ILayer }).inputLayer1,\n        cb\n      );\n    }\n    if (layer.hasOwnProperty('inputLayer2')) {\n      traverseLayersFrom(\n        (layer as ILayer & { inputLayer2: ILayer }).inputLayer2,\n        cb\n      );\n    }\n  }\n  cb(layer);\n}\n","import { ILayer } from '../layer/base-layer';\nimport { traverseLayersFrom } from './traverse-layers-from';\n\nexport function flattenLayers(layers: ILayer[]): ILayer[] {\n  const result = layers.slice(0);\n  for (let i = 0; i < result.length; i++) {\n    let offset = 0;\n    traverseLayersFrom(result[i], (layer: ILayer) => {\n      if (!result.includes(layer)) {\n        result.splice(i + offset, 0, layer);\n        offset++;\n      }\n    });\n  }\n  return result;\n}\n","import { ILayer } from '../layer/base-layer';\n\nexport function checkSameSize(layer1: ILayer, layer2: ILayer): void {\n  if (layer1.width !== layer2.width) {\n    throw new Error(\n      `Layer width mismatch of ${layer1.width} and ${layer2.width}`\n    );\n  }\n\n  if (layer1.height !== layer2.height) {\n    throw new Error(\n      `Layer height mismatch of ${layer1.height} and ${layer2.height}`\n    );\n  }\n}\n","import { makeKernel, release, clone, clear } from '../utilities/kernel';\nimport { checkSameSize } from '../utilities/layer-size';\nimport { Operator } from './operator';\nimport { IKernelFunctionThis, IKernelRunShortcut, Texture } from 'gpu.js';\nimport { ILayerSettings, ILayer } from './base-layer';\n\nexport function predict(\n  this: IKernelFunctionThis,\n  inputWeights1: number[][],\n  inputWeights2: number[][]\n): number {\n  return (\n    inputWeights1[this.thread.y][this.thread.x] +\n    inputWeights2[this.thread.y][this.thread.x]\n  );\n}\n\nexport class Add extends Operator {\n  get width(): number {\n    return this.inputLayer1.width;\n  }\n\n  get height(): number {\n    return this.inputLayer1.height;\n  }\n\n  get depth(): number {\n    return this.inputLayer1.depth;\n  }\n\n  validate(): void {\n    super.validate();\n    checkSameSize(this.inputLayer1, this.inputLayer2);\n  }\n\n  setupKernels(): void {\n    this.predictKernel = makeKernel(predict, {\n      output: [this.width, this.height],\n      immutable: true,\n    });\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer1.weights,\n      this.inputLayer2.weights\n    ) as Texture;\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    // TODO: Do we need release and clone here?\n    release(this.inputLayer1.deltas);\n    release(this.inputLayer2.deltas);\n    this.inputLayer1.deltas = clone(this.deltas);\n    this.inputLayer2.deltas = clone(this.deltas);\n  }\n\n  learn(): void {}\n}\n\nexport function add(\n  inputLayer1: ILayer,\n  inputLayer2: ILayer,\n  settings?: ILayerSettings\n): Add {\n  return new Add(inputLayer1, inputLayer2, settings);\n}\n","export function randomWeight(): number {\n  return Math.random() * 0.4 - 0.2;\n}\n","/**\n * Returns a random float between given min and max bounds (inclusive)\n * @param min Minimum value of the ranfom float\n * @param max Maximum value of the random float\n */\nexport function randomFloat(min: number, max: number): number {\n  return Math.random() * (max - min) + min;\n}\n\n/**\n * Complicated math. All you need to know is that it returns a random number.\n * More info: https://en.wikipedia.org/wiki/Normal_distribution\n */\nexport function gaussRandom(): number {\n  if (gaussRandom.returnV) {\n    gaussRandom.returnV = false;\n    return gaussRandom.vVal;\n  }\n  const u = 2 * Math.random() - 1;\n  const v = 2 * Math.random() - 1;\n  const r = u * u + v * v;\n  if (r === 0 || r > 1) {\n    return gaussRandom();\n  }\n  const c = Math.sqrt((-2 * Math.log(r)) / r);\n  gaussRandom.vVal = v * c; // cache this\n  gaussRandom.returnV = true;\n  return u * c;\n}\n\n/**\n * Returns a random integer between given min and max bounds\n * @param min Minimum value of the random integer\n * @param max Maximum value of the random integer\n */\nexport function randomInteger(min: number, max: number): number {\n  return Math.floor(Math.random() * (max - min) + min);\n}\n\n/**\n * If you know what this is: https://en.wikipedia.org/wiki/Normal_distribution\n * @param mu\n * @param std\n */\nexport function randomN(mu: number, std: number): number {\n  return mu + gaussRandom() * std;\n}\n\ngaussRandom.returnV = false;\ngaussRandom.vVal = 0;\n","import { randomWeight } from './random-weight';\nimport { randomFloat } from './random';\n\n/**\n * Returns an array of given size, full of randomness\n */\nexport function randos(size: number, std: number | null = null): Float32Array {\n  const array: Float32Array = new Float32Array(size);\n  if (std === null) {\n    for (let i = 0; i < size; i++) {\n      array[i] = randomWeight();\n    }\n  } else {\n    for (let i = 0; i < size; i++) {\n      array[i] = randomFloat(-std, std);\n    }\n  }\n  return array;\n}\n\n/**\n * Returns a 2D matrix of given size, full of randomness\n */\nexport function randos2D(\n  width: number,\n  height: number,\n  std?: number | null\n): Float32Array[] {\n  const result: Float32Array[] = new Array(height);\n  for (let y = 0; y < height; y++) {\n    result[y] = randos(width, std);\n  }\n  return result;\n}\n\n/**\n * Returns a 3D tensor of given size, full of randomness\n */\nexport function randos3D(\n  width: number,\n  height: number,\n  depth: number,\n  std?: number | null\n): Float32Array[][] {\n  const result: Float32Array[][] = new Array(depth);\n  for (let z = 0; z < depth; z++) {\n    result[z] = randos2D(width, height, std);\n  }\n  return result;\n}\n","import { randos2D } from '../utilities/randos';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { baseLayerDefaultSettings, ILayer, ILayerSettings } from './base-layer';\nimport { Model } from './types';\n\nexport interface IRandomSettings extends ILayerSettings {\n  std?: number | null;\n}\n\nexport const defaults: IRandomSettings = {\n  ...baseLayerDefaultSettings,\n  std: null,\n};\n\nexport class Random extends Model implements ILayer {\n  settings: IRandomSettings;\n  constructor(settings: Partial<IRandomSettings>) {\n    super();\n    this.settings = { ...defaults, ...settings };\n    this.setupPraxis();\n    this.validate();\n\n    if (!this.weights) {\n      this.weights = randos2D(this.width, this.height, settings.std);\n    }\n    if (!this.deltas) {\n      this.deltas = zeros2D(this.width, this.height);\n    }\n  }\n\n  predict(): void {}\n\n  compare(): void {}\n}\n\nexport function random(settings: IRandomSettings): Random {\n  return new Random(settings);\n}\n","import { makeKernel, release, clear } from '../utilities/kernel';\nimport { Operator } from './operator';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelRunShortcut,\n  Texture,\n} from 'gpu.js';\nimport { ILayer, ILayerJSON, ILayerSettings } from './base-layer';\n\nexport interface IMultiplyConstants extends IConstantsThis {\n  size: number;\n}\n\nexport function predict(\n  this: IKernelFunctionThis<IMultiplyConstants>,\n  weights1: number[][],\n  weights2: number[][]\n): number {\n  let sum = 0;\n  for (let i = 0; i < this.constants.size; i++) {\n    sum += weights1[this.thread.y][i] * weights2[i][this.thread.x];\n  }\n  return sum;\n}\n\nexport function compareFromX(\n  this: IKernelFunctionThis<IMultiplyConstants>,\n  deltas: number[][],\n  inputDeltas: number[][],\n  inputWeights: number[][]\n): number {\n  let sum = inputDeltas[this.thread.y][this.thread.x];\n  for (let i = 0; i < this.constants.size; i++) {\n    sum += deltas[this.thread.y][i] * inputWeights[this.thread.x][i];\n  }\n  return sum;\n}\n\nexport function compareFromY(\n  this: IKernelFunctionThis<IMultiplyConstants>,\n  deltas: number[][],\n  inputDeltas: number[][],\n  inputWeights: number[][]\n): number {\n  let sum = inputDeltas[this.thread.y][this.thread.x];\n  for (let i = 0; i < this.constants.size; i++) {\n    sum += deltas[i][this.thread.x] * inputWeights[i][this.thread.y];\n  }\n  return sum;\n}\n\nexport class Multiply extends Operator {\n  compareKernel1: IKernelRunShortcut | null = null;\n  compareKernel2: IKernelRunShortcut | null = null;\n\n  get width(): number {\n    return this.inputLayer2.width;\n  }\n\n  set width(width: number) {\n    throw new Error('Cannot set width on Multiply');\n  }\n\n  get height(): number {\n    return this.inputLayer1.height;\n  }\n\n  set height(height: number) {\n    throw new Error('Cannot set height on Multiply');\n  }\n\n  get depth(): number {\n    return this.inputLayer1.depth;\n  }\n\n  set depth(depth: number) {\n    throw new Error('Cannot set depth on Multiply');\n  }\n\n  validate(): void {\n    super.validate();\n    if (this.inputLayer1.width !== this.inputLayer2.height) {\n      throw new Error(\n        `Layer width mismatch of ${this.inputLayer1.width} and ${this.inputLayer2.height}`\n      );\n    }\n  }\n\n  setupKernels(): void {\n    this.predictKernel = makeKernel(predict, {\n      output: [this.width, this.height],\n      constants: {\n        size: this.inputLayer2.height,\n      },\n      immutable: true,\n    });\n    this.compareKernel1 = makeKernel(compareFromX, {\n      output: [this.inputLayer1.width, this.inputLayer1.height],\n      constants: {\n        size: this.inputLayer2.width,\n      },\n      immutable: true,\n    });\n    this.compareKernel2 = makeKernel(compareFromY, {\n      output: [this.inputLayer2.width, this.inputLayer2.height],\n      constants: {\n        size: this.inputLayer1.height,\n      },\n      immutable: true,\n    });\n  }\n\n  reuseKernels(layer: ILayer): void {\n    super.reuseKernels(layer);\n    this.compareKernel1 = (layer as Multiply).compareKernel1;\n    this.compareKernel2 = (layer as Multiply).compareKernel2;\n  }\n\n  predict(): void {\n    release(this.weights);\n    if (!this.predictKernel) throw new Error('this.predictKernel is not set');\n    this.weights = this.predictKernel(\n      this.inputLayer1.weights,\n      this.inputLayer2.weights\n    ) as Texture;\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    if (!this.compareKernel1) throw new Error('this.compareKernel1 not set');\n    if (!this.compareKernel2) throw new Error('this.compareKernel2 not set');\n\n    const inputLayer1Deltas = this.inputLayer1.deltas;\n    const inputLayer2Deltas = this.inputLayer2.deltas;\n\n    const newDeltas1 = this.compareKernel1(\n      this.deltas,\n      this.inputLayer1.deltas,\n      this.inputLayer2.weights\n    );\n    const newDeltas2 = this.compareKernel2(\n      this.deltas,\n      this.inputLayer2.deltas,\n      this.inputLayer1.weights\n    );\n\n    this.inputLayer2.deltas = newDeltas2 as Texture;\n    this.inputLayer1.deltas = newDeltas1 as Texture;\n\n    release(inputLayer1Deltas);\n    release(inputLayer2Deltas);\n  }\n\n  setupPraxis(): void {}\n  learn(): void {}\n\n  toJSON(): Partial<ILayerJSON> {\n    return {\n      ...super.toJSON(),\n      width: this.width,\n      height: this.height,\n    };\n  }\n}\n\nexport function multiply(\n  inputLayer1: ILayer,\n  inputLayer2: ILayer,\n  settings?: ILayerSettings\n): Multiply {\n  return new Multiply(inputLayer1, inputLayer2, settings);\n}\n","import { ILayer, ILayerSettings } from './base-layer';\nimport { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\n\nimport { Activation } from './types';\nimport { makeKernel, release, clear } from '../utilities/kernel';\nimport { activate, measure } from '../activation/sigmoid';\n\nexport function predict2D(\n  this: IKernelFunctionThis,\n  inputs: number[][]\n): number {\n  return 1 / (1 + Math.exp(-inputs[this.thread.y][this.thread.x]));\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis,\n  inputs: number[][][]\n): number {\n  return (\n    1 / (1 + Math.exp(-inputs[this.thread.z][this.thread.y][this.thread.x]))\n  );\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  deltas: number[][]\n): number {\n  const weight = weights[this.thread.y][this.thread.x];\n  const delta = deltas[this.thread.y][this.thread.x];\n  return weight * (1 - weight) * delta;\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis,\n  weights: number[][][],\n  deltas: number[][][]\n): number {\n  const weight = weights[this.thread.z][this.thread.y][this.thread.x];\n  const delta = deltas[this.thread.z][this.thread.y][this.thread.x];\n  return weight * (1 - weight) * delta;\n}\n\nexport class Sigmoid extends Activation {\n  setupKernels(): void {\n    if (this.depth > 0) {\n      this.predictKernel = makeKernel(predict3D, {\n        output: [this.width, this.height, this.depth],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare3D, {\n        output: [this.width, this.height, this.depth],\n        functions: [measure],\n        immutable: true,\n      });\n    } else {\n      this.predictKernel = makeKernel(predict2D, {\n        output: [this.width, this.height],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare2D, {\n        output: [this.width, this.height],\n        functions: [measure],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    release(this.inputLayer.deltas);\n    this.inputLayer.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.weights,\n      this.deltas\n    );\n  }\n}\n\nexport function sigmoid(\n  inputLayer: ILayer,\n  settings?: ILayerSettings\n): Sigmoid {\n  return new Sigmoid(inputLayer, settings);\n}\n","import { IConvolutionSettingsBase } from '../layer/convolution';\n\nexport interface IStride {\n  strideX: number;\n  strideY: number;\n}\n\nexport function getStride(\n  settings: IConvolutionSettingsBase,\n  defaults: IConvolutionSettingsBase\n): IStride {\n  if (typeof settings.stride === 'number') {\n    return { strideX: settings.stride, strideY: settings.stride };\n  } else {\n    let strideX: number = defaults.stride as number;\n    let strideY: number = defaults.stride as number;\n    if (typeof settings.strideX === 'number') {\n      strideX = settings.strideX;\n    }\n    if (typeof settings.strideY === 'number') {\n      strideY = settings.strideY;\n    }\n    return { strideX, strideY };\n  }\n}\n\nexport interface IPadding {\n  paddingX: number;\n  paddingY: number;\n}\n\nexport function getPadding(\n  settings: IConvolutionSettingsBase,\n  defaults: IConvolutionSettingsBase\n): IPadding {\n  if (typeof settings.padding === 'number') {\n    return { paddingX: settings.padding, paddingY: settings.padding };\n  } else {\n    let paddingX: number = defaults.padding as number;\n    let paddingY: number = defaults.padding as number;\n    if (typeof settings.paddingX === 'number') {\n      paddingX = settings.paddingX;\n    }\n    if (typeof settings.paddingY === 'number') {\n      paddingY = settings.paddingY;\n    }\n    return { paddingX, paddingY };\n  }\n}\n","/**\n * Returns an array of a given size with each element filled with a single value\n */\nexport function values(size: number, value: number): Float32Array {\n  return new Float32Array(size).fill(value);\n}\n","import { makeKernel, release, clone, clear } from '../utilities/kernel';\nimport { getStride, getPadding } from '../utilities/layer-setup';\nimport { Filter } from './filter';\nimport { randos, randos3D } from '../utilities/randos';\nimport { zeros3D } from '../utilities/zeros-3d';\nimport { values } from '../utilities/values';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelRunShortcut,\n  KernelOutput,\n} from 'gpu.js';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { IPraxis } from '../praxis/base-praxis';\n\nexport interface IConvolutionConstantsBase extends IConstantsThis {\n  paddingX: number;\n  paddingY: number;\n  strideX: number;\n  strideY: number;\n  filterWidth: number;\n  filterHeight: number;\n}\n\nexport interface IPredictConstants extends IConvolutionConstantsBase {\n  inputWidth: number;\n  inputHeight: number;\n}\n\nexport function predict(\n  this: IKernelFunctionThis<IPredictConstants>,\n  inputs: number[][][],\n  filters: number[][][],\n  biases: number[]\n): number {\n  const startFilterX =\n    this.constants.paddingX - this.thread.x * this.constants.strideX;\n  const startInputX =\n    this.thread.x * this.constants.strideX - this.constants.paddingX;\n  const endFilterX = Math.min(\n    this.constants.filterWidth,\n    startFilterX + this.constants.inputWidth\n  );\n\n  const startFilterY =\n    this.constants.paddingY - this.thread.y * this.constants.strideY;\n  const startInputY =\n    this.thread.y * this.constants.strideY - this.constants.paddingY;\n  const endFilterY = Math.min(\n    this.constants.filterHeight,\n    startFilterY + this.constants.inputHeight\n  );\n\n  let sum = 0;\n  for (let z = 0; z < this.constants.inputDepth; z++) {\n    for (\n      let filterY = Math.max(0, startFilterY),\n        inputY = Math.max(0, startInputY);\n      filterY < endFilterY;\n      filterY++, inputY++\n    ) {\n      for (\n        let filterX = Math.max(0, startFilterX),\n          inputX = Math.max(0, startInputX);\n        filterX < endFilterX;\n        filterX++, inputX++\n      ) {\n        sum += filters[z][filterY][filterX] * inputs[z][inputY][inputX];\n      }\n    }\n  }\n  return sum + biases[this.thread.z];\n}\n\nexport interface ICompareFilterDeltasConstants\n  extends IConvolutionConstantsBase {\n  deltaWidth: number;\n  deltaHeight: number;\n  inputWidth: number;\n  inputHeight: number;\n  deltaZ: number;\n}\n\nexport function compareFilterDeltas(\n  this: IKernelFunctionThis<ICompareFilterDeltasConstants>,\n  filterDeltas: number[][][],\n  inputs: number[][][],\n  deltas: number[][][]\n): number {\n  const startDeltaX = Math.max(\n    0,\n    Math.ceil(\n      (this.constants.paddingX - this.thread.x) / this.constants.strideX\n    )\n  );\n  const startInputX =\n    startDeltaX * this.constants.strideX +\n    this.thread.x -\n    this.constants.paddingX;\n  const endDeltaX = Math.min(\n    this.constants.deltaWidth,\n    Math.floor(\n      (this.constants.inputWidth -\n        1 -\n        this.thread.x +\n        this.constants.paddingX) /\n        this.constants.strideX\n    ) + 1\n  );\n\n  const startDeltaY = Math.max(\n    0,\n    Math.ceil(\n      (this.constants.paddingY - this.thread.y) / this.constants.strideY\n    )\n  );\n  const startInputY =\n    startDeltaY * this.constants.strideY +\n    this.thread.y -\n    this.constants.paddingY;\n  const endDeltaY = Math.min(\n    this.constants.deltaHeight,\n    Math.floor(\n      (this.constants.inputHeight -\n        1 -\n        this.thread.y +\n        this.constants.paddingY) /\n        this.constants.strideY\n    ) + 1\n  );\n\n  let sum = filterDeltas[this.thread.z][this.thread.y][this.thread.x];\n  for (\n    let deltaY = startDeltaY, inputY = startInputY;\n    deltaY < endDeltaY;\n    deltaY++, inputY += this.constants.strideY\n  ) {\n    for (\n      let deltaX = startDeltaX, inputX = startInputX;\n      deltaX < endDeltaX;\n      deltaX++, inputX += this.constants.strideX\n    ) {\n      sum +=\n        inputs[this.thread.z][inputY][inputX] *\n        deltas[this.constants.deltaZ][deltaY][deltaX];\n    }\n  }\n  return sum;\n}\n\nexport interface ICompareInputDeltasConstants\n  extends IConvolutionConstantsBase {\n  deltaHeight: number;\n  deltaWidth: number;\n  deltaZ: number;\n}\n\nexport function compareInputDeltas(\n  this: IKernelFunctionThis<ICompareInputDeltasConstants>,\n  inputDeltas: number[][][],\n  filters: number[][][],\n  deltas: number[][][]\n): number {\n  const x = this.thread.x + this.constants.paddingX;\n  const startDeltaX =\n    x < this.constants.filterWidth\n      ? 0\n      : Math.floor(\n          (x - this.constants.filterWidth + this.constants.strideX) /\n            this.constants.strideX\n        );\n  const startFilterX = x - startDeltaX * this.constants.strideX;\n  const endDeltaX = Math.min(\n    startDeltaX + Math.floor(startFilterX / this.constants.strideX) + 1,\n    this.constants.deltaWidth\n  );\n\n  const y = this.thread.y + this.constants.paddingY;\n  const startDeltaY =\n    y < this.constants.filterHeight\n      ? 0\n      : Math.floor(\n          (y - this.constants.filterHeight + this.constants.strideY) /\n            this.constants.strideY\n        );\n  const startFilterY = y - startDeltaY * this.constants.strideY;\n  const endDeltaY = Math.min(\n    startDeltaY + Math.floor(startFilterY / this.constants.strideY) + 1,\n    this.constants.deltaHeight\n  );\n\n  let sum = inputDeltas[this.thread.z][this.thread.y][this.thread.x];\n  let deltaY = startDeltaY;\n  for (\n    let filterY = startFilterY;\n    deltaY < endDeltaY;\n    filterY -= this.constants.strideY, deltaY++\n  ) {\n    let deltaX = startDeltaX;\n    for (\n      let filterX = startFilterX;\n      deltaX < endDeltaX;\n      filterX -= this.constants.strideX, deltaX++\n    ) {\n      sum +=\n        filters[this.thread.z][filterY][filterX] *\n        deltas[this.constants.deltaZ][deltaY][deltaX];\n    }\n  }\n  return sum;\n}\n\nexport interface ICompareBiasesConstants extends IConstantsThis {\n  deltaHeight: number;\n  deltaWdith: number;\n}\n\nexport function compareBiases(\n  this: IKernelFunctionThis<ICompareBiasesConstants>,\n  biasDeltas: number[][][],\n  deltas: number[][][]\n): number {\n  let sum = 0;\n  for (let y = 0; y < this.constants.deltaHeight; y++) {\n    for (let x = 0; x < this.constants.deltaWidth; x++) {\n      sum += deltas[this.thread.z][y][x];\n    }\n  }\n  return biasDeltas[this.thread.z][this.thread.y][this.thread.x] + sum;\n}\n\nexport interface IConvolutionSettingsBase {\n  stride?: number;\n  strideX?: number;\n  strideY?: number;\n  padding?: number;\n  paddingX?: number;\n  paddingY?: number;\n  filterCount?: number;\n  filterWidth?: number;\n  filterHeight?: number;\n}\n\nexport interface IConvolutionSettings\n  extends ILayerSettings,\n    IConvolutionSettingsBase {\n  bias?: number;\n  biases?: KernelOutput;\n  biasDeltas?: KernelOutput;\n  filters?: KernelOutput;\n  filterDeltas?: KernelOutput;\n}\n\nexport const defaults: IConvolutionSettings = {\n  stride: 0,\n  padding: 0,\n  bias: 0.1,\n  filterCount: 1,\n  filterWidth: 0,\n  filterHeight: 0,\n};\n\nexport class Convolution extends Filter {\n  settings: Partial<IConvolutionSettings>;\n\n  get strideX(): number {\n    return this.settings.strideX as number;\n  }\n\n  get strideY(): number {\n    return this.settings.strideY as number;\n  }\n\n  get paddingX(): number {\n    return this.settings.paddingX as number;\n  }\n\n  get paddingY(): number {\n    return this.settings.paddingX as number;\n  }\n\n  get width(): number {\n    return Math.floor(\n      (this.inputLayer.width + this.paddingX * 2 - this.filterWidth) /\n        this.strideX +\n        1\n    );\n  }\n\n  get height(): number {\n    return Math.floor(\n      (this.inputLayer.height + this.paddingY * 2 - this.filterHeight) /\n        this.strideY +\n        1\n    );\n  }\n\n  get bias(): number {\n    return this.settings.bias as number;\n  }\n\n  get depth(): number {\n    return this.filterCount;\n  }\n\n  get biases(): KernelOutput {\n    return this.settings.biases;\n  }\n\n  set biases(biases: KernelOutput) {\n    this.settings.biases = biases;\n  }\n\n  get biasDeltas(): KernelOutput {\n    return this.settings.biasDeltas;\n  }\n\n  set biasDeltas(weights: KernelOutput) {\n    this.settings.biasDeltas = weights;\n  }\n\n  get filters(): KernelOutput {\n    return this.settings.filters;\n  }\n\n  set filters(filters: KernelOutput) {\n    this.settings.filters = filters;\n  }\n\n  get filterDeltas(): KernelOutput {\n    return this.settings.filterDeltas;\n  }\n\n  set filterDeltas(filterDeltas: KernelOutput) {\n    this.settings.filterDeltas = filterDeltas;\n  }\n\n  constructor(settings: IConvolutionSettings, inputLayer: ILayer) {\n    super(settings, inputLayer);\n    this.settings = {\n      ...defaults,\n      ...settings,\n      ...getPadding(settings, defaults),\n      ...getStride(settings, defaults),\n    };\n\n    this.weights =\n      settings.weights ?? randos3D(this.width, this.height, this.depth);\n    this.deltas = zeros3D(this.width, this.height, this.depth);\n\n    this.biases = values(this.depth, this.bias);\n    this.biasDeltas = settings.biasDeltas ?? randos(this.depth);\n\n    this.filters =\n      settings.filters ??\n      randos3D(this.filterWidth, this.filterHeight, this.filterCount);\n    this.filterDeltas = zeros3D(\n      this.filterWidth,\n      this.filterHeight,\n      this.filterCount\n    );\n    this.validate();\n  }\n\n  compareFilterDeltasKernel: IKernelRunShortcut | null = null;\n  compareInputDeltasKernel: IKernelRunShortcut | null = null;\n  compareBiasesKernel: IKernelRunShortcut | null = null;\n  setupKernels(): void {\n    this.predictKernel = makeKernel<\n      Parameters<typeof predict>,\n      IPredictConstants\n    >(predict, {\n      constants: {\n        inputWidth: this.inputLayer.width,\n        inputHeight: this.inputLayer.height,\n        inputDepth: this.inputLayer.depth,\n        strideX: this.strideX,\n        strideY: this.strideY,\n        paddingX: this.paddingX,\n        paddingY: this.paddingY,\n        filterWidth: this.filterWidth,\n        filterHeight: this.filterHeight,\n      },\n      output: [this.width, this.height, this.depth],\n      immutable: true,\n    });\n\n    this.compareFilterDeltasKernel = makeKernel(compareFilterDeltas, {\n      constants: {\n        deltasWidth: this.width,\n        deltasHeight: this.height,\n        deltasDepth: this.depth,\n        inputWidth: this.inputLayer.width,\n        inputHeight: this.inputLayer.height,\n        inputDepth: this.inputLayer.depth,\n        strideX: this.strideX,\n        strideY: this.strideY,\n        paddingX: this.paddingX,\n        paddingY: this.paddingY,\n        filterWidth: this.filterWidth,\n        filterHeight: this.filterHeight,\n      },\n      output: [this.width, this.height, this.depth],\n      immutable: true,\n    });\n\n    this.compareInputDeltasKernel = makeKernel(compareInputDeltas, {\n      constants: {\n        filterCount: this.filterCount,\n      },\n      output: [\n        this.inputLayer.width,\n        this.inputLayer.height,\n        this.inputLayer.depth,\n      ],\n      immutable: true,\n    });\n\n    this.compareBiasesKernel = makeKernel(compareBiases, {\n      output: [1, 1, this.depth],\n      constants: {\n        deltaWidth: this.width,\n        deltaHeight: this.height,\n      },\n      immutable: true,\n    });\n  }\n\n  predict(): void {\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights,\n      this.filters,\n      this.biases\n    );\n  }\n\n  compare(): void {\n    const { filterDeltas, biasDeltas } = this;\n    this.filterDeltas = (this.compareFilterDeltasKernel as IKernelRunShortcut)(\n      filterDeltas,\n      this.inputLayer.weights,\n      this.deltas\n    );\n    release(filterDeltas);\n    this.biasDeltas = (this.compareBiasesKernel as IKernelRunShortcut)(\n      biasDeltas,\n      this.deltas\n    );\n    release(biasDeltas);\n    release(this.deltas);\n    this.deltas = (this.compareInputDeltasKernel as IKernelRunShortcut)(\n      this.filters,\n      this.inputLayer.deltas\n    );\n\n    release(this.inputLayer.deltas);\n    // TODO: do we need to clone here?\n    this.inputLayer.deltas = clone(this.deltas);\n  }\n\n  learn(learningRate: number): void {\n    // TODO: handle filters\n    // TODO: do we need to release here?\n    const { weights: oldWeights } = this;\n    this.weights = (this.praxis as IPraxis).run(this, learningRate);\n    release(oldWeights);\n    clear(this.deltas);\n  }\n}\n\nexport function convolution(\n  settings: IConvolutionSettings,\n  inputLayer: ILayer\n): Convolution {\n  return new Convolution(settings, inputLayer);\n}\n","import { Filter, IFilterSettings } from './filter';\nimport { makeKernel, makeKernelMap, release } from '../utilities/kernel';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelMapRunShortcut,\n  IKernelRunShortcut,\n  ISubKernelObject,\n  KernelOutput,\n} from 'gpu.js';\nimport { ILayer, ILayerSettings, baseLayerDefaultSettings } from './base-layer';\n\nexport function setDropout(dropout: number): number {\n  return dropout;\n}\n\nexport interface IDropoutConstants extends IConstantsThis {\n  probability: number;\n}\n\nexport function trainingPredict(\n  this: IKernelFunctionThis<IDropoutConstants>,\n  inputs: number[][]\n): number {\n  if (setDropout(Math.random()) < this.constants.probability) {\n    return 0;\n  }\n  return inputs[this.thread.y][this.thread.x];\n}\n\nexport function predict(\n  this: IKernelFunctionThis<IDropoutConstants>,\n  inputs: number[][]\n): number {\n  return inputs[this.thread.y][this.thread.x] * this.constants.probability;\n}\n\nexport function compare(\n  this: IKernelFunctionThis,\n  dropouts: number[][],\n  deltas: number[][]\n): number {\n  if (dropouts[this.thread.y][this.thread.x] === 0) {\n    return 0;\n  }\n  return deltas[this.thread.y][this.thread.x];\n}\n\nexport interface IDropoutSettings extends ILayerSettings {\n  probability: number;\n}\n\nexport const dropoutDefaults: IDropoutSettings = {\n  ...baseLayerDefaultSettings,\n  probability: 0.5,\n};\n\nexport class Dropout extends Filter {\n  dropouts: KernelOutput | null;\n  predictKernelMap: IKernelMapRunShortcut<ISubKernelObject> | null = null;\n  settings: Partial<IDropoutSettings>;\n  constructor(\n    inputLayer: ILayer,\n    settings?: Partial<IDropoutSettings> & Partial<IFilterSettings>\n  ) {\n    super(settings as Partial<IFilterSettings>, inputLayer);\n    this.settings = { ...dropoutDefaults, ...settings };\n    this.dropouts = null;\n    this.validate();\n  }\n\n  setupKernels(isTraining?: boolean): void {\n    const output = [this.width, this.height];\n\n    if (isTraining) {\n      this.predictKernelMap = makeKernelMap<\n        Parameters<typeof trainingPredict>,\n        IDropoutConstants\n      >({ dropouts: setDropout }, trainingPredict, {\n        output,\n        immutable: true,\n      });\n      this.compareKernel = makeKernel(compare, { output, immutable: true });\n    } else {\n      this.predictKernelMap = makeKernelMap<\n        Parameters<typeof predict>,\n        IDropoutConstants\n      >({}, predict, { output, immutable: true });\n    }\n  }\n\n  predict(): void {\n    release(this.weights);\n    if (this.dropouts) {\n      release(this.dropouts);\n    }\n    const { result, dropouts } = (this\n      .predictKernelMap as IKernelMapRunShortcut<ISubKernelObject>)(\n      this.inputLayer.weights\n    );\n    this.weights = result;\n    this.dropouts = dropouts;\n  }\n\n  compare(): void {\n    release(this.deltas);\n    this.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.dropouts as KernelOutput,\n      this.inputLayer.deltas\n    );\n  }\n}\n\nexport function dropout(\n  inputLayer: ILayer,\n  settings?: Partial<IDropoutSettings>\n): Dropout {\n  return new Dropout(inputLayer, settings);\n}\n","import {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelRunShortcut,\n  KernelOutput,\n} from 'gpu.js';\nimport { Filter, IFilterSettings } from './filter';\nimport { makeKernel, release } from '../utilities/kernel';\nimport { values } from '../utilities/values';\nimport { randos2D, randos3D } from '../utilities/randos';\nimport { zeros } from '../utilities/zeros';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { zeros3D } from '../utilities/zeros-3d';\nimport { ILayer } from './base-layer';\n\nexport interface IPredictConstants extends IConstantsThis {\n  inputWidth: number;\n  inputHeight: number;\n}\n\nexport function predict(\n  this: IKernelFunctionThis<IPredictConstants>,\n  inputs: number[][],\n  filters: number[][],\n  biases: number[]\n): number {\n  let output = 0;\n  let i = 0;\n  for (let y = 0; y < this.constants.inputHeight; y++) {\n    for (let x = 0; x < this.constants.inputWidth; x++) {\n      output += inputs[y][x] * filters[this.thread.x][i];\n      i++;\n    }\n  }\n  return output + biases[this.thread.x];\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis<IPredictConstants>,\n  inputs: number[][][],\n  filters: number[][],\n  biases: number[]\n): number {\n  let output = 0;\n  let i = 0;\n  for (let z = 0; z < this.constants.inputDepth; z++) {\n    for (let y = 0; y < this.constants.inputHeight; y++) {\n      for (let x = 0; x < this.constants.inputWidth; x++) {\n        output += inputs[z][y][x] * filters[this.thread.x][i];\n        i++;\n      }\n    }\n  }\n  return output + biases[this.thread.x];\n}\n\nexport interface ICompareInputDeltasConstants extends IConstantsThis {\n  filterCount: number;\n}\n\nexport function compareInputDeltas(\n  this: IKernelFunctionThis<ICompareInputDeltasConstants>,\n  inputDeltas: number[][],\n  deltas: number[][],\n  filters: number[][]\n): number {\n  let sum = 0;\n  const filterX = this.thread.x + this.thread.y * this.output.x;\n  for (let filterY = 0; filterY < this.constants.filterCount; filterY++) {\n    sum += filters[filterY][filterX] * deltas[0][filterY];\n  }\n  return sum + inputDeltas[this.thread.y][this.thread.x];\n}\n\nexport function compareInputDeltas3D(\n  this: IKernelFunctionThis<ICompareInputDeltasConstants>,\n  inputDeltas: number[][][],\n  deltas: number[][],\n  filters: number[][]\n): number {\n  let sum = 0;\n  const filterX = this.thread.x + this.thread.y * this.output.x;\n  for (let filterY = 0; filterY < this.constants.filterCount; filterY++) {\n    sum += filters[filterY][filterX] * deltas[0][filterY];\n  }\n  return sum + inputDeltas[this.thread.z][this.thread.y][this.thread.x];\n}\n\nexport function compareBiases(\n  this: IKernelFunctionThis,\n  biases: number[],\n  deltas: number[][]\n): number {\n  return biases[this.thread.x] + deltas[this.thread.y][this.thread.x];\n}\n\nexport interface ICompareFiltersDeltas extends IConstantsThis {\n  deltaX: number;\n  deltaY: number;\n  inputWidth: number;\n  inputHeight: number;\n}\n\nexport function compareFilterDeltas(\n  this: IKernelFunctionThis<ICompareFiltersDeltas>,\n  filterDeltas: number[][],\n  inputWeights: number[][],\n  deltas: number[][]\n): number {\n  return (\n    filterDeltas[this.thread.y][this.thread.x] +\n    inputWeights[this.thread.y][this.thread.x] *\n      deltas[this.constants.deltaY][this.constants.deltaX]\n  );\n}\n\nexport function compareFilterDeltas3D(\n  this: IKernelFunctionThis<ICompareFiltersDeltas>,\n  filterDeltas: number[][],\n  inputWeights: number[][][],\n  deltas: number[][]\n): number {\n  const inputZ = Math.floor(\n    this.thread.x / (this.constants.inputWidth * this.constants.inputHeight)\n  );\n  const inputY = Math.floor(\n    (this.thread.x -\n      inputZ * this.constants.inputWidth * this.constants.inputHeight) /\n      this.constants.inputWidth\n  );\n  const inputX =\n    this.thread.x -\n    this.constants.inputWidth * (inputY + this.constants.inputHeight * inputZ);\n  return (\n    filterDeltas[this.thread.y][this.thread.x] +\n    inputWeights[inputZ][inputY][inputX] * deltas[0][this.thread.y]\n  );\n}\n\nexport interface IFullyConnectedDefaultSettings\n  extends Partial<IFilterSettings> {\n  bias?: number;\n  biases?: KernelOutput;\n  biasDeltas?: KernelOutput;\n}\n\nexport const defaults: IFullyConnectedDefaultSettings = {\n  bias: 0.1,\n};\n\nexport class FullyConnected extends Filter {\n  get bias(): number {\n    return this.settings.bias as number;\n  }\n\n  get biases(): KernelOutput {\n    return this.settings.biases;\n  }\n\n  set biases(biases: KernelOutput) {\n    this.settings.biases = biases;\n  }\n\n  get biasDeltas(): KernelOutput {\n    return this.settings.biases;\n  }\n\n  set biasDeltas(biasDeltas: KernelOutput) {\n    this.settings.biasDeltas = biasDeltas;\n  }\n\n  settings: Partial<IFullyConnectedDefaultSettings>;\n  compareFilterDeltasKernel: IKernelRunShortcut | null = null;\n  compareInputDeltasKernel: IKernelRunShortcut | null = null;\n  compareBiasesKernel: IKernelRunShortcut | null = null;\n  constructor(\n    settings: Partial<IFullyConnectedDefaultSettings>,\n    inputLayer: ILayer\n  ) {\n    super(settings, inputLayer);\n    this.settings = { ...settings };\n    this.validate();\n\n    const connectionCount =\n      inputLayer.width * inputLayer.height * inputLayer.depth;\n\n    this.biases = values(this.height, this.bias);\n    this.biasDeltas = zeros(this.height);\n\n    this.filters = randos2D(connectionCount, this.height);\n    this.filterDeltas = zeros2D(connectionCount, this.height);\n\n    if (this.depth > 0) {\n      this.weights = randos3D(this.width, this.height, this.depth);\n      this.deltas = zeros3D(this.width, this.height, this.depth);\n    } else if (this.height > 0) {\n      this.weights = randos2D(this.width, this.height);\n      this.deltas = zeros2D(this.width, this.height);\n    }\n  }\n\n  validate(): void {\n    super.validate();\n    if (this.depth > 0) throw new Error('depth not supported');\n  }\n\n  setupKernels(): void {\n    const { inputLayer } = this;\n    const connectionCount =\n      inputLayer.width * inputLayer.height * inputLayer.depth;\n    if (inputLayer.depth > 0) {\n      this.predictKernel = makeKernel(predict3D, {\n        output: [this.width, this.height],\n        constants: {\n          inputHeight: inputLayer.height,\n          inputWidth: inputLayer.width,\n          inputDepth: inputLayer.depth,\n        },\n      });\n\n      this.compareFilterDeltasKernel = makeKernel(compareFilterDeltas3D, {\n        output: [connectionCount, this.height],\n        constants: {\n          inputWidth: inputLayer.width,\n          inputHeight: inputLayer.height,\n        },\n        immutable: true,\n      });\n\n      this.compareInputDeltasKernel = makeKernel(compareInputDeltas3D, {\n        output: [inputLayer.width, inputLayer.height, inputLayer.depth],\n        constants: {\n          filterCount: this.height,\n        },\n        immutable: true,\n      });\n    } else {\n      this.predictKernel = makeKernel(predict, {\n        output: [this.width, this.height],\n        constants: {\n          inputHeight: inputLayer.height,\n          inputWidth: inputLayer.width,\n        },\n      });\n\n      this.compareFilterDeltasKernel = makeKernel(compareFilterDeltas, {\n        output: [connectionCount, this.height],\n        constants: {\n          inputWidth: inputLayer.width,\n        },\n      });\n\n      this.compareInputDeltasKernel = makeKernel(compareInputDeltas, {\n        output: [inputLayer.width, inputLayer.height],\n        constants: {\n          filterCount: this.height,\n        },\n      });\n    }\n\n    this.compareBiasesKernel = makeKernel(compareBiases, {\n      output: [this.width, this.height],\n    });\n  }\n\n  predict(): void {\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights,\n      this.filters,\n      this.biases\n    );\n  }\n\n  compare(): void {\n    const inputLayerDeltas = this.inputLayer.deltas;\n    this.inputLayer.deltas = (this\n      .compareInputDeltasKernel as IKernelRunShortcut)(\n      inputLayerDeltas,\n      this.deltas,\n      this.filters\n    );\n    release(inputLayerDeltas);\n\n    const { biasDeltas, filterDeltas } = this;\n    // TODO: handle biasDeltas learn\n    this.biasDeltas = (this.compareBiasesKernel as IKernelRunShortcut)(\n      this.biases,\n      this.deltas\n    );\n\n    // TODO: handle filterDeltas learn\n    this.filterDeltas = (this.compareFilterDeltasKernel as IKernelRunShortcut)(\n      filterDeltas,\n      this.inputLayer.weights,\n      this.deltas\n    );\n    release(biasDeltas);\n    release(filterDeltas);\n  }\n}\n\nexport function fullyConnected(\n  settings: IFullyConnectedDefaultSettings,\n  inputLayer: ILayer\n): FullyConnected {\n  return new FullyConnected(settings, inputLayer);\n}\n","import { makeKernel } from '../utilities/kernel';\nimport { Modifier } from './types';\nimport { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function predict(\n  this: IKernelFunctionThis,\n  weights: number[][]\n): number {\n  return -weights[this.thread.y][this.thread.x];\n}\n\nexport class Negative extends Modifier {\n  constructor(inputLayer: ILayer, settings?: ILayerSettings) {\n    super(inputLayer, settings);\n    this.validate();\n  }\n\n  setupKernels(): void {\n    this.predictKernel = makeKernel(predict, {\n      output: [this.width, this.height],\n    });\n  }\n\n  predict(): void {\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n  }\n}\n\nexport function negative(\n  inputLayer: ILayer,\n  settings?: ILayerSettings\n): Negative {\n  return new Negative(inputLayer, settings);\n}\n","import { makeKernel, release, clear } from '../utilities/kernel';\nimport { Operator } from './operator';\nimport { checkSameSize } from '../utilities/layer-size';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\n\nexport function predict(\n  this: IKernelFunctionThis,\n  inputLayerWeights1: number[][],\n  inputLayerWeights2: number[][]\n): number {\n  return (\n    inputLayerWeights1[this.thread.y][this.thread.x] *\n    inputLayerWeights2[this.thread.y][this.thread.x]\n  );\n}\n\nexport function compare(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  deltas: number[][]\n): number {\n  return (\n    weights[this.thread.y][this.thread.x] * deltas[this.thread.y][this.thread.x]\n  );\n}\n\nexport class MultiplyElement extends Operator {\n  get width(): number {\n    return this.inputLayer1.width;\n  }\n\n  get height(): number {\n    return this.inputLayer1.height;\n  }\n\n  get depth(): number {\n    return this.inputLayer1.depth;\n  }\n\n  validate(): void {\n    super.validate();\n    checkSameSize(this.inputLayer1, this.inputLayer2);\n  }\n\n  setupKernels(): void {\n    this.predictKernel = makeKernel(predict, {\n      output: [this.width, this.height],\n      immutable: true,\n    });\n\n    this.compareKernel = makeKernel(compare, {\n      output: [this.width, this.height],\n      immutable: true,\n    });\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer1.weights,\n      this.inputLayer2.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    release(this.inputLayer1.deltas);\n    release(this.inputLayer2.deltas);\n    this.inputLayer1.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.inputLayer2.weights,\n      this.deltas\n    );\n    this.inputLayer2.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.inputLayer1.weights,\n      this.deltas\n    );\n  }\n}\n\nexport function multiplyElement(\n  inputLayer1: ILayer,\n  inputLayer2: ILayer,\n  settings?: ILayerSettings\n): MultiplyElement {\n  return new MultiplyElement(inputLayer1, inputLayer2, settings);\n}\n","export function ones(size: number): Float32Array {\n  return new Float32Array(size).fill(1);\n}\n\nexport function ones2D(width: number, height: number): Float32Array[] {\n  const result = new Array(height);\n  for (let y = 0; y < height; y++) {\n    result[y] = ones(width);\n  }\n  return result;\n}\n","import { ILayerSettings } from './base-layer';\n\nimport { ones2D } from '../utilities/ones';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { Model } from './types';\n\nexport class Ones extends Model {\n  constructor(settings: ILayerSettings) {\n    super(settings);\n    this.validate();\n    this.weights = ones2D(this.width, this.height);\n    this.deltas = zeros2D(this.width, this.height);\n  }\n}\n\nexport function ones(settings: ILayerSettings): Ones {\n  return new Ones(settings);\n}\n","import { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\n\nimport { Activation } from './activation';\nimport { activate, measure } from '../activation/tanh';\nimport { release, clear, makeKernel } from '../utilities/kernel';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function predict2D(\n  this: IKernelFunctionThis,\n  inputs: number[][]\n): number {\n  return activate(inputs[this.thread.y][this.thread.x]);\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis,\n  inputs: number[][][]\n): number {\n  return activate(inputs[this.thread.z][this.thread.y][this.thread.x]);\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  errors: number[][]\n): number {\n  return measure(\n    weights[this.thread.y][this.thread.x],\n    errors[this.thread.y][this.thread.x]\n  );\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis,\n  weights: number[][][],\n  errors: number[][][]\n): number {\n  return measure(\n    weights[this.thread.z][this.thread.y][this.thread.x],\n    errors[this.thread.z][this.thread.y][this.thread.x]\n  );\n}\n\nexport class Tanh extends Activation {\n  setupKernels(): void {\n    if (this.depth > 0) {\n      this.predictKernel = makeKernel(predict3D, {\n        output: [this.width, this.height, this.depth],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare3D, {\n        output: [this.width, this.height, this.depth],\n        functions: [measure],\n        immutable: true,\n      });\n    } else {\n      this.predictKernel = makeKernel(predict2D, {\n        output: [this.width, this.height],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare2D, {\n        output: [this.width, this.height],\n        functions: [measure],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    release(this.inputLayer.deltas);\n    this.inputLayer.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.weights,\n      this.deltas\n    );\n  }\n}\n\nexport function tanh(inputLayer: ILayer, settings?: ILayerSettings): Tanh {\n  return new Tanh(inputLayer, settings);\n}\n","import { zeros2D } from '../utilities/zeros-2d';\nimport { Model } from './types';\nimport { ILayerSettings } from './base-layer';\n\nexport class Zeros extends Model {\n  constructor(settings: ILayerSettings) {\n    super(settings);\n    this.validate();\n    this.weights = zeros2D(this.width, this.height);\n    this.deltas = zeros2D(this.width, this.height);\n  }\n\n  predict(): void {\n    // throw new Error(`${this.constructor.name}-predict is not yet implemented`)\n  }\n\n  compare(): void {\n    // throw new Error(`${this.constructor.name}-compare is not yet implemented`)\n  }\n}\n\nexport function zeros(settings: ILayerSettings): Zeros {\n  return new Zeros(settings);\n}\n","import { IKernelFunctionThis, IKernelRunShortcut, KernelOutput } from 'gpu.js';\nimport { EntryPoint } from './types';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport {\n  makeKernel,\n  release,\n  kernelInput,\n  clear,\n  clone,\n} from '../utilities/kernel';\n\nexport const defaults: ILayerSettings = {\n  weights: null,\n};\n\nexport class Input extends EntryPoint {\n  reshapeInput: IKernelRunShortcut | null = null;\n  constructor(settings: ILayerSettings) {\n    super({ ...defaults, ...settings });\n    this.validate();\n    this.reshapeInput = null;\n    this.deltas = zeros2D(this.width, this.height);\n  }\n\n  setupKernels(): void {\n    if (this.width === 1) {\n      this.predict = this.predict1D;\n      this.reshapeInput = makeKernel(\n        function (this: IKernelFunctionThis, value: number[]) {\n          return value[this.thread.y];\n        },\n        {\n          output: [1, this.height],\n          immutable: true,\n        }\n      );\n    }\n  }\n\n  reuseKernels(layer: ILayer): void {\n    // super.reuseKernels(layer);\n    this.reshapeInput = (layer as Input).reshapeInput;\n  }\n\n  predict(inputs: KernelOutput): void {\n    if (\n      (Array.isArray(inputs) || inputs instanceof Float32Array) &&\n      typeof inputs[0] === 'number' &&\n      inputs.length === this.height * this.width\n    ) {\n      release(this.weights);\n      this.weights = kernelInput(inputs as number[], [this.width, this.height]);\n    } else if (\n      Array.isArray(inputs) &&\n      inputs.length === this.height &&\n      (Array.isArray(inputs[0]) || inputs[0] instanceof Float32Array) &&\n      inputs[0].length === this.width\n    ) {\n      this.weights = clone(inputs);\n    } else {\n      throw new Error('Inputs are not of sized correctly');\n    }\n    clear(this.deltas);\n  }\n\n  predict1D(inputs: KernelOutput): void {\n    if (this.weights) release(this.weights);\n    if (this.reshapeInput) {\n      this.weights = this.reshapeInput(inputs);\n    } else {\n      this.weights = inputs;\n    }\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    // throw new Error(`${this.constructor.name}-compare is not yet implemented`)\n  }\n}\n\nexport function input(settings: ILayerSettings): Input {\n  return new Input(settings);\n}\n","import { Activation } from './types';\nimport { makeKernel, release, clear } from '../utilities/kernel';\nimport { activate, measure } from '../activation/leaky-relu';\nimport { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function predict2D(\n  this: IKernelFunctionThis,\n  inputs: number[][]\n): number {\n  return activate(inputs[this.thread.y][this.thread.x]);\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis,\n  inputs: number[][][]\n): number {\n  return activate(inputs[this.thread.z][this.thread.y][this.thread.x]);\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  deltas: number[][]\n): number {\n  return measure(\n    weights[this.thread.y][this.thread.x],\n    deltas[this.thread.y][this.thread.x]\n  );\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis,\n  weights: number[][][],\n  deltas: number[][][]\n): number {\n  return measure(\n    weights[this.thread.z][this.thread.y][this.thread.x],\n    deltas[this.thread.z][this.thread.y][this.thread.x]\n  );\n}\n\nexport class LeakyRelu extends Activation {\n  setupKernels(): void {\n    const { width, height, depth } = this.inputLayer;\n    if (this.depth > 0) {\n      this.predictKernel = makeKernel(predict3D, {\n        output: [width, height, depth],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare3D, {\n        output: [width, height, depth],\n        functions: [measure],\n        immutable: true,\n      });\n    } else {\n      this.predictKernel = makeKernel(predict2D, {\n        output: [width, height],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare2D, {\n        output: [width, height],\n        functions: [measure],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    const { deltas } = this;\n    this.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.weights,\n      deltas\n    );\n    release(deltas);\n  }\n}\n\nexport function leakyRelu(\n  inputLayer: ILayer,\n  settings: ILayerSettings\n): LeakyRelu {\n  return new LeakyRelu(inputLayer, settings);\n}\n","import { Filter } from './filter';\nimport { makeKernel, makeKernelMap, release } from '../utilities/kernel';\nimport { getPadding, getStride } from '../utilities/layer-setup';\nimport { zeros3D } from '../utilities/zeros-3d';\nimport { randos3D } from '../utilities/randos';\nimport {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelMapRunShortcut,\n  IKernelRunShortcut,\n  ISubKernelObject,\n  KernelOutput,\n} from 'gpu.js';\nimport {\n  IConvolutionSettingsBase,\n  IConvolutionConstantsBase,\n} from './convolution';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function setSwitchY(value: number): number {\n  return value;\n}\n\nexport function setSwitchX(value: number): number {\n  return value;\n}\n\nexport interface IPredictConstants extends IConvolutionConstantsBase {\n  inputWidth: number;\n  inputHeight: number;\n}\n\nexport function predict(\n  this: IKernelFunctionThis<IPredictConstants>,\n  inputs: number[][][]\n): number {\n  const startFilterX =\n    this.constants.paddingX - this.thread.x * this.constants.strideX;\n  const startInputX =\n    this.thread.x * this.constants.strideX - this.constants.paddingX;\n  const endFilterX = Math.min(\n    this.constants.filterWidth,\n    startFilterX + this.constants.inputWidth\n  );\n\n  const startFilterY =\n    this.constants.paddingY - this.thread.y * this.constants.strideY;\n  const startInputY =\n    this.thread.y * this.constants.strideY - this.constants.paddingY;\n  const endFilterY = Math.min(\n    this.constants.filterHeight,\n    startFilterY + this.constants.inputHeight\n  );\n\n  let largestValue = -99999;\n  let largestX = -1;\n  let largestY = -1;\n\n  // convolve centered at this particular location\n  for (\n    let filterY = Math.max(0, startFilterY), inputY = Math.max(0, startInputY);\n    filterY < endFilterY;\n    filterY++, inputY++\n  ) {\n    for (\n      let filterX = Math.max(0, startFilterX),\n        inputX = Math.max(0, startInputX);\n      filterX < endFilterX;\n      filterX++, inputX++\n    ) {\n      if (\n        inputY >= 0 &&\n        inputY < this.constants.inputHeight &&\n        inputX >= 0 &&\n        inputX < this.constants.inputWidth\n      ) {\n        const input = inputs[this.thread.z][inputY][inputX];\n        if (input > largestValue) {\n          largestValue = input;\n          largestY = inputY;\n          largestX = inputX;\n        }\n      }\n    }\n  }\n  setSwitchY(largestY);\n  setSwitchX(largestX);\n  return largestValue;\n}\n\nexport interface ICompareConstants extends IConstantsThis {\n  inputWidth: number;\n  inputHeight: number;\n\n  outputWidth: number;\n  outputHeight: number;\n}\n\nexport function compare(\n  this: IKernelFunctionThis<ICompareConstants>,\n  deltas: number[][],\n  switchY: number[][],\n  switchX: number[][]\n): number {\n  const x = Math.floor(\n    (this.thread.x / this.output.x) * this.constants.outputWidth\n  );\n  const y = Math.floor(\n    (this.thread.y / this.output.y) * this.constants.outputHeight\n  );\n\n  let value = 0;\n\n  for (let deltasY = 0; deltasY < this.constants.inputHeight; deltasY++) {\n    for (let deltasX = 0; deltasX < this.constants.inputWidth; deltasX++) {\n      const switchXValue = switchX[deltasY][deltasX];\n      const switchYValue = switchY[deltasY][deltasX];\n      if (switchXValue === x && switchYValue === y) {\n        value += deltas[deltasY][deltasX];\n      }\n    }\n  }\n\n  return value;\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis<ICompareConstants>,\n  deltas: number[][][],\n  switchY: number[][][],\n  switchX: number[][][]\n): number {\n  const x = Math.floor(\n    (this.thread.x / this.output.x) * this.constants.outputWidth\n  );\n  const y = Math.floor(\n    (this.thread.y / this.output.y) * this.constants.outputHeight\n  );\n\n  let value = 0;\n\n  for (let deltasY = 0; deltasY < this.constants.inputHeight; deltasY++) {\n    for (let deltasX = 0; deltasX < this.constants.inputWidth; deltasX++) {\n      const switchXValue = switchX[this.thread.z][deltasY][deltasX];\n      const switchYValue = switchY[this.thread.z][deltasY][deltasX];\n      if (switchXValue === x && switchYValue === y) {\n        value += deltas[this.thread.z][deltasY][deltasX];\n      }\n    }\n  }\n\n  return value;\n}\n\nexport interface IPoolSettings\n  extends ILayerSettings,\n    IConvolutionSettingsBase {\n  switchX?: KernelOutput;\n  switchY?: KernelOutput;\n}\n\nexport const defaults: IPoolSettings = {\n  padding: 0,\n  stride: 0,\n  filterWidth: 0,\n  filterHeight: 0,\n  filterCount: 0,\n};\n\nexport class Pool extends Filter {\n  settings: Partial<IPoolSettings>;\n\n  get strideX(): number {\n    return this.settings.strideX as number;\n  }\n\n  get strideY(): number {\n    return this.settings.strideY as number;\n  }\n\n  get paddingX(): number {\n    return this.settings.paddingX as number;\n  }\n\n  get paddingY(): number {\n    return this.settings.paddingY as number;\n  }\n\n  get width(): number {\n    return Math.floor(\n      (this.inputLayer.width + this.paddingX * 2 - this.filterWidth) /\n        this.strideX +\n        1\n    );\n  }\n\n  get height(): number {\n    return Math.floor(\n      (this.inputLayer.height + this.paddingY * 2 - this.filterHeight) /\n        this.strideY +\n        1\n    );\n  }\n\n  get depth(): number {\n    return this.settings.filterCount as number;\n  }\n\n  get filterCount(): number {\n    // TODO: handle 1 depth?\n    return this.settings.filterCount as number;\n  }\n\n  get switchX(): KernelOutput {\n    return this.settings.switchX;\n  }\n\n  set switchX(switchX: KernelOutput) {\n    this.settings.switchX = switchX;\n  }\n\n  get switchY(): KernelOutput {\n    return this.settings.switchY;\n  }\n\n  set switchY(switchY: KernelOutput) {\n    this.settings.switchY = switchY;\n  }\n\n  predictKernelMap: IKernelMapRunShortcut<ISubKernelObject> | null = null;\n  constructor(settings: IPoolSettings, inputLayer: ILayer) {\n    super(settings, inputLayer);\n    this.settings = {\n      ...settings,\n      ...getStride(settings, defaults),\n      ...getPadding(settings, defaults),\n    };\n\n    this.weights = randos3D(this.width, this.height, this.depth);\n    this.deltas = zeros3D(this.width, this.height, this.depth);\n\n    this.filters = randos3D(\n      this.filterWidth,\n      this.filterHeight,\n      this.filterCount\n    );\n    this.filterDeltas = zeros3D(\n      this.filterWidth,\n      this.filterHeight,\n      this.filterCount\n    );\n    this.validate();\n  }\n\n  setupKernels(): void {\n    this.predictKernelMap = makeKernelMap<\n      Parameters<typeof predict>,\n      IPredictConstants\n    >(\n      {\n        switchX: setSwitchX,\n        switchY: setSwitchY,\n      },\n      predict,\n      {\n        output: [this.width, this.height, this.depth],\n        constants: {\n          inputWidth: this.inputLayer.width,\n          inputHeight: this.inputLayer.height,\n          paddingX: this.paddingX,\n          paddingY: this.paddingY,\n          filterHeight: this.filterHeight,\n          filterWidth: this.filterWidth,\n        },\n      }\n    );\n\n    this.compareKernel = makeKernel(compare, {\n      output: [\n        this.inputLayer.width,\n        this.inputLayer.height,\n        this.inputLayer.depth,\n      ],\n      constants: {\n        inputWidth: this.inputLayer.width,\n        inputHeight: this.inputLayer.height,\n\n        outputWidth: this.width,\n        outputHeight: this.height,\n      },\n    });\n  }\n\n  predict(): void {\n    const { result: weights, switchX, switchY } = (this\n      .predictKernelMap as IKernelMapRunShortcut<ISubKernelObject>)(\n      this.inputLayer.weights\n    );\n    this.switchX = switchX;\n    this.switchY = switchY;\n    this.weights = weights;\n  }\n\n  compare(): void {\n    // debugger;\n    // const depth = this.inputLayer.deltas.length;\n    // const height = this.inputLayer.deltas[0].length;\n    // const width = this.inputLayer.deltas[0][0].length;\n    // const type = typeof this.inputLayer.deltas[0][0][0];\n    const inputLayerDeltas = this.inputLayer.deltas;\n    this.inputLayer.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.deltas,\n      this.switchX,\n      this.switchY\n    );\n    release(inputLayerDeltas);\n    // debugger;\n    // if (depth !== this.inputLayer.deltas.length) debugger;\n    // if (height !== this.inputLayer.deltas[0].length) debugger;\n    // if (width !== this.inputLayer.deltas[0][0].length) debugger;\n    // if (type !== typeof this.inputLayer.deltas[0][0][0]) debugger;\n  }\n}\n\nexport function pool(settings: IPoolSettings, inputLayer: ILayer): Pool {\n  return new Pool(settings, inputLayer);\n}\n","import { KernelOutput } from 'gpu.js';\nimport { IPraxis } from '../praxis/base-praxis';\nimport { release } from '../utilities/kernel';\nimport { BaseLayer, ILayer } from './base-layer';\nimport { Internal } from './internal';\n\nexport interface IRecurrentInput extends ILayer {\n  setDimensions?: (width: number, height: number) => void;\n}\n\nexport class RecurrentInput extends Internal implements IRecurrentInput {\n  recurrentInput: ILayer;\n  praxis: IPraxis | null = null;\n  predictKernel = null;\n  compareKernel = null;\n  settings = {};\n  constructor(recurrentInput: ILayer) {\n    super();\n    this.recurrentInput = recurrentInput;\n    this.validate();\n  }\n\n  get width(): number {\n    return this.recurrentInput.width;\n  }\n\n  get height(): number {\n    return this.recurrentInput.height;\n  }\n\n  get depth(): number {\n    return this.recurrentInput.depth;\n  }\n\n  get deltas(): KernelOutput {\n    return this.recurrentInput.deltas;\n  }\n\n  set deltas(deltas: KernelOutput) {\n    const recurrentInputDeltas = this.recurrentInput.deltas;\n    this.recurrentInput.deltas = deltas;\n    release(recurrentInputDeltas);\n  }\n\n  get weights(): KernelOutput {\n    return this.recurrentInput.weights as KernelOutput;\n  }\n\n  set weights(weights: KernelOutput) {\n    const recurrentInputWeights = this.recurrentInput.weights;\n    this.recurrentInput.weights = weights;\n    release(recurrentInputWeights);\n  }\n\n  validate(): void {\n    BaseLayer.prototype.validate.call(this);\n    if (this.width !== this.recurrentInput.width) {\n      throw new Error(\n        `${this.constructor.name} layer width ${this.width} and ${this.recurrentInput.constructor.name} width (${this.recurrentInput.width}) are not same`\n      );\n    }\n\n    if (this.height !== this.recurrentInput.height) {\n      throw new Error(\n        `${this.constructor.name} layer height ${this.height} and ${this.recurrentInput.constructor.name} width (${this.recurrentInput.height}) are not same`\n      );\n    }\n  }\n\n  setDimensions(width: number, height: number): void {\n    this.recurrentInput.width = width;\n    this.recurrentInput.height = height;\n  }\n\n  predict(): void {\n    // throw new Error(`${this.constructor.name}-predict is not yet implemented`)\n  }\n\n  compare(): void {\n    // throw new Error(`${this.constructor.name}-compare is not yet implemented`)\n  }\n\n  learn(): void {\n    // throw new Error(`${this.constructor.name}-learn is not yet implemented`)\n  }\n\n  setupKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-setupKernels is not yet implemented`\n    // )\n  }\n\n  reuseKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-reuseKernels is not yet implemented`\n    // )\n  }\n}\n","import { IPraxis } from '../praxis/base-praxis';\nimport { clear, release } from '../utilities/kernel';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { ILayerSettings } from './base-layer';\nimport { Internal } from './internal';\nimport { IRecurrentInput } from './recurrent-input';\n\nexport class RecurrentZeros extends Internal implements IRecurrentInput {\n  praxis: IPraxis | null = null;\n  settings: Partial<ILayerSettings> = {};\n  predictKernel = null;\n  compareKernel = null;\n\n  constructor(settings?: Partial<ILayerSettings>) {\n    super();\n    if (settings) {\n      this.settings = { ...settings };\n    }\n  }\n\n  setDimensions(width: number, height: number): void {\n    this.praxis = null;\n    this.settings = {\n      ...this.settings,\n      width,\n      height,\n      weights: zeros2D(width, height),\n      deltas: zeros2D(width, height),\n    };\n  }\n\n  setupKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-setupKernels is not yet implemented`\n    // )\n  }\n\n  reuseKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-reuseKernels is not yet implemented`\n    // )\n  }\n\n  predict(): void {\n    // throw new Error(`${this.constructor.name}-predict is not yet implemented`)\n  }\n\n  compare(): void {\n    // throw new Error(`${this.constructor.name}-compare is not yet implemented`)\n  }\n\n  learn(learningRate: number): void {\n    const { weights: oldWeights } = this;\n    this.weights = (this.praxis as IPraxis).run(this, learningRate);\n    // this.deltas = deltas;\n    release(oldWeights);\n    clear(this.deltas);\n  }\n\n  // validate(): void {\n  //   throw new Error(`${this.constructor.name}-validate is not yet implemented`);\n  // }\n\n  // reset(): void {\n  //   throw new Error(`${this.constructor.name}-reset is not yet implemented`);\n  // }\n}\n\nexport function recurrentZeros(): RecurrentZeros {\n  return new RecurrentZeros();\n}\n","import { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\n\nimport { Activation } from './types';\nimport { makeKernel, release, clear } from '../utilities/kernel';\nimport { activate, measure } from '../activation/relu';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function predict2D(\n  this: IKernelFunctionThis,\n  inputs: number[][]\n): number {\n  return activate(inputs[this.thread.y][this.thread.x]);\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  weights: number[][],\n  deltas: number[][]\n): number {\n  return measure(\n    weights[this.thread.y][this.thread.x],\n    deltas[this.thread.y][this.thread.x]\n  );\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis,\n  inputs: number[][][]\n): number {\n  return activate(inputs[this.thread.z][this.thread.y][this.thread.x]);\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis,\n  weights: number[][][],\n  deltas: number[][][]\n): number {\n  return measure(\n    weights[this.thread.z][this.thread.y][this.thread.x],\n    deltas[this.thread.z][this.thread.y][this.thread.x]\n  );\n}\n\nexport class Relu extends Activation {\n  setupKernels(): void {\n    const { width, height, depth } = this.inputLayer;\n    if (depth > 0) {\n      this.predictKernel = makeKernel(predict3D, {\n        output: [width, height, depth],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare3D, {\n        output: [width, height, depth],\n        functions: [measure],\n        immutable: true,\n      });\n    } else {\n      this.predictKernel = makeKernel(predict2D, {\n        output: [width, height],\n        functions: [activate],\n        immutable: true,\n      });\n\n      this.compareKernel = makeKernel(compare2D, {\n        output: [width, height],\n        functions: [measure],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    release(this.inputLayer.deltas);\n    this.inputLayer.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.weights,\n      this.deltas\n    );\n  }\n}\n\nexport function relu(inputLayer: ILayer, settings?: ILayerSettings): Relu {\n  return new Relu(inputLayer, settings);\n}\n","import { IKernelFunctionThis, KernelOutput } from 'gpu.js';\n\nimport { BaseLayer, ILayer, ILayerSettings } from './base-layer';\nimport { clone, release } from '../utilities/kernel';\n\nexport class Regression extends BaseLayer {\n  inputLayer: ILayer;\n  constructor(settings: ILayerSettings, inputLayer: ILayer) {\n    super(settings);\n    this.inputLayer = inputLayer;\n    this.validate();\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = clone(this.inputLayer.weights as KernelOutput);\n  }\n\n  learn(): void {\n    // throw new Error(`${this.constructor.name}-learn is not yet implemented`)\n  }\n}\n\n// TODO: Connect up\nexport function learn(\n  this: IKernelFunctionThis,\n  inputs: number[],\n  targets: number[]\n): number {\n  return inputs[this.thread.x] - targets[this.thread.x];\n}\n\n// TODO: handle `loss += 0.5*dy*dy;` total and sum in learn\nexport function regression(\n  settings: ILayerSettings,\n  inputLayer: ILayer\n): Regression {\n  return new Regression(settings, inputLayer);\n}\n","import {\n  IConstantsThis,\n  IKernelFunctionThis,\n  IKernelRunShortcut,\n  KernelOutput,\n  Texture,\n} from 'gpu.js';\n\nimport { makeKernel, release, clone } from '../utilities/kernel';\nimport { randos, randos2D, randos3D } from '../utilities/randos';\nimport { zeros } from '../utilities/zeros';\nimport { zeros2D } from '../utilities/zeros-2d';\nimport { zeros3D } from '../utilities/zeros-3d';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { Modifier } from './modifier';\n\ninterface ISoftMaxConstants extends IConstantsThis {\n  inputWidth: number;\n}\n\nexport function getMaxValue(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[]\n): number {\n  let maxInput = -Infinity;\n  for (let x = 0; x < this.constants.inputWidth; x++) {\n    const input = inputs[x];\n    if (input > maxInput) {\n      maxInput = input;\n    }\n  }\n  return maxInput;\n}\n\nexport function getMaxValue2D(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[][]\n): number {\n  let maxInput = -Infinity;\n  for (let y = 0; y < this.constants.inputHeight; y++) {\n    for (let x = 0; x < this.constants.inputWidth; x++) {\n      const input = inputs[y][x];\n      if (input > maxInput) {\n        maxInput = input;\n      }\n    }\n  }\n  return maxInput;\n}\n\nexport function getMaxValue3D(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[][][]\n): number {\n  let maxInput = -Infinity;\n  for (let z = 0; z < this.constants.inputDepth; z++) {\n    for (let y = 0; y < this.constants.inputHeight; y++) {\n      for (let x = 0; x < this.constants.inputWidth; x++) {\n        const input = inputs[z][y][x];\n        if (input > maxInput) {\n          maxInput = input;\n        }\n      }\n    }\n  }\n  return maxInput;\n}\n\nexport function getSum(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[]\n): number {\n  let sum = 0;\n  for (let x = 0; x < this.constants.inputWidth; x++) {\n    sum += inputs[x];\n  }\n  return sum;\n}\n\nexport function getSum2D(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[][]\n): number {\n  let sum = 0;\n  for (let y = 0; y < this.constants.inputHeight; y++) {\n    for (let x = 0; x < this.constants.inputWidth; x++) {\n      sum += inputs[y][x];\n    }\n  }\n  return sum;\n}\n\nexport function getSum3D(\n  this: IKernelFunctionThis<ISoftMaxConstants>,\n  inputs: number[][][]\n): number {\n  let sum = 0;\n  for (let z = 0; z < this.constants.inputDepth; z++) {\n    for (let y = 0; y < this.constants.inputHeight; y++) {\n      for (let x = 0; x < this.constants.inputWidth; x++) {\n        sum += inputs[z][y][x];\n      }\n    }\n  }\n  return sum;\n}\n\nexport function getExponentials(\n  this: IKernelFunctionThis,\n  inputs: number[],\n  maxInput: number[]\n): number {\n  return Math.exp(inputs[this.thread.x] - maxInput[0]);\n}\n\nexport function getExponentials2D(\n  this: IKernelFunctionThis,\n  inputs: number[][],\n  maxInput: number[]\n): number {\n  return Math.exp(inputs[this.thread.y][this.thread.x] - maxInput[0]);\n}\n\nexport function getExponentials3D(\n  this: IKernelFunctionThis,\n  inputs: number[][][],\n  maxInput: number[]\n): number {\n  return Math.exp(\n    inputs[this.thread.z][this.thread.y][this.thread.x] - maxInput[0]\n  );\n}\n\nexport function predict(\n  this: IKernelFunctionThis,\n  exponentials: number[],\n  exponentialsSum: number[]\n): number {\n  return exponentials[this.thread.x] / exponentialsSum[0];\n}\n\nexport function predict2D(\n  this: IKernelFunctionThis,\n  exponentials: number[][],\n  exponentialsSum: number[]\n): number {\n  return exponentials[this.thread.y][this.thread.x] / exponentialsSum[0];\n}\n\nexport function predict3D(\n  this: IKernelFunctionThis,\n  exponentials: number[][][],\n  exponentialsSum: number[]\n): number {\n  return (\n    exponentials[this.thread.z][this.thread.y][this.thread.x] /\n    exponentialsSum[0]\n  );\n}\n\nexport function compare(\n  this: IKernelFunctionThis,\n  target: number,\n  exponentials: number[]\n): number {\n  let indicator = 0;\n  if (this.thread.x === target) {\n    indicator = 1;\n  }\n  return -(indicator - exponentials[this.thread.x]);\n}\n\nexport function compare2D(\n  this: IKernelFunctionThis,\n  target: number,\n  exponentials: number[][]\n): number {\n  let indicator = 0;\n  const index = this.thread.x + this.thread.y * this.output.x;\n  if (index === target) {\n    indicator = 1;\n  }\n  return -(indicator - exponentials[this.thread.y][this.thread.x]);\n}\n\nexport function compare3D(\n  this: IKernelFunctionThis,\n  target: number,\n  exponentials: number[][][]\n): number {\n  let indicator = 0;\n  const index =\n    this.thread.x +\n    this.thread.y * this.output.x +\n    this.thread.z * this.output.x * this.output.y;\n  if (index === target) {\n    indicator = 1;\n  }\n  return -(\n    indicator - exponentials[this.thread.z][this.thread.y][this.thread.x]\n  );\n}\n\nexport function loss(): number {\n  return -Math.log(0);\n}\n\n// TODO: handle: `return -Math.log(this.es[y]);` in learn\n\nexport class SoftMax extends Modifier {\n  getExponentialsKernel: IKernelRunShortcut | null;\n  getMaxValueKernel: IKernelRunShortcut | null;\n  getSumKernel: IKernelRunShortcut | null;\n  errors: KernelOutput | null = null;\n  constructor(inputLayer: ILayer, settings?: ILayerSettings) {\n    super(inputLayer, settings);\n    this.getExponentialsKernel = null;\n    this.getMaxValueKernel = null;\n    this.getSumKernel = null;\n    this.validate();\n\n    if (this.depth > 0) {\n      this.weights = randos3D(this.width, this.height, this.depth);\n      this.deltas = zeros3D(this.width, this.height, this.depth);\n    } else if (this.height > 0) {\n      this.weights = randos2D(this.width, this.height);\n      this.deltas = zeros2D(this.width, this.height);\n    } else {\n      this.weights = randos(this.width);\n      this.deltas = zeros(this.width);\n    }\n  }\n\n  setupKernels(): void {\n    const { width, height, depth } = this;\n    if (depth > 0) {\n      this.getExponentialsKernel = makeKernel(getExponentials3D, {\n        output: [width, height, depth],\n      });\n      this.getMaxValueKernel = makeKernel(getMaxValue3D, {\n        output: [1, 1, 1],\n        constants: {\n          inputWidth: width,\n          inputHeight: height,\n          inputDepth: depth,\n        },\n      });\n      this.getSumKernel = makeKernel(getSum3D, {\n        output: [1, 1, 1],\n        constants: {\n          inputWidth: width,\n          inputHeight: height,\n          inputDepth: depth,\n        },\n      });\n      this.predictKernel = makeKernel(predict3D, {\n        output: [width, height, depth],\n      });\n      this.compareKernel = makeKernel(compare3D, {\n        output: [width, height, depth],\n        immutable: true,\n      });\n    } else {\n      this.getExponentialsKernel = makeKernel(getExponentials, {\n        output: [width, height],\n      });\n      this.getMaxValueKernel = makeKernel(getMaxValue2D, {\n        output: [1, 1],\n        constants: {\n          inputWidth: width,\n          inputHeight: height,\n        },\n      });\n      this.getSumKernel = makeKernel(getSum2D, {\n        output: [1, 1],\n        constants: {\n          inputWidth: width,\n          inputHeight: height,\n        },\n      });\n      this.predictKernel = makeKernel(predict2D, {\n        output: [width, height],\n      });\n      this.compareKernel = makeKernel(compare2D, {\n        output: [width, height],\n        immutable: true,\n      });\n    }\n  }\n\n  predict(): void {\n    const maxValue = (this.getMaxValueKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    const exponentials = (this.getExponentialsKernel as IKernelRunShortcut)(\n      this.inputLayer.weights,\n      maxValue\n    );\n    const exponentialsSum = (this.getSumKernel as IKernelRunShortcut)(\n      exponentials\n    );\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      exponentials,\n      exponentialsSum\n    );\n  }\n\n  compare(targetValues: KernelOutput): void {\n    const { deltas, errors } = this;\n    this.errors = (this.compareKernel as IKernelRunShortcut)(\n      (targetValues as number[])[0],\n      deltas\n    );\n    this.deltas = clone(this.errors);\n    release(deltas);\n    release(errors as Texture);\n\n    const inputLayerDeltas = this.inputLayer.deltas;\n    this.inputLayer.deltas = clone(this.deltas);\n    release(inputLayerDeltas);\n  }\n}\n\nexport function softMax(\n  inputLayer: ILayer,\n  settings?: ILayerSettings\n): SoftMax {\n  return new SoftMax(inputLayer, settings);\n}\n","import { KernelOutput } from 'gpu.js';\n\nimport { BaseLayer, ILayer, ILayerSettings } from './base-layer';\nimport { clone, release } from '../utilities/kernel';\n\nexport class SVM extends BaseLayer {\n  inputLayer: ILayer;\n  constructor(inputLayer: ILayer, settings: ILayerSettings) {\n    super(settings);\n    this.inputLayer = inputLayer;\n  }\n\n  predict(): void {\n    release(this.weights);\n    this.weights = clone(this.inputLayer.weights as KernelOutput);\n    this.validate();\n  }\n\n  learn(): void {\n    // throw new Error(`${this.constructor.name}-learn is not yet implemented`)\n  }\n}\n\n// function learn(target) {\n//   if (y === i) {\n//     continue;\n//   }\n//   const ydiff = -yscore + x.w[i] + margin;\n//   if (ydiff > 0) {\n//     // violating dimension, apply loss\n//     x.dw[i] += 1;\n//     x.dw[y] -= 1;\n//     loss += ydiff;\n//   }\n// }\n\nexport function svm(inputLayer: ILayer, settings: ILayerSettings): SVM {\n  return new SVM(inputLayer, settings);\n}\n","import { IKernelFunctionThis, IKernelRunShortcut } from 'gpu.js';\nimport { clear, makeKernel } from '../utilities/kernel';\nimport { ILayer } from './base-layer';\nimport { Modifier } from './types';\n\nexport function predict(this: IKernelFunctionThis, value: number[][]): number {\n  return value[this.thread.x][this.thread.y];\n}\n\nconst compare = predict;\n\nexport class Transpose extends Modifier {\n  get width(): number {\n    return this.inputLayer.height;\n  }\n\n  get height(): number {\n    return this.inputLayer.width;\n  }\n\n  constructor(inputLayer: ILayer) {\n    super(inputLayer);\n    this.validate();\n  }\n\n  setupKernels(): void {\n    this.predictKernel = makeKernel(predict, {\n      output: [this.height, this.width],\n    });\n    this.compareKernel = makeKernel(compare, {\n      output: [this.width, this.height],\n    });\n  }\n\n  predict(): void {\n    this.weights = (this.predictKernel as IKernelRunShortcut)(\n      this.inputLayer.weights\n    );\n    clear(this.deltas);\n  }\n\n  compare(): void {\n    this.inputLayer.deltas = (this.compareKernel as IKernelRunShortcut)(\n      this.deltas\n    );\n  }\n}\n\nexport function transpose(inputLayer: ILayer): Transpose {\n  return new Transpose(inputLayer);\n}\n","import {\n  Activation,\n  EntryPoint,\n  Filter,\n  Internal,\n  InternalModel,\n  Model,\n  Modifier,\n  Operator,\n  Target,\n} from './types';\n\nexport { Add, add } from './add';\nexport { arthurFeedForward } from './arthur-feed-forward';\nexport {\n  BaseLayer,\n  ILayer,\n  ILayerSettings,\n  ILayerJSON,\n  baseLayerDefaultSettings,\n} from './base-layer';\nexport { Convolution, convolution } from './convolution';\nexport { Dropout, dropout } from './dropout';\nexport { feedForward } from './feed-forward';\nexport { FullyConnected, fullyConnected } from './fully-connected';\nexport { gru } from './gru';\nexport { Input, input } from './input';\nexport { LeakyRelu, leakyRelu } from './leaky-relu';\nexport { lstmCell } from './lstm-cell';\nexport { Multiply, multiply } from './multiply';\nexport { MultiplyElement, multiplyElement } from './multiply-element';\nexport { Negative, negative } from './negative';\nexport { Ones, ones } from './ones';\nexport { output } from './output';\nexport { Pool, pool } from './pool';\nexport { Random, random } from './random';\nexport { RecurrentInput, IRecurrentInput } from './recurrent-input';\nexport { RecurrentZeros } from './recurrent-zeros';\nexport { rnnCell } from './rnn-cell';\nexport { Regression, regression } from './regression';\nexport { Relu, relu } from './relu';\nexport { Sigmoid, sigmoid } from './sigmoid';\nexport { SoftMax, softMax } from './soft-max';\nexport { SVM, svm } from './svm';\nexport { Tanh, tanh } from './tanh';\nexport { Target, target } from './target';\nexport { Transpose, transpose } from './transpose';\nexport { Zeros, zeros } from './zeros';\n\nexport const layerTypes = {\n  Activation,\n  Internal,\n  InternalModel,\n  EntryPoint,\n  Filter,\n  Model,\n  Modifier,\n  Operator,\n  Target,\n};\n","import {\n  ArthurDeviationWeights,\n  arthurDeviationWeights,\n  IArthurDeviationWeightsSettings,\n} from '../praxis/arthur-deviation-weights';\nimport {\n  arthurDeviationBiases,\n  IArthurDeviationBiasesSettings,\n} from '../praxis/arthur-deviation-biases';\nimport { ILayer } from './base-layer';\nimport { add } from './add';\nimport { IRandomSettings, random } from './random';\nimport { multiply } from './multiply';\nimport { Sigmoid, sigmoid } from './sigmoid';\nimport { IPraxis } from '../praxis/base-praxis';\n\nexport interface IArthurFeedForwardPraxisSettings\n  extends IArthurDeviationBiasesSettings,\n    IArthurDeviationWeightsSettings {}\n\nexport interface IArthurFeedForwardSettings extends IRandomSettings {\n  initPraxis?: (\n    layerTemplate: ILayer,\n    settings?: IArthurFeedForwardPraxisSettings | null\n  ) => IPraxis;\n}\n\nexport function arthurFeedForward(\n  settings: IArthurFeedForwardPraxisSettings,\n  inputLayer: ILayer\n): Sigmoid {\n  const { height } = settings;\n  function initWeightsPraxis(\n    layerTemplate: ILayer,\n    settings?: IArthurDeviationWeightsSettings\n  ): IPraxis {\n    const praxis = arthurDeviationWeights(layerTemplate, settings);\n    praxis.setupKernels();\n    return praxis;\n  }\n  function initBiasesPraxis(\n    layerTemplate: ILayer,\n    settings?: IArthurDeviationBiasesSettings\n  ): IPraxis {\n    const praxis = arthurDeviationBiases(layerTemplate, settings);\n    praxis.setupKernels();\n    return praxis;\n  }\n  const weightsLayer = random({\n    id: 'weights',\n    height,\n    width: inputLayer.height,\n    initPraxis: initWeightsPraxis,\n  });\n\n  const biasesLayer = random({\n    id: 'biases',\n    height,\n    initPraxis: initBiasesPraxis,\n  });\n\n  const multiplyLayer = multiply(weightsLayer, inputLayer);\n  const addLayer = add(multiplyLayer, biasesLayer);\n  const sigmoidLayer = sigmoid(addLayer);\n\n  const weightsPraxis = weightsLayer.praxis as ArthurDeviationWeights;\n  weightsPraxis.weightsLayer = weightsLayer;\n  weightsPraxis.incomingLayer = inputLayer;\n  weightsPraxis.deltaLayer = sigmoidLayer;\n  return sigmoidLayer;\n}\n","import { random } from './random';\nimport { add } from './add';\nimport { multiply } from './multiply';\nimport { sigmoid } from './sigmoid';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function feedForward(settings: ILayerSettings, input: ILayer): ILayer {\n  const { height, praxisOpts = null } = settings;\n  const weights = random({\n    id: 'weights',\n    height,\n    width: input.height,\n    praxisOpts,\n  });\n  const biases = random({ id: 'biases', height, praxisOpts });\n  return sigmoid(\n    add(multiply(weights, input, { praxisOpts }), biases, { praxisOpts }),\n    { praxisOpts }\n  );\n}\n","import { add } from './add';\nimport { negative } from './negative';\nimport { multiply } from './multiply';\nimport { multiplyElement } from './multiply-element';\nimport { ones } from './ones';\nimport { sigmoid } from './sigmoid';\nimport { random } from './random';\nimport { tanh } from './tanh';\nimport { zeros } from './zeros';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { RecurrentInput } from './recurrent-input';\n\nexport function gru(\n  settings: ILayerSettings,\n  recurrentInput: RecurrentInput,\n  input: ILayer\n): ILayer {\n  const { height } = settings;\n  const updateGateWeights = random({ height, width: input.height });\n  const updateGatePeepholes = random({ width: height, height });\n  const updateGateBias = zeros({ height });\n  const updateGate = sigmoid(\n    add(\n      add(\n        multiply(updateGateWeights, input),\n        multiply(updateGatePeepholes, recurrentInput)\n      ),\n      updateGateBias\n    )\n  );\n\n  const resetGateWeights = random({ height, width: input.height });\n  const resetGatePeepholes = random({ width: height, height });\n  const resetGateBias = zeros({ height });\n  const resetGate = sigmoid(\n    add(\n      add(\n        multiply(resetGateWeights, input),\n        multiply(resetGatePeepholes, recurrentInput)\n      ),\n      resetGateBias\n    )\n  );\n\n  const cellWeights = random({ height, width: input.height });\n  const cellPeepholes = random({ width: height, height });\n  const cellBias = zeros({ height });\n  const cell = tanh(\n    add(\n      add(\n        multiply(cellWeights, input),\n        multiply(cellPeepholes, multiplyElement(resetGate, recurrentInput))\n      ),\n      cellBias\n    )\n  );\n\n  // compute hidden state as gated, saturated cell activations\n  // negate updateGate\n  return add(\n    multiplyElement(\n      add(\n        ones({ width: updateGate.width, height: updateGate.height }),\n        negative(updateGate)\n      ),\n      cell\n    ),\n    multiplyElement(recurrentInput, updateGate)\n  );\n}\n","import { add } from './add';\nimport { multiply } from './multiply';\nimport { multiplyElement } from './multiply-element';\nimport { random } from './random';\nimport { sigmoid } from './sigmoid';\nimport { tanh } from './tanh';\nimport { zeros } from './zeros';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { IRecurrentInput } from './recurrent-input';\n\nexport function lstmCell(\n  settings: ILayerSettings,\n  input: ILayer,\n  recurrentInput: IRecurrentInput\n): ILayer {\n  const { height } = settings;\n\n  if (typeof height !== 'number') {\n    throw new Error('no settings.height given');\n  }\n  if (recurrentInput.setDimensions) {\n    recurrentInput.setDimensions(1, height);\n  }\n\n  const inputGateWeights = random({\n    height,\n    width: input.height,\n    std: 0.08,\n    id: 'inputGateWeights',\n  });\n  const inputGatePeepholes = random({\n    width: height,\n    height,\n    std: 0.08,\n    id: 'inputGatePeepholes',\n  });\n  const inputGateBias = zeros({ height, id: 'inputGateBias' });\n  const inputGate = sigmoid(\n    add(\n      add(\n        multiply(inputGateWeights, input),\n        multiply(inputGatePeepholes, recurrentInput)\n      ),\n      inputGateBias\n    ),\n    { id: 'inputGate' }\n  );\n\n  const forgetGateWeights = random({\n    height,\n    width: input.height,\n    std: 0.08,\n    id: 'forgetGateWeights',\n  });\n  const forgetGatePeepholes = random({\n    width: height,\n    height,\n    std: 0.08,\n    id: 'forgetGatePeepholes',\n  });\n  const forgetGateBias = zeros({ height, id: 'forgetGateBias' });\n  const forgetGate = sigmoid(\n    add(\n      add(\n        multiply(forgetGateWeights, input),\n        multiply(forgetGatePeepholes, recurrentInput)\n      ),\n      forgetGateBias\n    ),\n    { id: 'forgetGate' }\n  );\n\n  const outputGateWeights = random({\n    height,\n    width: input.height,\n    std: 0.08,\n    id: 'outputGateWeights',\n  });\n  const outputGatePeepholes = random({\n    width: height,\n    height,\n    std: 0.08,\n    id: 'outputGatePeepholes',\n  });\n  const outputGateBias = zeros({ height, id: 'outputGateBias' });\n  const outputGate = sigmoid(\n    add(\n      add(\n        multiply(outputGateWeights, input),\n        multiply(outputGatePeepholes, recurrentInput)\n      ),\n      outputGateBias\n    ),\n    { id: 'outputGate' }\n  );\n\n  const memoryWeights = random({\n    height,\n    width: input.height,\n    std: 0.08,\n    id: 'memoryWeights',\n  });\n  const memoryPeepholes = random({\n    width: height,\n    height,\n    std: 0.08,\n    id: 'memoryPeepholes',\n  });\n  const memoryBias = zeros({ height, id: 'memoryBias' });\n  const memory = tanh(\n    add(\n      add(\n        multiply(memoryWeights, input),\n        multiply(memoryPeepholes, recurrentInput)\n      ),\n      memoryBias\n    ),\n    { id: 'memory' }\n  );\n\n  // compute new cell activation\n  const retainCell = multiplyElement(forgetGate, recurrentInput, {\n    id: 'retainCell',\n  }); // what do we keep from cell\n  const writeCell = multiplyElement(inputGate, memory, { id: 'writeCell' }); // what do we write to cell\n  const cell = add(retainCell, writeCell, { id: 'cell' }); // new cell contents\n\n  // compute hidden state as gated, saturated cell activations\n  return multiplyElement(outputGate, tanh(cell), { id: 'activations' });\n}\n","import { add } from './add';\nimport { multiply } from './multiply';\nimport { random } from './random';\nimport { target } from './target';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport function output(settings: ILayerSettings, inputLayer: ILayer): ILayer {\n  const { height } = settings;\n  const outputGate = random({\n    height,\n    width: inputLayer.height,\n    id: 'outputGate',\n    std: 0.08,\n  });\n  const output = random({ height, id: 'output', std: 0.08 });\n  const outputGateConnector = multiply(outputGate, inputLayer, {\n    id: 'outputGateConnected',\n  });\n  return target(\n    { id: 'target', ...settings },\n    add(outputGateConnector, output)\n  );\n}\n","import { add } from './add';\nimport { ILayer, ILayerSettings } from './base-layer';\nimport { multiply } from './multiply';\nimport { random } from './random';\nimport { relu } from './relu';\nimport { zeros } from './zeros';\nimport { IRecurrentInput } from './recurrent-input';\n\nexport function rnnCell(\n  settings: ILayerSettings,\n  input: ILayer,\n  recurrentInput: IRecurrentInput\n): ILayer {\n  const { height } = settings;\n\n  if (typeof height !== 'number') throw new Error('height not set');\n  if (recurrentInput.setDimensions) {\n    recurrentInput.setDimensions(1, height);\n  }\n\n  // wxh\n  const weight = random({\n    id: 'weight',\n    height,\n    width: input.height,\n    std: 0.08,\n  });\n  // whh\n  const transition = random({\n    id: 'transition',\n    height,\n    width: height,\n    std: 0.08,\n  });\n  // bhh\n  const bias = zeros({ id: 'bias', height });\n\n  return relu(\n    add(\n      add(multiply(weight, input), multiply(transition, recurrentInput)),\n      bias\n    )\n  );\n}\n","import * as layer from '../layer';\nimport { layerTypes, ILayerJSON, ILayer, Target } from '../layer';\nimport { ActivationType } from '../layer/activation';\nimport { FilterType } from '../layer/filter';\nimport { InternalType } from '../layer/internal';\nimport { ModifierType } from '../layer/modifier';\nimport { OperatorType } from '../layer/operator';\nimport { BaseLayerType } from '../layer/base-layer';\nimport { TargetType } from '../layer/target';\n\nconst layerNameTypes = Object.keys(layer);\n\nexport function layerFromJSON(\n  jsonLayer: ILayerJSON,\n  inputLayer1?: ILayer,\n  inputLayer2?: ILayer\n): ILayer | null {\n  if (\n    !layerNameTypes.find((layerNameType) => layerNameType === jsonLayer.type)\n  ) {\n    return null;\n  }\n  const Layer = ((layer as unknown) as {\n    [layerType: string]:\n      | TargetType\n      | ActivationType\n      | FilterType\n      | InternalType\n      | ModifierType\n      | OperatorType;\n  })[jsonLayer.type];\n  if (Layer.prototype instanceof layerTypes.Filter) {\n    if (!inputLayer1) throw new Error('inputLayer missing');\n    return new (Layer as FilterType)(jsonLayer, inputLayer1);\n  } else if (\n    Layer.prototype instanceof layerTypes.Activation ||\n    Layer.prototype instanceof layerTypes.Modifier\n  ) {\n    if (!inputLayer1) throw new Error('inputLayer missing');\n    return new (Layer as ActivationType)(inputLayer1, jsonLayer);\n  } else if (Layer.prototype instanceof layerTypes.Internal) {\n    return new (Layer as InternalType)(jsonLayer);\n  } else if (Layer.prototype instanceof layerTypes.Operator) {\n    if (!inputLayer1) throw new Error('inputLayer1 missing');\n    if (!inputLayer2) throw new Error('inputLayer2 missing');\n    return new (Layer as OperatorType)(inputLayer1, inputLayer2, jsonLayer);\n  } else if (\n    Layer.prototype instanceof layerTypes.InternalModel ||\n    Layer.prototype instanceof layerTypes.EntryPoint ||\n    Layer.prototype instanceof layerTypes.Model\n  ) {\n    return new (Layer as BaseLayerType)(jsonLayer);\n  } else if (Layer === Target) {\n    if (!inputLayer1) throw new Error('inputLayer missing');\n    return new (Layer as TargetType)(jsonLayer, inputLayer1);\n  }\n  return null;\n}\n","import { InputOutputValue, INumberHash, ITrainingDatum } from '../lookup';\n\nexport type LookupTableProp = 'input' | 'output';\n\nexport class LookupTable {\n  length: number;\n  prop: LookupTableProp | null = null;\n  table: INumberHash = {};\n  constructor(\n    data: ITrainingDatum[] | InputOutputValue[] | InputOutputValue[][],\n    prop?: LookupTableProp\n  ) {\n    this.length = 0;\n    const table = this.table;\n    if (prop) {\n      this.prop = prop;\n      for (let i = 0; i < data.length; i++) {\n        const datum = (data as ITrainingDatum[])[i];\n        const object = datum[prop] as INumberHash;\n        for (const p in object) {\n          if (!object.hasOwnProperty(p)) continue;\n          if (table.hasOwnProperty(p)) continue;\n          table[p] = this.length++;\n        }\n      }\n    } else if (Array.isArray(data) && Array.isArray(data[0])) {\n      for (let i = 0; i < data.length; i++) {\n        const array = (data as InputOutputValue[][])[i];\n        for (let j = 0; j < array.length; j++) {\n          const object = array[j];\n          for (const p in object) {\n            if (!object.hasOwnProperty(p)) continue;\n            if (table.hasOwnProperty(p)) continue;\n            table[p] = this.length++;\n          }\n        }\n      }\n    } else {\n      for (let i = 0; i < data.length; i++) {\n        const object = (data as INumberHash[])[i];\n        for (const p in object) {\n          if (!object.hasOwnProperty(p)) continue;\n          if (table.hasOwnProperty(p)) continue;\n          table[p] = this.length++;\n        }\n      }\n    }\n  }\n}\n","import { IKernelFunctionThis, KernelOutput, Texture } from 'gpu.js';\nimport { MeanSquaredError } from './estimator/mean-squared-error';\nimport { ILayer, ILayerJSON } from './layer';\nimport { Model } from './layer/types';\nimport { InputOutputValue, INumberArray, INumberHash, lookup } from './lookup';\nimport * as praxis from './praxis';\nimport { IPraxis, IPraxisSettings } from './praxis/base-praxis';\nimport { flattenLayers } from './utilities/flatten-layers';\nimport { makeKernel, release } from './utilities/kernel';\nimport { layerFromJSON } from './utilities/layer-from-json';\nimport { LookupTable } from './utilities/lookup-table';\n\nexport interface IFeedForwardTrainingData<\n  InputType extends InputOutputValue | KernelOutput = number[] | Float32Array,\n  OutputType extends InputOutputValue | KernelOutput = number[] | Float32Array\n> {\n  input: InputType;\n  output: OutputType;\n}\n\nexport interface IFeedForwardNormalizedTrainingData {\n  input: Float32Array;\n  output: Float32Array;\n}\n\nexport interface IFeedForwardGPUTrainingData {\n  input: KernelOutput;\n  output: KernelOutput;\n}\n\nexport interface ITrainingStatus {\n  iterations: number;\n  error: number;\n}\n\nexport type Log = (status: string) => void;\nexport type FeedForwardCallback = (status: ITrainingStatus) => void;\n\nexport interface IFeedForwardTrainingOptions {\n  iterations?: number;\n  errorThresh?: number;\n  log?: boolean | Log;\n  logPeriod?: number;\n  learningRate?: number;\n  callback?: FeedForwardCallback;\n  callbackPeriod?: number;\n  errorCheckInterval?: number;\n  timeout?: number;\n}\n\nexport interface IFeedForwardOptions {\n  learningRate?: number;\n  binaryThresh?: number;\n  hiddenLayers?: Array<(inputLayer: ILayer, layerIndex: number) => ILayer>;\n  inputLayer?: () => ILayer;\n  outputLayer?: (inputLayer: ILayer, index: number) => ILayer;\n  praxisOpts?: Partial<IPraxisSettings>;\n  initPraxis?: (\n    layerTemplate: ILayer,\n    settings: Partial<IPraxisSettings>\n  ) => IPraxis;\n  praxis?: IPraxis;\n\n  // JSON\n  layers?: ILayer[];\n  inputLayerIndex?: number;\n  outputLayerIndex?: number;\n  sizes?: number[];\n}\n\nexport interface IFeedForwardPreppedTrainingData {\n  status: ITrainingStatus;\n  preparedData: IFeedForwardGPUTrainingData[];\n  endTime: number;\n}\n\nexport const defaults: IFeedForwardOptions = {\n  learningRate: 0.3,\n  binaryThresh: 0.5,\n  initPraxis: (\n    layerTemplate: ILayer,\n    settings: Partial<IPraxisSettings>\n  ): IPraxis =>\n    praxis.momentumRootMeanSquaredPropagation(\n      layerTemplate,\n      layerTemplate.settings.praxisOpts ?? settings\n    ),\n};\n\nexport const trainDefaults: IFeedForwardTrainingOptions = {\n  iterations: 20000,\n  errorThresh: 0.005,\n  log: false,\n  logPeriod: 10,\n  learningRate: 0.3,\n  callbackPeriod: 10,\n  errorCheckInterval: 100,\n  timeout: Infinity,\n};\n\nexport interface IFeedForwardJSON {\n  type: string;\n  sizes: number[];\n  layers: ILayerJSON[];\n  inputLayerIndex: number;\n  outputLayerIndex: number;\n}\n\nexport class FeedForward<\n  InputType extends InputOutputValue | KernelOutput = number[] | Float32Array,\n  OutputType extends InputOutputValue | KernelOutput = number[] | Float32Array\n> {\n  static _validateTrainingOptions(\n    options: Partial<IFeedForwardTrainingOptions>\n  ): void {\n    const {\n      iterations,\n      errorThresh,\n      log,\n      logPeriod,\n      learningRate,\n      callback,\n      callbackPeriod,\n      timeout,\n    } = options;\n    interface IValidation {\n      [optionName: string]: () => boolean;\n    }\n    const validations: IValidation = {\n      iterations: () => typeof iterations === 'number' && iterations > 0,\n      errorThresh: () =>\n        typeof errorThresh === 'number' && errorThresh > 0 && errorThresh < 1,\n      log: () => typeof log === 'function' || typeof log === 'boolean',\n      logPeriod: () => typeof logPeriod === 'number' && logPeriod > 0,\n      learningRate: () =>\n        typeof learningRate === 'number' &&\n        learningRate > 0 &&\n        learningRate < 1,\n      callback: () => typeof callback === 'function' || callback === null,\n      callbackPeriod: () =>\n        typeof callbackPeriod === 'number' && callbackPeriod > 0,\n      timeout: () => typeof timeout === 'number' && timeout > 0,\n    };\n    Object.keys(trainDefaults).forEach((key: string): void => {\n      if (validations.hasOwnProperty(key) && !validations[key]()) {\n        const val = options[key as keyof IFeedForwardTrainingOptions];\n        throw new Error(\n          `[${key}, ${(\n            val ?? 'undefined'\n          ).toString()}] is out of normal training range, your network will probably not train.`\n        );\n      }\n    });\n  }\n\n  /**\n   * if a method is passed in method is used\n   * if false passed in nothing is logged\n   */\n  _setLogMethod(log: Log | undefined | boolean): void {\n    if (typeof log === 'function') {\n      this.trainOpts.log = log;\n    } else if (log) {\n      // eslint-disable-next-line\n      this.trainOpts.log = console.log;\n    } else {\n      this.trainOpts.log = false;\n    }\n  }\n\n  _updateTrainingOptions(opts: Partial<IFeedForwardTrainingOptions>): void {\n    this.trainOpts = { ...trainDefaults, ...this.trainOpts, ...opts };\n    FeedForward._validateTrainingOptions(this.trainOpts);\n    this._setLogMethod(opts.log ?? this.trainOpts.log);\n    const { callback, callbackPeriod, errorCheckInterval } = this.trainOpts;\n    if (callback && callbackPeriod !== errorCheckInterval) {\n      console.warn(\n        `options.callbackPeriod with value of ${(\n          callbackPeriod ?? 'undefined'\n        ).toString()} does not match options.errorCheckInterval with value of ${(\n          errorCheckInterval ?? 'undefined'\n        ).toString()}, if logging error, it will repeat.  These values may need to match`\n      );\n    }\n  }\n\n  trainOpts: Partial<IFeedForwardTrainingOptions> = {};\n  options: IFeedForwardOptions;\n  layers: ILayer[] | null = null;\n  _inputLayer: ILayer | null = null;\n  _hiddenLayers: ILayer[] | null = null;\n  _outputLayer: ILayer | null = null;\n  _model: ILayer[] | null = null;\n  meanSquaredError: MeanSquaredError | null = null;\n  inputLookup: INumberHash | null = null;\n  inputLookupLength: number | null = null;\n  outputLookup: INumberHash | null = null;\n  outputLookupLength: number | null = null;\n  constructor(options: IFeedForwardOptions = {}) {\n    this.options = { ...defaults, ...options };\n    this._updateTrainingOptions({\n      ...trainDefaults,\n      ...options,\n    });\n  }\n\n  _connectOptionsLayers(): ILayer[] {\n    const { inputLayerIndex, outputLayerIndex, layers } = this.options;\n    if (!layers) throw new Error('this.options.layers in unexpected state');\n    if (typeof inputLayerIndex !== 'number')\n      throw new Error('inputLayerIndex not a number');\n    if (typeof outputLayerIndex !== 'number')\n      throw new Error('inputLayerIndex not a number');\n    const inputLayer = layers[inputLayerIndex];\n    if (!inputLayer) {\n      throw new Error('inputLayer not found in this.options.layers');\n    }\n    const outputLayer = layers[outputLayerIndex];\n    if (!outputLayer) {\n      throw new Error('outputLayer not found in this.options.layers');\n    }\n    this._inputLayer = inputLayer;\n    this._hiddenLayers = layers.slice(\n      inputLayerIndex,\n      outputLayerIndex - inputLayerIndex\n    );\n    this._outputLayer = outputLayer;\n    return layers;\n  }\n\n  _connectNewLayers(): ILayer[] {\n    const { inputLayer, outputLayer } = this.options;\n    if (!inputLayer) throw new Error('inputLayer not defined');\n    const layers: ILayer[] = [];\n    this._inputLayer = inputLayer();\n    const hiddenLayers = this._connectHiddenLayers(this._inputLayer);\n\n    if (!outputLayer) throw new Error('outputLayer not defined');\n    this._outputLayer = outputLayer(\n      hiddenLayers[hiddenLayers.length - 1],\n      hiddenLayers.length\n    );\n    layers.push(this._inputLayer);\n    layers.push(...hiddenLayers);\n    layers.push(this._outputLayer);\n    return flattenLayers(layers);\n  }\n\n  _connectHiddenLayers(previousLayer: ILayer): ILayer[] {\n    this._hiddenLayers = [];\n    const result: ILayer[] = [];\n    const { hiddenLayers } = this.options;\n\n    if (!hiddenLayers) throw new Error('hiddenLayers not defined');\n\n    for (let i = 0; i < hiddenLayers.length; i++) {\n      const hiddenLayer = hiddenLayers[i](previousLayer, i);\n      result.push(hiddenLayer);\n      this._hiddenLayers.push(hiddenLayer);\n      previousLayer = hiddenLayer;\n    }\n\n    return result;\n  }\n\n  initialize(): void {\n    this.layers = this.options.layers\n      ? this._connectOptionsLayers()\n      : this._connectNewLayers();\n    this.initializeLayers(this.layers);\n    this._model = this.layers.filter((l) => l instanceof Model);\n  }\n\n  initializeLayers(layers: ILayer[]): void {\n    for (let i = 0; i < layers.length; i++) {\n      const layer = layers[i];\n      // TODO: optimize for when training or just running\n      layer.setupKernels(true);\n      if (\n        layer instanceof Model &&\n        layer.praxis === null &&\n        typeof this.options.initPraxis === 'function'\n      ) {\n        layer.praxis = this.options.initPraxis(\n          layer,\n          layer.settings.praxisOpts ?? this.options.praxisOpts ?? {}\n        );\n        layer.praxis.setupKernels();\n      }\n    }\n\n    const lastLayer = layers[layers.length - 1];\n    this.meanSquaredError = new MeanSquaredError({\n      width: lastLayer.width,\n      height: lastLayer.height,\n    });\n  }\n\n  run(input: InputType): OutputType {\n    let typeSafeInput: INumberArray | KernelOutput;\n    if (Array.isArray(input) || (input as Float32Array).buffer) {\n      typeSafeInput = input as INumberArray;\n    } else {\n      if (this.inputLookup) {\n        typeSafeInput = lookup.toArray(\n          this.inputLookup,\n          input as INumberHash,\n          this.inputLookupLength as number\n        );\n      } else {\n        throw new Error('input is incompatible with net');\n      }\n    }\n\n    let output = this.runInput(typeSafeInput as KernelOutput);\n    if (output instanceof Texture) {\n      output = output.toArray();\n    }\n\n    if (this.outputLookup) {\n      return lookup.toObject(\n        this.outputLookup,\n        output as number[]\n      ) as OutputType;\n    }\n    return output as OutputType;\n  }\n\n  runInput(input: KernelOutput): KernelOutput {\n    if (!this.layers) throw new Error('not initialized');\n    this.layers[0].predict(input);\n    for (let i = 1; i < this.layers.length; i++) {\n      this.layers[i].predict();\n    }\n    return this.layers[this.layers.length - 1].weights as KernelOutput;\n  }\n\n  train(\n    data: Array<IFeedForwardTrainingData<InputType, OutputType>>,\n    options: Partial<IFeedForwardTrainingOptions> = {}\n  ): ITrainingStatus {\n    const { preparedData, status, endTime } = this._prepTraining(data, options);\n    let continueTicking = true;\n    const calculateError = (): number =>\n      this._calculateTrainingError(preparedData);\n    const trainPatters = (): void => this._trainPatterns(preparedData);\n    while (continueTicking) {\n      continueTicking = this._trainingTick(\n        status,\n        endTime,\n        calculateError,\n        trainPatters\n      );\n    }\n    return status;\n  }\n\n  _trainingTick(\n    status: ITrainingStatus,\n    endTime: number,\n    calculateError: () => number,\n    trainPatterns: () => void\n  ): boolean {\n    const { trainOpts } = this;\n    if (\n      status.iterations >= (trainOpts.iterations as number) ||\n      status.error <= (trainOpts.errorThresh as number) ||\n      Date.now() >= endTime\n    ) {\n      return false;\n    }\n\n    if (\n      typeof trainOpts.log === 'function' &&\n      status.iterations % (trainOpts.logPeriod as number) === 0\n    ) {\n      status.error = calculateError();\n      trainOpts.log(\n        `iterations: ${status.iterations}, training error: ${status.error}`\n      );\n    } else if (\n      status.iterations % (trainOpts.errorCheckInterval as number) ===\n      0\n    ) {\n      status.error = calculateError();\n    } else {\n      trainPatterns();\n    }\n\n    if (\n      trainOpts.callback &&\n      status.iterations % (trainOpts.callbackPeriod as number) === 0\n    ) {\n      trainOpts.callback(Object.assign(status));\n    }\n\n    status.iterations++;\n    return true;\n  }\n\n  _prepTraining(\n    data: Array<IFeedForwardTrainingData<InputType, OutputType>>,\n    options: Partial<IFeedForwardTrainingOptions>\n  ): IFeedForwardPreppedTrainingData {\n    this._updateTrainingOptions(options);\n\n    const formattedData = this.formatData(data);\n    const endTime = this.trainOpts.timeout\n      ? Date.now() + this.trainOpts.timeout\n      : 0;\n\n    const status = {\n      error: 1,\n      iterations: 0,\n    };\n\n    this.verifyIsInitialized();\n\n    return {\n      preparedData: this.transferData(formattedData),\n      status,\n      endTime,\n    };\n  }\n\n  verifyIsInitialized(): void {\n    if (!this._model) {\n      this.initialize();\n    }\n  }\n\n  _calculateTrainingError(preparedData: IFeedForwardGPUTrainingData[]): number {\n    let sum: Float32Array | KernelOutput = new Float32Array([0]);\n    const meanSquaredError = this.meanSquaredError as MeanSquaredError;\n    for (let i = 0; i < preparedData.length; ++i) {\n      const prevSum = sum;\n      const error = this._trainPattern(\n        preparedData[i].input,\n        preparedData[i].output,\n        true\n      ) as number;\n      sum = meanSquaredError.add(sum, error);\n      release(error);\n      release(prevSum);\n    }\n    const result = meanSquaredError.divide(preparedData.length, sum);\n    release(sum);\n    if (result instanceof Texture) {\n      const resultArray: number[] = result.toArray() as number[];\n      release(result);\n      return resultArray[0];\n    }\n    return (result as number[])[0];\n  }\n\n  /**\n   * @param data\n   * @private\n   */\n  _trainPatterns(data: IFeedForwardGPUTrainingData[]): void {\n    for (let i = 0; i < data.length; ++i) {\n      this._trainPattern(data[i].input, data[i].output, false);\n    }\n  }\n\n  _trainPattern(\n    input: KernelOutput,\n    target: KernelOutput,\n    logErrorRate: boolean\n  ): KernelOutput | null {\n    // forward propagate\n    this.runInput(input);\n\n    // back propagate\n    this._calculateDeltas(target);\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      if (!this._outputLayer?.errors) {\n        throw new Error('outputLayer.errors not defined');\n      }\n      return (this.meanSquaredError as MeanSquaredError).calculate(\n        this._outputLayer.errors\n      );\n    }\n    return null;\n  }\n\n  _calculateDeltas(target: KernelOutput): void {\n    const layers = this.layers as ILayer[];\n    for (let i = layers.length - 1; i > -1; i--) {\n      layers[i].compare(target);\n    }\n  }\n\n  /**\n   *\n   */\n  adjustWeights(): void {\n    const _model = this._model as ILayer[];\n    for (let i = 0; i < _model.length; i++) {\n      _model[i].learn(this.trainOpts.learningRate as number);\n    }\n  }\n\n  /**\n   *\n   * @param data\n   * @returns {*}\n   */\n  formatData(\n    data:\n      | Array<IFeedForwardTrainingData<InputType, OutputType>>\n      | IFeedForwardTrainingData<InputType, OutputType>\n  ): IFeedForwardNormalizedTrainingData[] {\n    if (!Array.isArray(data)) {\n      // turn stream datum into array\n      const tmp = [];\n      tmp.push(data);\n      data = tmp;\n    }\n\n    // turn sparse hash input into arrays with 0s as filler\n    const inputDatumCheck = data[0].input;\n    let formattedData: Array<Partial<IFeedForwardNormalizedTrainingData>>;\n    if (\n      Array.isArray(data) &&\n      !Array.isArray(inputDatumCheck) &&\n      !(inputDatumCheck instanceof Float32Array)\n    ) {\n      if (!this.inputLookup) {\n        const lookupTable = new LookupTable(data, 'input');\n        this.inputLookup = lookupTable.table;\n        this.inputLookupLength = lookupTable.length;\n      }\n      formattedData = data.map((datumParam): Partial<\n        IFeedForwardNormalizedTrainingData\n      > => {\n        const array = lookup.toArray(\n          this.inputLookup as INumberHash,\n          datumParam.input as INumberHash,\n          this.inputLookupLength as number\n        );\n        return { input: array };\n      }, this);\n    } else {\n      formattedData = data as typeof formattedData;\n    }\n\n    const outputDatumCheck = data[0].output;\n    if (\n      !Array.isArray(outputDatumCheck) &&\n      !(outputDatumCheck instanceof Float32Array)\n    ) {\n      if (!this.outputLookup) {\n        const lookupTable = new LookupTable(data, 'output');\n        this.outputLookup = lookupTable.table;\n        this.outputLookupLength = lookupTable.length;\n      }\n      formattedData = data.map(\n        (datumParam, index): IFeedForwardNormalizedTrainingData => {\n          const array = lookup.toArray(\n            this.outputLookup as INumberHash,\n            datumParam.output as INumberHash,\n            this.inputLookupLength as number\n          );\n          return {\n            input: formattedData[index].input as Float32Array,\n            output: array,\n          };\n        },\n        this\n      );\n    }\n    return formattedData as IFeedForwardNormalizedTrainingData[];\n  }\n\n  transferData(\n    formattedData: IFeedForwardNormalizedTrainingData[]\n  ): IFeedForwardGPUTrainingData[] {\n    const transferredData = new Array(formattedData.length);\n    const transferInput = makeKernel(\n      function (value: number[]): number {\n        return value[this.thread.x];\n      },\n      {\n        output: [formattedData[0].input.length],\n        immutable: true,\n      }\n    );\n    const transferOutput = makeKernel(\n      function (this: IKernelFunctionThis, value: number[]): number {\n        return value[this.thread.x];\n      },\n      {\n        output: [formattedData[0].output.length],\n        immutable: true,\n      }\n    );\n\n    for (let i = 0; i < formattedData.length; i++) {\n      const formattedDatum = formattedData[i];\n      transferredData[i] = {\n        input: transferInput(formattedDatum.input),\n        output: transferOutput(formattedDatum.output),\n      };\n    }\n    return transferredData;\n  }\n\n  /**\n   *\n   * @param data\n   * @returns {\n   *  {\n   *    error: number,\n   *    misclasses: Array\n   *  }\n   * }\n   */\n  test(): void {\n    throw new Error(`${this.constructor.name}-test is not yet implemented`);\n  }\n\n  /**\n   *\n   */\n  toJSON(): IFeedForwardJSON {\n    if (!this.layers) {\n      this.initialize();\n    }\n    if (\n      !this._model ||\n      !this.layers ||\n      !this._inputLayer ||\n      !this._hiddenLayers ||\n      !this._outputLayer\n    ) {\n      throw new Error('network is not initialized');\n    }\n    const jsonLayers = [];\n    for (let i = 0; i < this.layers.length; i++) {\n      const layer = this.layers[i];\n      const jsonLayer = layer.toJSON();\n      if (layer.hasOwnProperty('inputLayer')) {\n        jsonLayer.inputLayerIndex = this.layers.indexOf(\n          layer.inputLayer as ILayer\n        );\n      } else if (\n        layer.hasOwnProperty('inputLayer1') &&\n        layer.hasOwnProperty('inputLayer2')\n      ) {\n        jsonLayer.inputLayer1Index = this.layers.indexOf(\n          layer.inputLayer1 as ILayer\n        );\n        jsonLayer.inputLayer2Index = this.layers.indexOf(\n          layer.inputLayer2 as ILayer\n        );\n      }\n      jsonLayers.push(jsonLayer);\n    }\n\n    return {\n      type: this.constructor.name,\n      sizes:\n        this.options.sizes ??\n        [this._inputLayer.height]\n          .concat(this._hiddenLayers.map((l) => l.height))\n          .concat([this._outputLayer.height]),\n      outputLayerIndex: this.layers.indexOf(this._outputLayer),\n      layers: jsonLayers as ILayerJSON[],\n      inputLayerIndex: this.layers.indexOf(this._inputLayer),\n    };\n  }\n\n  static fromJSON(\n    json: IFeedForwardJSON,\n    getLayer?: (\n      layerJson: ILayerJSON,\n      inputLayer1?: ILayer,\n      inputLayer2?: ILayer\n    ) => ILayer\n  ): FeedForward {\n    const jsonLayers = json.layers;\n    const layers: ILayer[] = [];\n    const inputLayer = getLayer\n      ? layerFromJSON(jsonLayers[0]) ?? getLayer(jsonLayers[0])\n      : layerFromJSON(jsonLayers[0]);\n\n    if (!inputLayer) throw new Error('unable to find layer');\n\n    layers.push(inputLayer);\n\n    for (let i = 1; i < jsonLayers.length; i++) {\n      const jsonLayer = jsonLayers[i];\n      if (\n        typeof jsonLayer.inputLayerIndex === 'undefined' &&\n        typeof jsonLayer.inputLayer1Index === 'undefined' &&\n        typeof jsonLayer.inputLayer2Index === 'undefined'\n      ) {\n        const layer = getLayer\n          ? layerFromJSON(jsonLayer) ?? getLayer(jsonLayer)\n          : layerFromJSON(jsonLayer);\n        if (!layer) throw new Error('unable to find layer');\n        layers.push(layer);\n      } else if (typeof jsonLayer.inputLayerIndex === 'number') {\n        const inputLayer = layers[jsonLayer.inputLayerIndex];\n        if (!inputLayer) {\n          throw new Error('inputLayer1 not found');\n        }\n        const layer = getLayer\n          ? layerFromJSON(jsonLayer, inputLayer) ??\n            getLayer(jsonLayer, inputLayer)\n          : layerFromJSON(jsonLayer, inputLayer);\n        if (!layer) throw new Error('unable to find layer');\n        layers.push(layer);\n      } else {\n        if (typeof jsonLayer.inputLayer1Index !== 'number') {\n          throw new Error(\n            'Cannot create network from provided JSON. inputLayer1Index not defined.'\n          );\n        }\n        if (typeof jsonLayer.inputLayer2Index !== 'number') {\n          throw new Error(\n            'Cannot create network from provided JSON. inputLayer2Index not defined.'\n          );\n        }\n        const inputLayer1 = layers[jsonLayer.inputLayer1Index];\n        const inputLayer2 = layers[jsonLayer.inputLayer2Index];\n\n        if (inputLayer1 === undefined)\n          throw new Error(\n            `Cannot create network from provided JSON. layer of index ${jsonLayer.inputLayer1Index} not found.`\n          );\n        if (inputLayer2 === undefined)\n          throw new Error(\n            `Cannot create network from provided JSON. layer of index ${jsonLayer.inputLayer2Index} not found.`\n          );\n\n        const layer = getLayer\n          ? layerFromJSON(jsonLayer, inputLayer1, inputLayer2) ??\n            getLayer(jsonLayer, inputLayer1, inputLayer2)\n          : layerFromJSON(jsonLayer, inputLayer1, inputLayer2);\n\n        if (!layer) throw new Error('unable to find layer');\n        layers.push(layer);\n      }\n    }\n\n    return new this({ ...json, layers });\n  }\n\n  /**\n   *\n   * @returns {Function}\n   */\n  toFunction(): void {\n    throw new Error(\n      `${this.constructor.name}-toFunction is not yet implemented`\n    );\n  }\n\n  /**\n   * This will create a TrainStream (WriteStream) for us to send the training data to.\n   * @param opts training options\n   * @returns {TrainStream|*}\n   */\n  createTrainStream(): void {\n    throw new Error(\n      `${this.constructor.name}-createTrainStream is not yet implemented`\n    );\n  }\n}\n","\"use strict\";\nvar __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.thaw = exports.Block = exports.Thaw = void 0;\n/**\n * thaw an array of items\n */\nvar Thaw = /** @class */ (function () {\n    function Thaw(items, options) {\n        var _this = this;\n        if (options === void 0) { options = {}; }\n        var _a = __assign(__assign({}, Thaw.defaultSettings), options), each = _a.each, done = _a.done;\n        this.i = 0;\n        this.isStopped = false;\n        this.items = items;\n        this.options = options;\n        this.tick = function () {\n            if (_this.isStopped)\n                return;\n            _this.timeout = setTimeout(_this.tick, 0);\n            if (Thaw.thawing)\n                return;\n            var item = _this.items[_this.i];\n            if (_this.i >= _this.items.length) {\n                if (done !== null) {\n                    Thaw.thawing = true;\n                    done();\n                    Thaw.thawing = false;\n                }\n                _this.isStopped = true;\n                clearTimeout(_this.timeout);\n                return;\n            }\n            if (each !== null) {\n                Thaw.thawing = true;\n                each(item, _this.i);\n                Thaw.thawing = false;\n            }\n            else if (item !== undefined) {\n                item();\n            }\n            _this.i++;\n        };\n        Thaw.thaws.push(this);\n        if (!options.delay) {\n            this.tick();\n        }\n    }\n    Object.defineProperty(Thaw, \"isThawing\", {\n        /**\n         * returns if Thaw.js is thawing\n         */\n        get: function () {\n            return Thaw.thawing;\n        },\n        enumerable: false,\n        configurable: true\n    });\n    /**\n     * Stops all Thaw instances\n     */\n    Thaw.stopAll = function () {\n        for (var i = 0; i < Thaw.thaws.length; i++) {\n            Thaw.thaws[i].stop();\n        }\n    };\n    /**\n     * readies thaw to continue\n     */\n    Thaw.prototype.makeReady = function () {\n        if (this.isStopped) {\n            this.isStopped = false;\n            return true;\n        }\n        return false;\n    };\n    /**\n     * Adds an item to the end of this instance of Thaw and readies Thaw to process it\n     */\n    Thaw.prototype.add = function (item) {\n        this.items.push(item);\n        if (this.makeReady()) {\n            this.tick();\n        }\n        return this;\n    };\n    /**\n     * Inserts an item just after the current item being processed in Thaw and readies Thaw to process it\n     */\n    Thaw.prototype.insert = function (item) {\n        this.items.splice(this.i, 0, item);\n        if (this.makeReady()) {\n            this.tick();\n        }\n        return this;\n    };\n    /**\n     * Adds an Array to the end of this instance of Thaw and readies Thaw to process it\n     */\n    Thaw.prototype.addArray = function (items) {\n        this.items = this.items.concat(items);\n        if (this.makeReady()) {\n            this.tick();\n        }\n        return this;\n    };\n    /**\n     * Inserts an Array just after the current item being processed in Thaw and readies Thaw to process them\n     */\n    Thaw.prototype.insertArray = function (items) {\n        var before = this.items.splice(0, this.i);\n        var after = this.items;\n        this.items = before.concat(items, after);\n        if (this.makeReady()) {\n            this.tick();\n        }\n        return this;\n    };\n    /**\n     * Stops this instance of Thaw\n     */\n    Thaw.prototype.stop = function () {\n        this.isStopped = true;\n        clearTimeout(this.timeout);\n        if (this.options.done) {\n            this.options.done();\n        }\n        return this;\n    };\n    Thaw.thawing = false;\n    Thaw.thaws = [];\n    Thaw.defaultSettings = {\n        each: null,\n        done: null\n    };\n    return Thaw;\n}());\nexports.Thaw = Thaw;\n/**\n * simple thaw\n */\nfunction thaw(items, options) {\n    return new Thaw(items, options);\n}\nexports.thaw = thaw;\nvar Block = /** @class */ (function () {\n    function Block(options, count) {\n        if (count === void 0) { count = 200; }\n        this.index = 0;\n        this.thaws = [];\n        this.count = count;\n        this.options = options;\n    }\n    /**\n     * add an item to the end of items\n     */\n    Block.prototype.add = function (item) {\n        var next = this.next();\n        next.add(item);\n        return this;\n    };\n    /**\n     * add an Array to the end of items\n     */\n    Block.prototype.addArray = function (items) {\n        var next = this.next();\n        next.addArray(items);\n        return this;\n    };\n    /**\n     * insert an item into items @ current position\n     */\n    Block.prototype.insert = function (item) {\n        var next = this.next();\n        next.insert(item);\n        return this;\n    };\n    /**\n     * insert and array into items @ current position\n     */\n    Block.prototype.insertArray = function (items) {\n        var next = this.next();\n        next.insertArray(items);\n        return this;\n    };\n    /**\n     * Stops all thaws in this block\n     */\n    Block.prototype.stop = function () {\n        for (var i = 0; i < this.thaws.length; i++) {\n            this.thaws[i].stop();\n        }\n        return this;\n    };\n    /**\n     * Get next available in block\n     */\n    Block.prototype.next = function () {\n        var thaw;\n        var thaws = this.thaws;\n        if (thaws.length < this.count) {\n            thaw = new Thaw([], this.options);\n            thaws.push(thaw);\n        }\n        else {\n            thaw = thaws[this.index] || null;\n        }\n        this.index++;\n        if (this.index >= this.count) {\n            this.index = 0;\n        }\n        return thaw;\n    };\n    return Block;\n}());\nexports.Block = Block;\nif (typeof window !== 'undefined') {\n    // @ts-ignore\n    window.Thaw = Thaw;\n    // @ts-ignore\n    window.thaw = thaw;\n    // @ts-ignore\n    window.Thaw.Block = Block;\n}\n","export function arraysToFloat32Arrays(arrays: number[][]): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (let i = 0; i < arrays.length; i++) {\n    result.push(Float32Array.from(arrays[i]));\n  }\n  return result;\n}\n\nexport function inputOutputArraysToFloat32Arrays(\n  input: number[][],\n  output: number[][]\n): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (let i = 0; i < input.length; i++) {\n    result.push(Float32Array.from(input[i]));\n  }\n  for (let i = 0; i < output.length; i++) {\n    result.push(Float32Array.from(output[i]));\n  }\n  return result;\n}\n\nexport function arrayToFloat32Arrays(array: number[]): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (let i = 0; i < array.length; i++) {\n    result.push(Float32Array.from([array[i]]));\n  }\n  return result;\n}\n\nexport function inputOutputArrayToFloat32Arrays(\n  input: number[],\n  output: number[]\n): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (let i = 0; i < input.length; i++) {\n    result.push(Float32Array.from([input[i]]));\n  }\n  for (let i = 0; i < output.length; i++) {\n    result.push(Float32Array.from([output[i]]));\n  }\n  return result;\n}\n\nexport function arrayToFloat32Array(array: number[]): Float32Array {\n  return Float32Array.from(array);\n}\n\nexport function objectsToFloat32Arrays(\n  objects: Array<Record<string, number>>,\n  table: Record<string, number>,\n  length: number\n): Float32Array[] {\n  const results: Float32Array[] = [];\n  for (let i = 0; i < objects.length; i++) {\n    const object = objects[i];\n    const result = new Float32Array(length);\n    for (const p in object) {\n      if (object.hasOwnProperty(p)) {\n        result[table[p]] = object[p];\n      }\n    }\n    results.push(result);\n  }\n  return results;\n}\n\nexport function inputOutputObjectsToFloat32Arrays(\n  input: Array<Record<string, number>>,\n  output: Array<Record<string, number>>,\n  inputTable: Record<string, number>,\n  outputTable: Record<string, number>,\n  inputLength: number,\n  outputLength: number\n): Float32Array[] {\n  const results: Float32Array[] = [];\n  for (let i = 0; i < input.length; i++) {\n    const object = input[i];\n    const result = new Float32Array(inputLength);\n    for (const p in object) {\n      if (object.hasOwnProperty(p)) {\n        result[inputTable[p]] = object[p];\n      }\n    }\n    results.push(result);\n  }\n  for (let i = 0; i < output.length; i++) {\n    const object = output[i];\n    const result = new Float32Array(outputLength);\n    for (const p in object) {\n      if (object.hasOwnProperty(p)) {\n        result[outputTable[p]] = object[p];\n      }\n    }\n    results.push(result);\n  }\n  return results;\n}\n\nexport function objectToFloat32Arrays(\n  object: Record<string, number>\n): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (const p in object) {\n    if (!object.hasOwnProperty(p)) continue;\n    result.push(Float32Array.from([object[p]]));\n  }\n  return result;\n}\n\nexport function inputOutputObjectToFloat32Arrays(\n  input: Record<string, number>,\n  output: Record<string, number>\n): Float32Array[] {\n  const result: Float32Array[] = [];\n  for (const p in input) {\n    if (!input.hasOwnProperty(p)) continue;\n    result.push(Float32Array.from([input[p]]));\n  }\n  for (const p in output) {\n    if (!output.hasOwnProperty(p)) continue;\n    result.push(Float32Array.from([output[p]]));\n  }\n  return result;\n}\n\nexport function objectToFloat32Array(\n  object: Record<string, number>,\n  table: Record<string, number>,\n  length: number\n): Float32Array {\n  const result = new Float32Array(length);\n  for (const p in object) {\n    if (object.hasOwnProperty(p)) {\n      result[table[p]] = object[p];\n    }\n  }\n  return result;\n}\n","export function max(\n  values:\n    | Float32Array\n    | {\n        [key: string]: number;\n      }\n): number {\n  if (Array.isArray(values) || values instanceof Float32Array) {\n    return Math.max(...values);\n  } else {\n    return Math.max(...Object.values(values));\n  }\n}\n","export function mse(errors: Float32Array): number {\n  // mean squared error\n  let sum = 0;\n  for (let i = 0; i < errors.length; i++) {\n    sum += errors[i] ** 2;\n  }\n  return sum / errors.length;\n}\n","import { Thaw } from 'thaw.js';\nimport { ITrainingStatus } from './feed-forward';\nimport { INumberHash, lookup } from './lookup';\nimport {\n  INeuralNetworkBinaryTestResult,\n  INeuralNetworkState,\n  INeuralNetworkTestResult,\n} from './neural-network-types';\nimport { arrayToFloat32Array } from './utilities/cast';\nimport { LookupTable } from './utilities/lookup-table';\nimport { max } from './utilities/max';\nimport { mse } from './utilities/mse';\nimport { randos } from './utilities/randos';\nimport { zeros } from './utilities/zeros';\n\ntype NeuralNetworkFormatter =\n  | ((v: INumberHash) => Float32Array)\n  | ((v: number[]) => Float32Array);\n\nfunction getTypedArrayFn(\n  value: INeuralNetworkData,\n  table: INumberHash | null\n): null | NeuralNetworkFormatter {\n  if ((value as Float32Array).buffer instanceof ArrayBuffer) {\n    return null;\n  }\n  if (Array.isArray(value)) {\n    return arrayToFloat32Array;\n  }\n  if (!table) throw new Error('table is not Object');\n  const { length } = Object.keys(table);\n  return (v: INumberHash): Float32Array => {\n    const array = new Float32Array(length);\n    for (const p in table) {\n      if (!table.hasOwnProperty(p)) continue;\n      array[table[p]] = v[p] || 0;\n    }\n    return array;\n  };\n}\n\nexport type NeuralNetworkActivation =\n  | 'sigmoid'\n  | 'relu'\n  | 'leaky-relu'\n  | 'tanh';\n\nexport interface IJSONLayer {\n  biases: number[];\n  weights: number[][];\n}\n\nexport interface INeuralNetworkJSON {\n  type: string;\n  sizes: number[];\n  layers: IJSONLayer[];\n  inputLookup: INumberHash | null;\n  inputLookupLength: number;\n  outputLookup: INumberHash | null;\n  outputLookupLength: number;\n  options: INeuralNetworkOptions;\n  trainOpts: INeuralNetworkTrainOptionsJSON;\n}\n\nexport interface INeuralNetworkOptions {\n  inputSize: number;\n  outputSize: number;\n  binaryThresh: number;\n  hiddenLayers?: number[];\n}\n\nexport function defaults(): INeuralNetworkOptions {\n  return {\n    inputSize: 0,\n    outputSize: 0,\n    binaryThresh: 0.5,\n  };\n}\n\nexport interface INeuralNetworkTrainOptionsJSON {\n  activation: NeuralNetworkActivation | string;\n  iterations: number;\n  errorThresh: number;\n  log: boolean;\n  logPeriod: number;\n  leakyReluAlpha: number;\n  learningRate: number;\n  momentum: number;\n  callbackPeriod: number;\n  timeout: number | 'Infinity';\n  praxis?: 'adam';\n  beta1: number;\n  beta2: number;\n  epsilon: number;\n}\n\nexport interface INeuralNetworkPreppedTrainingData<T> {\n  status: ITrainingStatus;\n  preparedData: Array<INeuralNetworkDatumFormatted<T>>;\n  endTime: number;\n}\n\nexport interface INeuralNetworkTrainOptions {\n  activation: NeuralNetworkActivation | string;\n  iterations: number;\n  errorThresh: number;\n  log: boolean | ((status: INeuralNetworkState) => void);\n  logPeriod: number;\n  leakyReluAlpha: number;\n  learningRate: number;\n  momentum: number;\n  callback?: (status: { iterations: number; error: number }) => void;\n  callbackPeriod: number;\n  timeout: number;\n  praxis?: 'adam';\n  beta1: number;\n  beta2: number;\n  epsilon: number;\n}\n\nexport function trainDefaults(): INeuralNetworkTrainOptions {\n  return {\n    activation: 'sigmoid',\n    iterations: 20000, // the maximum times to iterate the training data\n    errorThresh: 0.005, // the acceptable error percentage from training data\n    log: false, // true to use console.log, when a function is supplied it is used\n    logPeriod: 10, // iterations between logging out\n    leakyReluAlpha: 0.01,\n    learningRate: 0.3, // multiply's against the input and the delta then adds to momentum\n    momentum: 0.1, // multiply's against the specified \"change\" then adds to learning rate for change\n    callbackPeriod: 10, // the number of iterations through the training data between callback calls\n    timeout: Infinity, // the max number of milliseconds to train for\n    beta1: 0.9,\n    beta2: 0.999,\n    epsilon: 1e-8,\n  };\n}\n\nexport type INeuralNetworkData = number[] | Float32Array | Partial<INumberHash>;\n\n// TODO: should be replaced by ITrainingDatum\nexport interface INeuralNetworkDatum<InputType, OutputType> {\n  input: InputType;\n  output: OutputType;\n}\n\nexport interface INeuralNetworkDatumFormatted<T> {\n  input: T;\n  output: T;\n}\n\nexport class NeuralNetwork<\n  InputType extends INeuralNetworkData,\n  OutputType extends INeuralNetworkData\n> {\n  options: INeuralNetworkOptions = defaults();\n  trainOpts: INeuralNetworkTrainOptions = trainDefaults();\n  sizes: number[] = [];\n  outputLayer = -1;\n  biases: Float32Array[] = [];\n  weights: Float32Array[][] = []; // weights for bias nodes\n  outputs: Float32Array[] = [];\n  // state for training\n  deltas: Float32Array[] = [];\n  changes: Float32Array[][] = []; // for momentum\n  errors: Float32Array[] = [];\n\n  errorCheckInterval = 1;\n\n  inputLookup: INumberHash | null = null;\n  inputLookupLength = 0;\n  outputLookup: INumberHash | null = null;\n  outputLookupLength = 0;\n\n  _formatInput: NeuralNetworkFormatter | null = null;\n  _formatOutput: NeuralNetworkFormatter | null = null;\n\n  runInput: (input: Float32Array) => Float32Array = (input: Float32Array) => {\n    this.setActivation();\n    return this.runInput(input);\n  };\n\n  calculateDeltas: (output: Float32Array) => void = (\n    output: Float32Array\n  ): void => {\n    this.setActivation();\n    return this.calculateDeltas(output);\n  };\n\n  // adam\n  biasChangesLow: Float32Array[] = [];\n  biasChangesHigh: Float32Array[] = [];\n  changesLow: Float32Array[][] = [];\n  changesHigh: Float32Array[][] = [];\n  iterations = 0;\n\n  constructor(\n    options: Partial<INeuralNetworkOptions & INeuralNetworkTrainOptions> = {}\n  ) {\n    this.options = { ...this.options, ...options };\n    this.updateTrainingOptions(options);\n\n    const { inputSize, hiddenLayers, outputSize } = this.options;\n    if (inputSize && outputSize) {\n      this.sizes = [inputSize].concat(hiddenLayers ?? []).concat([outputSize]);\n    }\n  }\n\n  /**\n   *\n   * Expects this.sizes to have been set\n   */\n  initialize(): void {\n    if (!this.sizes.length) {\n      throw new Error('Sizes must be set before initializing');\n    }\n\n    this.outputLayer = this.sizes.length - 1;\n    this.biases = new Array(this.outputLayer); // weights for bias nodes\n    this.weights = new Array(this.outputLayer);\n    this.outputs = new Array(this.outputLayer);\n\n    // state for training\n    this.deltas = new Array(this.outputLayer);\n    this.changes = new Array(this.outputLayer); // for momentum\n    this.errors = new Array(this.outputLayer);\n\n    for (let layerIndex = 0; layerIndex <= this.outputLayer; layerIndex++) {\n      const size = this.sizes[layerIndex];\n      this.deltas[layerIndex] = zeros(size);\n      this.errors[layerIndex] = zeros(size);\n      this.outputs[layerIndex] = zeros(size);\n\n      if (layerIndex > 0) {\n        this.biases[layerIndex] = randos(size);\n        this.weights[layerIndex] = new Array(size);\n        this.changes[layerIndex] = new Array(size);\n\n        for (let nodeIndex = 0; nodeIndex < size; nodeIndex++) {\n          const prevSize = this.sizes[layerIndex - 1];\n          this.weights[layerIndex][nodeIndex] = randos(prevSize);\n          this.changes[layerIndex][nodeIndex] = zeros(prevSize);\n        }\n      }\n    }\n\n    this.setActivation();\n    if (this.trainOpts.praxis === 'adam') {\n      this._setupAdam();\n    }\n  }\n\n  setActivation(activation?: NeuralNetworkActivation): void {\n    const value = activation ?? this.trainOpts.activation;\n    switch (value) {\n      case 'sigmoid':\n        this.runInput = this._runInputSigmoid;\n        this.calculateDeltas = this._calculateDeltasSigmoid;\n        break;\n      case 'relu':\n        this.runInput = this._runInputRelu;\n        this.calculateDeltas = this._calculateDeltasRelu;\n        break;\n      case 'leaky-relu':\n        this.runInput = this._runInputLeakyRelu;\n        this.calculateDeltas = this._calculateDeltasLeakyRelu;\n        break;\n      case 'tanh':\n        this.runInput = this._runInputTanh;\n        this.calculateDeltas = this._calculateDeltasTanh;\n        break;\n      default:\n        throw new Error(\n          `Unknown activation ${value}. Available activations are: 'sigmoid', 'relu', 'leaky-relu', 'tanh'`\n        );\n    }\n  }\n\n  get isRunnable(): boolean {\n    return this.sizes.length > 0;\n  }\n\n  run(input: Partial<InputType>): OutputType {\n    if (!this.isRunnable) {\n      throw new Error('network not runnable');\n    }\n    let formattedInput: Float32Array;\n    if (this.inputLookup) {\n      formattedInput = lookup.toArray(\n        this.inputLookup,\n        (input as unknown) as INumberHash,\n        this.inputLookupLength\n      );\n    } else {\n      formattedInput = (input as unknown) as Float32Array;\n    }\n    if (formattedInput.length !== this.sizes[0]) {\n      throw new Error(`input is not in correct length of ${this.sizes[0]}`);\n    }\n    const output = this.runInput(formattedInput).slice(0);\n    if (this.outputLookup) {\n      return (lookup.toObject(\n        this.outputLookup,\n        output\n      ) as unknown) as OutputType;\n    }\n    return (output as unknown) as OutputType;\n  }\n\n  _runInputSigmoid(input: Float32Array): Float32Array {\n    this.outputs[0] = input; // set output state of input layer\n\n    let output = null;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const activeLayer = this.sizes[layer];\n      const activeWeights = this.weights[layer];\n      const activeBiases = this.biases[layer];\n      const activeOutputs = this.outputs[layer];\n      for (let node = 0; node < activeLayer; node++) {\n        const weights = activeWeights[node];\n\n        let sum = activeBiases[node];\n        for (let k = 0; k < weights.length; k++) {\n          sum += weights[k] * input[k];\n        }\n        // sigmoid\n        activeOutputs[node] = 1 / (1 + Math.exp(-sum));\n      }\n      output = input = activeOutputs;\n    }\n    if (!output) {\n      throw new Error('output was empty');\n    }\n    return output;\n  }\n\n  _runInputRelu(input: Float32Array): Float32Array {\n    this.outputs[0] = input; // set output state of input layer\n\n    let output = null;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const activeSize = this.sizes[layer];\n      const activeWeights = this.weights[layer];\n      const activeBiases = this.biases[layer];\n      const activeOutputs = this.outputs[layer];\n      for (let node = 0; node < activeSize; node++) {\n        const weights = activeWeights[node];\n\n        let sum = activeBiases[node];\n        for (let k = 0; k < weights.length; k++) {\n          sum += weights[k] * input[k];\n        }\n        // relu\n        activeOutputs[node] = sum < 0 ? 0 : sum;\n      }\n      output = input = activeOutputs;\n    }\n    if (!output) {\n      throw new Error('output was empty');\n    }\n    return output;\n  }\n\n  _runInputLeakyRelu(input: Float32Array): Float32Array {\n    this.outputs[0] = input; // set output state of input layer\n    const { leakyReluAlpha } = this.trainOpts;\n    let output = null;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const activeSize = this.sizes[layer];\n      const activeWeights = this.weights[layer];\n      const activeBiases = this.biases[layer];\n      const activeOutputs = this.outputs[layer];\n      for (let node = 0; node < activeSize; node++) {\n        const weights = activeWeights[node];\n\n        let sum = activeBiases[node];\n        for (let k = 0; k < weights.length; k++) {\n          sum += weights[k] * input[k];\n        }\n        // leaky relu\n        activeOutputs[node] = Math.max(sum, leakyReluAlpha * sum);\n      }\n      output = input = activeOutputs;\n    }\n    if (!output) {\n      throw new Error('output was empty');\n    }\n    return output;\n  }\n\n  _runInputTanh(input: Float32Array): Float32Array {\n    this.outputs[0] = input; // set output state of input layer\n\n    let output = null;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const activeSize = this.sizes[layer];\n      const activeWeights = this.weights[layer];\n      const activeBiases = this.biases[layer];\n      const activeOutputs = this.outputs[layer];\n      for (let node = 0; node < activeSize; node++) {\n        const weights = activeWeights[node];\n\n        let sum = activeBiases[node];\n        for (let k = 0; k < weights.length; k++) {\n          sum += weights[k] * input[k];\n        }\n        // tanh\n        activeOutputs[node] = Math.tanh(sum);\n      }\n      output = input = activeOutputs;\n    }\n    if (!output) {\n      throw new Error('output was empty');\n    }\n    return output;\n  }\n\n  /**\n   *\n   * Verifies network sizes are initialized\n   * If they are not it will initialize them based off the data set.\n   */\n  verifyIsInitialized(\n    preparedData: Array<INeuralNetworkDatumFormatted<Float32Array>>\n  ): void {\n    if (this.sizes.length) return;\n\n    this.sizes = [];\n    this.sizes.push(preparedData[0].input.length);\n    if (!this.options.hiddenLayers) {\n      this.sizes.push(\n        Math.max(3, Math.floor(preparedData[0].input.length / 2))\n      );\n    } else {\n      this.options.hiddenLayers.forEach((size) => {\n        this.sizes.push(size);\n      });\n    }\n    this.sizes.push(preparedData[0].output.length);\n\n    this.initialize();\n  }\n\n  updateTrainingOptions(trainOpts: Partial<INeuralNetworkTrainOptions>): void {\n    const merged = { ...this.trainOpts, ...trainOpts };\n    this.validateTrainingOptions(merged);\n    this.trainOpts = merged;\n    this.setLogMethod(this.trainOpts.log);\n  }\n\n  validateTrainingOptions(options: INeuralNetworkTrainOptions): void {\n    const validations: { [fnName: string]: () => boolean } = {\n      activation: () => {\n        return ['sigmoid', 'relu', 'leaky-relu', 'tanh'].includes(\n          options.activation\n        );\n      },\n      iterations: () => {\n        const val = options.iterations;\n        return typeof val === 'number' && val > 0;\n      },\n      errorThresh: () => {\n        const val = options.errorThresh;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      log: () => {\n        const val = options.log;\n        return typeof val === 'function' || typeof val === 'boolean';\n      },\n      logPeriod: () => {\n        const val = options.logPeriod;\n        return typeof val === 'number' && val > 0;\n      },\n      leakyReluAlpha: () => {\n        const val = options.leakyReluAlpha;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      learningRate: () => {\n        const val = options.learningRate;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      momentum: () => {\n        const val = options.momentum;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      callback: () => {\n        const val = options.callback;\n        return typeof val === 'function' || val === undefined;\n      },\n      callbackPeriod: () => {\n        const val = options.callbackPeriod;\n        return typeof val === 'number' && val > 0;\n      },\n      timeout: () => {\n        const val = options.timeout;\n        return typeof val === 'number' && val > 0;\n      },\n      praxis: () => {\n        const val = options.praxis;\n        return !val || val === 'adam';\n      },\n      beta1: () => {\n        const val = options.beta1;\n        return val > 0 && val < 1;\n      },\n      beta2: () => {\n        const val = options.beta2;\n        return val > 0 && val < 1;\n      },\n      epsilon: () => {\n        const val = options.epsilon;\n        return val > 0 && val < 1;\n      },\n    };\n    for (const p in validations) {\n      const v = (options as unknown) as { [v: string]: string };\n      if (!validations[p]()) {\n        throw new Error(\n          `[${p}, ${v[p]}] is out of normal training range, your network will probably not train.`\n        );\n      }\n    }\n  }\n\n  /**\n   *\n   *  Gets JSON of trainOpts object\n   *    NOTE: Activation is stored directly on JSON object and not in the training options\n   */\n  getTrainOptsJSON(): INeuralNetworkTrainOptionsJSON {\n    const {\n      activation,\n      iterations,\n      errorThresh,\n      log,\n      logPeriod,\n      leakyReluAlpha,\n      learningRate,\n      momentum,\n      callbackPeriod,\n      timeout,\n      praxis,\n      beta1,\n      beta2,\n      epsilon,\n    } = this.trainOpts;\n    return {\n      activation,\n      iterations,\n      errorThresh,\n      log:\n        typeof log === 'function'\n          ? true\n          : typeof log === 'boolean'\n          ? log\n          : false,\n      logPeriod,\n      leakyReluAlpha,\n      learningRate,\n      momentum,\n      callbackPeriod,\n      timeout: timeout === Infinity ? 'Infinity' : timeout,\n      praxis,\n      beta1,\n      beta2,\n      epsilon,\n    };\n  }\n\n  setLogMethod(log: boolean | ((state: INeuralNetworkState) => void)): void {\n    if (typeof log === 'function') {\n      this.trainOpts.log = log;\n    } else if (log) {\n      this.trainOpts.log = this.logTrainingStatus;\n    } else {\n      this.trainOpts.log = false;\n    }\n  }\n\n  logTrainingStatus(status: INeuralNetworkState): void {\n    console.log(\n      `iterations: ${status.iterations}, training error: ${status.error}`\n    );\n  }\n\n  calculateTrainingError(\n    data: Array<INeuralNetworkDatumFormatted<Float32Array>>\n  ): number {\n    let sum = 0;\n    for (let i = 0; i < data.length; ++i) {\n      sum += this.trainPattern(data[i], true) as number;\n    }\n    return sum / data.length;\n  }\n\n  trainPatterns(data: Array<INeuralNetworkDatumFormatted<Float32Array>>): void {\n    for (let i = 0; i < data.length; ++i) {\n      this.trainPattern(data[i]);\n    }\n  }\n\n  trainingTick(\n    data: Array<INeuralNetworkDatumFormatted<Float32Array>>,\n    status: INeuralNetworkState,\n    endTime: number\n  ): boolean {\n    const {\n      callback,\n      callbackPeriod,\n      errorThresh,\n      iterations,\n      log,\n      logPeriod,\n    } = this.trainOpts;\n\n    if (\n      status.iterations >= iterations ||\n      status.error <= errorThresh ||\n      Date.now() >= endTime\n    ) {\n      return false;\n    }\n\n    status.iterations++;\n\n    if (log && status.iterations % logPeriod === 0) {\n      status.error = this.calculateTrainingError(data);\n      (log as (state: INeuralNetworkState) => void)(status);\n    } else if (status.iterations % this.errorCheckInterval === 0) {\n      status.error = this.calculateTrainingError(data);\n    } else {\n      this.trainPatterns(data);\n    }\n\n    if (callback && status.iterations % callbackPeriod === 0) {\n      callback({\n        iterations: status.iterations,\n        error: status.error,\n      });\n    }\n    return true;\n  }\n\n  prepTraining(\n    data: Array<INeuralNetworkDatum<InputType, OutputType>>,\n    options: Partial<INeuralNetworkTrainOptions> = {}\n  ): INeuralNetworkPreppedTrainingData<Float32Array> {\n    this.updateTrainingOptions(options);\n    const preparedData = this.formatData(data);\n    const endTime = Date.now() + this.trainOpts.timeout;\n\n    const status = {\n      error: 1,\n      iterations: 0,\n    };\n\n    this.verifyIsInitialized(preparedData);\n\n    return {\n      preparedData,\n      status,\n      endTime,\n    };\n  }\n\n  train(\n    data: Array<INeuralNetworkDatum<Partial<InputType>, Partial<OutputType>>>,\n    options: Partial<INeuralNetworkTrainOptions> = {}\n  ): INeuralNetworkState {\n    const { preparedData, status, endTime } = this.prepTraining(\n      data as Array<INeuralNetworkDatum<InputType, OutputType>>,\n      options\n    );\n\n    while (true) {\n      if (!this.trainingTick(preparedData, status, endTime)) {\n        break;\n      }\n    }\n    return status;\n  }\n\n  async trainAsync(\n    data: Array<INeuralNetworkDatum<InputType, OutputType>>,\n    options: Partial<INeuralNetworkTrainOptions> = {}\n  ): Promise<ITrainingStatus> {\n    const { preparedData, status, endTime } = this.prepTraining(data, options);\n\n    return await new Promise((resolve, reject) => {\n      try {\n        const thawedTrain: Thaw = new Thaw(\n          new Array(this.trainOpts.iterations),\n          {\n            delay: true,\n            each: () =>\n              this.trainingTick(preparedData, status, endTime) ||\n              thawedTrain.stop(),\n            done: () => resolve(status),\n          }\n        );\n        thawedTrain.tick();\n      } catch (trainError) {\n        reject(trainError);\n      }\n    });\n  }\n\n  trainPattern(\n    value: INeuralNetworkDatumFormatted<Float32Array>,\n    logErrorRate?: boolean\n  ): number | null {\n    // forward propagate\n    this.runInput(value.input);\n\n    // back propagate\n    this.calculateDeltas(value.output);\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      return mse(this.errors[this.outputLayer]);\n    }\n    return null;\n  }\n\n  _calculateDeltasSigmoid(target: Float32Array): void {\n    for (let layer = this.outputLayer; layer >= 0; layer--) {\n      const activeSize = this.sizes[layer];\n      const activeOutput = this.outputs[layer];\n      const activeError = this.errors[layer];\n      const activeDeltas = this.deltas[layer];\n      const nextLayer = this.weights[layer + 1];\n\n      for (let node = 0; node < activeSize; node++) {\n        const output = activeOutput[node];\n\n        let error = 0;\n        if (layer === this.outputLayer) {\n          error = target[node] - output;\n        } else {\n          const deltas = this.deltas[layer + 1];\n          for (let k = 0; k < deltas.length; k++) {\n            error += deltas[k] * nextLayer[k][node];\n          }\n        }\n        activeError[node] = error;\n        activeDeltas[node] = error * output * (1 - output);\n      }\n    }\n  }\n\n  _calculateDeltasRelu(target: Float32Array): void {\n    for (let layer = this.outputLayer; layer >= 0; layer--) {\n      const currentSize = this.sizes[layer];\n      const currentOutputs = this.outputs[layer];\n      const nextWeights = this.weights[layer + 1];\n      const nextDeltas = this.deltas[layer + 1];\n      const currentErrors = this.errors[layer];\n      const currentDeltas = this.deltas[layer];\n\n      for (let node = 0; node < currentSize; node++) {\n        const output = currentOutputs[node];\n\n        let error = 0;\n        if (layer === this.outputLayer) {\n          error = target[node] - output;\n        } else {\n          for (let k = 0; k < nextDeltas.length; k++) {\n            error += nextDeltas[k] * nextWeights[k][node];\n          }\n        }\n        currentErrors[node] = error;\n        currentDeltas[node] = output > 0 ? error : 0;\n      }\n    }\n  }\n\n  _calculateDeltasLeakyRelu(target: Float32Array): void {\n    const alpha = this.trainOpts.leakyReluAlpha;\n    for (let layer = this.outputLayer; layer >= 0; layer--) {\n      const currentSize = this.sizes[layer];\n      const currentOutputs = this.outputs[layer];\n      const nextDeltas = this.deltas[layer + 1];\n      const nextWeights = this.weights[layer + 1];\n      const currentErrors = this.errors[layer];\n      const currentDeltas = this.deltas[layer];\n\n      for (let node = 0; node < currentSize; node++) {\n        const output = currentOutputs[node];\n\n        let error = 0;\n        if (layer === this.outputLayer) {\n          error = target[node] - output;\n        } else {\n          for (let k = 0; k < nextDeltas.length; k++) {\n            error += nextDeltas[k] * nextWeights[k][node];\n          }\n        }\n        currentErrors[node] = error;\n        currentDeltas[node] = output > 0 ? error : alpha * error;\n      }\n    }\n  }\n\n  _calculateDeltasTanh(target: Float32Array): void {\n    for (let layer = this.outputLayer; layer >= 0; layer--) {\n      const currentSize = this.sizes[layer];\n      const currentOutputs = this.outputs[layer];\n      const nextDeltas = this.deltas[layer + 1];\n      const nextWeights = this.weights[layer + 1];\n      const currentErrors = this.errors[layer];\n      const currentDeltas = this.deltas[layer];\n\n      for (let node = 0; node < currentSize; node++) {\n        const output = currentOutputs[node];\n\n        let error = 0;\n        if (layer === this.outputLayer) {\n          error = target[node] - output;\n        } else {\n          for (let k = 0; k < nextDeltas.length; k++) {\n            error += nextDeltas[k] * nextWeights[k][node];\n          }\n        }\n        currentErrors[node] = error;\n        currentDeltas[node] = (1 - output * output) * error;\n      }\n    }\n  }\n\n  /**\n   *\n   * Changes weights of networks\n   */\n  adjustWeights(): void {\n    const { learningRate, momentum } = this.trainOpts;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const incoming = this.outputs[layer - 1];\n      const activeSize = this.sizes[layer];\n      const activeDelta = this.deltas[layer];\n      const activeChanges = this.changes[layer];\n      const activeWeights = this.weights[layer];\n      const activeBiases = this.biases[layer];\n\n      for (let node = 0; node < activeSize; node++) {\n        const delta = activeDelta[node];\n\n        for (let k = 0; k < incoming.length; k++) {\n          let change = activeChanges[node][k];\n\n          change = learningRate * delta * incoming[k] + momentum * change;\n\n          activeChanges[node][k] = change;\n          activeWeights[node][k] += change;\n        }\n        activeBiases[node] += learningRate * delta;\n      }\n    }\n  }\n\n  _setupAdam(): void {\n    this.biasChangesLow = [];\n    this.biasChangesHigh = [];\n    this.changesLow = [];\n    this.changesHigh = [];\n    this.iterations = 0;\n\n    for (let layer = 0; layer <= this.outputLayer; layer++) {\n      const size = this.sizes[layer];\n      if (layer > 0) {\n        this.biasChangesLow[layer] = zeros(size);\n        this.biasChangesHigh[layer] = zeros(size);\n        this.changesLow[layer] = new Array(size);\n        this.changesHigh[layer] = new Array(size);\n\n        for (let node = 0; node < size; node++) {\n          const prevSize = this.sizes[layer - 1];\n          this.changesLow[layer][node] = zeros(prevSize);\n          this.changesHigh[layer][node] = zeros(prevSize);\n        }\n      }\n    }\n\n    this.adjustWeights = this._adjustWeightsAdam;\n  }\n\n  _adjustWeightsAdam(): void {\n    this.iterations++;\n\n    const { iterations } = this;\n    const { beta1, beta2, epsilon, learningRate } = this.trainOpts;\n\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const incoming = this.outputs[layer - 1];\n      const currentSize = this.sizes[layer];\n      const currentDeltas = this.deltas[layer];\n      const currentChangesLow = this.changesLow[layer];\n      const currentChangesHigh = this.changesHigh[layer];\n      const currentWeights = this.weights[layer];\n      const currentBiases = this.biases[layer];\n      const currentBiasChangesLow = this.biasChangesLow[layer];\n      const currentBiasChangesHigh = this.biasChangesHigh[layer];\n\n      for (let node = 0; node < currentSize; node++) {\n        const delta = currentDeltas[node];\n\n        for (let k = 0; k < incoming.length; k++) {\n          const gradient = delta * incoming[k];\n          const changeLow =\n            currentChangesLow[node][k] * beta1 + (1 - beta1) * gradient;\n          const changeHigh =\n            currentChangesHigh[node][k] * beta2 +\n            (1 - beta2) * gradient * gradient;\n\n          const momentumCorrection =\n            changeLow / (1 - Math.pow(beta1, iterations));\n          const gradientCorrection =\n            changeHigh / (1 - Math.pow(beta2, iterations));\n\n          currentChangesLow[node][k] = changeLow;\n          currentChangesHigh[node][k] = changeHigh;\n          currentWeights[node][k] +=\n            (learningRate * momentumCorrection) /\n            (Math.sqrt(gradientCorrection) + epsilon);\n        }\n\n        const biasGradient = currentDeltas[node];\n        const biasChangeLow =\n          currentBiasChangesLow[node] * beta1 + (1 - beta1) * biasGradient;\n        const biasChangeHigh =\n          currentBiasChangesHigh[node] * beta2 +\n          (1 - beta2) * biasGradient * biasGradient;\n\n        const biasMomentumCorrection =\n          currentBiasChangesLow[node] / (1 - Math.pow(beta1, iterations));\n        const biasGradientCorrection =\n          currentBiasChangesHigh[node] / (1 - Math.pow(beta2, iterations));\n\n        currentBiasChangesLow[node] = biasChangeLow;\n        currentBiasChangesHigh[node] = biasChangeHigh;\n        currentBiases[node] +=\n          (learningRate * biasMomentumCorrection) /\n          (Math.sqrt(biasGradientCorrection) + epsilon);\n      }\n    }\n  }\n\n  formatData(\n    data: Array<INeuralNetworkDatum<InputType, OutputType>>\n  ): Array<INeuralNetworkDatumFormatted<Float32Array>> {\n    if (!Array.isArray(data[0].input)) {\n      if (this.inputLookup) {\n        this.inputLookupLength = Object.keys(this.inputLookup).length;\n      } else {\n        const inputLookup = new LookupTable(data, 'input');\n        this.inputLookup = inputLookup.table;\n        this.inputLookupLength = inputLookup.length;\n      }\n    }\n\n    if (!Array.isArray(data[0].output)) {\n      if (this.outputLookup) {\n        this.outputLookupLength = Object.keys(this.outputLookup).length;\n      } else {\n        const lookup = new LookupTable(data, 'output');\n        this.outputLookup = lookup.table;\n        this.outputLookupLength = lookup.length;\n      }\n    }\n\n    if (!this._formatInput) {\n      this._formatInput = getTypedArrayFn(data[0].input, this.inputLookup);\n    }\n\n    if (!this._formatOutput) {\n      this._formatOutput = getTypedArrayFn(data[0].output, this.outputLookup);\n    }\n\n    // turn sparse hash input into arrays with 0s as filler\n    if (this._formatInput && this._formatOutput) {\n      const result: Array<INeuralNetworkDatumFormatted<Float32Array>> = [];\n      for (let i = 0; i < data.length; i++) {\n        result.push({\n          input: (this._formatInput as (v: INumberHash) => Float32Array)(\n            (data[i].input as unknown) as INumberHash\n          ),\n          output: (this._formatOutput as (v: INumberHash) => Float32Array)(\n            (data[i].output as unknown) as INumberHash\n          ),\n        });\n      }\n      return result;\n    }\n    if (this._formatInput) {\n      const result: Array<INeuralNetworkDatumFormatted<Float32Array>> = [];\n      for (let i = 0; i < data.length; i++) {\n        result.push({\n          input: (this._formatInput as (v: INumberHash) => Float32Array)(\n            (data[i].input as unknown) as INumberHash\n          ),\n          output: (data[i].output as unknown) as Float32Array,\n        });\n      }\n      return result;\n    }\n    if (this._formatOutput) {\n      const result: Array<INeuralNetworkDatumFormatted<Float32Array>> = [];\n      for (let i = 0; i < data.length; i++) {\n        result.push({\n          input: (data[i].input as unknown) as Float32Array,\n          output: (this._formatOutput as (v: INumberHash) => Float32Array)(\n            (data[i].output as unknown) as INumberHash\n          ),\n        });\n      }\n      return result;\n    }\n    return (data as unknown) as Array<\n      INeuralNetworkDatumFormatted<Float32Array>\n    >;\n  }\n\n  addFormat(data: INeuralNetworkDatum<InputType, OutputType>): void {\n    if (!Array.isArray(data.input) || typeof data.input[0] !== 'number') {\n      this.inputLookup = lookup.addKeys(\n        (data.input as unknown) as INumberHash,\n        this.inputLookup ?? {}\n      );\n      if (this.inputLookup) {\n        this.inputLookupLength = Object.keys(this.inputLookup).length;\n      }\n    }\n    if (!Array.isArray(data.output) || typeof data.output[0] !== 'number') {\n      this.outputLookup = lookup.addKeys(\n        (data.output as unknown) as INumberHash,\n        this.outputLookup ?? {}\n      );\n      if (this.outputLookup) {\n        this.outputLookupLength = Object.keys(this.outputLookup).length;\n      }\n    }\n  }\n\n  test(\n    data: Array<INeuralNetworkDatum<Partial<InputType>, Partial<OutputType>>>\n  ): INeuralNetworkTestResult | INeuralNetworkBinaryTestResult {\n    const { preparedData } = this.prepTraining(\n      data as Array<INeuralNetworkDatum<InputType, OutputType>>\n    );\n    // for binary classification problems with one output node\n    const isBinary = preparedData[0].output.length === 1;\n    // for classification problems\n    const misclasses = [];\n    // run each pattern through the trained network and collect\n    // error and misclassification statistics\n    let errorSum = 0;\n    if (isBinary) {\n      let falsePos = 0;\n      let falseNeg = 0;\n      let truePos = 0;\n      let trueNeg = 0;\n\n      for (let i = 0; i < preparedData.length; i++) {\n        const output = this.runInput(preparedData[i].input);\n        const target = preparedData[i].output;\n        const actual = output[0] > this.options.binaryThresh ? 1 : 0;\n        const expected = target[0];\n\n        if (actual !== expected) {\n          const misclass = preparedData[i];\n          misclasses.push({\n            input: misclass.input,\n            output: misclass.output,\n            actual,\n            expected,\n          });\n        }\n\n        if (actual === 0 && expected === 0) {\n          trueNeg++;\n        } else if (actual === 1 && expected === 1) {\n          truePos++;\n        } else if (actual === 0 && expected === 1) {\n          falseNeg++;\n        } else if (actual === 1 && expected === 0) {\n          falsePos++;\n        }\n\n        errorSum += mse(\n          output.map((value, i) => {\n            return target[i] - value;\n          })\n        );\n      }\n\n      return {\n        error: errorSum / preparedData.length,\n        misclasses,\n        total: preparedData.length,\n        trueNeg,\n        truePos,\n        falseNeg,\n        falsePos,\n        precision: truePos > 0 ? truePos / (truePos + falsePos) : 0,\n        recall: truePos > 0 ? truePos / (truePos + falseNeg) : 0,\n        accuracy: (trueNeg + truePos) / preparedData.length,\n      };\n    }\n\n    for (let i = 0; i < preparedData.length; i++) {\n      const output = this.runInput(preparedData[i].input);\n      const target = preparedData[i].output;\n      const actual = output.indexOf(max(output));\n      const expected = target.indexOf(max(target));\n\n      if (actual !== expected) {\n        const misclass = preparedData[i];\n        misclasses.push({\n          input: misclass.input,\n          output: misclass.output,\n          actual,\n          expected,\n        });\n      }\n\n      errorSum += mse(\n        output.map((value, i) => {\n          return target[i] - value;\n        })\n      );\n    }\n    return {\n      error: errorSum / preparedData.length,\n      misclasses,\n      total: preparedData.length,\n    };\n  }\n\n  toJSON(): INeuralNetworkJSON {\n    if (!this.isRunnable) {\n      this.initialize();\n    }\n    // use Array.from, keeping json small\n    const jsonLayerWeights = this.weights.map((layerWeights) => {\n      return layerWeights.map((layerWeights) => Array.from(layerWeights));\n    });\n    const jsonLayerBiases = this.biases.map((layerBiases) =>\n      Array.from(layerBiases)\n    );\n    const jsonLayers: IJSONLayer[] = [];\n    const outputLength = this.sizes.length - 1;\n    for (let i = 0; i <= outputLength; i++) {\n      jsonLayers.push({\n        weights: jsonLayerWeights[i] ?? [],\n        biases: jsonLayerBiases[i] ?? [],\n      });\n    }\n    return {\n      type: 'NeuralNetwork',\n      sizes: [...this.sizes],\n      layers: jsonLayers,\n      inputLookup: this.inputLookup ? { ...this.inputLookup } : null,\n      inputLookupLength: this.inputLookupLength,\n      outputLookup: this.outputLookup ? { ...this.outputLookup } : null,\n      outputLookupLength: this.outputLookupLength,\n      options: { ...this.options },\n      trainOpts: this.getTrainOptsJSON(),\n    };\n  }\n\n  fromJSON(json: INeuralNetworkJSON): this {\n    this.options = { ...defaults(), ...json.options };\n    if (json.hasOwnProperty('trainOpts')) {\n      const trainOpts = {\n        ...json.trainOpts,\n        timeout:\n          json.trainOpts.timeout === 'Infinity'\n            ? Infinity\n            : json.trainOpts.timeout,\n      };\n      this.updateTrainingOptions(trainOpts);\n    }\n    this.sizes = json.sizes;\n    this.initialize();\n\n    this.inputLookup = json.inputLookup ? { ...json.inputLookup } : null;\n    this.inputLookupLength = json.inputLookupLength;\n    this.outputLookup = json.outputLookup ? { ...json.outputLookup } : null;\n    this.outputLookupLength = json.outputLookupLength;\n\n    const jsonLayers = json.layers;\n    const layerWeights = this.weights.map((layerWeights, layerIndex) => {\n      return jsonLayers[layerIndex].weights.map((layerWeights) =>\n        Float32Array.from(layerWeights)\n      );\n    });\n    const layerBiases = this.biases.map((layerBiases, layerIndex) =>\n      Float32Array.from(jsonLayers[layerIndex].biases)\n    );\n    for (let i = 0; i <= this.outputLayer; i++) {\n      this.weights[i] = layerWeights[i] || [];\n      this.biases[i] = layerBiases[i] || [];\n    }\n    return this;\n  }\n\n  toFunction(\n    cb?: (source: string) => string\n  ): (input: Partial<InputType>) => OutputType {\n    const { activation, leakyReluAlpha } = this.trainOpts;\n    let needsVar = false;\n    const nodeHandle = (layerIndex: number, nodeIndex: number): string => {\n      if (layerIndex === 0) {\n        return `(input[${nodeIndex}]||0)`;\n      }\n\n      const weights: Float32Array = this.weights[layerIndex][nodeIndex];\n      const bias: number = this.biases[layerIndex][nodeIndex];\n      if (!weights) {\n        throw new Error(\n          `weights at layerIndex ${layerIndex} & nodeIndex ${nodeIndex} not found`\n        );\n      }\n      if (!bias) {\n        throw new Error(\n          `bias as layerIndex ${layerIndex} & nodeIndex ${nodeIndex} not found`\n        );\n      }\n      const weightsArray: string[] = [];\n      weights.forEach((weight: number, subNodeIndex: number): void => {\n        if (weight < 0) {\n          weightsArray.push(\n            `${weight}*${nodeHandle(layerIndex - 1, subNodeIndex)}`\n          );\n        } else {\n          weightsArray.push(\n            `+${weight}*${nodeHandle(layerIndex - 1, subNodeIndex)}`\n          );\n        }\n      });\n      const result = `(${bias.toString()}${weightsArray.join('')})`;\n\n      switch (activation) {\n        case 'sigmoid':\n          return `1/(1+1/Math.exp(${result}))`;\n        case 'relu': {\n          needsVar = true;\n          return `((v=${result})<0?0:v)`;\n        }\n        case 'leaky-relu': {\n          needsVar = true;\n          return `Math.max((v=${result}),${leakyReluAlpha}*v)`;\n        }\n        case 'tanh':\n          return `Math.tanh(${result})`;\n        default:\n          throw new Error(\n            `Unknown activation ${activation}. Available activations are: 'sigmoid', 'relu', 'leaky-relu', 'tanh'`\n          );\n      }\n    };\n\n    function checkKeys(keys: string[]): void {\n      if (keys.find((v) => v.includes('\"'))) {\n        throw new Error(`key contains '\"', which is not compatible`);\n      }\n    }\n\n    const layersAsMath: string[] = [];\n    let result: string;\n\n    let inputLookup = '';\n    if (this.inputLookup) {\n      const keys = Object.keys(this.inputLookup);\n      checkKeys(keys);\n      inputLookup = `input = new Float32Array([${Object.keys(this.inputLookup)\n        .map((key) => `input[\"${key}\"]`)\n        .join(',')}]);`;\n    }\n    if (this.sizes.length < 1) throw new Error('No layers');\n    for (\n      let nodeIndex = 0;\n      nodeIndex < this.sizes[this.outputLayer];\n      nodeIndex++\n    ) {\n      layersAsMath.push(nodeHandle(this.outputLayer, nodeIndex));\n    }\n    if (this.outputLookup) {\n      const keys = Object.keys(this.outputLookup);\n      checkKeys(keys);\n      const values = keys\n        .map((key, i) => `\"${key}\":${layersAsMath[i]}`)\n        .join(',');\n      result = `{${values}}`;\n    } else {\n      result = `[${layersAsMath.join(',')}]`;\n    }\n\n    const source = `${inputLookup}${needsVar ? 'var v;' : ''}return ${result};`;\n    // eslint-disable-next-line @typescript-eslint/no-implied-eval,no-new-func\n    return new Function('input', cb ? cb(source) : source) as (\n      input: Partial<InputType>\n    ) => OutputType;\n  }\n}\n","import {\n  alias,\n  GPU,\n  GPUFunction,\n  IKernelFunctionThis,\n  IKernelMapRunShortcut,\n  IMappedKernelResult,\n  KernelOutput,\n  Texture,\n  utils,\n} from 'gpu.js';\nimport { ITrainingStatus } from './feed-forward';\nimport { INumberHash, lookup } from './lookup';\nimport {\n  IJSONLayer,\n  INeuralNetworkDatum,\n  INeuralNetworkJSON,\n  INeuralNetworkOptions,\n  INeuralNetworkPreppedTrainingData,\n  INeuralNetworkTrainOptions,\n  NeuralNetwork,\n} from './neural-network';\nimport { release } from './utilities/kernel';\n\nexport interface INeuralNetworkGPUDatumFormatted {\n  input: KernelOutput;\n  output: KernelOutput;\n}\n\nexport interface INeuralNetworkGPUPreppedTrainingData\n  extends INeuralNetworkPreppedTrainingData<KernelOutput> {\n  status: ITrainingStatus;\n  endTime: number;\n}\n\ninterface ISizedKernelThis extends IKernelFunctionThis {\n  constants: {\n    size: number;\n  };\n}\n\nfunction weightedSumSigmoid(\n  this: ISizedKernelThis,\n  weights: number[][],\n  biases: number[],\n  inputs: number[]\n): number {\n  let sum = biases[this.thread.x];\n  for (let k = 0; k < this.constants.size; k++) {\n    sum += weights[this.thread.x][k] * inputs[k];\n  }\n  // sigmoid\n  return 1 / (1 + Math.exp(-sum));\n}\n\nfunction weightedSumRelu(\n  this: ISizedKernelThis,\n  weights: number[][],\n  biases: number[],\n  inputs: number[]\n): number {\n  let sum = biases[this.thread.x];\n  for (let k = 0; k < this.constants.size; k++) {\n    sum += weights[this.thread.x][k] * inputs[k];\n  }\n  // relu\n  return sum < 0 ? 0 : sum;\n}\n\nfunction weightedSumLeakyRelu(\n  this: ISizedKernelThis,\n  weights: number[][],\n  biases: number[],\n  inputs: number[]\n): number {\n  let sum = biases[this.thread.x];\n  for (let k = 0; k < this.constants.size; k++) {\n    sum += weights[this.thread.x][k] * inputs[k];\n  }\n  // leaky relu\n  return sum < 0 ? 0 : 0.01 * sum;\n}\n\nfunction weightedSumTanh(\n  this: ISizedKernelThis,\n  weights: number[][],\n  biases: number[],\n  inputs: number[]\n): number {\n  let sum = biases[this.thread.x];\n  for (let k = 0; k < this.constants.size; k++) {\n    sum += weights[this.thread.x][k] * inputs[k];\n  }\n  // tanh\n  return Math.tanh(sum);\n}\n\nfunction calcErrorOutput(output: number, target: number): number {\n  return target - output;\n}\n\nfunction calcDeltasSigmoid(error: number, output: number): number {\n  // sigmoid derivative\n  return error * output * (1 - output);\n}\n\nfunction calcDeltasRelu(error: number, output: number): number {\n  // relu derivative\n  return output > 0 ? error : 0;\n}\n\nfunction calcDeltasLeakyRelu(error: number, output: number): number {\n  // leaky relu derivative\n  return output > 0 ? error : 0.01 * error;\n}\n\nfunction calcDeltasTanh(error: number, output: number): number {\n  // tanh derivative\n  return (1 - output * output) * error;\n}\n\nfunction calcError(\n  x: number,\n  size: number,\n  nextWeights: number[][],\n  nextDeltas: number[]\n): number {\n  let error = 0;\n  for (let k = 0; k < size; k++) {\n    error += nextDeltas[k] * nextWeights[k][x];\n  }\n  return error;\n}\n\ninterface ILearningKernelThis extends IKernelFunctionThis {\n  constants: {\n    momentum: number;\n    learningRate: number;\n  };\n}\n\nfunction calcChanges(\n  learningRate: number,\n  momentum: number,\n  previousChange: number,\n  delta: number,\n  previousOutput: number\n): number {\n  return learningRate * delta * previousOutput + momentum * previousChange;\n}\n\nfunction addWeights(change: number, weight: number): number {\n  return change + weight;\n}\n\nfunction addBiases(\n  this: ILearningKernelThis,\n  biases: number[],\n  deltas: number[]\n): number {\n  return (\n    biases[this.thread.x] + deltas[this.thread.x] * this.constants.learningRate\n  );\n}\n\n// mean squared error, reimplemented for GPU\nfunction mse(this: ISizedKernelThis, errors: number[]): number {\n  let sum = 0;\n  for (let i = 0; i < this.constants.size; i++) {\n    sum += errors[i] ** 2;\n  }\n  return sum / this.constants.size;\n}\n\nexport interface INeuralNetworkGPUOptions extends INeuralNetworkOptions {\n  mode?: 'cpu' | 'gpu';\n}\n\nexport type BackPropagateOutput = (\n  this: IKernelFunctionThis,\n  outputs: KernelOutput,\n  targets: KernelOutput\n) => { result: KernelOutput; error: KernelOutput };\n\nexport type BackPropagateLayer = (\n  this: IKernelFunctionThis,\n  weights: KernelOutput,\n  outputs: KernelOutput,\n  deltas: KernelOutput\n) => { result: KernelOutput; error: KernelOutput };\n\nexport class NeuralNetworkGPU<InputType, OutputType> extends NeuralNetwork<\n  InputType,\n  OutputType\n> {\n  gpu: GPU;\n\n  texturizeInputData: (value: KernelOutput) => KernelOutput = () => {\n    throw new Error('not yet setup');\n  };\n\n  forwardPropagate: Array<\n    (\n      weights: KernelOutput,\n      biases: KernelOutput,\n      inputs: KernelOutput\n    ) => KernelOutput\n  > = [];\n\n  backwardPropagate: Array<BackPropagateOutput | BackPropagateLayer> = [];\n\n  changesPropagate: Array<\n    ((\n      this: IKernelFunctionThis<{\n        size: number;\n        learningRate: number;\n        momentum: number;\n      }>,\n      previousOutputs: number[],\n      deltas: number[],\n      weights: number[][],\n      previousChanges: number[][]\n    ) => IMappedKernelResult) &\n      IKernelMapRunShortcut<{ weights: number[][]; changes: number[][] }>\n  > = [];\n\n  biasesPropagate: Array<\n    (biases: KernelOutput, deltas: KernelOutput) => KernelOutput\n  > = [];\n\n  getMSE: (error: KernelOutput) => KernelOutput = () => {\n    throw new Error('not yet setup');\n  };\n\n  _addMSE: (sum: KernelOutput, error: KernelOutput) => KernelOutput = () => {\n    throw new Error('not yet setup');\n  };\n\n  _divideMSESum: (length: number, sum: KernelOutput) => KernelOutput = () => {\n    throw new Error('not yet setup');\n  };\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  outputs: KernelOutput[] = [];\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  deltas: KernelOutput[] = [];\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  errors: KernelOutput[] = [];\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  weights: KernelOutput[] = [];\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  changes: KernelOutput[] = [];\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  biases: KernelOutput[] = [];\n\n  constructor(options: Partial<INeuralNetworkGPUOptions> = {}) {\n    super(options);\n    this.errorCheckInterval = 100;\n    this.gpu = new GPU({ mode: options.mode });\n  }\n\n  initialize(): void {\n    super.initialize();\n    this.buildRunInput();\n    this.buildCalculateDeltas();\n    this.buildGetChanges();\n    this.buildChangeBiases();\n    this.buildGetMSE();\n  }\n\n  setActivation(): void {}\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  trainPattern(\n    value: INeuralNetworkGPUDatumFormatted,\n    logErrorRate?: boolean\n  ): KernelOutput | null {\n    // forward propagate\n    this.runInput(value.input);\n\n    // back propagate\n    this.calculateDeltas(value.output);\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      return this.getMSE(this.errors[this.outputLayer]);\n    }\n    return null;\n  }\n\n  calculateTrainingError(data: INeuralNetworkGPUDatumFormatted[]): number {\n    let sum = new Float32Array([0]) as KernelOutput;\n    for (let i = 0; i < data.length; ++i) {\n      const prevSum = sum;\n      const error = this.trainPattern(data[i], true) as KernelOutput;\n      sum = this._addMSE(sum, error);\n      release(error);\n      release(prevSum);\n    }\n    const result = this._divideMSESum(data.length, sum);\n    release(sum);\n    return (result instanceof Texture\n      ? (result.toArray() as number[])\n      : (result as number[]))[0];\n  }\n\n  adjustWeights(): void {\n    this.getChanges();\n    this.changeBiases();\n  }\n\n  buildRunInput(): void {\n    let weightedSum = null;\n\n    switch (this.trainOpts.activation) {\n      case 'sigmoid':\n        weightedSum = weightedSumSigmoid;\n        break;\n      case 'relu':\n        weightedSum = weightedSumRelu;\n        break;\n      case 'leaky-relu':\n        weightedSum = weightedSumLeakyRelu;\n        break;\n      case 'tanh':\n        weightedSum = weightedSumTanh;\n        break;\n      default:\n        throw new Error(\n          `Unknown activation ${this.trainOpts.activation}. Available activations are: 'sigmoid', 'relu', 'leaky-relu', 'tanh'`\n        );\n    }\n\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      this.forwardPropagate[layer] = this.gpu.createKernel(weightedSum, {\n        output: [this.sizes[layer]],\n        pipeline: true,\n        constants: {\n          size: this.sizes[layer - 1],\n        },\n        immutable: true,\n      });\n    }\n\n    this.texturizeInputData = this.gpu.createKernel(\n      function (value: number[]): number {\n        return value[this.thread.x];\n      },\n      {\n        output: [this.sizes[1]],\n        pipeline: true,\n        immutable: true,\n      }\n    );\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  runInput = (input: KernelOutput): KernelOutput => {\n    let output;\n    this.outputs[0] = input;\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      release(this.outputs[layer]);\n      this.outputs[layer] = this.forwardPropagate[layer](\n        this.weights[layer],\n        this.biases[layer],\n        input\n      );\n      output = input = this.outputs[layer];\n    }\n    return output;\n  };\n\n  buildCalculateDeltas(): void {\n    let calcDeltas: GPUFunction<[number, number]>;\n    switch (this.trainOpts.activation) {\n      case 'sigmoid':\n        calcDeltas = calcDeltasSigmoid;\n        break;\n      case 'relu':\n        calcDeltas = calcDeltasRelu;\n        break;\n      case 'leaky-relu':\n        calcDeltas = calcDeltasLeakyRelu;\n        break;\n      case 'tanh':\n        calcDeltas = calcDeltasTanh;\n        break;\n      default:\n        throw new Error(\n          `Unknown activation ${this.trainOpts.activation}. Available activations are: 'sigmoid', 'relu', 'leaky-relu', 'tanh'`\n        );\n    }\n\n    calcDeltas = alias(\n      utils.getMinifySafeName(() => calcDeltas),\n      calcDeltas\n    );\n    this.gpu.addFunction(calcDeltas);\n    for (let layer = this.outputLayer; layer > 0; layer--) {\n      if (layer === this.outputLayer) {\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        this.backwardPropagate[this.outputLayer] = this.gpu.createKernelMap(\n          {\n            error: calcErrorOutput,\n          },\n          function (\n            this: IKernelFunctionThis,\n            outputs: number[],\n            targets: number[]\n          ): number {\n            const output = outputs[this.thread.x];\n            const target = targets[this.thread.x];\n            // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n            // @ts-expect-error\n            return calcDeltas(calcErrorOutput(output, target), output);\n          },\n          {\n            output: [this.sizes[this.outputLayer]],\n            pipeline: true,\n            immutable: true,\n          }\n        );\n      } else {\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        this.backwardPropagate[layer] = this.gpu.createKernelMap(\n          {\n            error: calcError,\n          },\n          function (\n            this: ISizedKernelThis,\n            nextWeights: number[][],\n            outputs: number[],\n            nextDeltas: number[]\n          ): number {\n            const output = outputs[this.thread.x];\n            // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n            // @ts-expect-error\n            return calcDeltas(\n              calcError(\n                this.thread.x,\n                this.constants.size,\n                nextWeights,\n                nextDeltas\n              ),\n              output\n            );\n          },\n          {\n            output: [this.sizes[layer]],\n            pipeline: true,\n            constants: {\n              size: this.sizes[layer + 1],\n            },\n            immutable: true,\n          }\n        );\n      }\n    }\n  }\n\n  calculateDeltas = (target: KernelOutput): void => {\n    for (let layer = this.outputLayer; layer > 0; layer--) {\n      release(this.deltas[layer]);\n      release(this.errors[layer]);\n\n      let output;\n      if (layer === this.outputLayer) {\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        output = this.backwardPropagate[layer](this.outputs[layer], target);\n      } else {\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        output = this.backwardPropagate[layer](\n          this.weights[layer + 1],\n          this.outputs[layer],\n          this.deltas[layer + 1]\n        );\n      }\n      this.deltas[layer] = output.result;\n      this.errors[layer] = output.error;\n    }\n  };\n\n  buildGetChanges(): void {\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n      // @ts-expect-error\n      this.changesPropagate[layer] = this.gpu.createKernelMap(\n        {\n          weights: addWeights,\n          changes: calcChanges,\n        },\n        function (\n          this: IKernelFunctionThis<{\n            size: number;\n            learningRate: number;\n            momentum: number;\n          }>,\n          previousOutputs: number[],\n          deltas: number[],\n          weights: number[][],\n          previousChanges: number[][]\n        ) {\n          const change = calcChanges(\n            this.constants.learningRate,\n            this.constants.momentum,\n            previousChanges[this.thread.y][this.thread.x],\n            deltas[this.thread.y],\n            previousOutputs[this.thread.x]\n          );\n          return addWeights(change, weights[this.thread.y][this.thread.x]);\n        },\n        {\n          output: [this.sizes[layer - 1], this.sizes[layer]],\n          pipeline: true,\n          constants: {\n            size: this.sizes[layer - 1],\n            learningRate: this.trainOpts.learningRate,\n            momentum: this.trainOpts.momentum,\n          },\n          immutable: true,\n        }\n      );\n    }\n  }\n\n  getChanges(): void {\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const weights = this.weights[layer];\n      const changes = this.changes[layer];\n      const output = this.changesPropagate[layer](\n        this.outputs[layer - 1],\n        this.deltas[layer],\n        weights,\n        changes\n      );\n      release(weights);\n      release(changes);\n      this.weights[layer] = output.weights;\n      this.changes[layer] = output.changes;\n      release(output.result);\n    }\n  }\n\n  buildChangeBiases(): void {\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      this.biasesPropagate[layer] = this.gpu.createKernel(addBiases, {\n        output: [this.sizes[layer]],\n        pipeline: true,\n        constants: {\n          learningRate: this.trainOpts.learningRate,\n        },\n        immutable: true,\n      });\n    }\n  }\n\n  changeBiases(): void {\n    for (let layer = 1; layer <= this.outputLayer; layer++) {\n      const biases = this.biases[layer];\n      this.biases[layer] = this.biasesPropagate[layer](\n        biases,\n        this.deltas[layer]\n      );\n      release(biases);\n    }\n  }\n\n  buildGetMSE(): void {\n    this.getMSE = this.gpu.createKernel(mse, {\n      output: [1],\n      constants: {\n        size: this.sizes[this.outputLayer],\n      },\n      pipeline: true,\n      immutable: true,\n    });\n    this._addMSE = this.gpu.createKernel(\n      function (value1: number[], value2: number[]): number {\n        return value1[0] + value2[0];\n      },\n      {\n        output: [1],\n        pipeline: true,\n        immutable: true,\n      }\n    );\n    this._divideMSESum = this.gpu.createKernel(\n      function (length: number, mseSum: number[]): number {\n        const value = mseSum[0];\n        if (value > 0) {\n          return value / length;\n        }\n        return 0;\n      },\n      {\n        output: [1],\n      }\n    );\n  }\n\n  run(input: InputType): OutputType {\n    if (!this.isRunnable) {\n      throw new Error('network not runnable');\n    }\n    let formattedInput: Float32Array;\n    if (this.inputLookup) {\n      formattedInput = lookup.toArray(\n        this.inputLookup,\n        (input as unknown) as INumberHash,\n        this.inputLookupLength\n      );\n    } else {\n      formattedInput = (input as unknown) as Float32Array;\n    }\n    const outputTextures = this.runInput(formattedInput);\n    const output =\n      outputTextures instanceof Texture\n        ? outputTextures.toArray()\n        : outputTextures;\n\n    if (this.outputLookup) {\n      return (lookup.toObject(\n        this.outputLookup,\n        output as Float32Array\n      ) as unknown) as OutputType;\n    }\n\n    return (output as unknown) as OutputType;\n  }\n\n  // @ts-expect-error the underlying network works as normal, but we are working on the GPU\n  prepTraining(\n    data: Array<INeuralNetworkDatum<InputType, OutputType>>,\n    options: Partial<INeuralNetworkTrainOptions> = {}\n  ): INeuralNetworkGPUPreppedTrainingData {\n    this.updateTrainingOptions(options);\n    const preparedData = this.formatData(data);\n    const endTime = Date.now() + this.trainOpts.timeout;\n\n    const status = {\n      error: 1,\n      iterations: 0,\n    };\n\n    this.verifyIsInitialized(preparedData);\n\n    const texturizeOutputData = this.gpu.createKernel(\n      function (value: number[]): number {\n        return value[this.thread.x];\n      },\n      {\n        output: [preparedData[0].output.length],\n        pipeline: true,\n        immutable: true,\n      }\n    );\n    return {\n      preparedData: preparedData.map((set) => ({\n        input: this.texturizeInputData(set.input),\n        output: texturizeOutputData(set.output),\n      })),\n      status,\n      endTime,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  toFunction(): (input: InputType) => OutputType {\n    throw new Error(\n      `${this.constructor.name}-toFunction is not yet implemented`\n    );\n  }\n\n  toJSON(): INeuralNetworkJSON {\n    if (this.sizes === null) {\n      this.initialize();\n    }\n    // use Array.from, keeping json small\n    const jsonLayerWeights = this.weights.map((layerWeights) => {\n      return (layerWeights instanceof Texture\n        ? (layerWeights.toArray() as Float32Array[])\n        : (layerWeights as Float32Array[])\n      ).map((layerWeights) => Array.from(layerWeights));\n    });\n    const jsonLayerBiases = this.biases.map((layerBiases) =>\n      Array.from(\n        layerBiases instanceof Texture\n          ? (layerBiases.toArray() as Float32Array)\n          : (layerBiases as Float32Array)\n      )\n    );\n    const jsonLayers: IJSONLayer[] = [];\n    for (let i = 0; i <= this.outputLayer; i++) {\n      jsonLayers.push({\n        weights: jsonLayerWeights[i] ?? [],\n        biases: jsonLayerBiases[i] ?? [],\n      });\n    }\n    return {\n      type: 'NeuralNetworkGPU',\n      sizes: [...this.sizes],\n      layers: jsonLayers,\n      inputLookup: this.inputLookup ? { ...this.inputLookup } : null,\n      inputLookupLength: this.inputLookupLength,\n      outputLookup: this.outputLookup ? { ...this.outputLookup } : null,\n      outputLookupLength: this.outputLookupLength,\n      options: { ...this.options },\n      trainOpts: this.getTrainOptsJSON(),\n    };\n  }\n}\n","import { KernelOutput } from 'gpu.js';\n\nimport { Internal } from './internal';\nimport { release } from '../utilities/kernel';\nimport { ILayer, ILayerSettings } from './base-layer';\n\nexport class RecurrentConnection extends Internal {\n  settings: ILayerSettings = {};\n  layer: ILayer | null = null;\n  setLayer(layer: ILayer): void {\n    this.layer = layer;\n  }\n\n  get width(): number {\n    if (!this.layer) throw new Error('layer not set');\n    return this.layer.width;\n  }\n\n  set width(value: number) {\n    throw new Error(`${this.constructor.name}-width is not yet implemented`);\n  }\n\n  get height(): number {\n    if (!this.layer) throw new Error('layer not set');\n    return this.layer.height;\n  }\n\n  set height(value: number) {\n    throw new Error(`${this.constructor.name}-height is not yet implemented`);\n  }\n\n  get deltas(): KernelOutput {\n    if (!this.layer) throw new Error('layer not set');\n    return this.layer.deltas;\n  }\n\n  set deltas(deltas: KernelOutput) {\n    if (!this.layer) throw new Error('layer not set');\n    release(this.layer.deltas);\n    this.layer.deltas = deltas;\n  }\n\n  get weights(): KernelOutput {\n    if (!this.layer) throw new Error('layer not set');\n    return this.layer.weights as KernelOutput;\n  }\n\n  set weights(weights: KernelOutput) {\n    if (!this.layer) throw new Error('layer not set');\n    release(this.layer.weights);\n    this.layer.weights = weights;\n  }\n\n  predict(): void {\n    // throw new Error(`${this.constructor.name}-predict is not yet implemented`)\n  }\n\n  compare(): void {\n    // throw new Error(`${this.constructor.name}-compare is not yet implemented`)\n  }\n\n  learn(): void {\n    throw new Error('no longer using');\n  }\n\n  setupKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-setupKernels is not yet implemented`\n    // )\n  }\n\n  reuseKernels(): void {\n    // throw new Error(\n    //   `${this.constructor.name}-reuseKernels is not yet implemented`\n    // )\n  }\n}\n","import { RecurrentConnection } from './layer/recurrent-connection';\nimport {\n  IRecurrentInput,\n  RecurrentInput,\n  RecurrentZeros,\n  ILayer,\n  ILayerSettings,\n} from './layer';\nimport {\n  Activation,\n  EntryPoint,\n  EntryPointType,\n  Filter,\n  Internal,\n  InternalModel,\n  Model,\n  Modifier,\n  Operator,\n  Target,\n} from './layer/types';\nimport { flattenLayers } from './utilities/flatten-layers';\nimport {\n  FeedForward,\n  IFeedForwardOptions,\n  IFeedForwardTrainingOptions,\n  ITrainingStatus,\n} from './feed-forward';\nimport { release, clone } from './utilities/kernel';\nimport { KernelOutput, Texture, TextureArrayOutput } from 'gpu.js';\nimport { OperatorType } from './layer/operator';\nimport { ModifierType } from './layer/modifier';\nimport { FilterType } from './layer/filter';\nimport { ActivationType } from './layer/activation';\nimport { TargetType } from './layer/target';\n\nexport interface IRecurrentTrainingOptions\n  extends IFeedForwardTrainingOptions {}\n\n// eslint-disable-next-line @typescript-eslint/ban-ts-comment\n// @ts-expect-error\nexport interface IRecurrentOptions extends IFeedForwardOptions {\n  hiddenLayers: Array<\n    (\n      inputLayer: ILayer,\n      recurrentInput: IRecurrentInput,\n      index: number\n    ) => ILayer\n  >;\n}\n\nexport interface IRecurrentPreppedTrainingData {\n  status: ITrainingStatus;\n  preparedData: KernelOutput[][];\n  endTime: number;\n}\n\nexport class Recurrent extends FeedForward {\n  trainOpts: IRecurrentTrainingOptions = {};\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  options: IRecurrentOptions;\n  _outputConnection: RecurrentConnection | null = null;\n  _layerSets: ILayer[][] = [];\n  _hiddenLayerOutputIndices: number[] = [];\n  _model: ILayer[] | null = null;\n\n  // TODO: use generics in extend\n  constructor(\n    options: Partial<IRecurrentOptions & IRecurrentTrainingOptions> = {}\n  ) {\n    // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n    // @ts-expect-error\n    super(options);\n  }\n\n  _connectLayers(): {\n    inputLayer: ILayer;\n    hiddenLayers: ILayer[];\n    outputLayer: ILayer;\n  } {\n    if (!this.options.inputLayer) {\n      throw new Error('inputLayer not found');\n    }\n    if (!this.options.outputLayer) {\n      throw new Error('outputLayer not found');\n    }\n    const inputLayer = this.options.inputLayer();\n    const hiddenLayers = this._connectHiddenLayers(inputLayer);\n    const outputLayer = this.options.outputLayer(\n      hiddenLayers[hiddenLayers.length - 1],\n      -1\n    );\n    return {\n      inputLayer,\n      hiddenLayers,\n      outputLayer,\n    };\n  }\n\n  _connectLayersDeep(): ILayer[] {\n    const layers: ILayer[] = [];\n    const previousLayers = this._layerSets[this._layerSets.length - 1];\n    let usedHiddenLayerOutputIndex = 0;\n\n    function findInputLayer(inputLayer: ILayer) {\n      const index = previousLayers.indexOf(inputLayer);\n      if (index < 0) throw new Error('unable to find layer');\n      return layers[index];\n    }\n\n    function layerSettings(layer: ILayer): ILayerSettings {\n      return {\n        ...layer.settings,\n        weights: null,\n        deltas: null,\n        praxis: null,\n      };\n    }\n\n    for (let i = 0; i < previousLayers.length; i++) {\n      const previousLayer = previousLayers[i];\n      let layer: ILayer;\n\n      if (previousLayer instanceof Activation) {\n        layer = new (previousLayer.constructor as ActivationType)(\n          findInputLayer(previousLayer.inputLayer),\n          layerSettings(previousLayer)\n        );\n      } else if (previousLayer instanceof EntryPoint) {\n        layer = new (previousLayer.constructor as EntryPointType)(\n          layerSettings(previousLayer)\n        );\n      } else if (previousLayer instanceof Filter) {\n        layer = new (previousLayer.constructor as FilterType)(\n          layerSettings(previousLayer.inputLayer),\n          findInputLayer(previousLayer.inputLayer)\n        );\n      } else if (previousLayer instanceof Internal) {\n        const previousHiddenLayerOutput =\n          previousLayers[\n            this._hiddenLayerOutputIndices[usedHiddenLayerOutputIndex++]\n          ];\n        if (previousLayer instanceof RecurrentConnection) {\n          throw new Error('unfinished');\n        } else if (previousLayer instanceof RecurrentInput) {\n          layer = new RecurrentInput(previousHiddenLayerOutput);\n        } else if (previousLayer instanceof RecurrentZeros) {\n          layer = new RecurrentInput(previousHiddenLayerOutput);\n        } else {\n          throw new Error(\n            `hidden layer ${previousLayer.constructor.name} extends unknown hidden layer`\n          );\n        }\n      } else if (\n        previousLayer instanceof InternalModel ||\n        previousLayer instanceof Model\n      ) {\n        layer = previousLayer;\n      } else if (previousLayer instanceof Modifier) {\n        layer = new (previousLayer.constructor as ModifierType)(\n          findInputLayer(previousLayer.inputLayer),\n          layerSettings(previousLayer.inputLayer)\n        );\n      } else if (previousLayer instanceof Operator) {\n        layer = new (previousLayer.constructor as OperatorType)(\n          findInputLayer(previousLayer.inputLayer1),\n          findInputLayer(previousLayer.inputLayer2),\n          layerSettings(previousLayer)\n        );\n      } else if (previousLayer instanceof Target) {\n        layer = new (previousLayer.constructor as TargetType)(\n          layerSettings(previousLayer),\n          findInputLayer(previousLayer.inputLayer)\n        );\n      } else {\n        throw new Error(\n          `hidden layer ${previousLayer.constructor.name} extends unknown hidden layer`\n        );\n      }\n      layers.push(layer);\n    }\n\n    return layers;\n  }\n\n  _connectHiddenLayers(previousLayer: ILayer): ILayer[] {\n    const hiddenLayers = [];\n\n    if (!this.options.hiddenLayers) throw new Error('hiddenLayers not defined');\n\n    for (let i = 0; i < this.options.hiddenLayers.length; i++) {\n      const recurrentInput = new RecurrentZeros();\n      const hiddenLayer = this.options.hiddenLayers[i](\n        previousLayer,\n        recurrentInput,\n        i\n      );\n      previousLayer = hiddenLayer;\n      hiddenLayers.push(hiddenLayer);\n    }\n\n    return hiddenLayers;\n  }\n\n  initialize(): void {\n    this._outputConnection = new RecurrentConnection();\n    let layerSet: ILayer[];\n    if (this.options.layers) {\n      layerSet = this._connectOptionsLayers();\n    } else {\n      const { inputLayer, hiddenLayers, outputLayer } = this._connectLayers();\n      layerSet = flattenLayers([inputLayer, ...hiddenLayers, outputLayer]);\n      this._hiddenLayerOutputIndices = hiddenLayers.map((l) =>\n        layerSet.indexOf(l)\n      );\n      this._inputLayer = inputLayer;\n      this._hiddenLayers = hiddenLayers;\n      this._outputLayer = outputLayer;\n    }\n    this.layers = layerSet;\n    this._layerSets = [layerSet];\n    this._model = layerSet.filter(\n      (l) => l instanceof Model || l instanceof InternalModel\n    );\n    this.initializeLayers(layerSet);\n  }\n\n  initializeDeep(): void {\n    const layers = this._connectLayersDeep();\n    for (let i = 0; i < layers.length; i++) {\n      const layer = layers[i];\n      layer.setupKernels(true);\n      // TODO: enable this?\n      // layer.reuseKernels(this._layerSets[0][i]);\n    }\n    this._layerSets.push(layers);\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  run(inputs: KernelOutput[]): TextureArrayOutput {\n    while (this._layerSets.length <= inputs.length) {\n      this.initializeDeep();\n    }\n    const result = this.runInputs(inputs);\n    if (result instanceof Texture) return result.toArray();\n    return result as TextureArrayOutput;\n  }\n\n  runInput(input: KernelOutput): KernelOutput {\n    throw new Error('use .runInputs()');\n  }\n\n  runInputs(inputs: KernelOutput[]): KernelOutput {\n    while (this._layerSets.length < inputs.length) {\n      this.initializeDeep();\n    }\n    const max = inputs.length - 1; // last output will be compared with last index\n    for (let x = 0; x <= max; x++) {\n      const layerSet = this._layerSets[x];\n      layerSet[0].predict(inputs[x]);\n      for (let i = 1; i < layerSet.length; i++) {\n        layerSet[i].predict();\n      }\n    }\n    const lastLayerUsed = this._layerSets[max];\n    const result = lastLayerUsed[lastLayerUsed.length - 1].weights;\n    this.end();\n    return result as KernelOutput;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  train(\n    data: KernelOutput[][],\n    options: Partial<IRecurrentTrainingOptions> = {}\n  ): ITrainingStatus {\n    const { preparedData, status, endTime } = this._prepTraining(data, options);\n    let continueTicking = true;\n    const calculateError = (): number =>\n      this._calculateTrainingError(preparedData);\n    const trainPatters = (): void => this._trainPatterns(preparedData);\n    while (continueTicking) {\n      continueTicking = this._trainingTick(\n        status,\n        endTime,\n        calculateError,\n        trainPatters\n      );\n    }\n    return status;\n  }\n\n  end(): void {\n    const x = this._layerSets.length - 1;\n    const lastLayerSet = this._layerSets[x];\n    lastLayerSet[0].predict([new Float32Array([0])]);\n    for (let i = 1; i < lastLayerSet.length; i++) {\n      lastLayerSet[i].predict();\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  transferData(formattedData: KernelOutput[][]): KernelOutput[][] {\n    return formattedData;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  _prepTraining(\n    data: KernelOutput[][],\n    options: Partial<IRecurrentTrainingOptions>\n  ): IRecurrentPreppedTrainingData {\n    this._updateTrainingOptions(options);\n    const endTime = this.trainOpts.timeout\n      ? Date.now() + this.trainOpts.timeout\n      : 0;\n\n    const status = {\n      error: 1,\n      iterations: 0,\n    };\n\n    this.verifyIsInitialized();\n\n    return {\n      preparedData: this.transferData(data),\n      status,\n      endTime,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  _calculateTrainingError(data: KernelOutput[][]): number {\n    if (!this.meanSquaredError) {\n      throw new Error('this.meanSquaredError not setup');\n    }\n    let sum: KernelOutput = new Float32Array(1);\n    for (let i = 0; i < data.length; ++i) {\n      const prevSum = sum;\n      const error = this._trainPattern(data[i], true) as KernelOutput;\n      sum = this.meanSquaredError.add(sum, error);\n      release(error);\n      release(prevSum);\n    }\n    const result = this.meanSquaredError.divide(data.length, sum);\n    release(sum);\n    if (result instanceof Texture) {\n      const resultArray = result.toArray() as number[];\n      return resultArray[0];\n    }\n    return (result as number[])[0];\n  }\n\n  // TODO: more types\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  formatData(data: Float32Array): Float32Array {\n    return data;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  _calculateDeltas(target: KernelOutput[]): void {\n    const lastLayerSet = this._layerSets[this._layerSets.length - 1];\n    // Iterate from the second to last layer backwards, propagating 0's\n    for (let i = lastLayerSet.length - 2; i >= 0; i--) {\n      lastLayerSet[i].compare();\n    }\n\n    for (let x = target.length - 2; x >= 0; x--) {\n      const layerSet = this._layerSets[x];\n      layerSet[layerSet.length - 1].compare(target[x + 1]);\n      for (let i = layerSet.length - 2; i >= 0; i--) {\n        layerSet[i].compare();\n      }\n    }\n  }\n\n  adjustWeights(): void {\n    const _model = this._model as ILayer[];\n    for (let i = 0; i < _model.length; i++) {\n      _model[i].learn(this.options.learningRate ?? 0);\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  _trainPatterns(data: KernelOutput[][]): void {\n    for (let i = 0; i < data.length; ++i) {\n      this._trainPattern(data[i], false);\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  _trainPattern(\n    inputs: KernelOutput[],\n    logErrorRate: boolean\n  ): KernelOutput | null {\n    // forward propagate\n    this.runInputs(inputs);\n\n    // back propagate\n    this._calculateDeltas(inputs);\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      if (!this.meanSquaredError) {\n        throw new Error('this.meanSquaredError not setup');\n      }\n      let error: KernelOutput = new Float32Array(1);\n      for (let i = 0, max = inputs.length - 1; i <= max; i++) {\n        const layerSet = this._layerSets[i];\n        const lastLayer = layerSet[layerSet.length - 1];\n        const prevError: KernelOutput = error;\n        error = this.meanSquaredError.addAbsolute(\n          prevError,\n          lastLayer.errors as KernelOutput\n        );\n        release(prevError);\n      }\n      return clone(this.meanSquaredError.divide(inputs.length, error));\n    }\n    return null;\n  }\n}\n","import { zeros } from '../../utilities/zeros';\n\nexport interface IMatrixJSON {\n  rows: number;\n  columns: number;\n  weights: number[];\n}\n/**\n * A matrix\n */\nexport class Matrix {\n  rows = 0;\n  columns = 0;\n  weights: Float32Array;\n  deltas: Float32Array;\n\n  constructor(rows?: number, columns?: number) {\n    if (rows) this.rows = rows;\n    if (columns) this.columns = columns;\n\n    this.weights = zeros(this.rows * this.columns);\n    this.deltas = zeros(this.rows * this.columns);\n  }\n\n  getWeight(row: number, col: number): number {\n    // slow but careful accessor function\n    // we want row-major order\n    const ix = this.columns * row + col;\n\n    if (ix < 0 || ix >= this.weights.length) {\n      throw new Error('get accessor is skewed');\n    }\n\n    return this.weights[ix];\n  }\n\n  setWeight(row: number, col: number, v: number): Matrix {\n    // slow but careful accessor function\n    const ix = this.columns * row + col;\n\n    if (ix < 0 || ix >= this.weights.length) {\n      throw new Error('set accessor is skewed');\n    }\n\n    this.weights[ix] = v;\n\n    return this;\n  }\n\n  getDelta(row: number, col: number): number {\n    // slow but careful accessor function\n    // we want row-major order\n    const ix = this.columns * row + col;\n\n    if (ix < 0 || ix >= this.deltas.length) {\n      throw new Error('get accessor is skewed');\n    }\n\n    return this.deltas[ix];\n  }\n\n  setDelta(row: number, col: number, v: number): Matrix {\n    // slow but careful accessor function\n    const ix = this.columns * row + col;\n\n    if (ix < 0 || ix >= this.weights.length) {\n      throw new Error('set accessor is skewed');\n    }\n\n    this.deltas[ix] = v;\n\n    return this;\n  }\n\n  toJSON(): IMatrixJSON {\n    return {\n      rows: this.rows,\n      columns: this.columns,\n      weights: Array.from(this.weights.slice(0)),\n    };\n  }\n\n  static fromJSON(json: IMatrixJSON): Matrix {\n    const matrix = new Matrix(json.rows, json.columns);\n\n    for (let i = 0, max = json.rows * json.columns; i < max; i++) {\n      matrix.weights[i] = json.weights[i]; // copy over weights\n    }\n\n    return matrix;\n  }\n\n  static fromArray(weights: Float32Array[] | number[][]): Matrix {\n    const matrix = new Matrix(weights.length, weights[0].length);\n    matrix.fromArray(weights);\n    return matrix;\n  }\n\n  deltasToArray(): number[][] {\n    return this.toArray('deltas');\n  }\n\n  weightsToArray(): number[][] {\n    return this.toArray('weights');\n  }\n\n  toArray(prop: 'weights' | 'deltas' = 'weights'): number[][] {\n    const result: number[][] = new Array(this.rows);\n    this.iterate({\n      row: (rowIndex): void => {\n        result[rowIndex] = new Array(this.columns);\n      },\n      column: (rowIndex, columnIndex): void => {\n        if (prop === 'weights') {\n          result[rowIndex][columnIndex] = this.getWeight(rowIndex, columnIndex);\n        } else if (prop === 'deltas') {\n          result[rowIndex][columnIndex] = this.getDelta(rowIndex, columnIndex);\n        }\n      },\n    });\n    return result;\n  }\n\n  fromArray(\n    array: number[][] | Float32Array[],\n    prop: 'weights' | 'deltas' = 'weights'\n  ): this {\n    if (array.length !== this.rows) {\n      throw new Error('rows do not match');\n    }\n    if (array[0].length !== this.columns) {\n      throw new Error('columns do not match');\n    }\n    this.iterate({\n      column: (rowIndex, columnIndex): void => {\n        const value = array[rowIndex][columnIndex];\n        if (typeof value !== 'number') {\n          throw new Error('value not number');\n        }\n        if (prop === 'weights') {\n          this.setWeight(rowIndex, columnIndex, value);\n        } else if (prop === 'deltas') {\n          this.setDelta(rowIndex, columnIndex, value);\n        }\n      },\n    });\n    return this;\n  }\n\n  iterate(callbacks: {\n    column?: (rowIndex: number, columnIndex: number) => void;\n    row?: (rowIndex: number) => void;\n  }): this {\n    const rows = this.rows;\n    const columns = this.columns;\n    for (let rowIndex = 0; rowIndex < rows; rowIndex++) {\n      if (callbacks.row) {\n        callbacks.row(rowIndex);\n      }\n      for (let columnIndex = 0; columnIndex < columns; columnIndex++) {\n        if (callbacks.column) {\n          callbacks.column(rowIndex, columnIndex);\n        }\n      }\n    }\n    return this;\n  }\n}\n","import { Matrix } from '.';\nimport { randomFloat } from '../../utilities/random';\n\n/** return Matrix but filled with random numbers from gaussian\n */\nexport class RandomMatrix extends Matrix {\n  std: number;\n\n  constructor(rows: number, columns: number, std: number) {\n    super(rows, columns);\n\n    this.std = std;\n\n    for (let i = 0, max = this.weights.length; i < max; i++) {\n      this.weights[i] = randomFloat(-std, std);\n    }\n  }\n}\n","import { Value, IRNNDatum } from '../recurrent/rnn-data-types';\n\nexport interface IDataFormatter {\n  indexTable: { [value: string]: number };\n  toIndexesInputOutput: (input: Value, output?: Value) => number[];\n  toIndexes: (input: string) => number[];\n  toCharacters: (output: number[]) => string[];\n  characters: Array<string | number>;\n  specialIndexes: number[];\n  toFunctionString: () => string;\n  formatDataIn: (input?: Value, output?: Value) => number[];\n  formatDataOut: (input: number[], output: number[]) => string;\n  format: (data: Array<IRNNDatum | Value>) => number[][];\n  isSetup: boolean;\n  toJSON: () => IDataFormatterJSON;\n}\n\nexport class DataFormatter implements IDataFormatter {\n  indexTable: { [key: string]: number; [key: number]: number } = {};\n  characterTable: { [key: number]: string | number | null } = {};\n  characters: Array<string | number> = [];\n  specialIndexes: number[] = [];\n  isSetup = false;\n\n  constructor(private values?: Array<IRNNDatum | Value>, maxThreshold = 0) {\n    if (values === undefined) return;\n\n    this.setup(values, maxThreshold);\n  }\n\n  setup(values: Array<IRNNDatum | Value>, maxThreshold = 0): void {\n    if (this.isSetup) throw new Error('DataFormatter is already setup');\n    this.values = values;\n    // go over all characters and keep track of all unique ones seen\n    // count up all characters\n\n    this.buildCharactersFromIterable(values);\n    this.buildTables(maxThreshold);\n    if ((values[0] as IRNNDatum).input) {\n      this.addInputOutput();\n    }\n    this.addUnrecognized();\n    this.isSetup = true;\n  }\n\n  buildCharactersFromIterable(values: Array<IRNNDatum | Value>): void {\n    const tempCharactersTable: { [character: string]: boolean } = {};\n    for (\n      let dataFormatterIndex = 0, dataFormatterLength = values.length;\n      dataFormatterIndex < dataFormatterLength;\n      dataFormatterIndex++\n    ) {\n      const characters = values[dataFormatterIndex];\n\n      // if (typeof characters === 'string') {\n      //   const character = characters;\n      //   if (tempCharactersTable.hasOwnProperty(character)) continue;\n      //   tempCharactersTable[character] = true;\n      //   this.characters.push(character);\n      if (characters.hasOwnProperty('length')) {\n        const iteratable = characters as string[] | string;\n        for (\n          let characterIndex = 0, charactersLength = iteratable.length;\n          characterIndex < charactersLength;\n          characterIndex++\n        ) {\n          const character = iteratable[characterIndex];\n          if (tempCharactersTable.hasOwnProperty(character)) continue;\n          tempCharactersTable[character] = true;\n          this.characters.push(character);\n        }\n      } else if (typeof characters === 'number') {\n        if (tempCharactersTable.hasOwnProperty(characters)) continue;\n        tempCharactersTable[characters] = true;\n        this.characters.push(characters);\n      } else if (typeof characters === 'boolean') {\n        const character = characters.toString();\n        if (tempCharactersTable.hasOwnProperty(character)) continue;\n        tempCharactersTable[character] = true;\n        this.characters.push(character);\n      } else if (\n        Array.isArray(characters) &&\n        typeof characters[0] === 'string'\n      ) {\n        for (let i = 0; i < characters.length; i++) {\n          const character = characters[i] as string;\n          if (tempCharactersTable.hasOwnProperty(character)) continue;\n          tempCharactersTable[character] = true;\n          this.characters.push(character);\n        }\n      } else if (\n        Array.isArray(characters) &&\n        (typeof characters[0] === 'number' ||\n          typeof characters[0] === 'boolean')\n      ) {\n        for (let i = 0; i < characters.length; i++) {\n          const character = characters[i].toString();\n          if (tempCharactersTable.hasOwnProperty(dataFormatterIndex)) continue;\n          tempCharactersTable[character] = true;\n          this.characters.push(character);\n        }\n      } else if (\n        characters.hasOwnProperty('input') &&\n        characters.hasOwnProperty('output')\n      ) {\n        const { input, output } = (characters as unknown) as IRNNDatum;\n        if (Array.isArray(input)) {\n          this.addCharacters(input, tempCharactersTable);\n        } else {\n          this.addCharacters(input.toString(), tempCharactersTable);\n        }\n\n        if (Array.isArray(output)) {\n          this.addCharacters(output, tempCharactersTable);\n        } else {\n          this.addCharacters(output.toString(), tempCharactersTable);\n        }\n      } else {\n        throw new Error('Unhandled value');\n      }\n    }\n  }\n\n  addCharacters(\n    characters: string | string[] | boolean[] | number[],\n    charactersTable: { [character: string]: boolean }\n  ): void {\n    for (let i = 0; i < characters.length; i++) {\n      const character = characters[i].toString();\n      if (charactersTable.hasOwnProperty(character)) continue;\n      charactersTable[character] = true;\n      this.characters.push(character);\n    }\n  }\n\n  buildTables(maxThreshold: number): void {\n    // filter by count threshold and create pointers\n    const charactersLength = this.characters.length;\n    for (\n      let characterIndex = 0;\n      characterIndex < charactersLength;\n      characterIndex++\n    ) {\n      const character = this.characters[characterIndex];\n      if (characterIndex >= maxThreshold) {\n        // add character to dataFormatter\n        this.indexTable[character] = characterIndex;\n        this.characterTable[characterIndex] = character;\n      }\n    }\n  }\n\n  toIndexes(value: Value, maxThreshold = 0): number[] {\n    const result = [];\n    const { indexTable } = this;\n\n    switch (typeof value) {\n      case 'number':\n      case 'boolean':\n        value = value.toString();\n    }\n\n    for (let i = 0, max = value.length; i < max; i++) {\n      const character = value[i].toString();\n      let index = indexTable[character];\n      if (index === undefined) {\n        if (indexTable.unrecognized) {\n          index = indexTable.unrecognized;\n        } else {\n          throw new Error(`unrecognized character \"${character}\"`);\n        }\n      }\n      if (index < maxThreshold) continue;\n      result.push(index);\n    }\n    return result;\n  }\n\n  toIndexesInputOutput(\n    input: Value,\n    output?: Value,\n    maxThreshold = 0\n  ): number[] {\n    const result: number[] = this.toIndexesValue(input, maxThreshold, true);\n\n    if (typeof output === 'undefined') return result;\n    return result.concat(this.toIndexesValue(output, maxThreshold, false));\n  }\n\n  toIndexesValue(\n    value: Value,\n    maxThreshold: number,\n    isInput: boolean\n  ): number[] {\n    if (typeof value === 'string') {\n      value = value.split('');\n    } else if (typeof value === 'number' || typeof value === 'boolean') {\n      value = value.toString().split('');\n    } else if (\n      Array.isArray(value) &&\n      (typeof (value as number[])[0] === 'number' ||\n        typeof (value as boolean[])[0] === 'boolean' ||\n        typeof (value as string[])[0] === 'string')\n    ) {\n      value = (value as string[]).map((v) => v.toString());\n    } else {\n      throw new Error('unrecognized value');\n    }\n    if (isInput) {\n      value = value.concat(['stop-input', 'start-output']);\n    }\n    return this.toIndexes(value, maxThreshold);\n  }\n\n  toCharacters(indices: number[], maxThreshold = 0): string[] {\n    const result: string[] = [];\n    const { indexTable, characterTable } = this;\n\n    for (let i = 0, max = indices.length; i < max; i++) {\n      const index = indices[i];\n      if (index < maxThreshold) continue;\n      let character = characterTable[index];\n      if (character === undefined) {\n        if (indexTable.unrecognized) {\n          character = characterTable[indexTable.unrecognized];\n        } else {\n          throw new Error(`unrecognized index \"${index}\"`);\n        }\n      } else if (character !== null) {\n        result.push(character.toString());\n      }\n    }\n\n    return result;\n  }\n\n  toString(indices: number[], maxThreshold: number): string {\n    return this.toCharacters(indices, maxThreshold).join('');\n  }\n\n  addInputOutput(): void {\n    this.addSpecial('stop-input');\n    this.addSpecial('start-output');\n  }\n\n  addUnrecognized(): void {\n    this.addSpecial('unrecognized');\n  }\n\n  static fromAllPrintable(\n    maxThreshold: number,\n    values = ['\\n']\n  ): DataFormatter {\n    for (let i = 32; i <= 126; i++) {\n      values.push(String.fromCharCode(i));\n    }\n    return new DataFormatter(values, maxThreshold);\n  }\n\n  static fromAllPrintableInputOutput(\n    maxThreshold: number,\n    values = ['\\n']\n  ): DataFormatter {\n    const dataFormatter = DataFormatter.fromAllPrintable(maxThreshold, values);\n    dataFormatter.addInputOutput();\n    dataFormatter.addUnrecognized();\n    return dataFormatter;\n  }\n\n  static fromStringInputOutput(\n    string: string,\n    maxThreshold: number\n  ): DataFormatter {\n    const values = Array.from(new Set(string)).join('');\n    const dataFormatter = new DataFormatter(values.split(''), maxThreshold);\n    dataFormatter.addInputOutput();\n    dataFormatter.addUnrecognized();\n    dataFormatter.isSetup = true;\n    return dataFormatter;\n  }\n\n  static fromArrayInputOutput(\n    data: IRNNDatum[],\n    maxThreshold?: number\n  ): DataFormatter {\n    const values: Array<string | string[]> = [];\n\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      values.push(validateAndCast(datum.input), validateAndCast(datum.output));\n    }\n    const flatArray: string[] = Array.isArray(values)\n      ? (values as string[][]).flat()\n      : values;\n    const dataFormatter = new DataFormatter(\n      Array.from(new Set(flatArray)),\n      maxThreshold\n    );\n    dataFormatter.addInputOutput();\n    dataFormatter.addUnrecognized();\n    dataFormatter.isSetup = true;\n    return dataFormatter;\n  }\n\n  static fromString(string: string, maxThreshold = 0): DataFormatter {\n    const values = Array.from(new Set(string)).join('');\n    return new DataFormatter(values.split(''), maxThreshold);\n  }\n\n  toJSON(): IDataFormatterJSON {\n    return {\n      indexTable: this.indexTable,\n      characterTable: this.characterTable,\n      values: this.values as Value[],\n      characters: this.characters,\n      specialIndexes: this.specialIndexes,\n    };\n  }\n\n  /** TODO: Type better, The type of json is not \"string that is a valid JSON\", it is a POJO in the shape of DataFormatter.\n   * this method re-hydrates the the data as an instance of DataFormatter.\n   */\n  static fromJSON(json: IDataFormatterJSON): DataFormatter {\n    const dataFormatter = new DataFormatter();\n    dataFormatter.indexTable = json.indexTable;\n    dataFormatter.characterTable = json.characterTable;\n    dataFormatter.values = json.values;\n    dataFormatter.characters = json.characters;\n    dataFormatter.specialIndexes = json.specialIndexes;\n    return dataFormatter;\n  }\n\n  addSpecial(special: string | number, character = null): void {\n    const specialIndex = (this.indexTable[special] = this.characters.length);\n    this.characterTable[specialIndex] = character;\n    this.specialIndexes.push(this.characters.length);\n    this.characters.push(special);\n  }\n\n  toFunctionString(): string {\n    return `\nvar characterTable = ${JSON.stringify(this.characterTable)};\nvar indexTable = ${JSON.stringify(this.indexTable)};\nvar characters = ${JSON.stringify(this.characters)};\nvar dataFormatter = {\n  toIndexes: function ${this.toIndexes.toString()},\n  toIndexesInputOutput: function ${this.toIndexesInputOutput.toString()},\n  toCharacters: function ${this.toCharacters.toString()},\n  toIndexesValue: function ${this.toIndexesValue.toString()},\n};`;\n  }\n\n  formatDataIn(input?: Value, output?: Value): number[] {\n    if (input === undefined) return [];\n    if (Array.isArray(input) && typeof input[0] === 'number') {\n      return input as number[];\n    }\n    if (this.indexTable?.hasOwnProperty('stop-input')) {\n      return this.toIndexesInputOutput(input, output);\n    }\n    return this.toIndexes(input);\n  }\n\n  formatDataOut(input: number[], output: number[]): string {\n    return this.toCharacters(output).join('');\n  }\n\n  format(data: Array<IRNNDatum | Value>): number[][] {\n    if (\n      typeof data[0] === 'number' &&\n      !Array.isArray(data[0]) &&\n      (!data[0].hasOwnProperty('input') || !data[0].hasOwnProperty('output'))\n    ) {\n      return data as number[][];\n    }\n    const result: number[][] = [];\n    if (\n      typeof data[0] === 'string' ||\n      typeof data[0] === 'number' ||\n      Array.isArray(data[0])\n    ) {\n      if (!this.isSetup) {\n        this.setup(data);\n        for (let i = 0; i < data.length; i++) {\n          result.push(this.formatDataIn(validateAndCast(data[i] as Value)));\n        }\n      } else {\n        for (let i = 0, max = data.length; i < max; i++) {\n          result.push(this.formatDataIn(data[i] as Value));\n        }\n      }\n    } else if ((data[0] as IRNNDatum).input && (data[0] as IRNNDatum).output) {\n      if (!this.isSetup) {\n        this.setup(data);\n      }\n      for (let i = 0, max = data.length; i < max; i++) {\n        result.push(\n          this.formatDataIn(\n            validateAndCast((data[i] as IRNNDatum).input),\n            validateAndCast((data[i] as IRNNDatum).output)\n          )\n        );\n      }\n    } else {\n      throw new Error('unrecognized data');\n    }\n    return result;\n  }\n}\n\nfunction validateAndCast(value: Value): string | string[] {\n  if (typeof value === 'string') return value;\n  if (typeof value === 'number') return value.toString();\n  if (typeof value === 'boolean') return value.toString();\n  if (Array.isArray(value) && typeof value[0] === 'string')\n    return value as string[];\n  if (typeof value[0] === 'boolean') {\n    return (value as boolean[]).map((v: boolean) => v.toString());\n  }\n  if (typeof value[0] === 'number') {\n    return (value as number[]).map((v: number) => v.toString());\n  }\n  throw new Error(\n    'unrecognized value, expected string[], string, number[], number, boolean[], or boolean'\n  );\n}\n\nexport interface IDataFormatterJSON {\n  indexTable: { [key: string]: number; [key: number]: number };\n  characterTable: { [key: number]: string | number | null };\n  values: Value[];\n  characters: Array<string | number>;\n  specialIndexes: number[];\n}\n","import { Matrix } from '.';\n\n/**\n * add {left} and {right} matrix weights into {into}\n */\nexport function add(product: Matrix, left: Matrix, right: Matrix): void {\n  for (let i = 0; i < left.weights.length; i++) {\n    product.weights[i] = left.weights[i] + right.weights[i];\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * adds {from} deltas to {left} and {right} deltas\n */\nexport function addB(product: Matrix, left: Matrix, right: Matrix): void {\n  for (let i = 0; i < product.deltas.length; i++) {\n    left.deltas[i] = product.deltas[i];\n    right.deltas[i] = product.deltas[i];\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * makes matrix weights and deltas all ones\n */\nexport function allOnes(product: Matrix): void {\n  for (let i = 0; i < product.weights.length; i++) {\n    product.weights[i] = 1;\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\nexport function cloneNegative(product: Matrix, left: Matrix): void {\n  product.rows = left.rows;\n  product.columns = left.columns;\n  product.weights = left.weights.slice(0);\n  product.deltas = left.deltas.slice(0);\n\n  for (let i = 0; i < left.weights.length; i++) {\n    product.weights[i] = -left.weights[i];\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * multiply {left} and {right} matrix weights to {into}\n */\nexport function multiply(product: Matrix, left: Matrix, right: Matrix): void {\n  const leftRows = left.rows;\n  const leftColumns = left.columns;\n  const rightColumns = right.columns;\n\n  // loop over rows of left\n  for (let leftRow = 0; leftRow < leftRows; leftRow++) {\n    const leftRowBase = leftColumns * leftRow;\n    const rightRowBase = rightColumns * leftRow;\n\n    // loop over cols of right\n    for (let rightColumn = 0; rightColumn < rightColumns; rightColumn++) {\n      // dot product loop\n      let dot = 0;\n\n      // loop over columns of left\n      for (let leftColumn = 0; leftColumn < leftColumns; leftColumn++) {\n        const rightColumnBase = rightColumns * leftColumn;\n        const leftIndex = leftRowBase + leftColumn;\n        const rightIndex = rightColumnBase + rightColumn;\n        dot += left.weights[leftIndex] * right.weights[rightIndex];\n        left.deltas[leftIndex] = 0;\n        right.deltas[rightIndex] = 0;\n      }\n\n      product.weights[rightRowBase + rightColumn] = dot;\n    }\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * multiplies {from} deltas to {left} and {right}\n */\nexport function multiplyB(product: Matrix, left: Matrix, right: Matrix): void {\n  const leftRows = left.rows;\n  const leftColumns = left.columns;\n  const rightColumns = right.columns;\n\n  // loop over rows of left\n  for (let leftRowRoot = 0; leftRowRoot < leftRows; leftRowRoot++) {\n    const leftRowBase = leftColumns * leftRowRoot;\n    const rightRowBase = rightColumns * leftRowRoot;\n\n    // loop over cols of right\n    for (let rightColumn = 0; rightColumn < rightColumns; rightColumn++) {\n      // loop over columns of left\n      for (let leftColumn = 0; leftColumn < leftColumns; leftColumn++) {\n        const rightColumnBase = rightColumns * leftColumn;\n        const leftRow = leftRowBase + leftColumn;\n        const rightRow = rightColumnBase + rightColumn;\n        const backPropagateValue = product.deltas[rightRowBase + rightColumn];\n        left.deltas[leftRow] += right.weights[rightRow] * backPropagateValue;\n        right.deltas[rightRow] += left.weights[leftRow] * backPropagateValue;\n      }\n    }\n  }\n}\n","import { Matrix } from '.';\n\nexport function multiplyElement(\n  product: Matrix,\n  left: Matrix,\n  right: Matrix\n): void {\n  const { weights } = left;\n\n  for (let i = 0; i < weights.length; i++) {\n    product.weights[i] = left.weights[i] * right.weights[i];\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * multiplies {left} and {right} weight by {from} deltas into {left} and {right} deltas\n */\nexport function multiplyElementB(\n  product: Matrix,\n  left: Matrix,\n  right: Matrix\n): void {\n  for (let i = 0; i < left.weights.length; i++) {\n    left.deltas[i] = right.weights[i] * product.deltas[i];\n    right.deltas[i] = left.weights[i] * product.deltas[i];\n  }\n}\n","import { Matrix } from '.';\n\n/**\n *\n * relu {m} weights to {into} weights\n */\nexport function relu(product: Matrix, left: Matrix): void {\n  for (let i = 0; i < left.weights.length; i++) {\n    product.weights[i] = Math.max(0, left.weights[i]); // relu\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * adds {from} deltas to {m} deltas when {m} weights are above other a threshold of 0\n */\nexport function reluB(product: Matrix, left: Matrix): void {\n  for (let i = 0; i < product.deltas.length; i++) {\n    left.deltas[i] = left.weights[i] > 0 ? product.deltas[i] : 0;\n  }\n}\n","import { Matrix } from '.';\n\nexport function rowPluck(\n  product: Matrix,\n  left: Matrix,\n  rowPluckIndex: number\n): void {\n  const { columns } = left;\n  const rowBase = columns * rowPluckIndex;\n\n  for (let column = 0; column < columns; column++) {\n    product.weights[column] = left.weights[rowBase + column];\n    product.deltas[column] = 0;\n  }\n}\n","import { Matrix } from '.';\n\n/**\n * adds {from} deltas into {m} deltas\n */\nexport function rowPluckB(\n  product: Matrix,\n  left: Matrix,\n  rowIndex: number\n): void {\n  const { columns } = left;\n  const rowBase = columns * rowIndex;\n\n  for (let column = 0; column < columns; column++) {\n    left.deltas[rowBase + column] = product.deltas[column];\n  }\n}\n","import { Matrix } from '.';\n\nexport function sigmoid(product: Matrix, left: Matrix): void {\n  // sigmoid nonlinearity\n  for (let i = 0; i < left.weights.length; i++) {\n    product.weights[i] = 1 / (1 + Math.exp(-left.weights[i]));\n    product.deltas[i] = 0;\n  }\n}\n\n// function sig(x) {\n//   // helper function for computing sigmoid\n//   return 1 / (1 + Math.exp(-x));\n// }\n","import { Matrix } from '.';\n\nexport function sigmoidB(product: Matrix, left: Matrix): void {\n  for (let i = 0; i < product.deltas.length; i++) {\n    const mwi = product.weights[i];\n    left.deltas[i] = mwi * (1 - mwi) * product.deltas[i];\n  }\n}\n","import { Matrix } from '.';\n\nexport function softmax(matrix: Matrix): Matrix {\n  // probability volume\n  const result = new Matrix(matrix.rows, matrix.columns);\n  let maxVal = -999999;\n\n  for (let i = 0; i < matrix.weights.length; i++) {\n    if (matrix.weights[i] > maxVal) {\n      maxVal = matrix.weights[i];\n    }\n  }\n\n  let s = 0;\n  for (let i = 0; i < matrix.weights.length; i++) {\n    result.weights[i] = Math.exp(matrix.weights[i] - maxVal);\n    s += result.weights[i];\n  }\n\n  for (let i = 0; i < matrix.weights.length; i++) {\n    result.weights[i] /= s;\n  }\n\n  // no backward pass here needed\n  // since we will use the computed probabilities outside\n  // to set gradients directly on m\n  return result;\n}\n","import { Matrix } from '.';\n\nexport function tanh(product: Matrix, left: Matrix): void {\n  // tanh nonlinearity\n  for (let i = 0; i < left.weights.length; i++) {\n    product.weights[i] = Math.tanh(left.weights[i]);\n    product.deltas[i] = 0;\n  }\n}\n","import { Matrix } from '.';\n\nexport function tanhB(product: Matrix, left: Matrix): void {\n  for (let i = 0; i < product.deltas.length; i++) {\n    // grad for z = tanh(x) is (1 - z^2)\n    const mwi = product.weights[i];\n    left.deltas[i] = (1 - mwi * mwi) * product.deltas[i];\n  }\n}\n","import { Matrix } from '.';\nimport { add } from './add';\nimport { addB } from './add-b';\nimport { allOnes } from './all-ones';\nimport { cloneNegative } from './clone-negative';\nimport { multiply } from './multiply';\nimport { multiplyB } from './multiply-b';\nimport { multiplyElement } from './multiply-element';\nimport { multiplyElementB } from './multiply-element-b';\nimport { relu } from './relu';\nimport { reluB } from './relu-b';\nimport { rowPluck } from './row-pluck';\nimport { rowPluckB } from './row-pluck-b';\nimport { sigmoid } from './sigmoid';\nimport { sigmoidB } from './sigmoid-b';\nimport { softmax } from './softmax';\nimport { tanh } from './tanh';\nimport { tanhB } from './tanh-b';\n\ntype PropagateIndex = (product: Matrix, left: Matrix, index: number) => void;\ntype PropagateProduct = (product: Matrix) => void;\ntype PropagateProductFromLeft = (product: Matrix, left: Matrix) => void;\ntype PropagateProductFromLeftRight = (\n  product: Matrix,\n  left: Matrix,\n  right: Matrix\n) => void;\ntype PropagateFunction =\n  | PropagateIndex\n  | PropagateProduct\n  | PropagateProductFromLeft\n  | PropagateProductFromLeftRight;\n\nexport interface IState {\n  name: string;\n  product: Matrix;\n  left?: Matrix;\n  right?: Matrix;\n  forwardFn: PropagateFunction;\n  backpropagationFn: PropagateFunction;\n}\n\nexport class Equation {\n  states: IState[] = [];\n  inputValue?: Float32Array;\n  inputRow = 0;\n\n  add(left: Matrix, right: Matrix): Matrix {\n    if (left.weights.length !== right.weights.length) {\n      throw new Error('misaligned matrices');\n    }\n\n    const product = new Matrix(left.rows, left.columns);\n\n    this.states.push({\n      name: 'add',\n      product,\n      left,\n      right,\n      forwardFn: add,\n      backpropagationFn: addB,\n    });\n\n    return product;\n  }\n\n  allOnes(rows: number, columns: number): Matrix {\n    const product = new Matrix(rows, columns);\n\n    this.states.push({\n      name: 'allOnes',\n      product,\n      left: product,\n      forwardFn: allOnes,\n      backpropagationFn: () => {},\n    });\n\n    return product;\n  }\n\n  cloneNegative(matrix: Matrix): Matrix {\n    const product = new Matrix(matrix.rows, matrix.columns);\n\n    this.states.push({\n      name: 'cloneNegative',\n      product,\n      left: matrix,\n      forwardFn: cloneNegative,\n      backpropagationFn: () => {},\n    });\n\n    return product;\n  }\n\n  /**\n   * connects two matrices together by subtract\n   */\n  subtract(left: Matrix, right: Matrix): Matrix {\n    if (left.weights.length !== right.weights.length) {\n      throw new Error('misaligned matrices');\n    }\n\n    return this.add(\n      this.add(this.allOnes(left.rows, left.columns), this.cloneNegative(left)),\n      right\n    );\n  }\n\n  /**\n   * connects two matrices together by multiply\n   */\n  multiply(left: Matrix, right: Matrix): Matrix {\n    if (left.columns !== right.rows) {\n      throw new Error('misaligned matrices');\n    }\n\n    const product = new Matrix(left.rows, right.columns);\n\n    this.states.push({\n      name: 'multiply',\n      product,\n      left,\n      right,\n      forwardFn: multiply,\n      backpropagationFn: multiplyB,\n    });\n\n    return product;\n  }\n\n  /**\n   * connects two matrices together by multiplyElement\n   */\n  multiplyElement(left: Matrix, right: Matrix): Matrix {\n    if (left.weights.length !== right.weights.length) {\n      throw new Error('misaligned matrices');\n    }\n\n    const product = new Matrix(left.rows, left.columns);\n\n    this.states.push({\n      name: 'multiplyElement',\n      product,\n      left,\n      right,\n      forwardFn: multiplyElement,\n      backpropagationFn: multiplyElementB,\n    });\n\n    return product;\n  }\n\n  /**\n   * connects a matrix to relu\n   */\n  relu(matrix: Matrix): Matrix {\n    const product = new Matrix(matrix.rows, matrix.columns);\n\n    this.states.push({\n      name: 'relu',\n      product,\n      left: matrix,\n      forwardFn: relu,\n      backpropagationFn: reluB,\n    });\n\n    return product;\n  }\n\n  /**\n   * input a matrix\n   */\n  input(input: Matrix): Matrix {\n    this.states.push({\n      name: 'input',\n      product: input,\n      forwardFn: (product: Matrix) => {\n        if (!this.inputValue) return;\n        if (this.inputValue.length !== product.weights.length) {\n          throw new Error('this.inputValue is of wrong dimensions');\n        }\n        product.weights = input.weights = this.inputValue;\n      },\n      backpropagationFn: () => {},\n    });\n\n    return input;\n  }\n\n  /**\n   * connects a matrix via a row\n   */\n  inputMatrixToRow(matrix: Matrix): Matrix {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    const self = this;\n    const product = new Matrix(matrix.columns, 1);\n\n    this.states.push({\n      name: 'inputMatrixToRow',\n      product,\n      left: matrix,\n      get right() {\n        return (self.inputRow as unknown) as Matrix;\n      },\n      forwardFn: rowPluck,\n      backpropagationFn: rowPluckB,\n    });\n\n    return product;\n  }\n\n  /**\n   * connects a matrix to sigmoid\n   */\n  sigmoid(matrix: Matrix): Matrix {\n    const product = new Matrix(matrix.rows, matrix.columns);\n\n    this.states.push({\n      name: 'sigmoid',\n      product,\n      left: matrix,\n      forwardFn: sigmoid,\n      backpropagationFn: sigmoidB,\n    });\n\n    return product;\n  }\n\n  /**\n   * connects a matrix to tanh\n   */\n  tanh(matrix: Matrix): Matrix {\n    const product = new Matrix(matrix.rows, matrix.columns);\n\n    this.states.push({\n      name: 'tanh',\n      product,\n      left: matrix,\n      forwardFn: tanh,\n      backpropagationFn: tanhB,\n    });\n\n    return product;\n  }\n\n  /**\n   *\n   * Observe a matrix for debugging\n   */\n  observe(matrix: Matrix): Matrix {\n    this.states.push({\n      name: 'observe',\n      product: new Matrix(),\n      forwardFn: () => {},\n      backpropagationFn: () => {},\n    });\n\n    return matrix;\n  }\n\n  /**\n   * Run index through equations via forward propagation\n   */\n  runIndex(rowIndex = 0): Matrix {\n    this.inputRow = rowIndex;\n    let state = this.states[0];\n\n    for (let i = 0, max = this.states.length; i < max; i++) {\n      state = this.states[i];\n\n      if (!state.hasOwnProperty('forwardFn')) continue;\n      (state.forwardFn as PropagateProductFromLeftRight)(\n        state.product,\n        state.left as Matrix,\n        state.right as Matrix\n      );\n    }\n\n    return state.product;\n  }\n\n  /**\n   * Run value through equations via forward propagation\n   */\n  runInput(inputValue: Float32Array): Matrix {\n    this.inputValue = inputValue;\n    let state = this.states[0];\n\n    for (let i = 0, max = this.states.length; i < max; i++) {\n      state = this.states[i];\n\n      if (!state.hasOwnProperty('forwardFn')) continue;\n      (state.forwardFn as PropagateProductFromLeftRight)(\n        state.product,\n        state.left as Matrix,\n        state.right as Matrix\n      );\n    }\n\n    return state.product;\n  }\n\n  /**\n   * Run value through equations via back propagation\n   */\n  backpropagate(): Matrix {\n    let i = this.states.length;\n    let state = this.states[0];\n\n    while (i-- > 0) {\n      state = this.states[i];\n\n      if (!state.hasOwnProperty('backpropagationFn')) continue;\n      (state.backpropagationFn as PropagateProductFromLeftRight)(\n        state.product,\n        state.left as Matrix,\n        state.right as Matrix\n      );\n    }\n\n    return state.product;\n  }\n\n  /**\n   * Run index through equations via back propagation\n   */\n  backpropagateIndex(rowIndex = 0): Matrix {\n    this.inputRow = rowIndex;\n\n    let i = this.states.length;\n    let state = this.states[0];\n\n    while (i-- > 0) {\n      state = this.states[i];\n\n      if (!state.hasOwnProperty('backpropagationFn')) continue;\n      (state.backpropagationFn as PropagateProductFromLeftRight)(\n        state.product,\n        state.left as Matrix,\n        state.right as Matrix\n      );\n    }\n\n    return state.product;\n  }\n\n  /**\n   * Predict a target value from equation\n   */\n  predictTarget(input: Float32Array, target: Float32Array): number {\n    let errorSum = 0;\n    const output = this.runInput(input);\n\n    for (let i = 0; i < output.weights.length; i++) {\n      const error = output.weights[i] - target[i];\n      // set gradients into log probabilities\n      errorSum += Math.abs(error);\n      // write gradients into log probabilities\n      output.deltas[i] = error;\n    }\n\n    return errorSum;\n  }\n\n  /**\n   * Predict a target index from equation\n   */\n  predictTargetIndex(input: number, target: number): number {\n    const output = this.runIndex(input);\n    // set gradients into log probabilities\n    const logProbabilities = output; // interpret output as log probabilities\n    const probabilities = softmax(output); // compute the softmax probabilities\n\n    // write gradients into log probabilities\n    logProbabilities.deltas = probabilities.weights.slice(0);\n    logProbabilities.deltas[target] -= 1;\n\n    // accumulate base 2 log prob and do smoothing\n    return -Math.log2(probabilities.weights[target]);\n  }\n}\n","import { Matrix } from '.';\n\nexport function maxI(matrix: Matrix): number {\n  // argmax of array w\n  const { weights } = matrix;\n  let maxv = weights[0];\n  let maxix = 0;\n\n  for (let i = 1; i < weights.length; i++) {\n    const v = weights[i];\n    if (v < maxv) continue;\n\n    maxix = i;\n    maxv = v;\n  }\n\n  return maxix;\n}\n","import { Matrix } from '.';\nimport { randomFloat } from '../../utilities/random';\n\nexport function sampleI(matrix: Matrix): number {\n  // sample argmax from w, assuming w are\n  // probabilities that sum to one\n  const r = randomFloat(0, 1);\n  const w = matrix.weights;\n  let x = 0;\n  let i = 0;\n\n  while (true) {\n    x += w[i];\n\n    if (x > r) {\n      return i;\n    }\n\n    i++;\n  }\n}\n","import { Log } from '../feed-forward';\nimport { INeuralNetworkTrainOptions } from '../neural-network';\nimport {\n  DataFormatter,\n  IDataFormatter,\n  IDataFormatterJSON,\n} from '../utilities/data-formatter';\nimport { randomFloat } from '../utilities/random';\nimport { zeros } from '../utilities/zeros';\nimport { IMatrixJSON, Matrix } from './matrix';\nimport { copy } from './matrix/copy';\nimport { Equation } from './matrix/equation';\nimport { maxI } from './matrix/max-i';\nimport { RandomMatrix } from './matrix/random-matrix';\nimport { sampleI } from './matrix/sample-i';\nimport { softmax } from './matrix/softmax';\nimport { IRNNDatum, Value } from './rnn-data-types';\n\nexport interface IRNNModel {\n  isInitialized: boolean;\n  input: Matrix;\n  hiddenLayers: IRNNHiddenLayerModel[];\n  output: Matrix;\n  equations: Equation[];\n  allMatrices: Matrix[];\n  equationConnections: Matrix[][];\n  outputConnector: RandomMatrix | Matrix;\n}\n\nexport interface IRNNOptions {\n  inputSize: number;\n  inputRange: number;\n  hiddenLayers: number[];\n  outputSize: number;\n  decayRate: number;\n  smoothEps: number;\n  regc: number;\n  clipval: number;\n  maxPredictionLength: number;\n  dataFormatter: IDataFormatter;\n  json?: IRNNJSON;\n}\n\nexport interface IRNNJSONOptions {\n  inputSize: number;\n  inputRange: number;\n  hiddenLayers: number[];\n  outputSize: number;\n  decayRate: number;\n  smoothEps: number;\n  regc: number;\n  clipval: number;\n  maxPredictionLength: number;\n  dataFormatter: IDataFormatterJSON;\n}\n\nexport interface IRNNTrainingOptions {\n  iterations: number;\n  errorThresh: number;\n  log: boolean | ((status: string) => void);\n  logPeriod: number;\n  learningRate: number;\n  callback?: (status: IRNNStatus) => void;\n  callbackPeriod: number;\n  timeout: number;\n}\n\nexport interface IRNNJSONTrainOptions {\n  iterations: number;\n  errorThresh: number;\n  log: boolean | ((status: string) => void);\n  logPeriod: number;\n  learningRate: number;\n  callback?: (status: IRNNStatus) => void;\n  callbackPeriod: number;\n  timeout: number | 'Infinity';\n}\n\nexport const trainDefaults: IRNNTrainingOptions = {\n  iterations: 20000,\n  errorThresh: 0.005,\n  log: false,\n  logPeriod: 10,\n  learningRate: 0.01,\n  callbackPeriod: 10,\n  timeout: Infinity,\n};\n\nexport interface IRNNHiddenLayer {\n  [key: string]: RandomMatrix | Matrix;\n}\n\nexport interface IRNNHiddenLayerModel extends IRNNHiddenLayer {\n  // wxh\n  weight: RandomMatrix;\n  // whh\n  transition: RandomMatrix;\n  // bhh\n  bias: Matrix;\n}\n\nexport const defaults = (): IRNNOptions => {\n  return {\n    inputSize: 20,\n    inputRange: 20,\n    hiddenLayers: [20, 20],\n    outputSize: 20,\n    decayRate: 0.999,\n    smoothEps: 1e-8,\n    regc: 0.000001,\n    clipval: 5,\n    maxPredictionLength: 100,\n    dataFormatter: new DataFormatter(),\n  };\n};\n\nexport interface IRNNStatus {\n  iterations: number;\n  error: number;\n}\n\nexport interface IRNNPreppedTrainingData {\n  status: IRNNStatus;\n  preparedData: number[][];\n  endTime: number;\n}\n\nexport class RNN {\n  options: IRNNOptions = { ...defaults() };\n  trainOpts: IRNNTrainingOptions = { ...trainDefaults };\n  stepCache: { [index: number]: Float32Array } = {};\n  runs = 0;\n  ratioClipped = 0;\n  model: IRNNModel = Object.seal({\n    isInitialized: false,\n    input: new Matrix(0, 0),\n    hiddenLayers: [],\n    output: new Matrix(0, 0),\n    equations: [],\n    allMatrices: [],\n    equationConnections: [],\n    outputConnector: new RandomMatrix(0, 0, 0.08),\n  });\n\n  initialLayerInputs: Matrix[] = [];\n\n  constructor(options: Partial<IRNNOptions & IRNNTrainingOptions> = {}) {\n    this.options = { ...this.options, ...options };\n    this.updateTrainingOptions({\n      ...trainDefaults,\n      // ...options,\n    });\n\n    if (options.json) {\n      this.fromJSON(options.json);\n    }\n  }\n\n  initialize(): void {\n    const { dataFormatter } = this.options;\n    if (dataFormatter?.characters.length) {\n      this.options.inputSize = this.options.inputRange = this.options.outputSize =\n        dataFormatter.characters.length;\n    }\n    this.model = this.mapModel();\n  }\n\n  createHiddenLayers(): IRNNHiddenLayer[] {\n    const { hiddenLayers, inputSize } = this.options;\n    const hiddenLayersModel: IRNNHiddenLayer[] = [];\n    // 0 is end, so add 1 to offset\n    hiddenLayersModel.push(this.getHiddenLayer(hiddenLayers[0], inputSize));\n    let prevSize = hiddenLayers[0];\n\n    for (let d = 1; d < hiddenLayers.length; d++) {\n      // loop over depths\n      const hiddenSize = hiddenLayers[d];\n      hiddenLayersModel.push(this.getHiddenLayer(hiddenSize, prevSize));\n      prevSize = hiddenSize;\n    }\n    return hiddenLayersModel;\n  }\n\n  getHiddenLayer(hiddenSize: number, prevSize: number): IRNNHiddenLayer {\n    return {\n      // wxh\n      weight: new RandomMatrix(hiddenSize, prevSize, 0.08),\n      // whh\n      transition: new RandomMatrix(hiddenSize, hiddenSize, 0.08),\n      // bhh\n      bias: new Matrix(hiddenSize, 1),\n    };\n  }\n\n  getEquation(\n    equation: Equation,\n    inputMatrix: Matrix,\n    previousResult: Matrix,\n    hiddenLayer: IRNNHiddenLayer\n  ): Matrix {\n    if (!hiddenLayer.weight || !hiddenLayer.transition || !hiddenLayer.bias) {\n      throw new Error('hiddenLayer does not have expected properties');\n    }\n    const relu = equation.relu.bind(equation);\n    const add = equation.add.bind(equation);\n    const multiply = equation.multiply.bind(equation);\n\n    return relu(\n      add(\n        add(\n          multiply(hiddenLayer.weight, inputMatrix),\n          multiply(hiddenLayer.transition, previousResult)\n        ),\n        hiddenLayer.bias\n      )\n    );\n  }\n\n  createInputMatrix(): RandomMatrix {\n    const { inputRange, inputSize } = this.options;\n    if (inputRange < 1)\n      throw new Error('this.options.inputRange not an expected number');\n    if (inputSize < 1)\n      throw new Error('this.options.inputSize not an expected number');\n\n    // 0 is end, so add 1 to offset\n    return new RandomMatrix(inputRange + 1, inputSize, 0.08);\n  }\n\n  createOutputMatrices(): { outputConnector: RandomMatrix; output: Matrix } {\n    const { outputSize, hiddenLayers } = this.options;\n    const lastHiddenSize = last(hiddenLayers);\n\n    // 0 is end, so add 1 to offset\n    return {\n      // whd\n      outputConnector: new RandomMatrix(outputSize + 1, lastHiddenSize, 0.08),\n      // 0 is end, so add 1 to offset\n      // bd\n      output: new Matrix(outputSize + 1, 1),\n    };\n  }\n\n  bindEquation(): void {\n    const { model } = this;\n    const { hiddenLayers } = this.options;\n    const equation = new Equation();\n    const outputs: Matrix[] = [];\n    const equationConnection =\n      model.equationConnections.length > 0\n        ? last(model.equationConnections)\n        : this.initialLayerInputs;\n    // 0 index\n    let output = this.getEquation(\n      equation,\n      equation.inputMatrixToRow(model.input),\n      equationConnection[0],\n      model.hiddenLayers[0]\n    );\n    outputs.push(output);\n    // 1+ indices\n    for (let i = 1, max = hiddenLayers.length; i < max; i++) {\n      if (!equationConnection[i]) {\n        throw new Error(`Cannot find equation at index ${i}`);\n      }\n      output = this.getEquation(\n        equation,\n        output,\n        equationConnection[i],\n        model.hiddenLayers[i]\n      );\n      outputs.push(output);\n    }\n\n    model.equationConnections.push(outputs);\n    equation.add(\n      equation.multiply(model.outputConnector, output),\n      model.output\n    );\n    model.equations.push(equation);\n  }\n\n  mapModel(): IRNNModel {\n    const allMatrices: Matrix[] = [];\n    this.initialLayerInputs = this.options.hiddenLayers.map(\n      (size) => new Matrix(size, 1)\n    );\n\n    const input = this.createInputMatrix();\n    allMatrices.push(input);\n\n    const hiddenLayers = this.createHiddenLayers() as IRNNHiddenLayerModel[];\n    if (!hiddenLayers.length) throw new Error('net.hiddenLayers not set');\n    for (let i = 0, max = hiddenLayers.length; i < max; i++) {\n      const hiddenMatrix: IRNNHiddenLayerModel = hiddenLayers[i];\n      for (const property in hiddenMatrix) {\n        if (!hiddenMatrix.hasOwnProperty(property)) continue;\n        allMatrices.push(hiddenMatrix[property]);\n      }\n    }\n\n    const { output, outputConnector } = this.createOutputMatrices();\n    allMatrices.push(outputConnector);\n    allMatrices.push(output);\n\n    return Object.seal({\n      isInitialized: true,\n      input,\n      hiddenLayers,\n      output,\n      equations: [],\n      allMatrices,\n      equationConnections: [],\n      outputConnector,\n    });\n  }\n\n  trainInput(input: number[]): number {\n    this.runs++;\n    const { model } = this;\n    const max = input.length;\n    let log2ppl = 0;\n    let equation;\n    while (model.equations.length <= input.length + 1) {\n      // last is zero\n      this.bindEquation();\n    }\n    for (\n      let inputIndex = -1, inputMax = input.length;\n      inputIndex < inputMax;\n      inputIndex++\n    ) {\n      // start and end tokens are zeros\n      const equationIndex = inputIndex + 1;\n      equation = model.equations[equationIndex];\n\n      const source = inputIndex === -1 ? 0 : input[inputIndex] + 1; // first step: start with START token\n      const target = inputIndex === max - 1 ? 0 : input[inputIndex + 1] + 1; // last step: end with END token\n      log2ppl += equation.predictTargetIndex(source, target);\n    }\n    return Math.pow(2, log2ppl / (max - 1)) / 100;\n  }\n\n  backpropagate(input: number[]): void {\n    let i = input.length;\n    const { model } = this;\n    const { equations } = model;\n    while (i > 0) {\n      equations[i].backpropagateIndex(input[i - 1] + 1);\n      i--;\n    }\n    equations[0].backpropagateIndex(0);\n  }\n\n  adjustWeights(): void {\n    const { regc, clipval, decayRate, smoothEps } = this.options;\n    const { trainOpts, model, stepCache } = this;\n    const { learningRate } = trainOpts;\n    const { allMatrices } = model;\n    let numClipped = 0;\n    let numTot = 0;\n    for (let matrixIndex = 0; matrixIndex < allMatrices.length; matrixIndex++) {\n      const matrix = allMatrices[matrixIndex];\n      const { weights, deltas } = matrix;\n      if (!(matrixIndex in stepCache)) {\n        stepCache[matrixIndex] = zeros(matrix.rows * matrix.columns);\n      }\n      const cache = stepCache[matrixIndex];\n      for (let i = 0; i < weights.length; i++) {\n        let r = deltas[i];\n        const w = weights[i];\n        // rmsprop adaptive learning rate\n        cache[i] = cache[i] * decayRate + (1 - decayRate) * r * r;\n        // gradient clip\n        if (r > clipval) {\n          r = clipval;\n          numClipped++;\n        } else if (r < -clipval) {\n          r = -clipval;\n          numClipped++;\n        }\n        numTot++;\n        // update (and regularize)\n        weights[i] =\n          w + (-learningRate * r) / Math.sqrt(cache[i] + smoothEps) - regc * w;\n      }\n    }\n    this.ratioClipped = numClipped / numTot;\n  }\n\n  get isRunnable(): boolean {\n    if (this.model && this.model.equations.length === 0) {\n      console.error(`No equations bound, did you run train()?`);\n      return false;\n    }\n\n    return true;\n  }\n\n  checkRunnable(): void {\n    if (!this.isRunnable) {\n      throw new Error('Network not runnable');\n    }\n  }\n\n  run(rawInput: Value = [], isSampleI = false, temperature = 1): string {\n    const maxPredictionLength: number =\n      this.options.maxPredictionLength +\n      (rawInput !== null ? (rawInput as string).length : 0) +\n      (this.options.dataFormatter\n        ? this.options.dataFormatter.specialIndexes.length\n        : 0);\n\n    this.checkRunnable();\n\n    const input: number[] =\n      this.options.dataFormatter && (rawInput as string).length > 0\n        ? this.options.dataFormatter.formatDataIn(rawInput)\n        : (rawInput as number[]);\n    const { model } = this;\n    const output = [];\n    let i = 0;\n    while (true) {\n      const previousIndex =\n        i === 0 ? 0 : i < input.length ? input[i - 1] + 1 : output[i - 1];\n      while (model.equations.length <= i) {\n        this.bindEquation();\n      }\n      const equation = model.equations[i];\n      // sample predicted letter\n      const outputMatrix = equation.runIndex(previousIndex);\n      const logProbabilities = new Matrix(\n        model.output.rows,\n        model.output.columns\n      );\n      copy(logProbabilities, outputMatrix);\n      if (temperature !== 1 && isSampleI) {\n        /**\n         * scale log probabilities by temperature and re-normalize\n         * if temperature is high, logProbabilities will go towards zero\n         * and the softmax outputs will be more diffuse. if temperature is\n         * very low, the softmax outputs will be more peaky\n         */\n        for (let j = 0, max = logProbabilities.weights.length; j < max; j++) {\n          logProbabilities.weights[j] /= temperature;\n        }\n      }\n\n      const probs = softmax(logProbabilities);\n      const nextIndex = isSampleI ? sampleI(probs) : maxI(probs);\n\n      i++;\n      if (nextIndex === 0) {\n        // END token predicted, break out\n        break;\n      }\n      if (i >= maxPredictionLength) {\n        // something is wrong\n        break;\n      }\n\n      output.push(nextIndex);\n    }\n\n    /**\n     * we slice the input length here, not because output contains it, but it will be erroneous as we are sending the\n     * network what is contained in input, so the data is essentially guessed by the network what could be next, till it\n     * locks in on a value.\n     * Kind of like this, values are from input:\n     * 0 -> 4 (or in English: \"beginning on input\" -> \"I have no idea? I'll guess what they want next!\")\n     * 2 -> 2 (oh how interesting, I've narrowed down values...)\n     * 1 -> 9 (oh how interesting, I've now know what the values are...)\n     * then the output looks like: [4, 2, 9,...]\n     * so we then remove the erroneous data to get our true output\n     */\n    return this.options.dataFormatter.formatDataOut(\n      input,\n      output.slice(input.length).map((value) => value - 1)\n    );\n  }\n\n  /**\n   *\n   * Verifies network sizes are initialized\n   * If they are not it will initialize them\n   */\n  verifyIsInitialized(): void {\n    if (!this.model.isInitialized) {\n      this.initialize();\n    }\n  }\n\n  /**\n   *\n   * @param options\n   *    Supports all `trainDefaults` properties\n   *    also supports:\n   *       learningRate: (number),\n   *       momentum: (number),\n   *       activation: 'sigmoid', 'relu', 'leaky-relu', 'tanh'\n   */\n  updateTrainingOptions(options: Partial<IRNNTrainingOptions>): void {\n    this.trainOpts = { ...trainDefaults, ...options };\n    this.validateTrainingOptions(this.trainOpts as INeuralNetworkTrainOptions);\n    this.setLogMethod(options.log ?? this.trainOpts.log);\n    // TODO: Remove this?\n    // this.activation = options.activation || this.activation;\n  }\n\n  validateTrainingOptions(options: INeuralNetworkTrainOptions): void {\n    const validations: { [fnName: string]: () => boolean } = {\n      iterations: () => {\n        const val = options.iterations;\n        return typeof val === 'number' && val > 0;\n      },\n      errorThresh: () => {\n        const val = options.errorThresh;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      log: () => {\n        const val = options.log;\n        return typeof val === 'function' || typeof val === 'boolean';\n      },\n      logPeriod: () => {\n        const val = options.logPeriod;\n        return typeof val === 'number' && val > 0;\n      },\n      learningRate: () => {\n        const val = options.learningRate;\n        return typeof val === 'number' && val > 0 && val < 1;\n      },\n      callback: () => {\n        const val = options.callback;\n        return typeof val === 'function' || val === undefined;\n      },\n      callbackPeriod: () => {\n        const val = options.callbackPeriod;\n        return typeof val === 'number' && val > 0;\n      },\n      timeout: () => {\n        const val = options.timeout;\n        return typeof val === 'number' && val > 0;\n      },\n    };\n    for (const p in validations) {\n      const v = (options as unknown) as { [v: string]: string };\n      if (!validations[p]()) {\n        throw new Error(\n          `[${p}, ${v[p]}] is out of normal training range, your network will probably not train.`\n        );\n      }\n    }\n  }\n\n  setLogMethod(log: Log | undefined | boolean): void {\n    if (typeof log === 'function') {\n      this.trainOpts.log = log;\n    } else if (log) {\n      this.trainOpts.log = console.log;\n    } else {\n      this.trainOpts.log = false;\n    }\n  }\n\n  protected prepTraining(\n    data: Array<Value | IRNNDatum>,\n    options: Partial<IRNNTrainingOptions>\n  ): IRNNPreppedTrainingData {\n    this.updateTrainingOptions(options);\n    const preparedData = this.options.dataFormatter.format(data);\n    const endTime = Date.now() + (this.trainOpts.timeout ?? 0);\n\n    const status = {\n      error: 1,\n      iterations: 0,\n    };\n\n    this.verifyIsInitialized();\n\n    return {\n      preparedData,\n      status,\n      endTime,\n    };\n  }\n\n  train(\n    data: Array<Value | IRNNDatum>,\n    trainOpts: Partial<IRNNTrainingOptions> = {}\n  ): IRNNStatus {\n    this.trainOpts = trainOpts = {\n      ...trainDefaults,\n      ...trainOpts,\n    };\n    const {\n      iterations,\n      errorThresh,\n      logPeriod,\n      callback,\n      callbackPeriod,\n    } = this.trainOpts;\n    const log = trainOpts.log === true ? console.log : trainOpts.log;\n    let error = Infinity;\n    let i;\n\n    let inputs: number[][];\n    if (this.options?.dataFormatter) {\n      inputs = this.options.dataFormatter.format(data);\n    } else if (\n      Array.isArray(data) &&\n      Array.isArray(data[0]) &&\n      typeof (data as number[][])[0][0] === 'number'\n    ) {\n      inputs = data as number[][];\n    } else {\n      throw new Error('training not in expected format of number[][]');\n    }\n\n    this.verifyIsInitialized();\n\n    for (i = 0; i < iterations && error > errorThresh; i++) {\n      let sum = 0;\n      for (let j = 0; j < inputs.length; j++) {\n        const err = this.trainPattern(inputs[j], true);\n        sum += err;\n      }\n      error = sum / data.length;\n\n      if (isNaN(error)) {\n        throw new Error(\n          'Network error rate is unexpected NaN, check network configurations and try again. Most probably input format is not correct or training data is not enough. '\n        );\n      }\n      if (log && i % logPeriod === 0) {\n        log(`iterations: ${i}, training error: ${error}`);\n      }\n      if (callback && i % callbackPeriod === 0) {\n        callback({ error, iterations: i });\n      }\n    }\n\n    return {\n      error,\n      iterations: i,\n    };\n  }\n\n  addFormat(): void {\n    throw new Error('not yet implemented');\n  }\n\n  toJSON(): IRNNJSON {\n    if (!this.model.isInitialized) {\n      this.initialize();\n    }\n    const { model, options } = this;\n\n    return {\n      type: this.constructor.name,\n      options: { ...options, dataFormatter: options.dataFormatter.toJSON() },\n      trainOpts: {\n        ...this.trainOpts,\n        timeout:\n          this.trainOpts.timeout === Infinity\n            ? 'Infinity'\n            : this.trainOpts.timeout,\n      },\n      input: model.input.toJSON(),\n      hiddenLayers: model.hiddenLayers.map((hiddenLayer) => {\n        const layers: { [index: string]: IMatrixJSON } = {};\n        for (const p in hiddenLayer) {\n          if (!hiddenLayer.hasOwnProperty(p)) continue;\n          layers[p] = hiddenLayer[p].toJSON();\n        }\n        return layers;\n      }),\n      outputConnector: this.model.outputConnector.toJSON(),\n      output: this.model.output.toJSON(),\n    };\n  }\n\n  fromJSON(json: IRNNJSON): this {\n    const { options } = json;\n    const allMatrices = [];\n    const input = Matrix.fromJSON(json.input);\n    allMatrices.push(input);\n    const hiddenLayers: IRNNHiddenLayerModel[] = [];\n\n    json.hiddenLayers.forEach((hiddenLayer) => {\n      const layers: { [index: string]: Matrix } = {};\n      for (const p in hiddenLayer) {\n        layers[p] = Matrix.fromJSON(hiddenLayer[p]);\n        allMatrices.push(layers[p]);\n      }\n      hiddenLayers.push(layers as IRNNHiddenLayerModel);\n    });\n\n    const outputConnector = Matrix.fromJSON(json.outputConnector);\n    allMatrices.push(outputConnector);\n    const output = Matrix.fromJSON(json.output);\n    allMatrices.push(output);\n\n    if (options.dataFormatter) {\n      this.options = {\n        ...defaults(),\n        ...options,\n        dataFormatter: DataFormatter.fromJSON(options.dataFormatter),\n      };\n    } else {\n      this.options = {\n        ...defaults(),\n        ...options,\n        dataFormatter: new DataFormatter(),\n      };\n    }\n\n    this.model = Object.seal({\n      isInitialized: true,\n      input,\n      hiddenLayers,\n      output,\n      allMatrices,\n      outputConnector,\n      equations: [],\n      equationConnections: [],\n    });\n    this.initialLayerInputs = this.options.hiddenLayers.map(\n      (size) => new Matrix(size, 1)\n    );\n    this.bindEquation();\n    return this;\n  }\n\n  toFunction(cb?: (src: string) => string): RNNFunction {\n    const { model } = this;\n    const { equations } = this.model;\n    const equation = equations[1];\n    const { states } = equation;\n    const jsonString = JSON.stringify(this.toJSON());\n\n    function previousConnectionIndex(m: Matrix): number {\n      const connection = model.equationConnections[0];\n      const { states } = equations[0];\n      for (let i = 0, max = states.length; i < max; i++) {\n        if (states[i].product === m) {\n          return i;\n        }\n      }\n      return connection.indexOf(m);\n    }\n\n    function matrixOrigin(m: Matrix, stateIndex: number): string {\n      for (let i = 0, max = states.length; i < max; i++) {\n        const state = states[i];\n\n        if (i === stateIndex) {\n          const j = previousConnectionIndex(m);\n          if (j > -1 && (m === state.left || m === state.right)) {\n            return `typeof prevStates[${j}] === 'object' ? prevStates[${j}].product : new Matrix(${m.rows}, ${m.columns})`;\n          }\n          return `new Matrix(${m.rows}, ${m.columns})`;\n        }\n\n        if (m === state.product) return `states[${i}].product`;\n        if (m === state.right) return `states[${i}].right`;\n        if (m === state.left) return `states[${i}].left`;\n      }\n      return '';\n    }\n\n    function matrixToString(m: Matrix, stateIndex: number): string {\n      if (!m || !m.rows || !m.columns) return 'null';\n\n      if (m === model.input) return `json.input`;\n      if (m === model.outputConnector) return `json.outputConnector`;\n      if (m === model.output) return `json.output`;\n\n      for (let i = 0, max = model.hiddenLayers.length; i < max; i++) {\n        const hiddenLayer = model.hiddenLayers[i];\n        for (const p in hiddenLayer) {\n          if (!hiddenLayer.hasOwnProperty(p)) continue;\n          if (hiddenLayer[p] !== m) continue;\n          return `json.hiddenLayers[${i}].${p}`;\n        }\n      }\n\n      return matrixOrigin(m, stateIndex);\n    }\n\n    function toInner(fnString: string): string {\n      // crude, but should be sufficient for now\n      // function() { body }\n      const fnParts = fnString.toString().split('{');\n      fnParts.shift();\n      // body }\n      const fnBodyString = fnParts.join('{');\n      const fnBodyParts = fnBodyString.split('}');\n      fnBodyParts.pop();\n      // body\n      return fnBodyParts\n        .join('}')\n        .split('\\n')\n        .join('\\n        ')\n        .replace('product.deltas[i] = 0;', '')\n        .replace('product.deltas[column] = 0;', '')\n        .replace('left.deltas[leftIndex] = 0;', '')\n        .replace('right.deltas[rightIndex] = 0;', '')\n        .replace('product.deltas = left.deltas.slice(0);', '');\n    }\n\n    function fileName(fnName: string): string {\n      return `src/recurrent/matrix/${fnName.replace(/[A-Z]/g, function (value) {\n        return `-${value.toLowerCase()}`;\n      })}.js`;\n    }\n\n    const statesRaw = [];\n    const usedFunctionNames: { [methodName: string]: boolean } = {};\n    const innerFunctionsSwitch = [];\n    for (let i = 0, max = states.length; i < max; i++) {\n      const state = states[i];\n      statesRaw.push(`states[${i}] = {\n      name: '${state.forwardFn.name}',\n      left: ${state.left ? matrixToString(state.left, i) : 'undefined'},\n      right: ${state.right ? matrixToString(state.right, i) : 'undefined'},\n      product: ${matrixToString(state.product, i)}\n    }`);\n\n      const fnName = state.forwardFn.name;\n      if (!usedFunctionNames[fnName]) {\n        usedFunctionNames[fnName] = true;\n        innerFunctionsSwitch.push(\n          `        case '${fnName}': //compiled from ${fileName(fnName)}\n          ${toInner(state.forwardFn.toString())}\n          break;`\n        );\n      }\n    }\n\n    const src = `\n  if (typeof rawInput === 'undefined') rawInput = [];\n  if (typeof isSampleI === 'undefined') isSampleI = false;\n  if (typeof temperature === 'undefined') temperature = 1;\n  var json = ${jsonString};\n  ${\n    this.options.dataFormatter\n      ? `${this.options.dataFormatter.toFunctionString()};\n  Object.assign(dataFormatter, json.options.dataFormatter);`\n      : ''\n  }\n  ${\n    this.options.dataFormatter &&\n    typeof this.options.dataFormatter.formatDataIn === 'function'\n      ? `const formatDataIn = function (input, output) { ${toInner(\n          this.options.dataFormatter.formatDataIn.toString()\n        )} }.bind(dataFormatter);`\n      : ''\n  }\n  ${\n    this.options.dataFormatter !== null &&\n    typeof this.options.dataFormatter.formatDataOut === 'function'\n      ? `const formatDataOut = function formatDataOut(input, output) { ${toInner(\n          this.options.dataFormatter.formatDataOut.toString()\n        )} }.bind(dataFormatter);`\n      : ''\n  }\n  var maxPredictionLength =\n    ${this.options.maxPredictionLength} +\n    rawInput.length +\n    ${\n      this.options.dataFormatter\n        ? this.options.dataFormatter.specialIndexes.length\n        : 0\n    };\n  var input = ${\n    this.options.dataFormatter &&\n    typeof this.options.dataFormatter.formatDataIn === 'function'\n      ? 'formatDataIn(rawInput)'\n      : 'rawInput'\n  };\n  var _i = 0;\n  var output = [];\n  var states = [];\n  var prevStates;\n  while (true) {\n    var previousIndex = (_i === 0\n        ? 0\n        : _i < input.length\n          ? input[_i - 1] + 1\n          : output[_i - 1])\n          ;\n    var rowPluckIndex = previousIndex;\n    prevStates = states;\n    states = [];\n    ${statesRaw.join(';\\n    ')};\n    for (var stateIndex = 0, stateMax = ${\n      statesRaw.length\n    }; stateIndex < stateMax; stateIndex++) {\n      var state = states[stateIndex];\n      var product = state.product;\n      var left = state.left;\n      var right = state.right;\n      switch (state.name) {\n${innerFunctionsSwitch.join('\\n')}\n      }\n    }\n\n    var logProbabilities = state.product;\n    if (temperature !== 1 && isSampleI) {\n      for (var q = 0, nq = logProbabilities.weights.length; q < nq; q++) {\n        logProbabilities.weights[q] /= temperature;\n      }\n    }\n\n    var probs = softmax(logProbabilities);\n    var nextIndex = isSampleI ? sampleI(probs) : maxI(probs);\n\n    _i++;\n    if (nextIndex === 0) {\n      break;\n    }\n    if (_i >= maxPredictionLength) {\n      break;\n    }\n\n    output.push(nextIndex);\n  }\n  ${\n    this.options.dataFormatter &&\n    typeof this.options.dataFormatter.formatDataOut === 'function'\n      ? 'return formatDataOut(input, output.slice(input.length).map(function(value) { return value - 1; }))'\n      : 'return output.slice(input.length).map(function(value) { return value - 1; })'\n  };\n  function Matrix(rows, columns) {\n    this.rows = rows;\n    this.columns = columns;\n    this.weights = zeros(rows * columns);\n  }\n  ${zeros.toString()}\n  ${softmax.toString().replace('_1.Matrix', 'Matrix')}\n  ${randomFloat.toString()}\n  ${sampleI.toString()}\n  ${maxI.toString()}`;\n    // eslint-disable-next-line\n    return new Function(\n      'rawInput',\n      'isSampleI',\n      'temperature',\n      cb ? cb(src) : src\n    ) as RNNFunction;\n  }\n\n  trainPattern(input: number[], logErrorRate?: boolean): number {\n    const error = this.trainInput(input);\n    this.backpropagate(input);\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      return error;\n    }\n    return 0;\n  }\n}\n\nexport interface IRNNJSON {\n  type: string;\n  options: IRNNJSONOptions;\n  trainOpts: IRNNJSONTrainOptions;\n  input: IMatrixJSON;\n  hiddenLayers: Array<{ [index: string]: IMatrixJSON }>;\n  outputConnector: IMatrixJSON;\n  output: IMatrixJSON;\n}\n\nexport function last<T>(values: T[]): T {\n  return values[values.length - 1];\n}\n\nexport type RNNFunction = (\n  rawInput?: Array<Value | IRNNDatum> | string,\n  isSampleI?: boolean,\n  temperature?: number\n) => string;\n","import { Matrix } from '.';\n\nexport function copy(product: Matrix, left: Matrix): void {\n  product.rows = left.rows;\n  product.columns = left.columns;\n  product.weights = left.weights.slice(0);\n  product.deltas = left.deltas.slice(0);\n}\n","import { Matrix } from './matrix';\nimport { Equation } from './matrix/equation';\nimport { RandomMatrix } from './matrix/random-matrix';\nimport { IRNNHiddenLayer, RNN } from './rnn';\n\nexport interface IGRUHiddenLayer extends IRNNHiddenLayer {\n  updateGateInputMatrix: RandomMatrix;\n  updateGateHiddenMatrix: RandomMatrix;\n  updateGateBias: Matrix;\n  resetGateInputMatrix: RandomMatrix;\n  resetGateHiddenMatrix: RandomMatrix;\n  resetGateBias: Matrix;\n  cellWriteInputMatrix: RandomMatrix;\n  cellWriteHiddenMatrix: RandomMatrix;\n  cellWriteBias: Matrix;\n}\n\nexport class GRU extends RNN {\n  getHiddenLayer(hiddenSize: number, prevSize: number): IRNNHiddenLayer {\n    return getGRUHiddenLayer(hiddenSize, prevSize);\n  }\n\n  getEquation(\n    equation: Equation,\n    inputMatrix: Matrix,\n    previousResult: Matrix,\n    hiddenLayer: IRNNHiddenLayer\n  ): Matrix {\n    return getGRUEquation(\n      equation,\n      inputMatrix,\n      previousResult,\n      hiddenLayer as IGRUHiddenLayer\n    );\n  }\n}\n\nexport function getGRUHiddenLayer(\n  hiddenSize: number,\n  prevSize: number\n): IGRUHiddenLayer {\n  return {\n    // update Gate\n    // wzxh\n    updateGateInputMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wzhh\n    updateGateHiddenMatrix: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bz\n    updateGateBias: new Matrix(hiddenSize, 1),\n    // reset Gate\n    // wrxh\n    resetGateInputMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wrhh\n    resetGateHiddenMatrix: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // br\n    resetGateBias: new Matrix(hiddenSize, 1),\n    // cell write parameters\n    // wcxh\n    cellWriteInputMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wchh\n    cellWriteHiddenMatrix: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bc\n    cellWriteBias: new Matrix(hiddenSize, 1),\n  };\n}\n\nexport function getGRUEquation(\n  equation: Equation,\n  inputMatrix: Matrix,\n  previousResult: Matrix,\n  hiddenLayer: IGRUHiddenLayer\n): Matrix {\n  if (\n    !hiddenLayer.updateGateInputMatrix ||\n    !hiddenLayer.updateGateHiddenMatrix ||\n    !hiddenLayer.updateGateBias ||\n    !hiddenLayer.resetGateInputMatrix ||\n    !hiddenLayer.resetGateHiddenMatrix ||\n    !hiddenLayer.resetGateBias ||\n    !hiddenLayer.cellWriteInputMatrix ||\n    !hiddenLayer.cellWriteHiddenMatrix ||\n    !hiddenLayer.cellWriteBias\n  ) {\n    throw new Error('hiddenLayer does not have expected properties');\n  }\n\n  const sigmoid = equation.sigmoid.bind(equation);\n  const add = equation.add.bind(equation);\n  const multiply = equation.multiply.bind(equation);\n  const multiplyElement = equation.multiplyElement.bind(equation);\n  const tanh = equation.tanh.bind(equation);\n  const allOnes = equation.allOnes.bind(equation);\n  const cloneNegative = equation.cloneNegative.bind(equation);\n\n  // update gate\n  const updateGate = sigmoid(\n    add(\n      add(\n        multiply(hiddenLayer.updateGateInputMatrix, inputMatrix),\n        multiply(hiddenLayer.updateGateHiddenMatrix, previousResult)\n      ),\n      hiddenLayer.updateGateBias\n    )\n  );\n\n  // reset gate\n  const resetGate = sigmoid(\n    add(\n      add(\n        multiply(hiddenLayer.resetGateInputMatrix, inputMatrix),\n        multiply(hiddenLayer.resetGateHiddenMatrix, previousResult)\n      ),\n      hiddenLayer.resetGateBias\n    )\n  );\n\n  // cell\n  const cell = tanh(\n    add(\n      add(\n        multiply(hiddenLayer.cellWriteInputMatrix, inputMatrix),\n        multiply(\n          hiddenLayer.cellWriteHiddenMatrix,\n          multiplyElement(resetGate, previousResult)\n        )\n      ),\n      hiddenLayer.cellWriteBias\n    )\n  );\n\n  // compute hidden state as gated, saturated cell activations\n  // negate updateGate\n  return add(\n    multiplyElement(\n      add(\n        allOnes(updateGate.rows, updateGate.columns),\n        cloneNegative(updateGate)\n      ),\n      cell\n    ),\n    multiplyElement(previousResult, updateGate)\n  );\n}\n","export class ArrayLookupTable {\n  length = 0;\n  table: { [key: string]: number } = {};\n\n  constructor(\n    data: Array<{\n      input: Array<Record<string, number>>;\n      output: Array<Record<string, number>>;\n    }>,\n    public prop: 'input' | 'output'\n  ) {\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      const ioValue = datum[prop];\n      for (let j = 0; j < ioValue.length; j++) {\n        const value = ioValue[j];\n        for (const p in value) {\n          if (!value.hasOwnProperty(p)) continue;\n          if (this.table.hasOwnProperty(p)) continue;\n          this.table[p] = this.length++;\n        }\n      }\n    }\n  }\n}\n","import {\n  FormattableData,\n  InputOutputValue,\n  INumberArray,\n  INumberHash,\n  ITrainingDatum,\n  lookup,\n} from '../lookup';\nimport { ArrayLookupTable } from '../utilities/array-lookup-table';\nimport {\n  arraysToFloat32Arrays,\n  arrayToFloat32Arrays,\n  inputOutputArraysToFloat32Arrays,\n  inputOutputArrayToFloat32Arrays,\n  inputOutputObjectsToFloat32Arrays,\n  inputOutputObjectToFloat32Arrays,\n  objectToFloat32Array,\n  objectToFloat32Arrays,\n} from '../utilities/cast';\nimport { LookupTable } from '../utilities/lookup-table';\nimport { randomFloat } from '../utilities/random';\nimport { zeros } from '../utilities/zeros';\nimport { IMatrixJSON, Matrix } from './matrix';\nimport { Equation } from './matrix/equation';\nimport { maxI } from './matrix/max-i';\nimport { RandomMatrix } from './matrix/random-matrix';\nimport { sampleI } from './matrix/sample-i';\nimport { softmax } from './matrix/softmax';\nimport {\n  defaults as rnnDefaults,\n  IRNNHiddenLayer,\n  IRNNHiddenLayerModel,\n  IRNNOptions,\n  IRNNStatus,\n  IRNNTrainingOptions,\n  last,\n  RNN,\n  trainDefaults as rnnTrainDefaults,\n} from './rnn';\n\nexport type ValuesOf<\n  T extends InputOutputValue | InputOutputValue[]\n> = T[number];\n\nexport interface IRNNTimeStepOptions extends IRNNTimeStepJSONOptions {\n  inputSize: number;\n  inputRange: number;\n  hiddenLayers: number[];\n  outputSize: number;\n  decayRate: number;\n  smoothEps: number;\n  regc: number;\n  clipval: number;\n  maxPredictionLength: number;\n  json?: IRNNTimeStepJSON;\n}\n\nexport interface IRNNTimeStepJSONOptions {\n  inputSize: number;\n  inputRange: number;\n  hiddenLayers: number[];\n  outputSize: number;\n  decayRate: number;\n  smoothEps: number;\n  regc: number;\n  clipval: number;\n  maxPredictionLength: number;\n}\n\nexport interface IRNNTimeStepJSON {\n  type: string;\n  options: IRNNTimeStepJSONOptions;\n  hiddenLayers: Array<{ [index: string]: IMatrixJSON }>;\n  outputConnector: IMatrixJSON;\n  output: IMatrixJSON;\n  inputLookup: INumberHash | null;\n  inputLookupLength: number;\n  outputLookup: INumberHash | null;\n  outputLookupLength: number;\n}\n\nexport interface IMisclass {\n  value: FormattableData;\n  actual: FormattableData;\n}\n\nexport interface ITestResults {\n  misclasses: IMisclass[];\n  error: number;\n  total: number;\n}\n\nexport interface IRNNTimeStepModel {\n  isInitialized: boolean;\n  hiddenLayers: IRNNHiddenLayer[];\n  output: Matrix;\n  equations: Equation[];\n  allMatrices: Matrix[];\n  equationConnections: Matrix[][];\n  outputConnector: RandomMatrix | Matrix;\n}\n\nexport const defaults = (): IRNNOptions => {\n  return {\n    ...rnnDefaults(),\n    inputSize: 1,\n    hiddenLayers: [20],\n    outputSize: 1,\n    inputRange: 0,\n  };\n};\n\nexport class RNNTimeStep extends RNN {\n  inputLookupLength = 0;\n  inputLookup: INumberHash | null = null;\n  outputLookup: INumberHash | null = null;\n  outputLookupLength = 0;\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  model: IRNNTimeStepModel = Object.seal({\n    isInitialized: false,\n    hiddenLayers: [],\n    output: new Matrix(0, 0),\n    equations: [],\n    allMatrices: [],\n    equationConnections: [],\n    outputConnector: new RandomMatrix(0, 0, 0.08),\n  });\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  options: IRNNTimeStepOptions = defaults();\n  constructor(\n    options: Partial<IRNNTimeStepOptions & IRNNTrainingOptions> = {}\n  ) {\n    super();\n    this.options = { ...this.options, ...options };\n    this.updateTrainingOptions({\n      ...trainDefaults,\n      ...options,\n    });\n\n    if (options.json) {\n      this.fromJSON(options.json);\n    }\n  }\n\n  createInputMatrix(): RandomMatrix {\n    throw new Error('Input Matrices do not exist on RNNTimeStep');\n  }\n\n  createOutputMatrices(): { outputConnector: RandomMatrix; output: Matrix } {\n    const { outputSize } = this.options;\n    const lastHiddenSize = last(this.options.hiddenLayers);\n\n    // whd\n    const outputConnector = new RandomMatrix(outputSize, lastHiddenSize, 0.08);\n    // bd\n    const output = new RandomMatrix(outputSize, 1, 0.08);\n    return { output, outputConnector };\n  }\n\n  bindEquation(): void {\n    const { model, options } = this;\n    const { hiddenLayers, inputSize } = options;\n    const layers = model.hiddenLayers;\n    const equation = new Equation();\n    const outputs = [];\n    const equationConnection =\n      model.equationConnections.length > 0\n        ? model.equationConnections[model.equationConnections.length - 1]\n        : this.initialLayerInputs;\n    // 0 index\n    let output = this.getEquation(\n      equation,\n      equation.input(new Matrix(inputSize, 1)),\n      equationConnection[0],\n      layers[0]\n    );\n    outputs.push(output);\n    // 1+ indices\n    for (let i = 1, max = hiddenLayers.length; i < max; i++) {\n      output = this.getEquation(\n        equation,\n        output,\n        equationConnection[i],\n        layers[i]\n      );\n      outputs.push(output);\n    }\n\n    model.equationConnections.push(outputs);\n    equation.add(\n      equation.multiply(model.outputConnector, output),\n      model.output\n    );\n    model.equations.push(equation);\n  }\n\n  initialize(): void {\n    this.model = this.mapModel();\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  mapModel(): IRNNTimeStepModel {\n    const allMatrices: Matrix[] = [];\n    this.initialLayerInputs = this.options.hiddenLayers.map(\n      (size) => new Matrix(size, 1)\n    );\n\n    const hiddenLayers = this.createHiddenLayers();\n    for (let i = 0, max = hiddenLayers.length; i < max; i++) {\n      const hiddenMatrix = hiddenLayers[i];\n      for (const property in hiddenMatrix) {\n        if (!hiddenMatrix.hasOwnProperty(property)) continue;\n        allMatrices.push(hiddenMatrix[property]);\n      }\n    }\n\n    const { outputConnector, output } = this.createOutputMatrices();\n\n    allMatrices.push(outputConnector);\n    allMatrices.push(output);\n    return Object.seal({\n      isInitialized: true,\n      hiddenLayers,\n      output,\n      equations: [],\n      allMatrices,\n      equationConnections: [],\n      outputConnector,\n    });\n  }\n\n  backpropagate(): void {\n    for (let i = this.model.equations.length - 1; i > -1; i--) {\n      this.model.equations[i].backpropagate();\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  run<InputType extends InputOutputValue | InputOutputValue[]>(\n    rawInput: InputType\n  ): ValuesOf<InputType> {\n    const shape = lookup.dataShape(rawInput).join(',');\n    switch (shape) {\n      case 'array,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.runArray(rawInput as Float32Array);\n      case 'array,array,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.runArrayOfArray(rawInput as Float32Array[]);\n      case 'object,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.runObject(rawInput as INumberHash); // Backward compatibility, will be result of `unknown` and need casting.  Better to just use net.runObject() directly\n      case 'array,object,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.runArrayOfObject(rawInput as INumberHash[]);\n      default:\n        throw new Error(`Unrecognized data shape ${shape}`);\n    }\n  }\n\n  forecast<InputType extends InputOutputValue | InputOutputValue[]>(\n    rawInput: InputType,\n    count = 1\n  ): InputType {\n    const shape = lookup.dataShape(rawInput).join(',');\n    switch (shape) {\n      case 'array,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.forecastArray(rawInput as Float32Array, count);\n      case 'array,array,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.forecastArrayOfArray(rawInput as Float32Array[], count);\n      case 'object,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.runObject(rawInput as INumberHash);\n      case 'array,object,number':\n        // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n        // @ts-expect-error\n        return this.forecastArrayOfObject(rawInput as INumberHash[], count);\n      default:\n        throw new Error(`Unrecognized data shape ${shape}`);\n    }\n  }\n\n  forecastArray(input: Float32Array, count = 1): Float32Array {\n    this.checkRunnable();\n    const { model } = this;\n    const { equations } = model;\n    const length = input.length + count;\n    while (equations.length <= length) {\n      this.bindEquation();\n    }\n    let lastOutput;\n    let equationIndex = 0;\n    if (this.options.inputSize === 1) {\n      for (let i = 0; i < input.length; i++) {\n        lastOutput = equations[equationIndex++].runInput(\n          Float32Array.from([input[i]])\n        );\n      }\n    } else {\n      for (let i = 0; i < input.length; i++) {\n        lastOutput = equations[equationIndex++].runInput(Float32Array.from([]));\n      }\n    }\n    if (!lastOutput) {\n      throw new Error('lastOutput not set');\n    }\n    const result = [lastOutput.weights[0]];\n    for (let i = 0, max = count - 1; i < max; i++) {\n      lastOutput = equations[equationIndex++].runInput(lastOutput.weights);\n      result.push(lastOutput.weights[0]);\n    }\n    this.end();\n    return Float32Array.from(result);\n  }\n\n  forecastArrayOfArray(input: Float32Array[], count = 1): Float32Array[] {\n    this.checkRunnable();\n    const { model } = this;\n    const { equations } = model;\n    const length = input.length + count;\n    while (equations.length <= length) {\n      this.bindEquation();\n    }\n    let lastOutput;\n    let equationIndex = 0;\n    for (let i = 0; i < input.length; i++) {\n      lastOutput = equations[equationIndex++].runInput(input[i]);\n    }\n    if (!lastOutput) {\n      throw new Error('lastOutput not set');\n    }\n    const result = [Float32Array.from(lastOutput.weights)];\n    for (let i = 0, max = count - 1; i < max; i++) {\n      lastOutput = equations[equationIndex++].runInput(lastOutput.weights);\n      result.push(Float32Array.from(lastOutput.weights.slice(0)));\n    }\n    this.end();\n    return result;\n  }\n\n  forecastArrayOfObject(input: INumberHash[], count = 1): INumberHash[] {\n    if (!this.inputLookup) {\n      throw new Error('this.inputLookup not set');\n    }\n    if (!this.outputLookup) {\n      throw new Error('this.outputLookup not set');\n    }\n    const formattedData = input.map((value) =>\n      lookup.toArray(\n        this.inputLookup as INumberHash,\n        value,\n        this.inputLookupLength\n      )\n    );\n    return this.forecastArrayOfArray(formattedData, count).map((value) =>\n      lookup.toObject(this.outputLookup as INumberHash, value)\n    );\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  train(\n    data: FormattableData[],\n    trainOpts: Partial<IRNNTrainingOptions> = {}\n  ): IRNNStatus {\n    this.trainOpts = trainOpts = {\n      ...rnnTrainDefaults,\n      ...trainOpts,\n    };\n    // Don't destructure here because this.setSize() can reset this.options.\n    if (this.options.inputSize === 1 && this.options.outputSize === 1) {\n      this.setSize(data);\n    }\n    this.verifySize();\n\n    const formattedData = this.formatData(data);\n    let error = Infinity;\n    let i;\n\n    this.verifyIsInitialized();\n    const {\n      iterations,\n      errorThresh,\n      logPeriod,\n      callback,\n      callbackPeriod,\n    } = this.trainOpts;\n    const log = trainOpts.log === true ? console.log : trainOpts.log;\n    for (i = 0; i < iterations && error > errorThresh; i++) {\n      let sum = 0;\n      for (let j = 0; j < formattedData.length; j++) {\n        const err = this.trainPattern(formattedData[j], true);\n        sum += err;\n      }\n      error = sum / formattedData.length;\n\n      if (isNaN(error))\n        throw new Error(\n          'Network error rate is unexpected NaN, check network configurations and try again. Most probably input format is not correct or training data is not enough. '\n        );\n      if (log && i % logPeriod === 0) {\n        log(`iterations: ${i}, training error: ${error}`);\n      }\n      if (callback && i % callbackPeriod === 0) {\n        callback({ error, iterations: i });\n      }\n    }\n\n    return {\n      error,\n      iterations: i,\n    };\n  }\n\n  trainArrayOfArray(input: Float32Array[]): number {\n    if (input.length < 2) {\n      throw new Error('input must be an array of 2 or more');\n    }\n    const { equations } = this.model;\n    while (equations.length < input.length) {\n      this.bindEquation();\n    }\n    let errorSum = 0;\n    for (let i = 0, max = input.length - 1; i < max; i++) {\n      errorSum += equations[i].predictTarget(input[i], input[i + 1]);\n    }\n    this.end();\n    return errorSum / input.length;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  trainPattern(input: Float32Array[], logErrorRate?: boolean): number {\n    const error = this.trainArrayOfArray(input);\n    this.backpropagate();\n    this.adjustWeights();\n\n    if (logErrorRate) {\n      return error;\n    }\n    return 0;\n  }\n\n  setSize(data: FormattableData[]): void {\n    let size = 0;\n    const dataShape = lookup.dataShape(data).join(',');\n    switch (dataShape) {\n      case 'array,array,number':\n      case 'array,object,number':\n      case 'array,datum,array,number':\n      case 'array,datum,object,number':\n        size = 1;\n        // probably 1\n        break;\n      case 'array,array,array,number':\n        size = (data as number[][][])[0][0].length;\n        break;\n      case 'array,array,object,number':\n        // inputs and outputs should match\n        size = Object.keys(lookup.toTable2D(data as INumberHash[][])).length;\n        break;\n      case 'array,datum,array,array,number':\n        size = ((data as unknown) as Array<{\n          [key: string]: number[][];\n        }>)[0].input[0].length;\n        break;\n      case 'array,datum,array,object,number':\n        size = Object.keys(\n          lookup.toInputTable2D(\n            data as Array<{ input: Array<{ [key: string]: number }> }>\n          )\n        ).length;\n        break;\n      default:\n        throw new Error('unknown data shape or configuration');\n    }\n    this.options = Object.seal({\n      ...this.options,\n      inputSize: size,\n      outputSize: size,\n    });\n  }\n\n  verifySize(): void {\n    if (this.options.inputSize || this.options.outputSize) {\n      if (this.options.inputSize !== this.options.outputSize) {\n        throw new Error('manually set inputSize and outputSize mismatch');\n      }\n    }\n  }\n\n  runArray(input: Float32Array): number {\n    this.checkRunnable();\n    const { equations } = this.model;\n    while (equations.length <= input.length) {\n      this.bindEquation();\n    }\n    let lastOutput;\n    for (let i = 0; i < input.length; i++) {\n      lastOutput = equations[i].runInput(new Float32Array([input[i]]));\n    }\n    this.end();\n    return (lastOutput as Matrix).weights[0];\n  }\n\n  runArrayOfArray(input: Float32Array[]): Float32Array {\n    this.checkRunnable();\n    const { model } = this;\n    const { equations } = model;\n    while (equations.length <= input.length) {\n      this.bindEquation();\n    }\n    let lastOutput;\n    for (let i = 0; i < input.length; i++) {\n      const outputMatrix = equations[i].runInput(input[i]);\n      lastOutput = outputMatrix.weights;\n    }\n    this.end();\n    return lastOutput ?? Float32Array.from([]);\n  }\n\n  runObject(input: INumberHash): INumberHash {\n    if (!this.inputLookup) {\n      throw new Error('this.inputLookup not set');\n    }\n    if (!this.outputLookup) {\n      throw new Error('this.outputLookup not set');\n    }\n    if (!this.outputLookupLength) {\n      throw new Error('this.outputLookupLength not set');\n    }\n    if (this.inputLookup === this.outputLookup) {\n      const inputArray = lookup.toArrayShort(this.inputLookup, input);\n      return lookup.toObjectPartial(\n        this.outputLookup,\n        this.forecastArray(\n          inputArray,\n          this.outputLookupLength - inputArray.length\n        ),\n        inputArray.length\n      );\n    }\n    return lookup.toObject(\n      this.outputLookup,\n      this.forecastArray(\n        lookup.toArray(this.inputLookup, input, this.inputLookupLength),\n        this.outputLookupLength\n      )\n    );\n  }\n\n  runArrayOfObject(input: INumberHash[]): INumberHash {\n    if (this.inputLookup === null) {\n      throw new Error('this.inputLookup not set');\n    }\n    if (this.outputLookup === null) {\n      throw new Error('this.outputLookup not set');\n    }\n    const formattedInput = input.map((value) =>\n      lookup.toArray(\n        this.inputLookup as INumberHash,\n        value,\n        this.inputLookupLength\n      )\n    );\n    return this.forecastArrayOfArray(formattedInput, 1).map((value) =>\n      lookup.toObject(this.outputLookup as INumberHash, value)\n    )[0];\n  }\n\n  runArrayOfObjectOfArray(input: INumberHash[]): INumberHash {\n    if (!this.inputLookup) {\n      throw new Error('this.inputLookup not set');\n    }\n    if (!this.outputLookup) {\n      throw new Error('this.outputLookup not set');\n    }\n    return lookup.toObject(\n      this.outputLookup,\n      this.runArrayOfArray(\n        lookup.toArrays(this.inputLookup, input, this.inputLookupLength)\n      )\n    );\n  }\n\n  end(): void {\n    this.model.equations[this.model.equations.length - 1].runInput(\n      new Float32Array(this.options.outputSize)\n    );\n  }\n\n  requireInputOutputOfOne(): void {\n    if (this.options.inputSize !== 1) {\n      throw new Error('inputSize must be 1 for this data size');\n    }\n    if (this.options.outputSize !== 1) {\n      throw new Error('outputSize must be 1 for this data size');\n    }\n  }\n\n  // Handles data shape of 'array,number'\n  formatArray(data: number[]): Float32Array[][] {\n    const result = [];\n    this.requireInputOutputOfOne();\n    for (let i = 0; i < data.length; i++) {\n      result.push(Float32Array.from([data[i]]));\n    }\n    return [result];\n  }\n\n  // Handles data shape of 'array,array,number'\n  formatArrayOfArray(data: number[][]): Float32Array[][] {\n    const result = [];\n    const { inputSize, outputSize } = this.options;\n    if (inputSize === 1 && outputSize === 1) {\n      for (let i = 0; i < data.length; i++) {\n        result.push(arrayToFloat32Arrays(data[i]));\n      }\n      return result;\n    }\n    if (inputSize !== data[0].length) {\n      throw new Error('inputSize must match data input size');\n    }\n    if (outputSize !== data[0].length) {\n      throw new Error('outputSize must match data output size');\n    }\n    for (let i = 0; i < data.length; i++) {\n      result.push(Float32Array.from(data[i]));\n    }\n    return [result];\n  }\n\n  // Handles data shape of 'array,object,number'\n  formatArrayOfObject(data: INumberHash[]): Float32Array[][] {\n    this.requireInputOutputOfOne();\n    if (!this.inputLookup) {\n      const lookupTable = new LookupTable(data);\n      this.inputLookup = this.outputLookup = lookupTable.table;\n      this.inputLookupLength = this.outputLookupLength = lookupTable.length;\n    }\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      result.push(objectToFloat32Arrays(data[i]));\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,object,number' when this.options.inputSize > 1\n  formatArrayOfObjectMulti(data: INumberHash[]): Float32Array[][] {\n    if (!this.inputLookup) {\n      const lookupTable = new LookupTable(data);\n      this.inputLookup = this.outputLookup = lookupTable.table;\n      this.inputLookupLength = this.outputLookupLength = lookupTable.length;\n    }\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      result.push([\n        objectToFloat32Array(data[i], this.inputLookup, this.inputLookupLength),\n      ]);\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,datum,array,number'\n  formatArrayOfDatumOfArray(data: ITrainingDatum[]): Float32Array[][] {\n    const result = [];\n    this.requireInputOutputOfOne();\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      result.push(\n        inputOutputArrayToFloat32Arrays(\n          datum.input as number[],\n          datum.output as number[]\n        )\n      );\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,datum,object,number'\n  formatArrayOfDatumOfObject(data: ITrainingDatum[]): Float32Array[][] {\n    this.requireInputOutputOfOne();\n    if (!this.inputLookup) {\n      const inputLookup = new LookupTable(data, 'input');\n      this.inputLookup = inputLookup.table;\n      this.inputLookupLength = inputLookup.length;\n    }\n    if (!this.outputLookup) {\n      const outputLookup = new LookupTable(data, 'output');\n      this.outputLookup = outputLookup.table;\n      this.outputLookupLength = outputLookup.length;\n    }\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      result.push(\n        inputOutputObjectToFloat32Arrays(\n          datum.input as INumberHash,\n          datum.output as INumberHash\n        )\n      );\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,array,array,number'\n  formatArrayOfArrayOfArray(data: number[][][]): Float32Array[][] {\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      result.push(arraysToFloat32Arrays(data[i]));\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,array,object,number'\n  formatArrayOfArrayOfObject(data: INumberHash[][]): Float32Array[][] {\n    if (!this.inputLookup) {\n      const lookupTable = new LookupTable(data);\n      this.inputLookup = this.outputLookup = lookupTable.table;\n      this.inputLookupLength = this.outputLookupLength = lookupTable.length;\n    }\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      const array = [];\n      for (let j = 0; j < data[i].length; j++) {\n        array.push(\n          objectToFloat32Array(\n            data[i][j],\n            this.inputLookup,\n            this.inputLookupLength\n          )\n        );\n      }\n      result.push(array);\n    }\n    return result;\n  }\n\n  // Handles data shape of 'array,datum,array,array,number'\n  formatArrayOfDatumOfArrayOfArray(data: ITrainingDatum[]): Float32Array[][] {\n    const result = [];\n    const { inputSize, outputSize } = this.options;\n    if (inputSize !== (data[0].input as INumberArray[][])[0].length) {\n      throw new Error('inputSize must match data input size');\n    }\n    if (outputSize !== (data[0].output as INumberArray[][])[0].length) {\n      throw new Error('outputSize must match data output size');\n    }\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      result.push(\n        inputOutputArraysToFloat32Arrays(\n          datum.input as number[][],\n          datum.output as number[][]\n        )\n      );\n    }\n    return result;\n  }\n\n  // 'Handles data shape of array,datum,array,object,number'\n  formatArrayOfDatumOfArrayOfObject(\n    data: Array<{\n      input: Array<Record<string, number>>;\n      output: Array<Record<string, number>>;\n    }>\n  ): Float32Array[][] {\n    if (!this.inputLookup) {\n      const inputLookup = new ArrayLookupTable(data, 'input');\n      this.inputLookup = inputLookup.table;\n      this.inputLookupLength = inputLookup.length;\n    }\n    if (!this.outputLookup) {\n      const outputLookup = new ArrayLookupTable(data, 'output');\n      this.outputLookup = outputLookup.table;\n      this.outputLookupLength = outputLookup.length;\n    }\n    if (!this.outputLookupLength) {\n      throw new Error('this.outputLookupLength not set to usable number');\n    }\n    const result = [];\n    for (let i = 0; i < data.length; i++) {\n      const datum = data[i];\n      result.push(\n        inputOutputObjectsToFloat32Arrays(\n          datum.input,\n          datum.output,\n          this.inputLookup,\n          this.outputLookup,\n          this.inputLookupLength,\n          this.outputLookupLength\n        )\n      );\n    }\n    return result;\n  }\n\n  formatData(data: FormattableData[]): Float32Array[][] {\n    const dataShape = lookup.dataShape(data).join(',');\n    switch (dataShape) {\n      case 'array,number':\n        return this.formatArray(data as number[]);\n      case 'array,array,number':\n        return this.formatArrayOfArray(data as number[][]);\n      case 'array,object,number':\n        if (this.options.inputSize === 1) {\n          return this.formatArrayOfObject(data as INumberHash[]);\n        } else {\n          return this.formatArrayOfObjectMulti(data as INumberHash[]);\n        }\n      case 'array,datum,array,number':\n        return this.formatArrayOfDatumOfArray(data as ITrainingDatum[]);\n      case 'array,datum,object,number':\n        return this.formatArrayOfDatumOfObject(data as ITrainingDatum[]);\n      case 'array,array,array,number':\n        return this.formatArrayOfArrayOfArray(data as number[][][]);\n      case 'array,array,object,number':\n        return this.formatArrayOfArrayOfObject(data as INumberHash[][]);\n      case 'array,datum,array,array,number':\n        return this.formatArrayOfDatumOfArrayOfArray(data as ITrainingDatum[]);\n      case 'array,datum,array,object,number':\n        return this.formatArrayOfDatumOfArrayOfObject(\n          data as Array<{\n            input: Array<Record<string, number>>;\n            output: Array<Record<string, number>>;\n          }>\n        );\n      default:\n        throw new Error('unknown data shape or configuration');\n    }\n  }\n\n  test(data: FormattableData[]): ITestResults {\n    // for classification problems\n    const misclasses = [];\n    // run each pattern through the trained network and collect\n    // error and misclassification statistics\n    let errorSum = 0;\n    const formattedData = this.formatData(data);\n    for (let i = 0; i < formattedData.length; i++) {\n      const input = formattedData[i];\n      const output = this.run(input.splice(0, input.length - 1));\n      const target = input[input.length - 1];\n      let errors = 0;\n      let errorCount = 0;\n      for (let j = 0; j < output.length; j++) {\n        errorCount++;\n        const error = target[j] - output[j];\n        // mse\n        errors += error * error;\n      }\n      errorSum += errors / errorCount;\n      const errorsAbs = Math.abs(errors);\n      if (errorsAbs > this.trainOpts.errorThresh) {\n        const misclass = (data as number[][][])[i];\n        misclasses.push({\n          value: misclass,\n          actual: output,\n        });\n      }\n    }\n    return {\n      error: errorSum / formattedData.length,\n      misclasses,\n      total: formattedData.length,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  addFormat(value: FormattableData): void {\n    const dataShape = lookup.dataShape(value).join(',');\n    switch (dataShape) {\n      case 'array,array,number':\n      case 'datum,array,array,number':\n      case 'array,number':\n      case 'datum,array,number':\n        return;\n      case 'datum,object,number': {\n        this.inputLookup = lookup.addKeys(\n          (value as ITrainingDatum).input as INumberHash,\n          this.inputLookup ?? {}\n        );\n        if (this.inputLookup) {\n          this.inputLookupLength = Object.keys(this.inputLookup).length;\n        }\n        this.outputLookup = lookup.addKeys(\n          (value as ITrainingDatum).output as INumberHash,\n          this.outputLookup ?? {}\n        );\n        if (this.outputLookup) {\n          this.outputLookupLength = Object.keys(this.outputLookup).length;\n        }\n        break;\n      }\n      case 'object,number': {\n        this.inputLookup = this.outputLookup = lookup.addKeys(\n          value as INumberHash,\n          this.inputLookup ?? {}\n        );\n        if (this.inputLookup) {\n          this.inputLookupLength = this.outputLookupLength = Object.keys(\n            this.inputLookup\n          ).length;\n        }\n        break;\n      }\n      case 'array,object,number': {\n        const typedValue = value as INumberHash[];\n        for (let i = 0; i < typedValue.length; i++) {\n          this.inputLookup = this.outputLookup = lookup.addKeys(\n            typedValue[i],\n            this.inputLookup ?? {}\n          );\n          if (this.inputLookup) {\n            this.inputLookupLength = this.outputLookupLength = Object.keys(\n              this.inputLookup\n            ).length;\n          }\n        }\n        break;\n      }\n      case 'datum,array,object,number': {\n        const typedValue = value as ITrainingDatum;\n        const typedInput = typedValue.input as INumberHash[];\n        for (let i = 0; i < typedInput.length; i++) {\n          this.inputLookup = lookup.addKeys(\n            typedInput[i],\n            this.inputLookup ?? {}\n          );\n          if (this.inputLookup) {\n            this.inputLookupLength = Object.keys(this.inputLookup).length;\n          }\n        }\n        const typedOutput = typedValue.output as INumberHash[];\n        for (let i = 0; i < typedOutput.length; i++) {\n          this.outputLookup = lookup.addKeys(\n            typedOutput[i],\n            this.outputLookup ?? {}\n          );\n          if (this.outputLookup) {\n            this.outputLookupLength = Object.keys(this.outputLookup).length;\n          }\n        }\n        break;\n      }\n\n      default:\n        throw new Error('unknown data shape or configuration');\n    }\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  toJSON(): IRNNTimeStepJSON {\n    if (!this.model) {\n      this.initialize();\n    }\n    const { model } = this;\n    const options = { ...this.options, ...rnnDefaults };\n\n    return {\n      type: this.constructor.name,\n      options,\n      hiddenLayers: model.hiddenLayers.map((hiddenLayer) => {\n        const layers: { [index: string]: IMatrixJSON } = {};\n        for (const p in hiddenLayer) {\n          if (!hiddenLayer.hasOwnProperty(p)) continue;\n          layers[p] = hiddenLayer[p].toJSON();\n        }\n        return layers;\n      }),\n      outputConnector: model.outputConnector.toJSON(),\n      output: model.output.toJSON(),\n      inputLookup: this.inputLookup,\n      inputLookupLength: this.inputLookupLength,\n      outputLookup: this.outputLookup,\n      outputLookupLength: this.outputLookupLength,\n    };\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  fromJSON(json: IRNNTimeStepJSON): this {\n    const { options } = json;\n    const allMatrices = [];\n    const hiddenLayers: IRNNHiddenLayerModel[] = [];\n\n    // backward compatibility for hiddenSizes\n    json.hiddenLayers.forEach((hiddenLayer) => {\n      const layers: { [index: string]: Matrix } = {};\n      for (const p in hiddenLayer) {\n        layers[p] = Matrix.fromJSON(hiddenLayer[p]);\n        allMatrices.push(layers[p]);\n      }\n      hiddenLayers.push(layers as IRNNHiddenLayerModel);\n    });\n\n    const outputConnector = Matrix.fromJSON(json.outputConnector);\n    allMatrices.push(outputConnector);\n    const output = Matrix.fromJSON(json.output);\n    allMatrices.push(output);\n\n    // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n    // @ts-expect-error\n    this.options = { ...defaults(), ...options };\n    this.inputLookup = json.inputLookup;\n    this.inputLookupLength = json.inputLookupLength;\n    this.outputLookup = json.outputLookup;\n    this.outputLookupLength = json.outputLookupLength;\n\n    this.model = Object.seal({\n      isInitialized: true,\n      hiddenLayers,\n      output,\n      allMatrices,\n      outputConnector,\n      equations: [],\n      equationConnections: [],\n    });\n    this.initialLayerInputs = options.hiddenLayers.map(\n      (size) => new Matrix(size, 1)\n    );\n    this.bindEquation();\n    return this;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/ban-ts-comment\n  // @ts-expect-error\n  toFunction(cb?: (src: string) => string): RNNTimeStepFunction {\n    const {\n      model,\n      inputLookup,\n      inputLookupLength,\n      outputLookup,\n      outputLookupLength,\n    } = this;\n    const { inputSize } = this.options;\n    const { equations } = model;\n    const equation = equations[1];\n    const { states } = equation;\n    const jsonString = JSON.stringify(this.toJSON());\n\n    function previousConnectionIndex(m: Matrix) {\n      const connection = model.equationConnections[0];\n      const { states } = equations[0];\n      for (let i = 0, max = states.length; i < max; i++) {\n        if (states[i].product === m) {\n          return i;\n        }\n      }\n      return connection.indexOf(m);\n    }\n\n    function matrixOrigin(m: Matrix, stateIndex: number): string {\n      for (let i = 0, max = states.length; i < max; i++) {\n        const state = states[i];\n\n        if (i === stateIndex) {\n          const j = previousConnectionIndex(m);\n          switch (m) {\n            case state.left:\n              if (j > -1) {\n                return `typeof prevStates[${j}] === 'object' ? prevStates[${j}].product : new Matrix(${m.rows}, ${m.columns})`;\n              }\n            // eslint-disable-next-line no-fallthrough\n            case state.right:\n              if (j > -1) {\n                return `typeof prevStates[${j}] === 'object' ? prevStates[${j}].product : new Matrix(${m.rows}, ${m.columns})`;\n              }\n            // eslint-disable-next-line no-fallthrough\n            case state.product:\n              return `new Matrix(${m.rows}, ${m.columns})`;\n            default:\n              throw Error('unknown state');\n          }\n        }\n\n        if (m === state.product) return `states[${i}].product`;\n        if (m === state.right) return `states[${i}].right`;\n        if (m === state.left) return `states[${i}].left`;\n      }\n      return '';\n    }\n\n    function matrixToString(m: Matrix, stateIndex: number): string {\n      if (!m || !m.rows || !m.columns) return 'null';\n      if (m === model.outputConnector) return `json.outputConnector`;\n      if (m === model.output) return `json.output`;\n\n      for (let i = 0, max = model.hiddenLayers.length; i < max; i++) {\n        const hiddenLayer = model.hiddenLayers[i];\n        for (const p in hiddenLayer) {\n          if (!hiddenLayer.hasOwnProperty(p)) continue;\n          if (hiddenLayer[p] !== m) continue;\n          return `json.hiddenLayers[${i}].${p}`;\n        }\n      }\n\n      return matrixOrigin(m, stateIndex);\n    }\n\n    function formatInputData() {\n      if (!inputLookup) return '';\n      if (inputSize === 1) {\n        if (inputLookup === outputLookup) {\n          return `function lookupInput(input) {\n            var table = ${JSON.stringify(inputLookup)};\n            var result = [];\n            for (var p in table) {\n              if (!input.hasOwnProperty(p)) break;\n              result.push(Float32Array.from([input[p]]));\n            }\n            return result;\n          }`;\n        }\n        return `function lookupInput(input) {\n          var table = ${JSON.stringify(inputLookup)};\n          var result = [];\n          for (var p in table) {\n            result.push(Float32Array.from([input[p]]));\n          }\n          return result;\n        }`;\n      }\n      return `function lookupInput(rawInputs) {\n        var table = ${JSON.stringify(inputLookup)};\n        var result = [];\n        for (var i = 0; i < rawInputs.length; i++) {\n          var rawInput = rawInputs[i];\n          var input = new Float32Array(${inputLookupLength});\n          for (var p in table) {\n            input[table[p]] = rawInput.hasOwnProperty(p) ? rawInput[p] : 0;\n          }\n          result.push(input);\n        }\n        return result;\n      }`;\n    }\n\n    function formatOutputData() {\n      if (!outputLookup) return '';\n      if (inputSize === 1) {\n        if (inputLookup === outputLookup) {\n          return `function lookupOutputPartial(output, input) {\n            var table = ${JSON.stringify(outputLookup)};\n            var offset = input.length;\n            var result = {};\n            var i = 0;\n            for (var p in table) {\n              if (i++ < offset) continue;\n              result[p] = output[table[p] - offset][0];\n            }\n            return result;\n          }`;\n        }\n        return `function lookupOutput(output) {\n          var table = ${JSON.stringify(outputLookup)};\n          var result = {};\n          for (var p in table) {\n            result[p] = output[table[p]][0];\n          }\n          return result;\n        }`;\n      }\n      return `function lookupOutput(output) {\n        var table = ${JSON.stringify(outputLookup)};\n        var result = {};\n        for (var p in table) {\n          result[p] = output[table[p]];\n        }\n        return result;\n      }`;\n    }\n\n    function toInner(fnString: string) {\n      // crude, but should be sufficient for now\n      // function() { body }\n      // crude, but should be sufficient for now\n      // function() { body }\n      const fnParts = fnString.toString().split('{');\n      fnParts.shift();\n      // body }\n      const fnBodyString = fnParts.join('{');\n      const fnBodyParts = fnBodyString.split('}');\n      fnBodyParts.pop();\n      // body\n      return fnBodyParts\n        .join('}')\n        .split('\\n')\n        .join('\\n        ')\n        .replace('product.deltas[i] = 0;', '')\n        .replace('product.deltas[column] = 0;', '')\n        .replace('left.deltas[leftIndex] = 0;', '')\n        .replace('right.deltas[rightIndex] = 0;', '')\n        .replace('product.deltas = left.deltas.slice(0);', '');\n    }\n\n    function fileName(fnName: string) {\n      return `src/recurrent/matrix/${fnName.replace(/[A-Z]/g, function (value) {\n        return `-${value.toLowerCase()}`;\n      })}.js`;\n    }\n\n    const statesRaw = [];\n    const usedFunctionNames: { [methodName: string]: boolean } = {};\n    const innerFunctionsSwitch = [];\n    for (let i = 0, max = states.length; i < max; i++) {\n      const state = states[i];\n      statesRaw.push(`states[${i}] = {\n      name: '${state.forwardFn.name}',\n      left: ${state.left ? matrixToString(state.left, i) : 'undefined'},\n      right: ${state.right ? matrixToString(state.right, i) : 'undefined'},\n      product: ${matrixToString(state.product, i)}\n    }`);\n\n      const fnName = state.forwardFn.name;\n      if (!usedFunctionNames[fnName]) {\n        usedFunctionNames[fnName] = true;\n        if (state.name === 'input') {\n          innerFunctionsSwitch.push(`case '${fnName}':`);\n          innerFunctionsSwitch.push(\n            inputLookup && inputSize === 1\n              ? 'product.weights = _i < input.length ? input[_i]: prevStates[prevStates.length - 1].product.weights;'\n              : inputSize === 1\n              ? 'product.weights = [input[_i]];'\n              : 'product.weights = input[_i];'\n          );\n          innerFunctionsSwitch.push('break;');\n        } else {\n          innerFunctionsSwitch.push(\n            `        case '${fnName}':${\n              fnName !== 'forwardFn'\n                ? ` //compiled from ${fileName(fnName)}`\n                : ''\n            }\n          ${toInner(state.forwardFn.toString())}\n          break;`\n          );\n        }\n      }\n    }\n\n    const forceForecast = inputSize === 1 && this.outputLookup;\n    const src = `\n  var input = ${this.inputLookup ? 'lookupInput(rawInput)' : 'rawInput'};\n  var json = ${jsonString};\n  var output = [];\n  var states = [];\n  var prevStates;\n  var state;\n  var max = ${\n    forceForecast\n      ? inputLookup === outputLookup\n        ? inputLookupLength\n        : `input.length + ${outputLookupLength - 1}`\n      : 'input.length'\n  };\n  for (var _i = 0; _i < max; _i++) {\n    prevStates = states;\n    states = [];\n    ${statesRaw.join(';\\n    ')};\n    for (var stateIndex = 0, stateMax = ${\n      statesRaw.length\n    }; stateIndex < stateMax; stateIndex++) {\n      state = states[stateIndex];\n      var product = state.product;\n      var left = state.left;\n      var right = state.right;\n\n      switch (state.name) {\n${innerFunctionsSwitch.join('\\n')}\n      }\n    }\n    ${\n      inputSize === 1 && inputLookup\n        ? 'if (_i >= input.length - 1) { output.push(state.product.weights); }'\n        : 'output = state.product.weights;'\n    }\n  }\n  ${\n    outputLookup\n      ? outputLookup === inputLookup\n        ? 'return lookupOutputPartial(output, input)'\n        : 'return lookupOutput(output)'\n      : inputSize === 1\n      ? 'return output[0]'\n      : 'return output'\n  };\n  ${formatInputData()}\n  ${formatOutputData()}\n\n  function Matrix(rows, columns) {\n    this.rows = rows;\n    this.columns = columns;\n    this.weights = zeros(rows * columns);\n  }\n  ${zeros.toString()}\n  ${softmax.toString().replace('_2.default', 'Matrix')}\n  ${randomFloat.toString()}\n  ${sampleI.toString()}\n  ${maxI.toString()}`;\n    // eslint-disable-next-line\n    return new Function('rawInput', cb ? cb(src) : src) as RNNTimeStepFunction;\n  }\n}\n\nexport type RNNTimeStepFunction = <\n  InputType extends InputOutputValue | InputOutputValue[]\n>(\n  rawInput?: InputType,\n  isSampleI?: boolean,\n  temperature?: number\n) => ValuesOf<InputType>;\n\nexport const trainDefaults = { ...rnnTrainDefaults };\n","import { getGRUHiddenLayer, getGRUEquation, IGRUHiddenLayer } from './gru';\nimport { Matrix } from './matrix';\nimport { Equation } from './matrix/equation';\nimport { RNNTimeStep } from './rnn-time-step';\nimport { IRNNHiddenLayer } from './rnn';\n\nexport class GRUTimeStep extends RNNTimeStep {\n  getHiddenLayer(hiddenSize: number, prevSize: number): IRNNHiddenLayer {\n    return getGRUHiddenLayer(hiddenSize, prevSize);\n  }\n\n  getEquation(\n    equation: Equation,\n    inputMatrix: Matrix,\n    previousResult: Matrix,\n    hiddenLayer: IRNNHiddenLayer\n  ): Matrix {\n    return getGRUEquation(\n      equation,\n      inputMatrix,\n      previousResult,\n      hiddenLayer as IGRUHiddenLayer\n    );\n  }\n}\n","import { Matrix } from './matrix';\nimport { Equation } from './matrix/equation';\nimport { RandomMatrix } from './matrix/random-matrix';\nimport { IRNNHiddenLayer, RNN } from './rnn';\n\nexport interface ILSTMHiddenLayer extends IRNNHiddenLayer {\n  inputMatrix: Matrix;\n  inputHidden: Matrix;\n  inputBias: Matrix;\n  forgetMatrix: Matrix;\n  forgetHidden: Matrix;\n  forgetBias: Matrix;\n  outputMatrix: Matrix;\n  outputHidden: Matrix;\n  outputBias: Matrix;\n  cellActivationMatrix: Matrix;\n  cellActivationHidden: Matrix;\n  cellActivationBias: Matrix;\n}\n\nexport class LSTM extends RNN {\n  getHiddenLayer(hiddenSize: number, prevSize: number): IRNNHiddenLayer {\n    return getHiddenLSTMLayer(hiddenSize, prevSize);\n  }\n\n  getEquation(\n    equation: Equation,\n    inputMatrix: Matrix,\n    previousResult: Matrix,\n    hiddenLayer: IRNNHiddenLayer\n  ): Matrix {\n    return getLSTMEquation(\n      equation,\n      inputMatrix,\n      previousResult,\n      hiddenLayer as ILSTMHiddenLayer\n    );\n  }\n}\n\nexport function getHiddenLSTMLayer(\n  hiddenSize: number,\n  prevSize: number\n): ILSTMHiddenLayer {\n  return {\n    // gates parameters\n    // wix\n    inputMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wih\n    inputHidden: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bi\n    inputBias: new Matrix(hiddenSize, 1),\n    // wfx\n    forgetMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wfh\n    forgetHidden: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bf\n    forgetBias: new Matrix(hiddenSize, 1),\n    // wox\n    outputMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // woh\n    outputHidden: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bo\n    outputBias: new Matrix(hiddenSize, 1),\n    // cell write params\n    // wcx\n    cellActivationMatrix: new RandomMatrix(hiddenSize, prevSize, 0.08), // wch\n    cellActivationHidden: new RandomMatrix(hiddenSize, hiddenSize, 0.08), // bc\n    cellActivationBias: new Matrix(hiddenSize, 1),\n  };\n}\n\nexport function getLSTMEquation(\n  equation: Equation,\n  inputMatrix: Matrix,\n  previousResult: Matrix,\n  hiddenLayer: ILSTMHiddenLayer\n): Matrix {\n  if (\n    !hiddenLayer.inputMatrix ||\n    !hiddenLayer.inputHidden ||\n    !hiddenLayer.inputBias ||\n    !hiddenLayer.forgetMatrix ||\n    !hiddenLayer.forgetHidden ||\n    !hiddenLayer.forgetBias ||\n    !hiddenLayer.outputMatrix ||\n    !hiddenLayer.outputHidden ||\n    !hiddenLayer.outputBias ||\n    !hiddenLayer.cellActivationMatrix ||\n    !hiddenLayer.cellActivationHidden ||\n    !hiddenLayer.cellActivationBias\n  ) {\n    throw new Error('hiddenLayer does not have expected properties');\n  }\n\n  const sigmoid = equation.sigmoid.bind(equation);\n  const add = equation.add.bind(equation);\n  const multiply = equation.multiply.bind(equation);\n  const multiplyElement = equation.multiplyElement.bind(equation);\n  const tanh = equation.tanh.bind(equation);\n\n  const inputGate = sigmoid(\n    add(\n      add(\n        multiply(hiddenLayer.inputMatrix, inputMatrix),\n        multiply(hiddenLayer.inputHidden, previousResult)\n      ),\n      hiddenLayer.inputBias\n    )\n  );\n\n  const forgetGate = sigmoid(\n    add(\n      add(\n        multiply(hiddenLayer.forgetMatrix, inputMatrix),\n        multiply(hiddenLayer.forgetHidden, previousResult)\n      ),\n      hiddenLayer.forgetBias\n    )\n  );\n\n  // output gate\n  const outputGate = sigmoid(\n    add(\n      add(\n        multiply(hiddenLayer.outputMatrix, inputMatrix),\n        multiply(hiddenLayer.outputHidden, previousResult)\n      ),\n      hiddenLayer.outputBias\n    )\n  );\n\n  // write operation on cells\n  const cellWrite = tanh(\n    add(\n      add(\n        multiply(hiddenLayer.cellActivationMatrix, inputMatrix),\n        multiply(hiddenLayer.cellActivationHidden, previousResult)\n      ),\n      hiddenLayer.cellActivationBias\n    )\n  );\n\n  // compute new cell activation\n  const retainCell = multiplyElement(forgetGate, previousResult); // what do we keep from cell\n  const writeCell = multiplyElement(inputGate, cellWrite); // what do we write to cell\n  const cell = add(retainCell, writeCell); // new cell contents\n\n  // compute hidden state as gated, saturated cell activations\n  return multiplyElement(outputGate, tanh(cell));\n}\n","import { getHiddenLSTMLayer, getLSTMEquation, ILSTMHiddenLayer } from './lstm';\nimport { Matrix } from './matrix';\nimport { Equation } from './matrix/equation';\nimport { RNNTimeStep } from './rnn-time-step';\nimport { IRNNHiddenLayer } from './rnn';\n\nexport class LSTMTimeStep extends RNNTimeStep {\n  getHiddenLayer(hiddenSize: number, prevSize: number): IRNNHiddenLayer {\n    return getHiddenLSTMLayer(hiddenSize, prevSize);\n  }\n\n  getEquation(\n    equation: Equation,\n    inputMatrix: Matrix,\n    previousResult: Matrix,\n    hiddenLayer: IRNNHiddenLayer\n  ): Matrix {\n    return getLSTMEquation(\n      equation,\n      inputMatrix,\n      previousResult,\n      hiddenLayer as ILSTMHiddenLayer\n    );\n  }\n}\n","import { FeedForward, IFeedForwardJSON } from '../feed-forward';\nimport { recurrentZeros } from '../layer/recurrent-zeros';\nimport { Recurrent } from '../recurrent';\nimport { IRNNJSON, RNN } from '../recurrent/rnn';\nimport { INeuralNetworkJSON, NeuralNetwork } from '../neural-network';\nimport { GRU } from '../recurrent/gru';\nimport { LSTM } from '../recurrent/lstm';\nimport { NeuralNetworkGPU } from '../neural-network-gpu';\nimport { IRNNTimeStepJSON, RNNTimeStep } from '../recurrent/rnn-time-step';\nimport { LSTMTimeStep } from '../recurrent/lstm-time-step';\nimport { GRUTimeStep } from '../recurrent/gru-time-step';\nimport { ILayer } from '../layer';\n\ninterface LineDrawInfo {\n  className: string;\n  color: string;\n  width: number;\n}\n\ninterface NodeDrawInfo {\n  className: string;\n  color: string;\n}\n\ninterface BaseDrawArgs {\n  pixelX: number;\n  pixelY: number;\n  radius: number;\n  row: number;\n  column: number;\n}\n\ninterface InputDrawArgs extends BaseDrawArgs {\n  line: LineDrawInfo;\n  inputs: NodeDrawInfo & { labels?: string[] | null };\n  fontSize: string;\n  fontClassName: string;\n}\n\nexport function drawInput({\n  pixelX,\n  pixelY,\n  radius,\n  inputs,\n  row,\n  line,\n  fontSize,\n  fontClassName,\n}: InputDrawArgs): string {\n  let svg = `<rect\n              x=\"${pixelX / 2 - radius}\"\n              y=\"${pixelY / 2 + row * pixelY - radius}\"\n              width=\"${2 * radius}\"\n              height=\"${2 * radius}\"\n              stroke=\"black\"\n              stroke-width=\"1\"\n              fill=\"${inputs.color}\"\n              class=\"${inputs.className}\" />\n            <line\n              x1=\"${pixelX / 4}\"\n              y1=\"${pixelY / 2 + row * pixelY}\"\n              x2=\"${pixelX / 2 - radius}\"\n              y2=\"${pixelY / 2 + row * pixelY}\"\n              style=\"stroke:${line.color};stroke-width:${line.width}\"\n              class=\"${line.className}\" />`;\n  if (inputs.labels) {\n    svg += `<text\n              x=\"${pixelX / 8}\"\n              y=\"${pixelY / 2 + row * pixelY - 5}\"\n              fill=\"black\"\n              font-size=\"${fontSize}\"\n              class=\"${fontClassName}\">${inputs.labels[row]}</text>`;\n  }\n  return svg;\n}\n\nexport interface NeuronDrawArgs extends BaseDrawArgs {\n  column: number;\n  hidden: NodeDrawInfo;\n}\n\nexport function drawNeuron({\n  pixelX,\n  pixelY,\n  row,\n  column,\n  radius,\n  hidden,\n}: NeuronDrawArgs): string {\n  return `<circle\n            cx=\"${pixelX / 2 + column * pixelX}\"\n            cy=\"${pixelY / 2 + row * pixelY}\"\n            r=\"${radius}\"\n            stroke=\"black\"\n            stroke-width=\"1\"\n            fill=\"${hidden.color}\"\n            class=\"${hidden.className}\" />`;\n}\n\nexport interface OutputDrawArgs extends BaseDrawArgs {\n  column: number;\n  line: LineDrawInfo;\n  outputs: NodeDrawInfo;\n}\n\nexport function drawOutput({\n  pixelX,\n  pixelY,\n  row,\n  column,\n  line,\n  outputs,\n  radius,\n}: OutputDrawArgs): string {\n  return `<circle\n            cx=\"${pixelX / 2 + column * pixelX}\"\n            cy=\"${pixelY / 2 + row * pixelY}\"\n            r=\"${radius}\"\n            stroke=\"black\"\n            stroke-width=\"1\"\n            fill=\"${outputs.color}\"\n            class=\"${outputs.className}\" />\n          <line\n            x1=\"${pixelX / 2 + column * pixelX + radius}\"\n            y1=\"${pixelY / 2 + row * pixelY}\"\n            x2=\"${pixelX / 2 + column * pixelX + pixelX / 4}\"\n            y2=\"${pixelY / 2 + row * pixelY}\"\n            style=\"stroke:${line.color};stroke-width:${line.width}\"\n            class=\"${line.className}\" />`;\n}\n\nexport interface BackwardConnectionsDrawArgs extends BaseDrawArgs {\n  column: number;\n  lineY: number;\n  previousConnectionIndex: number;\n  line: LineDrawInfo;\n}\n\nexport function drawBackwardConnections({\n  pixelX,\n  pixelY,\n  row,\n  column,\n  radius,\n  lineY,\n  line,\n  previousConnectionIndex,\n}: BackwardConnectionsDrawArgs): string {\n  return `<line\n            x1=\"${pixelX / 2 + (column - 1) * pixelX + radius}\"\n            y1=\"${lineY / 2 + previousConnectionIndex * lineY}\"\n            x2=\"${pixelX / 2 + column * pixelX - radius}\"\n            y2=\"${pixelY / 2 + row * pixelY}\"\n            style=\"stroke:${line.color};stroke-width:${line.width}\"\n            class=\"${line.className}\" />`;\n}\n\nexport interface NeuralNetworkDrawOptions {\n  sizes: number[];\n  height: number;\n  width: number;\n  radius: number;\n  line: LineDrawInfo;\n  inputs: NodeDrawInfo & { labels?: string[] | null };\n  hidden: NodeDrawInfo;\n  outputs: NodeDrawInfo;\n  fontSize: string;\n  fontClassName: string;\n}\n\nexport function neuralNetworkToInnerSVG(\n  options: NeuralNetworkDrawOptions\n): string {\n  const { sizes, height, width } = options;\n  let svg = '';\n  const pixelX = width / sizes.length;\n  for (let column = 0; column < sizes.length; column++) {\n    const size = sizes[column];\n    const pixelY = height / size;\n    for (let row = 0; row < size; row++) {\n      if (column === 0) {\n        svg += drawInput({ pixelX, pixelY, row, column, ...options });\n      } else {\n        if (column === sizes.length - 1) {\n          svg += drawOutput({ pixelX, pixelY, row, column, ...options });\n        } else {\n          svg += drawNeuron({ pixelX, pixelY, row, column, ...options });\n        }\n        const previousSize = sizes[column - 1];\n        const lineY = height / previousSize;\n        for (\n          let previousConnectionIndex = 0;\n          previousConnectionIndex < previousSize;\n          previousConnectionIndex++\n        ) {\n          svg += drawBackwardConnections({\n            pixelX,\n            pixelY,\n            row,\n            column,\n            lineY,\n            previousConnectionIndex,\n            ...options,\n          });\n        }\n      }\n    }\n  }\n  return svg;\n}\n\nexport interface RecurrentConnectionsDrawArgs extends BaseDrawArgs {\n  column: number;\n  recurrentLine: LineDrawInfo;\n}\n\nexport function drawRecurrentConnections({\n  pixelX,\n  pixelY,\n  row,\n  column,\n  radius,\n  recurrentLine,\n}: RecurrentConnectionsDrawArgs): string {\n  const moveX = pixelX / 2 + column * pixelX + radius + 1;\n  const moveY = pixelY / 2 + row * pixelY;\n  const x = moveX - radius * 2 - 2;\n  const y = moveY;\n  const x1 = x + 100;\n  const y1 = y + 50;\n  const x2 = moveX - 100;\n  const y2 = moveY + 50;\n  return `<path\n              d=\"M ${moveX} ${moveY} C ${x1} ${y1}, ${x2} ${y2}, ${x} ${y}\"\n              stroke=\"${recurrentLine.color}\"\n              stroke-width=\"${recurrentLine.width}\"\n              fill=\"transparent\"\n              stroke-linecap=\"round\"\n              marker-end=\"url(#arrow)\"\n              class=\"${recurrentLine.className}\" />`;\n}\n\nexport interface RecurrentNeuralNetworkDrawOptions\n  extends NeuralNetworkDrawOptions {\n  recurrentLine: LineDrawInfo;\n}\n\nexport function rnnToInnerSVG(\n  options: RecurrentNeuralNetworkDrawOptions\n): string {\n  const { width, height, recurrentLine, sizes, radius } = options;\n  const pixelX = width / sizes.length;\n  let svg = `<defs>\n              <marker id=\"arrow\" markerWidth=\"10\" markerHeight=\"10\" refX=\"8\" refY=\"3\" orient=\"auto\" markerUnits=\"strokeWidth\">\n                <path d=\"M0,0 L0,6 L9,3 z\" fill=\"${recurrentLine.color}\" />\n              </marker>\n            </defs>`;\n  svg += neuralNetworkToInnerSVG(options);\n  for (let column = 1; column < sizes.length; column++) {\n    const size = sizes[column];\n    const pixelY = height / size;\n    for (let row = 0; row < size; row++) {\n      svg += drawRecurrentConnections({\n        pixelX,\n        pixelY,\n        row,\n        column,\n        radius,\n        recurrentLine,\n      });\n    }\n  }\n  return svg;\n}\n\nexport function getFeedForwardLayers(network: FeedForward): ISimpleNet {\n  const { options } = network;\n  if (!options) {\n    throw new Error('options not defined');\n  }\n  if (!options.inputLayer) {\n    throw new Error('options.inputLater not defined');\n  }\n  if (!options.hiddenLayers) {\n    throw new Error('options.hiddenLayers not defined');\n  }\n  if (options.hiddenLayers.length < 1) {\n    throw new Error('options.hiddenLayers is empty');\n  }\n  if (!options.outputLayer) {\n    throw new Error('options.outputLayer not defined');\n  }\n  const inputLayer = options.inputLayer();\n  const hiddenLayers = [];\n  hiddenLayers.push(options.hiddenLayers[0](inputLayer, 0));\n  for (let i = 1; i < options.hiddenLayers.length; i++) {\n    hiddenLayers.push(options.hiddenLayers[i](hiddenLayers[i - 1], i));\n  }\n  const outputLayer = options.outputLayer(\n    hiddenLayers[hiddenLayers.length - 1],\n    hiddenLayers.length\n  );\n  return {\n    inputSize: inputLayer.height,\n    hiddenLayers: hiddenLayers.map((hiddenLayer: ILayer) => hiddenLayer.height),\n    outputSize: outputLayer.height,\n  };\n}\n\nexport function getRecurrentLayers(network: Recurrent): ISimpleNet {\n  const hiddenLayers: ILayer[] = [];\n  const { options } = network;\n  if (!options.inputLayer) {\n    throw new Error('inputLayer not defined');\n  }\n  if (!options.outputLayer) {\n    throw new Error('outputLayer not defined');\n  }\n  const inputLayer = options.inputLayer();\n  hiddenLayers.push(options.hiddenLayers[0](inputLayer, recurrentZeros(), 0));\n  for (let i = 1; i < options.hiddenLayers.length; i++) {\n    hiddenLayers.push(\n      options.hiddenLayers[i](hiddenLayers[i - 1], recurrentZeros(), i)\n    );\n  }\n  const outputLayer = options.outputLayer(\n    hiddenLayers[hiddenLayers.length - 1],\n    -1\n  );\n  return {\n    inputSize: inputLayer.height,\n    hiddenLayers: hiddenLayers.map((hiddenLayer: ILayer) => hiddenLayer.height),\n    outputSize: outputLayer.height,\n  };\n}\n\nexport function wrapOuterSVG(\n  svgBody: string,\n  width: number,\n  height: number\n): string {\n  // language=html\n  return `<svg\n            xmlns=\"http://www.w3.org/2000/svg\"\n            xmlns:xlink=\"http://www.w3.org/1999/xlink\"\n            version=\"1.1\"\n            width=\"${width}\"\n            height=\"${height}\">${svgBody}</svg>`;\n}\n\nexport function getNeuralNetworkJSONSizes(json: INeuralNetworkJSON): number[] {\n  return json.sizes;\n}\n\nexport function getNeuralNetworkSizes<InputType, OutputType>(\n  net:\n    | NeuralNetwork<InputType, OutputType>\n    | NeuralNetworkGPU<InputType, OutputType>\n): number[] {\n  const { options, sizes } = net;\n  const { inputSize, outputSize, hiddenLayers } = options;\n  if (!sizes) {\n    if (typeof inputSize === 'number' && inputSize < 1) {\n      throw new Error('inputSize not set');\n    }\n    if (typeof outputSize === 'number' && outputSize < 1) {\n      throw new Error('outputSize not set');\n    }\n    if (hiddenLayers?.some((v) => v < 1)) {\n      throw new Error('hiddenLayers not set');\n    }\n  }\n  return typeof inputSize === 'number' &&\n    Array.isArray(hiddenLayers) &&\n    typeof outputSize === 'number'\n    ? [inputSize].concat(hiddenLayers).concat([outputSize])\n    : sizes;\n}\n\nexport function getRNNSizes(\n  net: RNN | LSTM | GRU | RNNTimeStep | LSTMTimeStep | GRUTimeStep | IRNNJSON\n): number[] {\n  const { options } = net;\n  const { inputSize, outputSize, hiddenLayers } = options;\n  return [inputSize].concat(hiddenLayers).concat([outputSize]);\n}\n\nexport function defaultOptions(): RecurrentNeuralNetworkDrawOptions {\n  return {\n    line: {\n      width: 0.5,\n      color: 'black',\n      className: 'connection',\n    },\n    recurrentLine: {\n      width: 1,\n      color: 'red',\n      className: 'recurrence',\n    },\n    inputs: {\n      color: 'rgba(0, 128, 0, 0.5)',\n      labels: null,\n      className: 'input',\n    },\n    outputs: {\n      color: 'rgba(100, 149, 237, 0.5)',\n      className: 'output',\n    },\n    hidden: {\n      color: 'rgba(255, 127, 80, 0.5)',\n      className: 'hidden-neuron',\n    },\n    fontSize: '14px',\n    fontClassName: 'label',\n    radius: 8,\n    width: 400,\n    height: 250,\n    sizes: [],\n  };\n}\n\nexport interface ISimpleNet {\n  inputSize: number;\n  hiddenLayers: number[];\n  outputSize: number;\n}\nexport interface ISizes {\n  sizes: number[];\n}\n\nexport function toSVG<\n  T extends\n    | ISimpleNet\n    | ISizes\n    | Recurrent\n    | FeedForward\n    | IFeedForwardJSON\n    | RNNTimeStep\n    | IRNNTimeStepJSON\n    | LSTMTimeStep\n    | GRUTimeStep\n    | RNN\n    | IRNNJSON\n    | GRU\n    | LSTM\n    | NeuralNetwork<InputType, OutputType>\n    | INeuralNetworkJSON\n    | NeuralNetworkGPU<InputType, OutputType>,\n  InputType,\n  OutputType\n>(\n  net: T,\n  options?:\n    | Partial<RecurrentNeuralNetworkDrawOptions>\n    | Partial<NeuralNetworkDrawOptions>\n): string {\n  const mergedOptions = { ...defaultOptions(), ...options };\n  const { width, height, inputs } = mergedOptions;\n\n  // Get network size array for NeuralNetwork or NeuralNetworkGPU\n  let sizes: number[] = [];\n  if (net instanceof NeuralNetwork || net instanceof NeuralNetworkGPU) {\n    sizes = getNeuralNetworkSizes(net);\n  }\n  // get network size for Recurrent\n  else if (net instanceof Recurrent) {\n    const { inputSize, hiddenLayers, outputSize } = getRecurrentLayers(net);\n    sizes = [inputSize].concat(hiddenLayers).concat([outputSize]);\n  }\n  // get network size for FeedForward\n  else if (net instanceof FeedForward) {\n    const { inputSize, hiddenLayers, outputSize } = getFeedForwardLayers(net);\n    sizes = [inputSize].concat(hiddenLayers).concat([outputSize]);\n  }\n  // handle json, recurrent first\n  else if (\n    net instanceof RNN ||\n    net instanceof LSTM ||\n    net instanceof GRU ||\n    net instanceof RNNTimeStep ||\n    net instanceof LSTMTimeStep ||\n    net instanceof GRUTimeStep\n  ) {\n    return wrapOuterSVG(\n      rnnToInnerSVG({\n        ...mergedOptions,\n        sizes: checkSizes(\n          getRNNSizes(\n            (net as unknown) as\n              | RNN\n              | LSTM\n              | GRU\n              | RNNTimeStep\n              | LSTMTimeStep\n              | GRUTimeStep\n          ),\n          inputs.labels\n        ),\n      }),\n      width,\n      height\n    );\n  }\n  // handle json, NeuralNetwork\n  else if (net.hasOwnProperty('type')) {\n    switch ((net as INeuralNetworkJSON).type) {\n      case 'NeuralNetwork':\n      case 'NeuralNetworkGPU':\n        return wrapOuterSVG(\n          neuralNetworkToInnerSVG({\n            ...mergedOptions,\n            sizes: checkSizes(\n              getNeuralNetworkJSONSizes(net as INeuralNetworkJSON),\n              inputs.labels\n            ),\n          }),\n          width,\n          height\n        );\n      case 'RNN':\n      case 'GRU':\n      case 'LSTM':\n      case 'RNNTimeStep':\n      case 'GRUTimeStep':\n      case 'LSTMTimeStep':\n        return wrapOuterSVG(\n          rnnToInnerSVG({\n            ...mergedOptions,\n            sizes: checkSizes(getRNNSizes(net as IRNNJSON), inputs.labels),\n          }),\n          width,\n          height\n        );\n      default:\n        throw new Error('unrecognized network');\n    }\n  } else if (\n    net.hasOwnProperty('inputSize') &&\n    net.hasOwnProperty('hiddenLayers') &&\n    net.hasOwnProperty('outputSize')\n  ) {\n    const { inputSize, hiddenLayers, outputSize } = net as ISimpleNet;\n    sizes = [inputSize, ...hiddenLayers, outputSize];\n  } else if (net.hasOwnProperty('sizes')) {\n    sizes = (net as ISizes).sizes;\n  } else {\n    throw new Error('unrecognized network');\n  }\n  return wrapOuterSVG(\n    neuralNetworkToInnerSVG({\n      ...mergedOptions,\n      sizes: checkSizes(sizes, inputs.labels),\n    }),\n    width,\n    height\n  );\n}\n\nexport function checkSizes(\n  sizes: number[],\n  labels: string[] | null | undefined\n): number[] {\n  if (!sizes) {\n    throw new Error('sizes not set');\n  }\n  if (sizes.some((size: number) => size < 1)) {\n    throw new Error('sizes not set correctly');\n  }\n  if (labels && labels.length !== sizes[0]) {\n    throw new Error('not enough labels for inputs');\n  }\n  return sizes;\n}\n","import * as activation from './activation';\nimport CrossValidate from './cross-validate';\nimport { FeedForward } from './feed-forward';\nimport * as layer from './layer';\nimport { layerTypes } from './layer';\nimport { likely } from './likely';\nimport { lookup } from './lookup';\nimport { NeuralNetwork } from './neural-network';\nimport { NeuralNetworkGPU } from './neural-network-gpu';\nimport * as praxis from './praxis';\nimport { Recurrent } from './recurrent';\nimport { GRU } from './recurrent/gru';\nimport { GRUTimeStep } from './recurrent/gru-time-step';\nimport { LSTM } from './recurrent/lstm';\nimport { LSTMTimeStep } from './recurrent/lstm-time-step';\nimport { RNN } from './recurrent/rnn';\nimport { RNNTimeStep } from './recurrent/rnn-time-step';\nimport { DataFormatter } from './utilities/data-formatter';\nimport { max } from './utilities/max';\nimport { mse } from './utilities/mse';\nimport { ones, ones2D } from './utilities/ones';\nimport * as random from './utilities/random';\nimport { randomWeight } from './utilities/random-weight';\nimport { randos } from './utilities/randos';\nimport { range } from './utilities/range';\nimport { toArray } from './utilities/to-array';\nimport { toSVG } from './utilities/to-svg';\nimport { zeros } from './utilities/zeros';\n\nconst recurrent = {\n  RNNTimeStep,\n  LSTMTimeStep,\n  GRUTimeStep,\n  RNN,\n  LSTM,\n  GRU,\n};\n\nconst utilities = {\n  max,\n  mse,\n  ones,\n  ones2D,\n  random,\n  randomWeight,\n  randos,\n  range,\n  toArray,\n  DataFormatter,\n  zeros,\n  toSVG,\n};\n\nexport {\n  activation,\n  CrossValidate,\n  likely,\n  layer,\n  layerTypes,\n  lookup,\n  praxis,\n  FeedForward,\n  NeuralNetwork,\n  NeuralNetworkGPU,\n  Recurrent,\n  recurrent,\n  utilities,\n};\n","/**\n *\n * @param start\n * @param end\n * @returns {Array}\n */\nexport function range(start: number, end: number): number[] {\n  const result: number[] = [];\n  for (; start < end; start++) {\n    result.push(start);\n  }\n  return result;\n}\n","export function toArray(\n  values: number[] | Float32Array | { [key: string]: number }\n): Float32Array {\n  if (Array.isArray(values)) {\n    return Float32Array.from(values);\n  }\n\n  return Float32Array.from(Object.values(values));\n}\n","export interface ILikelyNet<InputType, OutputType> {\n  run: (input: InputType) => OutputType;\n}\n\nexport function likely<\n  NetworkType extends ILikelyNet<\n    Parameters<NetworkType['run']>[0],\n    ReturnType<NetworkType['run']>\n  >\n>(\n  input: Parameters<NetworkType['run']>[0],\n  net: NetworkType\n): ReturnType<NetworkType['run']> | null {\n  if (!net) {\n    throw new TypeError(\n      `Required parameter 'net' is of type ${typeof net}. Must be of type 'brain.NeuralNetwork'`\n    );\n  }\n\n  const output = net.run(input);\n  let maxProp = null;\n  let maxValue = -1;\n\n  Object.entries(output).forEach(([key, value]) => {\n    if (\n      typeof value !== 'undefined' &&\n      typeof value === 'number' &&\n      value > maxValue\n    ) {\n      maxProp = key;\n      maxValue = value;\n    }\n  });\n\n  return maxProp;\n}\n"],"names":["activate","weight","Math","max","measure","delta","value","exp","error","tanh","CrossValidate","[object Object]","initClassifier","this","avgs","iterations","testTime","trainTime","stats","total","testSize","trainSize","sets","trainOpts","trainSet","testSet","classifier","beginTrain","Date","now","trainingStats","train","beginTest","testStats","test","endTest","network","toJSON","array","i","length","j","floor","random","temp","data","k","Error","shuffleArray","size","binaryStats","truePos","trueNeg","falsePos","falseNeg","precision","recall","accuracy","results","isBinary","dclone","slice","splice","result","testPartition","hasOwnProperty","Object","assign","isBinaryStats","isBinaryPartitionResults","push","json","fromJSON","crossValidateJson","winningJSON","reduce","prev","cur","undefined","gpuInstance","setup","makeKernel","fn","settings","_gpuInstance","GPU","mode","createKernel","setPipeline","makeKernelMap","map","createKernelMap","release","possibleTexture","Texture","delete","clear","Array","isArray","fill","x","y","row","clone","Float32Array","matrix","cube","mse2d","errors","sum","constants","height","width","MeanSquaredError","calculate","output","immutable","addAbsolute","prevError","prevLayerErrors","abs","add","value1","value2","divide","mseSum","baseLayerDefaultSettings","depth","weights","deltas","praxis","praxisOpts","BaseLayer","setupPraxis","id","title","initPraxis","Number","isNaN","constructor","name","isTraining","layer","predictKernel","compareKernel","inputs","targetValues","learningRate","oldWeights","run","toArray","toUntypedArray","type","from","zeros","zeros2D","zeros3D","z","Activation","inputLayer","super","validate","Filter","filterCount","filterWidth","filterHeight","filters","filterDeltas","Internal","Modifier","Operator","inputLayer1","inputLayer2","compare1D","thread","compare2D","Target","target","InternalModel","EntryPoint","Model","lookup","hashes","hash","memo","toHash","objects2D","table","valueIndex","objects","object","p","tableIndex","dataIndex","input","index","keys","arrayLength","offset","limit","shape","lastData","buffer","possibleNumber","parseInt","BasePraxis","layerTemplate","kernel","update","defaultSettings","ArthurDeviationBiases","arthurDeviationBiases","updateChange","changes","incomingWeights","inputDeltas","lastChange","inputDelta","incoming","momentum","weightsLayer","incomingLayer","deltaLayer","ArthurDeviationWeights","kernelMap","arthurDeviationWeights","getMomentum","decay","previousMomentum","clipByValue","min","previousMomenta","clippedDelta","clipValue","decayRate","sqrt","smoothEps","regularizationStrength","defaults","MomentumRootMeanSquaredPropagation","momenta","functions","momentumRootMeanSquaredPropagation","MRmsProp","mRmsProp","traverseLayersFrom","cb","flattenLayers","layers","includes","checkSameSize","layer1","layer2","predict","inputWeights1","inputWeights2","Add","randomWeight","randomFloat","gaussRandom","returnV","vVal","u","v","r","c","log","mu","std","randos","randos2D","randos3D","Random","weights1","weights2","compareFromX","inputWeights","compareFromY","Multiply","compareKernel1","compareKernel2","reuseKernels","inputLayer1Deltas","inputLayer2Deltas","newDeltas1","newDeltas2","multiply","predict2D","predict3D","compare3D","Sigmoid","sigmoid","getStride","stride","strideX","strideY","getPadding","padding","paddingX","paddingY","values","biases","startFilterX","startInputX","endFilterX","inputWidth","startFilterY","startInputY","endFilterY","inputHeight","inputDepth","filterY","inputY","filterX","inputX","compareFilterDeltas","startDeltaX","ceil","endDeltaX","deltaWidth","startDeltaY","endDeltaY","deltaHeight","deltaY","deltaX","deltaZ","compareInputDeltas","compareBiases","biasDeltas","bias","Convolution","compareFilterDeltasKernel","deltasWidth","deltasHeight","deltasDepth","compareInputDeltasKernel","compareBiasesKernel","setDropout","dropout","trainingPredict","probability","compare","dropouts","dropoutDefaults","Dropout","predictKernelMap","compareInputDeltas3D","compareFilterDeltas3D","inputZ","FullyConnected","connectionCount","inputLayerDeltas","Negative","negative","inputLayerWeights1","inputLayerWeights2","MultiplyElement","multiplyElement","ones","ones2D","Ones","Tanh","Zeros","Input","reshapeInput","predict1D","LeakyRelu","setSwitchY","setSwitchX","largestValue","switchY","switchX","outputWidth","outputHeight","deltasY","deltasX","switchXValue","switchYValue","Pool","RecurrentInput","recurrentInput","recurrentInputDeltas","recurrentInputWeights","prototype","call","RecurrentZeros","recurrentZeros","Relu","relu","Regression","getMaxValue2D","maxInput","Infinity","getMaxValue3D","getSum2D","getSum3D","getExponentials","getExponentials3D","exponentials","exponentialsSum","indicator","SoftMax","getExponentialsKernel","getMaxValueKernel","getSumKernel","maxValue","SVM","Transpose","layerTypes","setupKernels","biasesLayer","sigmoidLayer","weightsPraxis","updateGateWeights","updateGatePeepholes","updateGateBias","updateGate","resetGateWeights","resetGatePeepholes","resetGateBias","resetGate","cellWeights","cellPeepholes","cellBias","cell","setDimensions","inputGateWeights","inputGatePeepholes","inputGateBias","inputGate","forgetGateWeights","forgetGatePeepholes","forgetGateBias","forgetGate","outputGateWeights","outputGatePeepholes","outputGateBias","outputGate","memoryWeights","memoryPeepholes","memoryBias","memory","retainCell","writeCell","outputGateConnector","transition","layerNameTypes","layerFromJSON","jsonLayer","find","layerNameType","Layer","LookupTable","prop","binaryThresh","praxis.momentumRootMeanSquaredPropagation","trainDefaults","errorThresh","logPeriod","callbackPeriod","errorCheckInterval","timeout","FeedForward","options","_updateTrainingOptions","callback","validations","forEach","key","val","toString","console","opts","_validateTrainingOptions","_setLogMethod","warn","inputLayerIndex","outputLayerIndex","outputLayer","_inputLayer","_hiddenLayers","_outputLayer","hiddenLayers","_connectHiddenLayers","previousLayer","hiddenLayer","_connectOptionsLayers","_connectNewLayers","initializeLayers","_model","filter","l","lastLayer","meanSquaredError","typeSafeInput","inputLookup","inputLookupLength","runInput","outputLookup","toObject","preparedData","status","endTime","_prepTraining","continueTicking","calculateError","_calculateTrainingError","trainPatters","_trainPatterns","_trainingTick","trainPatterns","formattedData","formatData","verifyIsInitialized","transferData","initialize","prevSum","_trainPattern","resultArray","logErrorRate","_calculateDeltas","adjustWeights","learn","tmp","inputDatumCheck","lookupTable","datumParam","outputDatumCheck","outputLookupLength","transferredData","transferInput","transferOutput","formattedDatum","jsonLayers","indexOf","inputLayer1Index","inputLayer2Index","sizes","concat","getLayer","__assign","t","s","n","arguments","apply","defineProperty","exports","Thaw","items","_this","_a","each","done","isStopped","tick","setTimeout","thawing","item","clearTimeout","thaws","delay","get","enumerable","configurable","stopAll","stop","makeReady","insert","addArray","insertArray","before","after","thaw","Block","count","next","window","arraysToFloat32Arrays","arrays","inputOutputArraysToFloat32Arrays","arrayToFloat32Arrays","inputOutputArrayToFloat32Arrays","arrayToFloat32Array","inputOutputObjectsToFloat32Arrays","inputTable","outputTable","inputLength","outputLength","objectToFloat32Arrays","inputOutputObjectToFloat32Arrays","objectToFloat32Array","mse","getTypedArrayFn","ArrayBuffer","NeuralNetwork","inputSize","outputSize","activation","leakyReluAlpha","beta1","beta2","epsilon","setActivation","calculateDeltas","updateTrainingOptions","outputs","layerIndex","nodeIndex","prevSize","_setupAdam","_runInputSigmoid","_calculateDeltasSigmoid","_runInputRelu","_calculateDeltasRelu","_runInputLeakyRelu","_calculateDeltasLeakyRelu","_runInputTanh","_calculateDeltasTanh","isRunnable","formattedInput","activeLayer","activeWeights","activeBiases","activeOutputs","node","activeSize","merged","validateTrainingOptions","setLogMethod","logTrainingStatus","trainPattern","calculateTrainingError","prepTraining","trainingTick","Promise","resolve","reject","thawedTrain","trainError","activeOutput","activeError","activeDeltas","nextLayer","currentSize","currentOutputs","nextWeights","nextDeltas","currentErrors","currentDeltas","alpha","activeDelta","activeChanges","change","biasChangesLow","biasChangesHigh","changesLow","changesHigh","_adjustWeightsAdam","currentChangesLow","currentChangesHigh","currentWeights","currentBiases","currentBiasChangesLow","currentBiasChangesHigh","gradient","changeLow","changeHigh","momentumCorrection","pow","gradientCorrection","biasGradient","biasChangeLow","biasChangeHigh","biasMomentumCorrection","biasGradientCorrection","_formatInput","_formatOutput","addKeys","misclasses","errorSum","actual","expected","misclass","jsonLayerWeights","layerWeights","jsonLayerBiases","layerBiases","getTrainOptsJSON","needsVar","nodeHandle","weightsArray","subNodeIndex","join","checkKeys","layersAsMath","source","Function","weightedSumSigmoid","weightedSumRelu","weightedSumLeakyRelu","weightedSumTanh","calcErrorOutput","calcDeltasSigmoid","calcDeltasRelu","calcDeltasLeakyRelu","calcDeltasTanh","calcError","calcChanges","previousChange","previousOutput","addWeights","addBiases","NeuralNetworkGPU","forwardPropagate","backwardPropagate","gpu","buildRunInput","buildCalculateDeltas","buildGetChanges","buildChangeBiases","buildGetMSE","getMSE","_addMSE","_divideMSESum","getChanges","changeBiases","weightedSum","pipeline","texturizeInputData","calcDeltas","alias","utils","getMinifySafeName","addFunction","targets","changesPropagate","previousOutputs","previousChanges","biasesPropagate","outputTextures","texturizeOutputData","set","RecurrentConnection","Recurrent","previousLayers","_layerSets","usedHiddenLayerOutputIndex","findInputLayer","layerSettings","previousHiddenLayerOutput","_hiddenLayerOutputIndices","layerSet","_outputConnection","_connectLayers","_connectLayersDeep","initializeDeep","runInputs","lastLayerUsed","end","lastLayerSet","Matrix","rows","columns","col","ix","fromArray","iterate","rowIndex","column","columnIndex","getWeight","getDelta","setWeight","setDelta","callbacks","RandomMatrix","DataFormatter","maxThreshold","isSetup","buildCharactersFromIterable","buildTables","addInputOutput","addUnrecognized","tempCharactersTable","dataFormatterIndex","dataFormatterLength","characters","iteratable","characterIndex","charactersLength","character","addCharacters","charactersTable","indexTable","characterTable","unrecognized","toIndexesValue","isInput","split","toIndexes","indices","toCharacters","addSpecial","String","fromCharCode","dataFormatter","fromAllPrintable","string","Set","datum","validateAndCast","flatArray","flat","specialIndexes","special","specialIndex","JSON","stringify","toIndexesInputOutput","formatDataIn","product","left","right","addB","allOnes","cloneNegative","leftRows","leftColumns","rightColumns","leftRow","leftRowBase","rightRowBase","rightColumn","dot","leftColumn","leftIndex","rightIndex","multiplyB","leftRowRoot","rightRow","backPropagateValue","multiplyElementB","reluB","rowPluck","rowPluckIndex","rowBase","rowPluckB","sigmoidB","mwi","softmax","maxVal","tanhB","Equation","states","forwardFn","backpropagationFn","inputValue","self","inputRow","state","runIndex","logProbabilities","probabilities","log2","maxI","maxv","maxix","sampleI","w","inputRange","regc","clipval","maxPredictionLength","RNN","seal","isInitialized","equations","allMatrices","equationConnections","outputConnector","model","mapModel","hiddenLayersModel","getHiddenLayer","d","hiddenSize","equation","inputMatrix","previousResult","bind","lastHiddenSize","last","equationConnection","initialLayerInputs","getEquation","inputMatrixToRow","createInputMatrix","createHiddenLayers","hiddenMatrix","property","createOutputMatrices","runs","log2ppl","bindEquation","inputIndex","inputMax","equationIndex","predictTargetIndex","backpropagateIndex","stepCache","numClipped","numTot","matrixIndex","cache","ratioClipped","rawInput","isSampleI","temperature","checkRunnable","previousIndex","outputMatrix","probs","nextIndex","formatDataOut","format","jsonString","previousConnectionIndex","m","connection","matrixToString","stateIndex","matrixOrigin","toInner","fnString","fnParts","shift","fnBodyParts","pop","replace","fileName","fnName","toLowerCase","statesRaw","usedFunctionNames","innerFunctionsSwitch","src","toFunctionString","trainInput","backpropagate","GRU","getGRUHiddenLayer","getGRUEquation","updateGateInputMatrix","updateGateHiddenMatrix","resetGateInputMatrix","resetGateHiddenMatrix","cellWriteInputMatrix","cellWriteHiddenMatrix","cellWriteBias","ArrayLookupTable","ioValue","rnnDefaults","RNNTimeStep","dataShape","runArray","runArrayOfArray","runObject","runArrayOfObject","forecastArray","forecastArrayOfArray","forecastArrayOfObject","lastOutput","rnnTrainDefaults","setSize","verifySize","predictTarget","trainArrayOfArray","toTable2D","toInputTable2D","inputArray","toArrayShort","toObjectPartial","toArrays","requireInputOutputOfOne","formatArray","formatArrayOfArray","formatArrayOfObject","formatArrayOfObjectMulti","formatArrayOfDatumOfArray","formatArrayOfDatumOfObject","formatArrayOfArrayOfArray","formatArrayOfArrayOfObject","formatArrayOfDatumOfArrayOfArray","formatArrayOfDatumOfArrayOfObject","errorCount","typedValue","typedInput","typedOutput","forceForecast","GRUTimeStep","LSTM","getHiddenLSTMLayer","getLSTMEquation","inputHidden","inputBias","forgetMatrix","forgetHidden","forgetBias","outputHidden","outputBias","cellActivationMatrix","cellActivationHidden","cellActivationBias","cellWrite","LSTMTimeStep","drawInput","pixelX","pixelY","radius","line","fontSize","fontClassName","svg","color","className","labels","drawNeuron","hidden","drawOutput","drawBackwardConnections","lineY","neuralNetworkToInnerSVG","previousSize","drawRecurrentConnections","recurrentLine","moveX","moveY","rnnToInnerSVG","wrapOuterSVG","svgBody","getRNNSizes","net","checkSizes","some","recurrent","utilities","range","start","toSVG","mergedOptions","getNeuralNetworkSizes","getRecurrentLayers","getFeedForwardLayers","TypeError","maxProp","entries"],"mappings":"4RAIgBA,EAASC,GACvB,OAAOC,KAAKC,IAAI,EAAGF,YAMLG,EAAQH,EAAgBI,GACtC,OAAIJ,GAAU,EACL,EAEFI,sECZOL,EAASM,GACvB,OAAO,GAAK,EAAIJ,KAAKK,KAAKD,aAMZF,EAAQH,EAAgBO,GACtC,OAAOP,GAAU,EAAIA,GAAUO,sECRjBR,EAASC,GACvB,OAAOC,KAAKO,KAAKR,YAMHG,EAAQH,EAAgBO,GACtC,OAAQ,EAAIP,EAASA,GAAUO,sECPjBR,EAASC,GACvB,OAAOA,EAAS,EAAIA,EAAS,IAAOA,WAMtBG,EAAQH,EAAgBO,GACtC,OAAOP,EAAS,EAAIO,EAAQ,IAAOA,yICqEhBE,EAyBnBC,YAAYC,GAjBZC,UAEI,CACFC,KAAM,CACJN,MAAO,EACPO,WAAY,EACZC,SAAU,EACVC,UAAW,GAEbC,MAAO,CACLC,MAAO,EACPC,SAAU,EACVC,UAAW,GAEbC,KAAM,IAINT,KAAKD,eAAiBA,EAGxBD,cACEY,EACAC,EACAC,GAQA,MAAMC,EAAab,KAAKD,iBAClBe,EAAaC,KAAKC,MAClBC,EAAgBJ,EAAWK,MAAMP,EAAUD,GAC3CS,EAAYJ,KAAKC,MACjBI,EAE+BP,EAAWQ,KAAKT,GAC/CU,EAAUP,KAAKC,MACrB,MAAO,IACFI,EACHhB,UAAWe,EAAYL,EACvBX,SAAUmB,EAAUH,EACpBjB,WAAYe,EAAcf,WAC1BP,MAAOsB,EAActB,MACrBW,MAAOc,EAAUd,MACjBiB,QAAUV,EAEPW,UASP1B,aAAgB2B,GACd,IAAK,IAAIC,EAAID,EAAME,OAAS,EAAGD,EAAI,EAAGA,IAAK,CACzC,MAAME,EAAIvC,KAAKwC,MAAMxC,KAAKyC,UAAYJ,EAAI,IACpCK,EAAON,EAAMC,GACnBD,EAAMC,GAAKD,EAAMG,GACjBH,EAAMG,GAAKG,EAEb,OAAON,EAwBT3B,MACEkC,EACAtB,EAEI,GACJuB,EAAI,GAEJ,GAAID,EAAKL,OAASM,EAChB,MAAM,IAAIC,MACR,sCAAsCF,EAAKL,qBAAqBM,KAGpEjC,KAAKmC,aAAsBH,GAC3B,MAAMI,EAAOJ,EAAKL,OAASM,EAErBhC,EAAoC,CACxCG,UAAW,EACXD,SAAU,EACVD,WAAY,EACZP,MAAO,GAGHU,EAEqC,CACzCC,MAAO,EACPC,SAAU,EACVC,UAAW,GAGP6B,EAAoD,CACxD/B,MAAO,EACPC,SAAU,EACVC,UAAW,EACX8B,QAAS,EACTC,QAAS,EACTC,SAAU,EACVC,SAAU,EACVC,UAAW,EACXC,OAAQ,EACRC,SAAU,GAGNC,EAAU,GAChB,IAAIC,EAAW,KAEf,IAAK,IAAIpB,EAAI,EAAGA,EAAIO,EAAGP,IAAK,CAC1B,MAAMqB,EAASf,EAAKgB,MAAM,GACpBpC,EAAUmC,EAAOE,OAAOvB,EAAIU,EAAMA,GAClCzB,EAAWoC,EACXG,EAASlD,KAAKmD,cAAczC,EAAWC,EAAUC,GAEtC,OAAbkC,IACFA,EACEI,EAAOE,eAAe,aACtBF,EAAOE,eAAe,aACtBF,EAAOE,eAAe,YACtBF,EAAOE,eAAe,WACpBN,GACFO,OAAOC,OAAOjD,EAAOgC,IAIzBpC,EAAKC,YAAcgD,EAAOhD,WAC1BD,EAAKE,UAAY+C,EAAO/C,SACxBF,EAAKG,WAAa8C,EAAO9C,UACzBH,EAAKN,OAASuD,EAAOvD,MACrBU,EAAMC,OAAS4C,EAAO5C,MAEpBT,EAAc0D,cAAclD,IAC5BR,EAAc2D,yBAAyBN,KAEvC7C,EAAMuC,UAAYM,EAAON,SACzBvC,EAAMoC,UAAYS,EAAOT,SACzBpC,EAAMmC,UAAYU,EAAOV,SACzBnC,EAAMqC,WAAaQ,EAAOR,UAC1BrC,EAAMsC,QAAUO,EAAOP,OACvBtC,EAAMkC,SAAWW,EAAOX,QACxBlC,EAAMiC,SAAWY,EAAOZ,SAG1BO,EAAQY,KAAKP,GAqBf,OAnBAjD,EAAKN,OAASsC,EACdhC,EAAKC,YAAc+B,EACnBhC,EAAKE,UAAY8B,EACjBhC,EAAKG,WAAa6B,EAEdpC,EAAc0D,cAAclD,KAC9BA,EAAMqC,UAAYrC,EAAMiC,SAAWjC,EAAMiC,QAAUjC,EAAMmC,UACzDnC,EAAMsC,OAAStC,EAAMiC,SAAWjC,EAAMiC,QAAUjC,EAAMoC,UACtDpC,EAAMuC,UAAYvC,EAAMkC,QAAUlC,EAAMiC,SAAWjC,EAAMC,OAG3DD,EAAME,SAAW6B,EACjB/B,EAAMG,UAAYwB,EAAKL,OAASS,EAEhCpC,KAAK0D,KAAO,CACVzD,KAAMA,EACNI,MAAOA,EACPI,KAAMoC,GAED7C,KAAK0D,KAGd5D,kBACE,OAAOE,KAAK2D,SAAS3D,KAAK0D,MAG5B5D,SAGE,OAAOE,KAAK0D,KAGd5D,SACE8D,GAIA,MAAMC,EAMGD,EAENnD,KAAKqD,OAAO,CAACC,EAAMC,IAASD,EAAKpE,MAAQqE,EAAIrE,MAAQoE,EAAOC,GAC/D,OAAQhE,KAAKD,iBAAoD4D,SAC/DE,EAAYtC,UAvJT1B,gBACLQ,QAG+D4D,IAA5D5D,EAA+CuC,SAI7C/C,kBACLQ,QAEkE4D,IAAjE5D,EAA8CA,MAAMuC,SAEhD/C,2BACLQ,QAKA4D,IADC5D,EAA+DuC,SC/JpE,IAAIsB,EAA0B,cAKdC,EAAM1E,GACpByE,EAAczE,WAaA2E,EAIdC,EACAC,GAEA,IAAIC,EAAoBL,EAMxB,OALqB,OAAjBK,IACFA,EAAe,IAAIC,MAAI,CAAEC,KAAM,QAC/BN,EAAMI,IAGDA,EACJG,aAAuCL,EAAIC,GAC3CK,aAAY,YAGDC,EAIdC,EACAR,EACAC,GAEA,IAAIC,EAAoBL,EAMxB,OALqB,OAAjBK,IACFA,EAAe,IAAIC,MAAI,CAAEC,KAAM,QAC/BN,EAAMI,IAGDA,EACJO,gBAA0CD,EAAKR,EAAIC,GACnDK,aAAY,YAwBDI,EAAQC,GAClBA,aAA2BC,WAC7BD,EAAgBE,kBAOJC,EAAM1F,GACpB,KAAIA,aAAiBwF,WAArB,CAMA,GAAIG,MAAMC,QAAQ5F,GAChB,GAAwB,iBAAbA,EAAM,GACdA,EAAmB6F,KAAK,OACpB,CAAA,GAA2B,iBAAhB7F,EAAM,GAAG,GAAiB,CAC1C,IAAK,IAAI8F,EAAI,EAAGA,EAAI9F,EAAMkC,OAAQ4D,IAC/B9F,EAAM8F,GAAgBD,KAAK,GAE9B,OACK,GAA8B,iBAAnB7F,EAAM,GAAG,GAAG,GAAiB,CAE7C,IAAK,IAAI+F,EAAI,EAAGA,EAAI/F,EAAMkC,OAAQ6D,IAAK,CACrC,MAAMC,EAAkBhG,EAAM+F,GAC9B,IAAK,IAAID,EAAI,EAAGA,EAAIE,EAAI9D,OAAQ4D,IAC9BE,EAAIF,GAAGD,KAAK,GAGhB,QAGJ,MAAM,IAAIpD,MAAM,mBAxBdzC,EAAM0F,iBA8BMO,EAAMjG,GACpB,GAAIA,aAAiBwF,UACnB,OAAOxF,EAAMiG,QAEf,GAAIjG,aAAiBkG,aACnB,OAAOlG,EAAMuD,MAAM,GAErB,GAAIoC,MAAMC,QAAQ5F,GAAQ,CACxB,GAAwB,iBAAbA,EAAM,GACf,OAAOA,EAAMuD,MAAM,GACd,GAA2B,iBAAhBvD,EAAM,GAAG,GAAiB,CAC1C,MAAMmG,EAAS,IAAIR,MAAM3F,EAAMkC,QAC/B,IAAK,IAAI4D,EAAI,EAAGA,EAAI9F,EAAMkC,OAAQ4D,IAChCK,EAAOL,GAAM9F,EAAM8F,GAAoBvC,MAAM,GAE/C,OAAO4C,EACF,GAA8B,iBAAnBnG,EAAM,GAAG,GAAG,GAAiB,CAC7C,MAAMoG,EAAO,IAAIT,MAAM3F,EAAMkC,QAC7B,IAAK,IAAI6D,EAAI,EAAGA,EAAI/F,EAAMkC,OAAQ6D,IAAK,CACrC,MAAMC,EAAMhG,EAAM+F,GACZI,EAAS,IAAIR,MAAMK,EAAI9D,QAC7B,IAAK,IAAI4D,EAAI,EAAGA,EAAIE,EAAI9D,OAAQ4D,IAC9BK,EAAOL,GAAKE,EAAIF,GAAGvC,MAAM,GAG7B,OAAO6C,GAGX,MAAM,IAAI3D,MAAM,4BCxJF4D,EAEdC,GAEA,IAAIC,EAAM,EACV,IAAK,IAAIR,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUC,OAAQV,IACzC,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUE,MAAOZ,IACxCS,GAAOD,EAAOP,GAAGD,IAAM,EAG3B,OAAOS,EAAMhG,KAAKiG,UAAUtE,aAGjByE,EAUXtG,aAAYqG,MAAEA,EAAKD,OAAEA,IACnBlG,KAAKqG,UAAYjC,EAAW0B,EAAO,CACjCQ,OAAQ,CAAC,GACTL,UAAW,CACTE,MAAAA,EACAD,OAAAA,EACAvE,OAAQwE,EAAQD,GAElBK,WAAW,IAGbvG,KAAKwG,YAAcpC,GACjB,SAAUqC,EAAqBC,GAC7B,OAAOD,EAAU,GAAKpH,KAAKsH,IAAID,EAAgB,GAAG,MAEpD,CACEJ,OAAQ,CAAC,GACTC,WAAW,IAIfvG,KAAK4G,IAAMxC,GACT,SAAUyC,EAAkBC,GAC1B,OAAOD,EAAO,GAAKC,EAAO,KAE5B,CACER,OAAQ,CAAC,GACTC,WAAW,IAIfvG,KAAK+G,OAAS3C,GACZ,SAAUzC,EAAgBqF,GACxB,MAAMvH,EAAQuH,EAAO,GACrB,OAAIvH,EAAQ,EACHA,EAAQkC,EAEV,IAET,CACE2E,OAAQ,CAAC,GACTC,WAAW,KCbZ,MAAMU,EAA2C,CACtDd,MAAO,EACPD,OAAQ,EACRgB,MAAO,KACPC,QAAS,KACTC,OAAQ,KACRC,OAAQ,KACRC,WAAY,YAKDC,EA0CXzH,YAAYwE,GAzCZtE,YAAyB,KACzBA,mBAA2C,KAC3CA,mBAA2C,KAyCvCA,KAAKsE,SADHA,EACc,IAAK2C,KAA6B3C,GAElC,IAAK2C,GAEvBjH,KAAKwH,cA1CPrB,kBACE,iBAAOnG,KAAKsE,SAAS6B,qBAAS,EAGhCD,mBACE,iBAAOlG,KAAKsE,SAAS4B,sBAAU,EAGjCgB,kBACE,iBAAOlH,KAAKsE,SAAS4C,qBAAS,EAGhCC,cACE,OAAOnH,KAAKsE,SAAS6C,QAGvBA,YAAYA,GACVnH,KAAKsE,SAAS6C,QAAUA,EAG1BC,aACE,OAAOpH,KAAKsE,SAAS8C,OAGvBA,WAAWA,GACTpH,KAAKsE,SAAS8C,OAASA,EAGzBK,eACE,iBAAOzH,KAAKsE,SAASmD,kBAAM,GAG7BA,OAAOC,GACL1H,KAAKsE,SAASmD,GAAKC,EAYrB5H,cACE,MAAM6H,WAAEA,EAAUN,OAAEA,EAAMC,WAAEA,GAAetH,KAAKsE,SAC3CtE,KAAKqH,SACJM,EAEA3H,KAAKqH,OADHC,EACYK,EAAW3H,KAAMsH,GAEjBK,EAAW3H,MAElBqH,IACTrH,KAAKqH,OAASA,IAwDpBvH,WACE,GAAI8H,OAAOC,MAAM7H,KAAKkG,QACpB,MAAM,IAAIhE,MAASlC,KAAK8H,YAAYC,KAApB,iCAElB,GAAIH,OAAOC,MAAM7H,KAAKmG,OACpB,MAAM,IAAIjE,MAASlC,KAAK8H,YAAYC,KAApB,gCAElB,GAAI/H,KAAKkG,OAAS,EAChB,MAAM,IAAIhE,MAASlC,KAAK8H,YAAYC,KAApB,gCAElB,GAAI/H,KAAKmG,MAAQ,EACf,MAAM,IAAIjE,MAASlC,KAAK8H,YAAYC,KAApB,+BAIpBjI,aAAakI,IAEblI,aAAamI,GACX,GAAIA,EAAM9B,QAAUnG,KAAKmG,MACvB,MAAM,IAAIjE,MACR,GAAGlC,KAAK8H,YAAYC,8BAA8BE,EAAM9B,gBAAgBnG,KAAKmG,SAGjF,GAAI8B,EAAM/B,SAAWlG,KAAKkG,OACxB,MAAM,IAAIhE,MACR,GAAGlC,KAAK8H,YAAYC,8BAA8BE,EAAM/B,iBAAiBlG,KAAKkG,UAGlF,GAAI+B,EAAM7E,eAAe,kBAA4C,OAAxB6E,EAAMC,cAAwB,CACzE,IAAMD,EAAMC,cAAyB3B,UACnC,MAAM,IAAIrE,MACL+F,EAAMH,YAAYC,KAArB,+DAGJ/H,KAAKkI,cAAgBD,EAAMC,cAE7B,GAAID,EAAM7E,eAAe,kBAA4C,OAAxB6E,EAAME,cAAwB,CACzE,IAAMF,EAAME,cAAyB5B,UACnC,MAAM,IAAIrE,MACL+F,EAAMH,YAAYC,KAArB,+DAGJ/H,KAAKmI,cAAgBF,EAAME,cAE7BnI,KAAKqH,OAASY,EAAMZ,OAGtBvH,QAAQsI,IAERtI,QAAQuI,IAERvI,MAAMwI,GAEJ,MAAQnB,QAASoB,GAAevI,KAChC,IAAKA,KAAKqH,OAAQ,MAAM,IAAInF,MAAM,2BAClClC,KAAKmH,QAAUnH,KAAKqH,OAAOmB,IAAIxI,KAAMsI,GACrCvD,EAAQwD,GACRpD,EAAMnF,KAAKoH,QAGbtH,UACE,OAAOsF,MAAMC,QAAQrF,KAAKmH,SACtBnH,KAAKmH,QACJnH,KAAKmH,QAAoBsB,UAGhC3I,SACE,OAAOyH,EAAU/F,OAAOxB,MAG1BF,cAAcmI,GACZ,MAAMd,QAAEA,GAAYc,EACpB,MAAO,CACL9B,MAAO8B,EAAM9B,MACbD,OAAQ+B,EAAM/B,OACdgB,MAAOe,EAAMf,MACbC,QAASuB,EACNvB,GAAWA,aAAmBlC,UAC3BkC,EAAQsB,UACRtB,GASNwB,KAAMV,EAAMH,YAAYC,KACxBT,WAAYW,EAAMZ,OAASY,EAAMZ,OAAO7F,SAAW,OAKzD,SAASkH,EACPvB,GASA,GAAgB,OAAZA,EAAkB,OAAO,KAC7B,GAAI/B,MAAMC,QAAQ8B,GAAU,CAC1B,GAA0B,iBAAfA,EAAQ,GACjB,OAAOA,EACF,GAAI/B,MAAMC,QAAQ8B,EAAQ,KAAgC,iBAAlBA,EAAQ,GAAG,GACxD,OAAOA,EACF,GACL/B,MAAMC,QAAQ8B,EAAQ,GAAG,KACG,iBAArBA,EAAQ,GAAG,GAAG,GAErB,OAAOA,EACF,GAAIA,EAAQ,aAAcxB,aAAc,CAE7C,OADewB,EACDtC,IAAKY,GACVL,MAAMwD,KAAKnD,IAEf,GAAI0B,EAAQ,GAAG,aAAcxB,aAAc,CAEhD,OADawB,EACDtC,IAAKe,GACRA,EAAOf,IAAKY,GACVL,MAAMwD,KAAKnD,WAInB,GAAI0B,EACT,OAAO/B,MAAMwD,KAAKzB,GAEpB,MAAM,IAAIjF,MAAM,6BC9TF2G,EAAMzG,GACpB,OAAO,IAAIuD,aAAavD,YCCV0G,EAAQ3C,EAAeD,GACrC,MAAMhD,EAAyB,IAAIkC,MAAMc,GACzC,IAAK,IAAIV,EAAI,EAAGA,EAAIU,EAAQV,IAC1BtC,EAAOsC,GAAKqD,EAAM1C,GAEpB,OAAOjD,WCLO6F,EACd5C,EACAD,EACAgB,GAEA,MAAMhE,EAA2B,IAAIkC,MAAM8B,GAC3C,IAAK,IAAI8B,EAAI,EAAGA,EAAI9B,EAAO8B,IACzB9F,EAAO8F,GAAKF,EAAQ3C,EAAOD,GAE7B,OAAOhD,QCLI+F,UAAmB1B,EAe9BzH,YAAYoJ,EAAoB5E,GAC9B6E,MAAM7E,GACNtE,KAAKkJ,WAAaA,EAClB,MAAM/C,MAAEA,EAAKD,OAAEA,EAAMgB,MAAEA,GAAUlH,KACjCA,KAAKkI,cAAgB,KACrBlI,KAAKmI,cAAgB,KACrBnI,KAAKoJ,WACDlC,EAAQ,GACVlH,KAAKmH,QAAU4B,EAAQ5C,EAAOD,EAAQgB,GACtClH,KAAKoH,OAAS2B,EAAQ5C,EAAOD,EAAQgB,IAC5BhB,EAAS,IAClBlG,KAAKmH,QAAU2B,EAAQ3C,EAAOD,GAC9BlG,KAAKoH,OAAS0B,EAAQ3C,EAAOD,IAE/BlG,KAAKwH,cA1BPrB,YACE,OAAOnG,KAAKkJ,WAAW/C,MAGzBD,aACE,OAAOlG,KAAKkJ,WAAWhD,OAGzBgB,YACE,OAAOlH,KAAKkJ,WAAWhC,aCLdmC,UAAe9B,EA2C1BzH,YAAYwE,EAAoC4E,GAC9CC,QACAnJ,KAAKsE,SAAWA,EAChBtE,KAAKkJ,WAAaA,EA7CpB/C,YACE,OAAOnG,KAAKkJ,WAAW/C,MAGzBD,aACE,OAAOlG,KAAKkJ,WAAWhD,OAGzBgB,YACE,OAAOlH,KAAKkJ,WAAWhC,MAGzBoC,kBACE,OAAOtJ,KAAKsE,SAASgF,YAGvBC,kBACE,OAAOvJ,KAAKsE,SAASiF,YAGvBC,mBACE,OAAOxJ,KAAKsE,SAASkF,aAGvBC,cACE,OAAOzJ,KAAKsE,SAASmF,QAGvBA,YAAYA,GACVzJ,KAAKsE,SAASmF,QAAUA,EAG1BC,mBACE,OAAO1J,KAAKsE,SAASoF,aAGvBA,iBAAiBA,GACf1J,KAAKsE,SAASoF,aAAeA,SChDXC,EAAtB7J,cAMEE,mBAA2C,KAC3CA,mBAA2C,KAC3CA,YAAyB,KAEzBmG,YACE,OAAOnG,KAAKsE,SAAS6B,MAGvBD,aACE,OAAOlG,KAAKsE,SAAS4B,OAGvBgB,YACE,OAAOlH,KAAKsE,SAAS4C,MAGvBC,cACE,OAAOnH,KAAKsE,SAAS6C,QAGvBA,YAAYA,GACVnH,KAAKsE,SAAS6C,QAAUA,EAG1BC,aACE,OAAOpH,KAAKsE,SAAS8C,OAGvBA,WAAWA,GACTpH,KAAKsE,SAAS8C,OAASA,EAGzBtH,SACE,OAAOyH,EAAU/F,OAAOxB,aCtCf4J,UAAiBrC,EAE5BzH,YAAYoJ,EAAoB5E,GAC9B6E,MAAM,IACD7E,EACH6B,MAAO+C,EAAW/C,MAClBD,OAAQgD,EAAWhD,OACnBgB,MAAOgC,EAAWhC,QAEpBlH,KAAKkJ,WAAaA,EAGpBpJ,iBAGE,GAFAqJ,MAAMC,WAEFpJ,KAAKmG,QAAUnG,KAAKkJ,WAAW/C,MACjC,MAAM,IAAIjE,MACR,YAAYlC,KAAKmG,4CAA4CnG,KAAKkJ,WAAW/C,SAIjF,GAAInG,KAAKkG,SAAWlG,KAAKkJ,WAAWhD,OAClC,MAAM,IAAIhE,MACR,aAAalC,KAAKkG,8CAA8ClG,KAAKkJ,WAAWhD,UAIpF,GAAIlG,KAAKkH,mBAAWlH,KAAKkJ,WAAWhC,qBAAS,GAC3C,MAAM,IAAIhF,MACR,YAAYlC,KAAKkH,4CAA4ClH,KAAKkJ,WAAWhC,gBC3B/D2C,UAAiBtC,EAGrCzH,YACEgK,EACAC,EACAzF,GAEA6E,MAAM7E,GACNtE,KAAK8J,YAAcA,EACnB9J,KAAK+J,YAAcA,EACnB/J,KAAKoJ,WACLpJ,KAAKmH,QAAU2B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QACxClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QACvClG,KAAKwH,wBChBOwC,EAEd7C,EACAkB,GAEA,OAAOlB,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAK8C,EAAarI,KAAKiK,OAAO1E,YAG1D2E,EAEd/C,EACAkB,GAEA,OACElB,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACnC8C,EAAarI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,SAS/B4E,UAAe5C,EAG1BzH,YAAYwE,EAAmC4E,GAI7C,GAHAC,MAAM7E,GACNtE,KAAKkJ,WAAaA,EAClBlJ,KAAKoJ,WACDpJ,KAAKkH,MACP,MAAM,IAAIhF,MAAM,0CACPlC,KAAKkG,QACdlG,KAAKmH,QAAU2B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QACxClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QACvClG,KAAK+F,OAAS+C,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,UAEvClG,KAAKmH,QAAU0B,EAAM7I,KAAKmG,OAC1BnG,KAAKoH,OAASyB,EAAM7I,KAAKmG,OACzBnG,KAAK+F,OAAS8C,EAAM7I,KAAKmG,QAI7BrG,eACqB,IAAfE,KAAKmG,MACPnG,KAAKmI,cAAgB/D,EAAW4F,EAAW,CACzC1D,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BK,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAW8F,EAAW,CACzC5D,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BK,WAAW,IAKjBzG,UAGEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAUzB,EAAM1F,KAAKkJ,WAAW/B,SACrChC,EAAMnF,KAAKoH,QAGbtH,QAAQuI,GAGNtD,EAAQ/E,KAAKoH,QACbrC,EAAQ/E,KAAK+F,QACbhB,EAAQ/E,KAAKkJ,WAAW9B,QACxBpH,KAAKoH,OAAUpH,KAAKmI,cAClBnI,KAAKmH,QACLkB,GAEFrI,KAAKkJ,WAAW9B,OAAS1B,EAAM1F,KAAKoH,QACpCpH,KAAK+F,OAASL,EAAM1F,KAAKoH,QAG3BtH,yBAGcsK,EAAO9F,EAA0B4E,GAC/C,OAAO,IAAIiB,EAAO7F,EAAU4E,SCjFjBmB,SAIAC,UAAmB/C,SAGnBgD,UAAchD,SCSdiD,EAAS,CAMpB1K,QAAQ2K,GACN,MAAMC,EAAOD,EAAO3G,OAAO,CAAC6G,EAAMD,IACzBrH,OAAOC,OAAOqH,EAAMD,GAC1B,IAEH,OAAOF,EAAOI,OAAOF,IAMvB5K,UAAU+K,GACR,MAAMC,EAAqB,GAC3B,IAAIC,EAAa,EACjB,IAAK,IAAIrJ,EAAI,EAAGA,EAAImJ,EAAUlJ,OAAQD,IAAK,CACzC,MAAMsJ,EAAUH,EAAUnJ,GAC1B,IAAK,IAAIE,EAAI,EAAGA,EAAIoJ,EAAQrJ,OAAQC,IAAK,CACvC,MAAMqJ,EAASD,EAAQpJ,GACvB,IAAK,MAAMsJ,KAAKD,EACVA,EAAO7H,eAAe8H,KAAOJ,EAAM1H,eAAe8H,KACpDJ,EAAMI,GAAKH,MAKnB,OAAOD,GAGThL,eACEkC,GAEA,MAAM8I,EAAqB,GAC3B,IAAIK,EAAa,EACjB,IAAK,IAAIC,EAAY,EAAGA,EAAYpJ,EAAKL,OAAQyJ,IAAa,CAC5D,MAAMC,EAAQrJ,EAAKoJ,GAAWC,MAC9B,IAAK,IAAI3J,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAAK,CACrC,MAAMuJ,EAASI,EAAM3J,GACrB,IAAK,MAAMwJ,KAAKD,EACTA,EAAO7H,eAAe8H,KACtBJ,EAAM1H,eAAe8H,KACxBJ,EAAMI,GAAKC,OAKnB,OAAOL,GAGThL,gBACEkC,GAEA,MAAM8I,EAAqB,GAC3B,IAAIK,EAAa,EACjB,IAAK,IAAIC,EAAY,EAAGA,EAAYpJ,EAAKL,OAAQyJ,IAAa,CAC5D,MAAM9E,EAAStE,EAAKoJ,GAAW9E,OAC/B,IAAK,IAAI5E,EAAI,EAAGA,EAAI4E,EAAO3E,OAAQD,IAAK,CACtC,MAAMuJ,EAAS3E,EAAO5E,GACtB,IAAK,MAAMwJ,KAAKD,EACTA,EAAO7H,eAAe8H,KACtBJ,EAAM1H,eAAe8H,KACxBJ,EAAMI,GAAKC,OAKnB,OAAOL,GAMThL,OAAO4K,GACL,MAAMF,EAAsB,GAC5B,IAAIc,EAAQ,EACZ,MAAMC,EAAOlI,OAAOkI,KAAKb,GACzB,IAAK,IAAIhJ,EAAI,EAAGA,EAAI6J,EAAK5J,OAAQD,IAC/B8I,EAAOe,EAAK7J,IAAM4J,IAEpB,OAAOd,GAMT1K,QACE0K,EACAS,EACAO,GAEA,MAAMtI,EAAS,IAAIyC,aAAa6F,GAChC,IAAK,MAAMN,KAAKV,EACTA,EAAOpH,eAAe8H,KAC3BhI,EAAOsH,EAAOU,IAAMD,EAAO7H,eAAe8H,GAAKD,EAAOC,GAAK,GAE7D,OAAOhI,GAGTpD,aAAa0K,EAAqBS,GAChC,MAAM/H,EAAS,GACf,IAAK,MAAMgI,KAAKV,EACd,GAAKA,EAAOpH,eAAe8H,GAA3B,CACA,IAAKD,EAAO7H,eAAe8H,GAAI,MAC/BhI,EAAOsH,EAAOU,IAAMD,EAAOC,GAE7B,OAAOvF,aAAaiD,KAAK1F,IAG3BpD,SACE0K,EACAQ,EACAQ,GAEA,MAAMtI,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIsJ,EAAQrJ,OAAQD,IAClCwB,EAAOO,KAAKzD,KAAKyI,QAAQ+B,EAAQQ,EAAQtJ,GAAI8J,IAE/C,OAAOtI,GASTpD,SAAS0K,EAAqB/I,GAC5B,MAAMwJ,EAAsB,GAC5B,IAAK,MAAMC,KAAKV,EACTA,EAAOpH,eAAe8H,KAC3BD,EAAOC,GAAKzJ,EAAM+I,EAAOU,KAE3B,OAAOD,GAGTnL,gBACE0K,EACA/I,EACAgK,EAAS,EACTC,EAAQ,GAER,MAAMT,EAAsB,GAC5B,IAAIvJ,EAAI,EACR,IAAK,MAAMwJ,KAAKV,EACTA,EAAOpH,eAAe8H,KACvBO,EAAS,GACP/J,IAAM+J,GAERC,EAAQ,GACNhK,KAAOgK,IAEbT,EAAOC,GAAKzJ,EAAM+I,EAAOU,GAAKO,KAEhC,OAAOR,GAGTnL,UAAUkC,GACR,MAAM2J,EAAQ,GACd,IAAIC,EA2BAV,EACJ,IA3BIlJ,EAAKoB,eAAe,UACtBuI,EAAMlI,KAAK,SACXmI,EAAY5J,EAAwBqJ,OAC3BjG,MAAMC,QAAQrD,GAEpBA,EAA0B,IAC1BA,EAA0B,GAAGqJ,OAE9BM,EAAMlI,KAAK,QAAS,SACpBmI,EAAY5J,EAA0B,GAAGqJ,OAChCjG,MAAMC,QAAQrD,EAAK,KAC5B2J,EAAMlI,KAAK,SACXmI,EAAW5J,EAAK,IAEhB4J,EAAW5J,EAMb4J,EAAW5J,EAON4J,GAEL,GADAV,EAAI7H,OAAOkI,KAAKK,GAAU,GAExBxG,MAAMC,QAAQuG,IAC+B,iBAArCA,EAA0BC,OAClC,CACAF,EAAMlI,KAAK,SACX,MAAMqI,EAEcF,EAA4BG,SAASb,IACzD,GAA8B,iBAAnBY,EAA6B,CACtCH,EAAMlI,KAAK,UACX,MAEAmI,EAAWE,MAER,CAAA,GACe,iBAAbF,GACsC,iBAArCA,EAA0BC,OAalC,MAAM,IAAI3J,MAAM,uBAZhB,CACAyJ,EAAMlI,KAAK,UACX,MAAMqI,EAAwCF,EAC5CV,GAEF,GAA8B,iBAAnBY,EAA6B,CACtCH,EAAMlI,KAAK,UACX,MAEAmI,EAAWE,GAMjB,OAAOH,GAGT7L,QAAQL,EAA+BqL,GACrC,GAAI1F,MAAMC,QAAQ5F,GAAQ,OAAOqL,EACjC,IAAIpJ,EAAI2B,OAAOkI,KAAKT,GAAOnJ,OAC3B,IAAK,MAAMuJ,KAAKzL,EACTA,EAAM2D,eAAe8H,KACtBJ,EAAM1H,eAAe8H,KACzBJ,EAAMI,GAAKxJ,MAEb,OAAOoJ,UClOWkB,EAiBpBlM,YACEmM,EACA3H,EAAqC,IAErCtE,KAAKiM,cAAgBA,EACrBjM,KAAKsE,SAAW,IAAKA,GACrBtE,KAAKkM,OAAS,KAlBhB/F,YACE,OAAOnG,KAAKiM,cAAc9F,MAG5BD,aACE,OAAOlG,KAAKiM,cAAc/F,OAG5BgB,YACE,OAAOlH,KAAKiM,cAAc/E,MAY5BpH,gBAEAA,aAAauH,GACX,GAAIA,EAAOlB,QAAUnG,KAAKmG,MACxB,MAAM,IAAIjE,MACR,GAAGlC,KAAK8H,YAAYC,8BAA8BV,EAAOlB,gBAAgBnG,KAAKmG,SAGlF,GAAIkB,EAAOnB,SAAWlG,KAAKkG,OACzB,MAAM,IAAIhE,MACR,GAAGlC,KAAK8H,YAAYC,8BAA8BV,EAAOnB,iBAAiBlG,KAAKkG,UAG/EmB,EAAOjE,eAAe,YACxBpD,KAAKkM,OAAS7E,EAAO6E,QAMzBpM,SACE,MAAO,IAAKE,KAAKsE,oBCxEL6H,EAEdhF,EACAC,GAEA,OACED,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACnCvF,KAAKiG,UAAUqC,aAAelB,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAQ7D,MAAM6G,EAAkB,CAC7B9D,aAAc,UAGH+D,UAA8BL,EAGzClM,YAAYmI,EAAe3D,GACzB6E,MAAMlB,GACNjI,KAAKsE,SAAW,IAAK8H,KAAoB9H,GACzCtE,KAAKkM,OAAS,KAGhBpM,IAAImI,GACF,OAAQjI,KAAKkM,OAA8BjE,EAAMd,QAASc,EAAMb,QAGlEtH,eACEE,KAAKkM,OAAS9H,EAAW+H,EAAQ,CAC/B7F,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACTqC,aAActI,KAAKsE,SAASgE,0BAMpBgE,EACdrE,EACA3D,GAEA,OAAO,IAAI+H,EAAsBpE,EAAO3D,YC5C1BiI,EAAa9M,GAC3B,OAAOA,WAQO0M,EAEdK,EACArF,EACAsF,EACAC,GAEA,MAAMC,EAAqBH,EAAQxM,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACxDqH,EAAqBF,EAAY1M,KAAKiK,OAAOzE,GAAG,GAChDpG,EAAiB+H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACpDsH,EAAmBJ,EAAgBzM,KAAKiK,OAAO1E,GAAG,GAMxD,OAAOnG,GAHLY,KAAKiG,UAAUqC,aAAesE,EAAaC,EAC3C7M,KAAKiG,UAAU6G,SAAWH,GAiBvB,MAAMP,EAAmD,CAC9D9D,aAAc,GACdwE,SAAU,GACVC,aAAc,KACdC,cAAe,KACfC,WAAY,YAGDC,UAA+BlB,EAoC1ClM,YAAYmI,EAAe3D,GACzB6E,MAAMlB,GAnCRjI,eAA4D,KAoC1DA,KAAKsE,SAAW,IAAK8H,KAAoB9H,GACzCtE,KAAKwM,QAAU1D,EAAQb,EAAM9B,MAAO8B,EAAM/B,QAnC5CoC,mBACE,OAAOtI,KAAKsE,SAASgE,aAGvBwE,eACE,OAAO9M,KAAKsE,SAASwI,SAGvBC,mBACE,OAAO/M,KAAKsE,SAASyI,aAGvBA,iBAAiB9E,GACfjI,KAAKsE,SAASyI,aAAe9E,EAG/BgF,iBACE,OAAOjN,KAAKsE,SAAS2I,WAGvBA,eAAehF,GACbjI,KAAKsE,SAAS2I,WAAahF,EAG7B+E,oBACE,OAAOhN,KAAKsE,SAAS0I,cAGvBA,kBAAkB/E,GAChBjI,KAAKsE,SAAS0I,cAAgB/E,EAShCnI,MACE,MAAMwG,EAAUtG,KAAKmN,UACnBnN,KAAKwM,QACLxM,KAAK+M,aAAa5F,QAClBnH,KAAKgN,cAAc7F,QACnBnH,KAAKiN,WAAW7F,QAGlB,OADApH,KAAKwM,QAAUlG,EAAOkG,QACflG,EAAOpD,OAGhBpD,eACEE,KAAKmN,UAAYvI,EACf,CACE4H,QAASD,GAEXJ,EACA,CACE7F,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACTqC,aAActI,KAAKsI,aACnBwE,SAAU9M,KAAK8M,sBAOTM,EACdnF,EACA3D,GAEA,OAAO,IAAI4I,EAAuBjF,EAAO3D,YC1H3B+I,GACd7N,EACA8N,EACAC,GAEA,OAAOA,EAAmBD,GAAS,EAAIA,GAAS9N,EAAQA,WAG1CgO,GAAY/N,EAAeH,EAAamO,GACtD,OAAIhO,EAAQH,EACHA,EAELG,EAAQgO,EACHA,EAEFhO,WAYO0M,GAEdhF,EACAC,EACAsG,GAEA,MAAMlO,EAAQ4H,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC1CoI,EAAeH,GACnBhO,EACAQ,KAAKiG,UAAU2H,WACd5N,KAAKiG,UAAU2H,WAEZxO,EAAS+H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC5CgI,EAAmBG,EAAgB1N,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC9DuH,EAAWO,GACf7N,EACAQ,KAAKiG,UAAU4H,UACfN,GAEF,OACEnO,GACEY,KAAKiG,UAAUqC,aAAeqF,EAC9BtO,KAAKyO,KAAKhB,EAAW9M,KAAKiG,UAAU8H,WACtC/N,KAAKiG,UAAU+H,uBAAyB5O,EA2BrC,MAAM6O,GAAwD,CACnEJ,UAAW,KACXG,uBAAwB,KACxB1F,aAAc,IACdyF,UAAW,KACXH,UAAW,SAGAM,WAA2ClC,EAyBtDlM,YACEmM,EACA3H,EAAiE,IAEjE6E,MAAM8C,GA3BRjM,eAA4D,KA4B1DA,KAAKsE,SAAW,IAAK2J,MAAa3J,GAClCtE,KAAKmO,QAAUrF,EAAQmD,EAAc9F,MAAO8F,EAAc/F,QA1B5D0H,gBACE,OAAO5N,KAAKsE,SAASsJ,UAGvBC,gBACE,OAAO7N,KAAKsE,SAASuJ,UAGvBvF,mBACE,OAAOtI,KAAKsE,SAASgE,aAGvB0F,6BACE,OAAOhO,KAAKsE,SAAS0J,uBAGvBD,gBACE,OAAO/N,KAAKsE,SAASyJ,UAYvBjO,IAAImI,GACF,MAAMkG,QAAEA,EAAOjL,OAAEA,GAAYlD,KAAKmN,UAE/BlF,EAAMd,QAASc,EAAMb,OAAQpH,KAAKmO,SAGrC,OAFApJ,EAAQ/E,KAAKmO,SACbnO,KAAKmO,QAAUA,EACRjL,EAGTpD,eACEE,KAAKmN,UAAYvI,EACf,CACEuJ,QAASd,IAEXlB,GACA,CACE7F,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACT2H,UAAW5N,KAAK4N,UAChBC,UAAW7N,KAAK6N,UAChBvF,aAActI,KAAKsI,aACnB0F,uBAAwBhO,KAAKgO,uBAC7BD,UAAW/N,KAAK+N,WAElBK,UAAW,CAACZ,IACZjH,WAAW,cAMH8H,GACdpG,EACA3D,GAEA,OAAO,IAAI4J,GAAmCjG,EAAO3D,GAMhD,MAAMgK,GAAWJ,GACXK,GAAWF,yPC5KRG,GACdvG,EACAwG,GAEIxG,EAAM7E,eAAe,cACvBoL,GACGvG,EAA0CiB,WAC3CuF,IAGExG,EAAM7E,eAAe,gBACvBoL,GACGvG,EAA2C6B,YAC5C2E,GAGAxG,EAAM7E,eAAe,gBACvBoL,GACGvG,EAA2C8B,YAC5C0E,IAINA,EAAGxG,YCtBWyG,GAAcC,GAC5B,MAAMzL,EAASyL,EAAO3L,MAAM,GAC5B,IAAK,IAAItB,EAAI,EAAGA,EAAIwB,EAAOvB,OAAQD,IAAK,CACtC,IAAI+J,EAAS,EACb+C,GAAmBtL,EAAOxB,GAAKuG,IACxB/E,EAAO0L,SAAS3G,KACnB/E,EAAOD,OAAOvB,EAAI+J,EAAQ,EAAGxD,GAC7BwD,OAIN,OAAOvI,WCZO2L,GAAcC,EAAgBC,GAC5C,GAAID,EAAO3I,QAAU4I,EAAO5I,MAC1B,MAAM,IAAIjE,MACR,2BAA2B4M,EAAO3I,aAAa4I,EAAO5I,SAI1D,GAAI2I,EAAO5I,SAAW6I,EAAO7I,OAC3B,MAAM,IAAIhE,MACR,4BAA4B4M,EAAO5I,cAAc6I,EAAO7I,mBCL9C8I,GAEdC,EACAC,GAEA,OACED,EAAcjP,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACzC2J,EAAclP,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,SAIhC4J,WAAYtF,EACvB1D,YACE,OAAOnG,KAAK8J,YAAY3D,MAG1BD,aACE,OAAOlG,KAAK8J,YAAY5D,OAG1BgB,YACE,OAAOlH,KAAK8J,YAAY5C,MAG1BpH,WACEqJ,MAAMC,WACNyF,GAAc7O,KAAK8J,YAAa9J,KAAK+J,aAGvCjK,eACEE,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BK,WAAW,IAIfzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAK8J,YAAY3C,QACjBnH,KAAK+J,YAAY5C,SAEnBhC,EAAMnF,KAAKoH,QAGbtH,UAEEiF,EAAQ/E,KAAK8J,YAAY1C,QACzBrC,EAAQ/E,KAAK+J,YAAY3C,QACzBpH,KAAK8J,YAAY1C,OAAS1B,EAAM1F,KAAKoH,QACrCpH,KAAK+J,YAAY3C,OAAS1B,EAAM1F,KAAKoH,QAGvCtH,mBAGc8G,GACdkD,EACAC,EACAzF,GAEA,OAAO,IAAI6K,GAAIrF,EAAaC,EAAazF,YCnE3B8K,KACd,MAAuB,GAAhB/P,KAAKyC,SAAiB,YCIfuN,GAAY5B,EAAanO,GACvC,OAAOD,KAAKyC,UAAYxC,EAAMmO,GAAOA,WAOvB6B,KACd,GAAIA,GAAYC,QAEd,OADAD,GAAYC,SAAU,EACfD,GAAYE,KAErB,MAAMC,EAAI,EAAIpQ,KAAKyC,SAAW,EACxB4N,EAAI,EAAIrQ,KAAKyC,SAAW,EACxB6N,EAAIF,EAAIA,EAAIC,EAAIA,EACtB,GAAU,IAANC,GAAWA,EAAI,EACjB,OAAOL,KAET,MAAMM,EAAIvQ,KAAKyO,MAAO,EAAIzO,KAAKwQ,IAAIF,GAAMA,GAGzC,OAFAL,GAAYE,KAAOE,EAAIE,EACvBN,GAAYC,SAAU,EACfE,EAAIG,EAqBbN,GAAYC,SAAU,EACtBD,GAAYE,KAAO,4FAdW/B,EAAanO,GACzC,OAAOD,KAAKwC,MAAMxC,KAAKyC,UAAYxC,EAAMmO,GAAOA,qBAQ1BqC,EAAYC,GAClC,OAAOD,EAAKR,KAAgBS,cCvCdC,GAAO5N,EAAc2N,EAAqB,MACxD,MAAMtO,EAAsB,IAAIkE,aAAavD,GAC7C,GAAY,OAAR2N,EACF,IAAK,IAAIrO,EAAI,EAAGA,EAAIU,EAAMV,IACxBD,EAAMC,GAAK0N,UAGb,IAAK,IAAI1N,EAAI,EAAGA,EAAIU,EAAMV,IACxBD,EAAMC,GAAK2N,IAAaU,EAAKA,GAGjC,OAAOtO,WAMOwO,GACd9J,EACAD,EACA6J,GAEA,MAAM7M,EAAyB,IAAIkC,MAAMc,GACzC,IAAK,IAAIV,EAAI,EAAGA,EAAIU,EAAQV,IAC1BtC,EAAOsC,GAAKwK,GAAO7J,EAAO4J,GAE5B,OAAO7M,WAMOgN,GACd/J,EACAD,EACAgB,EACA6I,GAEA,MAAM7M,EAA2B,IAAIkC,MAAM8B,GAC3C,IAAK,IAAI8B,EAAI,EAAGA,EAAI9B,EAAO8B,IACzB9F,EAAO8F,GAAKiH,GAAS9J,EAAOD,EAAQ6J,GAEtC,OAAO7M,ECvCF,MAAM+K,GAA4B,IACpChH,EACH8I,IAAK,YAGMI,WAAe5F,EAE1BzK,YAAYwE,GACV6E,QACAnJ,KAAKsE,SAAW,IAAK2J,MAAa3J,GAClCtE,KAAKwH,cACLxH,KAAKoJ,WAEApJ,KAAKmH,UACRnH,KAAKmH,QAAU8I,GAASjQ,KAAKmG,MAAOnG,KAAKkG,OAAQ5B,EAASyL,MAEvD/P,KAAKoH,SACRpH,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,SAI3CpG,WAEAA,qBAGcgC,GAAOwC,GACrB,OAAO,IAAI6L,GAAO7L,YCtBJ0K,GAEdoB,EACAC,GAEA,IAAIrK,EAAM,EACV,IAAK,IAAItE,EAAI,EAAGA,EAAI1B,KAAKiG,UAAU7D,KAAMV,IACvCsE,GAAOoK,EAASpQ,KAAKiK,OAAOzE,GAAG9D,GAAK2O,EAAS3O,GAAG1B,KAAKiK,OAAO1E,GAE9D,OAAOS,WAGOsK,GAEdlJ,EACAsF,EACA6D,GAEA,IAAIvK,EAAM0G,EAAY1M,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACjD,IAAK,IAAI7D,EAAI,EAAGA,EAAI1B,KAAKiG,UAAU7D,KAAMV,IACvCsE,GAAOoB,EAAOpH,KAAKiK,OAAOzE,GAAG9D,GAAK6O,EAAavQ,KAAKiK,OAAO1E,GAAG7D,GAEhE,OAAOsE,WAGOwK,GAEdpJ,EACAsF,EACA6D,GAEA,IAAIvK,EAAM0G,EAAY1M,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACjD,IAAK,IAAI7D,EAAI,EAAGA,EAAI1B,KAAKiG,UAAU7D,KAAMV,IACvCsE,GAAOoB,EAAO1F,GAAG1B,KAAKiK,OAAO1E,GAAKgL,EAAa7O,GAAG1B,KAAKiK,OAAOzE,GAEhE,OAAOQ,QAGIyK,WAAiB5G,EAA9B/J,kCACEE,oBAA4C,KAC5CA,oBAA4C,KAE5CmG,YACE,OAAOnG,KAAK+J,YAAY5D,MAG1BA,UAAUA,GACR,MAAM,IAAIjE,MAAM,gCAGlBgE,aACE,OAAOlG,KAAK8J,YAAY5D,OAG1BA,WAAWA,GACT,MAAM,IAAIhE,MAAM,iCAGlBgF,YACE,OAAOlH,KAAK8J,YAAY5C,MAG1BA,UAAUA,GACR,MAAM,IAAIhF,MAAM,gCAGlBpC,WAEE,GADAqJ,MAAMC,WACFpJ,KAAK8J,YAAY3D,QAAUnG,KAAK+J,YAAY7D,OAC9C,MAAM,IAAIhE,MACR,2BAA2BlC,KAAK8J,YAAY3D,aAAanG,KAAK+J,YAAY7D,UAKhFpG,eACEE,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACT7D,KAAMpC,KAAK+J,YAAY7D,QAEzBK,WAAW,IAEbvG,KAAK0Q,eAAiBtM,EAAWkM,GAAc,CAC7ChK,OAAQ,CAACtG,KAAK8J,YAAY3D,MAAOnG,KAAK8J,YAAY5D,QAClDD,UAAW,CACT7D,KAAMpC,KAAK+J,YAAY5D,OAEzBI,WAAW,IAEbvG,KAAK2Q,eAAiBvM,EAAWoM,GAAc,CAC7ClK,OAAQ,CAACtG,KAAK+J,YAAY5D,MAAOnG,KAAK+J,YAAY7D,QAClDD,UAAW,CACT7D,KAAMpC,KAAK8J,YAAY5D,QAEzBK,WAAW,IAIfzG,aAAamI,GACXkB,MAAMyH,aAAa3I,GACnBjI,KAAK0Q,eAAkBzI,EAAmByI,eAC1C1Q,KAAK2Q,eAAkB1I,EAAmB0I,eAG5C7Q,UAEE,GADAiF,EAAQ/E,KAAKmH,UACRnH,KAAKkI,cAAe,MAAM,IAAIhG,MAAM,iCACzClC,KAAKmH,QAAUnH,KAAKkI,cAClBlI,KAAK8J,YAAY3C,QACjBnH,KAAK+J,YAAY5C,SAEnBhC,EAAMnF,KAAKoH,QAGbtH,UACE,IAAKE,KAAK0Q,eAAgB,MAAM,IAAIxO,MAAM,+BAC1C,IAAKlC,KAAK2Q,eAAgB,MAAM,IAAIzO,MAAM,+BAE1C,MAAM2O,EAAoB7Q,KAAK8J,YAAY1C,OACrC0J,EAAoB9Q,KAAK+J,YAAY3C,OAErC2J,EAAa/Q,KAAK0Q,eACtB1Q,KAAKoH,OACLpH,KAAK8J,YAAY1C,OACjBpH,KAAK+J,YAAY5C,SAEb6J,EAAahR,KAAK2Q,eACtB3Q,KAAKoH,OACLpH,KAAK+J,YAAY3C,OACjBpH,KAAK8J,YAAY3C,SAGnBnH,KAAK+J,YAAY3C,OAAS4J,EAC1BhR,KAAK8J,YAAY1C,OAAS2J,EAE1BhM,EAAQ8L,GACR9L,EAAQ+L,GAGVhR,eACAA,SAEAA,SACE,MAAO,IACFqJ,MAAM3H,SACT2E,MAAOnG,KAAKmG,MACZD,OAAQlG,KAAKkG,kBAKH+K,GACdnH,EACAC,EACAzF,GAEA,OAAO,IAAImM,GAAS3G,EAAaC,EAAazF,YCpKhC4M,GAEd9I,GAEA,OAAO,GAAK,EAAI/I,KAAKK,KAAK0I,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,cAG9C4L,GAEd/I,GAEA,OACE,GAAK,EAAI/I,KAAKK,KAAK0I,EAAOpI,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,cAIxD2E,GAEd/C,EACAC,GAEA,MAAMhI,EAAS+H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAElD,OAAOnG,GAAU,EAAIA,GADPgI,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAIlC6L,GAEdjK,EACAC,GAEA,MAAMhI,EAAS+H,EAAQnH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAEjE,OAAOnG,GAAU,EAAIA,GADPgI,EAAOpH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,SAIpD8L,WAAgBpI,EAC3BnJ,eACME,KAAKkH,MAAQ,GACflH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCkH,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAWgN,GAAW,CACzC9K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCkH,UAAW,CAAC7O,GACZgH,WAAW,MAGbvG,KAAKkI,cAAgB9D,EAAW8M,GAAW,CACzC5K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BkI,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAW8F,GAAW,CACzC5D,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BkI,UAAW,CAAC7O,GACZgH,WAAW,KAKjBzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,SAElBhC,EAAMnF,KAAKoH,QAGbtH,UACEiF,EAAQ/E,KAAKkJ,WAAW9B,QACxBpH,KAAKkJ,WAAW9B,OAAUpH,KAAKmI,cAC7BnI,KAAKmH,QACLnH,KAAKoH,kBAKKkK,GACdpI,EACA5E,GAEA,OAAO,IAAI+M,GAAQnI,EAAY5E,YCtFjBiN,GACdjN,EACA2J,GAEA,GAA+B,iBAApB3J,EAASkN,OAClB,MAAO,CAAEC,QAASnN,EAASkN,OAAQE,QAASpN,EAASkN,QAChD,CACL,IAAIC,EAAkBxD,EAASuD,OAC3BE,EAAkBzD,EAASuD,OAO/B,MANgC,iBAArBlN,EAASmN,UAClBA,EAAUnN,EAASmN,SAEW,iBAArBnN,EAASoN,UAClBA,EAAUpN,EAASoN,SAEd,CAAED,QAAAA,EAASC,QAAAA,aASNC,GACdrN,EACA2J,GAEA,GAAgC,iBAArB3J,EAASsN,QAClB,MAAO,CAAEC,SAAUvN,EAASsN,QAASE,SAAUxN,EAASsN,SACnD,CACL,IAAIC,EAAmB5D,EAAS2D,QAC5BE,EAAmB7D,EAAS2D,QAOhC,MANiC,iBAAtBtN,EAASuN,WAClBA,EAAWvN,EAASuN,UAEW,iBAAtBvN,EAASwN,WAClBA,EAAWxN,EAASwN,UAEf,CAAED,SAAAA,EAAUC,SAAAA,aC3CPC,GAAO3P,EAAc3C,GACnC,OAAO,IAAIkG,aAAavD,GAAMkD,KAAK7F,YCyBrBuP,GAEd5G,EACAqB,EACAuI,GAEA,MAAMC,EACJjS,KAAKiG,UAAU4L,SAAW7R,KAAKiK,OAAO1E,EAAIvF,KAAKiG,UAAUwL,QACrDS,EACJlS,KAAKiK,OAAO1E,EAAIvF,KAAKiG,UAAUwL,QAAUzR,KAAKiG,UAAU4L,SACpDM,EAAa9S,KAAKoO,IACtBzN,KAAKiG,UAAUsD,YACf0I,EAAejS,KAAKiG,UAAUmM,YAG1BC,EACJrS,KAAKiG,UAAU6L,SAAW9R,KAAKiK,OAAOzE,EAAIxF,KAAKiG,UAAUyL,QACrDY,EACJtS,KAAKiK,OAAOzE,EAAIxF,KAAKiG,UAAUyL,QAAU1R,KAAKiG,UAAU6L,SACpDS,EAAalT,KAAKoO,IACtBzN,KAAKiG,UAAUuD,aACf6I,EAAerS,KAAKiG,UAAUuM,aAGhC,IAAIxM,EAAM,EACV,IAAK,IAAIgD,EAAI,EAAGA,EAAIhJ,KAAKiG,UAAUwM,WAAYzJ,IAC7C,IACE,IAAI0J,EAAUrT,KAAKC,IAAI,EAAG+S,GACxBM,EAAStT,KAAKC,IAAI,EAAGgT,GACvBI,EAAUH,EACVG,IAAWC,IAEX,IACE,IAAIC,EAAUvT,KAAKC,IAAI,EAAG2S,GACxBY,EAASxT,KAAKC,IAAI,EAAG4S,GACvBU,EAAUT,EACVS,IAAWC,IAEX7M,GAAOyD,EAAQT,GAAG0J,GAASE,GAAWxK,EAAOY,GAAG2J,GAAQE,GAI9D,OAAO7M,EAAMgM,EAAOhS,KAAKiK,OAAOjB,YAYlB8J,GAEdpJ,EACAtB,EACAhB,GAEA,MAAM2L,EAAc1T,KAAKC,IACvB,EACAD,KAAK2T,MACFhT,KAAKiG,UAAU4L,SAAW7R,KAAKiK,OAAO1E,GAAKvF,KAAKiG,UAAUwL,UAGzDS,EACJa,EAAc/S,KAAKiG,UAAUwL,QAC7BzR,KAAKiK,OAAO1E,EACZvF,KAAKiG,UAAU4L,SACXoB,EAAY5T,KAAKoO,IACrBzN,KAAKiG,UAAUiN,WACf7T,KAAKwC,OACF7B,KAAKiG,UAAUmM,WACd,EACApS,KAAKiK,OAAO1E,EACZvF,KAAKiG,UAAU4L,UACf7R,KAAKiG,UAAUwL,SACf,GAGA0B,EAAc9T,KAAKC,IACvB,EACAD,KAAK2T,MACFhT,KAAKiG,UAAU6L,SAAW9R,KAAKiK,OAAOzE,GAAKxF,KAAKiG,UAAUyL,UAGzDY,EACJa,EAAcnT,KAAKiG,UAAUyL,QAC7B1R,KAAKiK,OAAOzE,EACZxF,KAAKiG,UAAU6L,SACXsB,EAAY/T,KAAKoO,IACrBzN,KAAKiG,UAAUoN,YACfhU,KAAKwC,OACF7B,KAAKiG,UAAUuM,YACd,EACAxS,KAAKiK,OAAOzE,EACZxF,KAAKiG,UAAU6L,UACf9R,KAAKiG,UAAUyL,SACf,GAGN,IAAI1L,EAAM0D,EAAa1J,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACjE,IACE,IAAI+N,EAASH,EAAaR,EAASL,EACnCgB,EAASF,EACTE,IAAUX,GAAU3S,KAAKiG,UAAUyL,QAEnC,IACE,IAAI6B,EAASR,EAAaF,EAASX,EACnCqB,EAASN,EACTM,IAAUV,GAAU7S,KAAKiG,UAAUwL,QAEnCzL,GACEoC,EAAOpI,KAAKiK,OAAOjB,GAAG2J,GAAQE,GAC9BzL,EAAOpH,KAAKiG,UAAUuN,QAAQF,GAAQC,GAG5C,OAAOvN,WAUOyN,GAEd/G,EACAjD,EACArC,GAEA,MAAM7B,EAAIvF,KAAKiK,OAAO1E,EAAIvF,KAAKiG,UAAU4L,SACnCkB,EACJxN,EAAIvF,KAAKiG,UAAUsD,YACf,EACAlK,KAAKwC,OACF0D,EAAIvF,KAAKiG,UAAUsD,YAAcvJ,KAAKiG,UAAUwL,SAC/CzR,KAAKiG,UAAUwL,SAEnBQ,EAAe1M,EAAIwN,EAAc/S,KAAKiG,UAAUwL,QAChDwB,EAAY5T,KAAKoO,IACrBsF,EAAc1T,KAAKwC,MAAMoQ,EAAejS,KAAKiG,UAAUwL,SAAW,EAClEzR,KAAKiG,UAAUiN,YAGX1N,EAAIxF,KAAKiK,OAAOzE,EAAIxF,KAAKiG,UAAU6L,SACnCqB,EACJ3N,EAAIxF,KAAKiG,UAAUuD,aACf,EACAnK,KAAKwC,OACF2D,EAAIxF,KAAKiG,UAAUuD,aAAexJ,KAAKiG,UAAUyL,SAChD1R,KAAKiG,UAAUyL,SAEnBW,EAAe7M,EAAI2N,EAAcnT,KAAKiG,UAAUyL,QAChD0B,EAAY/T,KAAKoO,IACrB0F,EAAc9T,KAAKwC,MAAMwQ,EAAerS,KAAKiG,UAAUyL,SAAW,EAClE1R,KAAKiG,UAAUoN,aAGjB,IAAIrN,EAAM0G,EAAY1M,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC5D+N,EAASH,EACb,IACE,IAAIT,EAAUL,EACdiB,EAASF,EACTV,GAAW1S,KAAKiG,UAAUyL,QAAS4B,IACnC,CACA,IAAIC,EAASR,EACb,IACE,IAAIH,EAAUX,EACdsB,EAASN,EACTL,GAAW5S,KAAKiG,UAAUwL,QAAS8B,IAEnCvN,GACEyD,EAAQzJ,KAAKiK,OAAOjB,GAAG0J,GAASE,GAChCxL,EAAOpH,KAAKiG,UAAUuN,QAAQF,GAAQC,GAG5C,OAAOvN,WAQO0N,GAEdC,EACAvM,GAEA,IAAIpB,EAAM,EACV,IAAK,IAAIR,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUoN,YAAa7N,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUiN,WAAY3N,IAC7CS,GAAOoB,EAAOpH,KAAKiK,OAAOjB,GAAGxD,GAAGD,GAGpC,OAAOoO,EAAW3T,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAKS,EAyB5D,MAAMiI,GAAiC,CAC5CuD,OAAQ,EACRI,QAAS,EACTgC,KAAM,GACNtK,YAAa,EACbC,YAAa,EACbC,aAAc,SAGHqK,WAAoBxK,EA2E/BvJ,YAAYwE,EAAgC4E,aAC1CC,MAAM7E,EAAU4E,GA0BlBlJ,+BAAuD,KACvDA,8BAAsD,KACtDA,yBAAiD,KA3B/CA,KAAKsE,SAAW,IACX2J,MACA3J,KACAqN,GAAWrN,EAAU2J,OACrBsD,GAAUjN,EAAU2J,KAGzBjO,KAAKmH,kBACH7C,EAAS6C,uBAAW+I,GAASlQ,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OAC7DlH,KAAKoH,OAAS2B,EAAQ/I,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OAEpDlH,KAAKgS,OAASD,GAAO/R,KAAKkH,MAAOlH,KAAK4T,MACtC5T,KAAK2T,qBAAarP,EAASqP,0BAAc3D,GAAOhQ,KAAKkH,OAErDlH,KAAKyJ,kBACHnF,EAASmF,uBACTyG,GAASlQ,KAAKuJ,YAAavJ,KAAKwJ,aAAcxJ,KAAKsJ,aACrDtJ,KAAK0J,aAAeX,EAClB/I,KAAKuJ,YACLvJ,KAAKwJ,aACLxJ,KAAKsJ,aAEPtJ,KAAKoJ,WAhGPqI,cACE,OAAOzR,KAAKsE,SAASmN,QAGvBC,cACE,OAAO1R,KAAKsE,SAASoN,QAGvBG,eACE,OAAO7R,KAAKsE,SAASuN,SAGvBC,eACE,OAAO9R,KAAKsE,SAASuN,SAGvB1L,YACE,OAAO9G,KAAKwC,OACT7B,KAAKkJ,WAAW/C,MAAwB,EAAhBnG,KAAK6R,SAAe7R,KAAKuJ,aAChDvJ,KAAKyR,QACL,GAINvL,aACE,OAAO7G,KAAKwC,OACT7B,KAAKkJ,WAAWhD,OAAyB,EAAhBlG,KAAK8R,SAAe9R,KAAKwJ,cACjDxJ,KAAK0R,QACL,GAINkC,WACE,OAAO5T,KAAKsE,SAASsP,KAGvB1M,YACE,OAAOlH,KAAKsJ,YAGd0I,aACE,OAAOhS,KAAKsE,SAAS0N,OAGvBA,WAAWA,GACThS,KAAKsE,SAAS0N,OAASA,EAGzB2B,iBACE,OAAO3T,KAAKsE,SAASqP,WAGvBA,eAAexM,GACbnH,KAAKsE,SAASqP,WAAaxM,EAG7BsC,cACE,OAAOzJ,KAAKsE,SAASmF,QAGvBA,YAAYA,GACVzJ,KAAKsE,SAASmF,QAAUA,EAG1BC,mBACE,OAAO1J,KAAKsE,SAASoF,aAGvBA,iBAAiBA,GACf1J,KAAKsE,SAASoF,aAAeA,EAiC/B5J,eACEE,KAAKkI,cAAgB9D,EAGnB4K,GAAS,CACT/I,UAAW,CACTmM,WAAYpS,KAAKkJ,WAAW/C,MAC5BqM,YAAaxS,KAAKkJ,WAAWhD,OAC7BuM,WAAYzS,KAAKkJ,WAAWhC,MAC5BuK,QAASzR,KAAKyR,QACdC,QAAS1R,KAAK0R,QACdG,SAAU7R,KAAK6R,SACfC,SAAU9R,KAAK8R,SACfvI,YAAavJ,KAAKuJ,YAClBC,aAAcxJ,KAAKwJ,cAErBlD,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCX,WAAW,IAGbvG,KAAK8T,0BAA4B1P,EAAW0O,GAAqB,CAC/D7M,UAAW,CACT8N,YAAa/T,KAAKmG,MAClB6N,aAAchU,KAAKkG,OACnB+N,YAAajU,KAAKkH,MAClBkL,WAAYpS,KAAKkJ,WAAW/C,MAC5BqM,YAAaxS,KAAKkJ,WAAWhD,OAC7BuM,WAAYzS,KAAKkJ,WAAWhC,MAC5BuK,QAASzR,KAAKyR,QACdC,QAAS1R,KAAK0R,QACdG,SAAU7R,KAAK6R,SACfC,SAAU9R,KAAK8R,SACfvI,YAAavJ,KAAKuJ,YAClBC,aAAcxJ,KAAKwJ,cAErBlD,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCX,WAAW,IAGbvG,KAAKkU,yBAA2B9P,EAAWqP,GAAoB,CAC7DxN,UAAW,CACTqD,YAAatJ,KAAKsJ,aAEpBhD,OAAQ,CACNtG,KAAKkJ,WAAW/C,MAChBnG,KAAKkJ,WAAWhD,OAChBlG,KAAKkJ,WAAWhC,OAElBX,WAAW,IAGbvG,KAAKmU,oBAAsB/P,EAAWsP,GAAe,CACnDpN,OAAQ,CAAC,EAAG,EAAGtG,KAAKkH,OACpBjB,UAAW,CACTiN,WAAYlT,KAAKmG,MACjBkN,YAAarT,KAAKkG,QAEpBK,WAAW,IAIfzG,UACEE,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,QAChBnH,KAAKyJ,QACLzJ,KAAKgS,QAITlS,UACE,MAAM4J,aAAEA,EAAYiK,WAAEA,GAAe3T,KACrCA,KAAK0J,aAAgB1J,KAAK8T,0BACxBpK,EACA1J,KAAKkJ,WAAW/B,QAChBnH,KAAKoH,QAEPrC,EAAQ2E,GACR1J,KAAK2T,WAAc3T,KAAKmU,oBACtBR,EACA3T,KAAKoH,QAEPrC,EAAQ4O,GACR5O,EAAQ/E,KAAKoH,QACbpH,KAAKoH,OAAUpH,KAAKkU,yBAClBlU,KAAKyJ,QACLzJ,KAAKkJ,WAAW9B,QAGlBrC,EAAQ/E,KAAKkJ,WAAW9B,QAExBpH,KAAKkJ,WAAW9B,OAAS1B,EAAM1F,KAAKoH,QAGtCtH,MAAMwI,GAGJ,MAAQnB,QAASoB,GAAevI,KAChCA,KAAKmH,QAAWnH,KAAKqH,OAAmBmB,IAAIxI,KAAMsI,GAClDvD,EAAQwD,GACRpD,EAAMnF,KAAKoH,kBCtcCgN,GAAWC,GACzB,OAAOA,WAOOC,GAEdlM,GAEA,OAAe/I,KAAKyC,SAAY9B,KAAKiG,UAAUsO,YACtC,EAEFnM,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAG3ByJ,GAEd5G,GAEA,OAAOA,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAKvF,KAAKiG,UAAUsO,qBAG/CC,GAEdC,EACArN,GAEA,OAA+C,IAA3CqN,EAASzU,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC/B,EAEF6B,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAOpC,MAAMmP,GAAoC,IAC5CzN,EACHsN,YAAa,UAGFI,WAAgBtL,EAI3BvJ,YACEoJ,EACA5E,GAEA6E,MAAM7E,EAAsC4E,GAN9ClJ,sBAAmE,KAOjEA,KAAKsE,SAAW,IAAKoQ,MAAoBpQ,GACzCtE,KAAKyU,SAAW,KAChBzU,KAAKoJ,WAGPtJ,aAAakI,GACX,MAAM1B,EAAS,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAE7B8B,GACFhI,KAAK4U,iBAAmBhQ,EAGtB,CAAE6P,SAAUL,IAAcE,GAAiB,CAC3ChO,OAAAA,EACAC,WAAW,IAEbvG,KAAKmI,cAAgB/D,EAAWoQ,GAAS,CAAElO,OAAAA,EAAQC,WAAW,KAE9DvG,KAAK4U,iBAAmBhQ,EAGtB,GAAIoK,GAAS,CAAE1I,OAAAA,EAAQC,WAAW,IAIxCzG,UACEiF,EAAQ/E,KAAKmH,SACTnH,KAAKyU,UACP1P,EAAQ/E,KAAKyU,UAEf,MAAMvR,OAAEA,EAAMuR,SAAEA,GAAczU,KAC3B4U,iBACD5U,KAAKkJ,WAAW/B,SAElBnH,KAAKmH,QAAUjE,EACflD,KAAKyU,SAAWA,EAGlB3U,UACEiF,EAAQ/E,KAAKoH,QACbpH,KAAKoH,OAAUpH,KAAKmI,cAClBnI,KAAKyU,SACLzU,KAAKkJ,WAAW9B,kBCxFN4H,GAEd5G,EACAqB,EACAuI,GAEA,IAAI1L,EAAS,EACT5E,EAAI,EACR,IAAK,IAAI8D,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAC7Ce,GAAU8B,EAAO5C,GAAGD,GAAKkE,EAAQzJ,KAAKiK,OAAO1E,GAAG7D,GAChDA,IAGJ,OAAO4E,EAAS0L,EAAOhS,KAAKiK,OAAO1E,YAGrB4L,GAEd/I,EACAqB,EACAuI,GAEA,IAAI1L,EAAS,EACT5E,EAAI,EACR,IAAK,IAAIsH,EAAI,EAAGA,EAAIhJ,KAAKiG,UAAUwM,WAAYzJ,IAC7C,IAAK,IAAIxD,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAC7Ce,GAAU8B,EAAOY,GAAGxD,GAAGD,GAAKkE,EAAQzJ,KAAKiK,OAAO1E,GAAG7D,GACnDA,IAIN,OAAO4E,EAAS0L,EAAOhS,KAAKiK,OAAO1E,YAOrBkO,GAEd/G,EACAtF,EACAqC,GAEA,IAAIzD,EAAM,EACV,MAAM4M,EAAU5S,KAAKiK,OAAO1E,EAAIvF,KAAKiK,OAAOzE,EAAIxF,KAAKsG,OAAOf,EAC5D,IAAK,IAAImN,EAAU,EAAGA,EAAU1S,KAAKiG,UAAUqD,YAAaoJ,IAC1D1M,GAAOyD,EAAQiJ,GAASE,GAAWxL,EAAO,GAAGsL,GAE/C,OAAO1M,EAAM0G,EAAY1M,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAGtCsP,GAEdnI,EACAtF,EACAqC,GAEA,IAAIzD,EAAM,EACV,MAAM4M,EAAU5S,KAAKiK,OAAO1E,EAAIvF,KAAKiK,OAAOzE,EAAIxF,KAAKsG,OAAOf,EAC5D,IAAK,IAAImN,EAAU,EAAGA,EAAU1S,KAAKiG,UAAUqD,YAAaoJ,IAC1D1M,GAAOyD,EAAQiJ,GAASE,GAAWxL,EAAO,GAAGsL,GAE/C,OAAO1M,EAAM0G,EAAY1M,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAGrDmO,GAEd1B,EACA5K,GAEA,OAAO4K,EAAOhS,KAAKiK,OAAO1E,GAAK6B,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAUnDuN,GAEdpJ,EACA6G,EACAnJ,GAEA,OACEsC,EAAa1J,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACxCgL,EAAavQ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACtC6B,EAAOpH,KAAKiG,UAAUqN,QAAQtT,KAAKiG,UAAUsN,iBAInCuB,GAEdpL,EACA6G,EACAnJ,GAEA,MAAM2N,EAAS1V,KAAKwC,MAClB7B,KAAKiK,OAAO1E,GAAKvF,KAAKiG,UAAUmM,WAAapS,KAAKiG,UAAUuM,cAExDG,EAAStT,KAAKwC,OACjB7B,KAAKiK,OAAO1E,EACXwP,EAAS/U,KAAKiG,UAAUmM,WAAapS,KAAKiG,UAAUuM,aACpDxS,KAAKiG,UAAUmM,YAEbS,EACJ7S,KAAKiK,OAAO1E,EACZvF,KAAKiG,UAAUmM,YAAcO,EAAS3S,KAAKiG,UAAUuM,YAAcuC,GACrE,OACErL,EAAa1J,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACxCgL,EAAawE,GAAQpC,GAAQE,GAAUzL,EAAO,GAAGpH,KAAKiK,OAAOzE,SAepDwP,WAAuB3L,EAyBlCvJ,YACEwE,EACA4E,GAEAC,MAAM7E,EAAU4E,GAPlBlJ,+BAAuD,KACvDA,8BAAsD,KACtDA,yBAAiD,KAM/CA,KAAKsE,SAAW,IAAKA,GACrBtE,KAAKoJ,WAEL,MAAM6L,EACJ/L,EAAW/C,MAAQ+C,EAAWhD,OAASgD,EAAWhC,MAEpDlH,KAAKgS,OAASD,GAAO/R,KAAKkG,OAAQlG,KAAK4T,MACvC5T,KAAK2T,WAAa9K,EAAM7I,KAAKkG,QAE7BlG,KAAKyJ,QAAUwG,GAASgF,EAAiBjV,KAAKkG,QAC9ClG,KAAK0J,aAAeZ,EAAQmM,EAAiBjV,KAAKkG,QAE9ClG,KAAKkH,MAAQ,GACflH,KAAKmH,QAAU+I,GAASlQ,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACtDlH,KAAKoH,OAAS2B,EAAQ/I,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,QAC3ClH,KAAKkG,OAAS,IACvBlG,KAAKmH,QAAU8I,GAASjQ,KAAKmG,MAAOnG,KAAKkG,QACzClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,SA9C3C0N,WACE,OAAO5T,KAAKsE,SAASsP,KAGvB5B,aACE,OAAOhS,KAAKsE,SAAS0N,OAGvBA,WAAWA,GACThS,KAAKsE,SAAS0N,OAASA,EAGzB2B,iBACE,OAAO3T,KAAKsE,SAAS0N,OAGvB2B,eAAeA,GACb3T,KAAKsE,SAASqP,WAAaA,EAiC7B7T,WAEE,GADAqJ,MAAMC,WACFpJ,KAAKkH,MAAQ,EAAG,MAAM,IAAIhF,MAAM,uBAGtCpC,eACE,MAAMoJ,WAAEA,GAAelJ,KACjBiV,EACJ/L,EAAW/C,MAAQ+C,EAAWhD,OAASgD,EAAWhC,MAChDgC,EAAWhC,MAAQ,GACrBlH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACTuM,YAAatJ,EAAWhD,OACxBkM,WAAYlJ,EAAW/C,MACvBsM,WAAYvJ,EAAWhC,SAI3BlH,KAAK8T,0BAA4B1P,EAAW0Q,GAAuB,CACjExO,OAAQ,CAAC2O,EAAiBjV,KAAKkG,QAC/BD,UAAW,CACTmM,WAAYlJ,EAAW/C,MACvBqM,YAAatJ,EAAWhD,QAE1BK,WAAW,IAGbvG,KAAKkU,yBAA2B9P,EAAWyQ,GAAsB,CAC/DvO,OAAQ,CAAC4C,EAAW/C,MAAO+C,EAAWhD,OAAQgD,EAAWhC,OACzDjB,UAAW,CACTqD,YAAatJ,KAAKkG,QAEpBK,WAAW,MAGbvG,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BD,UAAW,CACTuM,YAAatJ,EAAWhD,OACxBkM,WAAYlJ,EAAW/C,SAI3BnG,KAAK8T,0BAA4B1P,EAAW0O,GAAqB,CAC/DxM,OAAQ,CAAC2O,EAAiBjV,KAAKkG,QAC/BD,UAAW,CACTmM,WAAYlJ,EAAW/C,SAI3BnG,KAAKkU,yBAA2B9P,EAAWqP,GAAoB,CAC7DnN,OAAQ,CAAC4C,EAAW/C,MAAO+C,EAAWhD,QACtCD,UAAW,CACTqD,YAAatJ,KAAKkG,WAKxBlG,KAAKmU,oBAAsB/P,EAAWsP,GAAe,CACnDpN,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,UAI9BpG,UACEE,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,QAChBnH,KAAKyJ,QACLzJ,KAAKgS,QAITlS,UACE,MAAMoV,EAAmBlV,KAAKkJ,WAAW9B,OACzCpH,KAAKkJ,WAAW9B,OAAUpH,KACvBkU,yBACDgB,EACAlV,KAAKoH,OACLpH,KAAKyJ,SAEP1E,EAAQmQ,GAER,MAAMvB,WAAEA,EAAUjK,aAAEA,GAAiB1J,KAErCA,KAAK2T,WAAc3T,KAAKmU,oBACtBnU,KAAKgS,OACLhS,KAAKoH,QAIPpH,KAAK0J,aAAgB1J,KAAK8T,0BACxBpK,EACA1J,KAAKkJ,WAAW/B,QAChBnH,KAAKoH,QAEPrC,EAAQ4O,GACR5O,EAAQ2E,aCpSIsF,GAEd7H,GAEA,OAAQA,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,SAGhC4P,WAAiBvL,EAC5B9J,YAAYoJ,EAAoB5E,GAC9B6E,MAAMD,EAAY5E,GAClBtE,KAAKoJ,WAGPtJ,eACEE,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,UAI9BpG,UACEE,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,mBAKNiO,GACdlM,EACA5E,GAEA,OAAO,IAAI6Q,GAASjM,EAAY5E,YC7BlB0K,GAEdqG,EACAC,GAEA,OACED,EAAmBrV,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC9C+P,EAAmBtV,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,YAIlCiP,GAEdrN,EACAC,GAEA,OACED,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAK6B,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,SAIjEgQ,WAAwB1L,EACnC1D,YACE,OAAOnG,KAAK8J,YAAY3D,MAG1BD,aACE,OAAOlG,KAAK8J,YAAY5D,OAG1BgB,YACE,OAAOlH,KAAK8J,YAAY5C,MAG1BpH,WACEqJ,MAAMC,WACNyF,GAAc7O,KAAK8J,YAAa9J,KAAK+J,aAGvCjK,eACEE,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BK,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAWoQ,GAAS,CACvClO,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BK,WAAW,IAIfzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAK8J,YAAY3C,QACjBnH,KAAK+J,YAAY5C,SAEnBhC,EAAMnF,KAAKoH,QAGbtH,UACEiF,EAAQ/E,KAAK8J,YAAY1C,QACzBrC,EAAQ/E,KAAK+J,YAAY3C,QACzBpH,KAAK8J,YAAY1C,OAAUpH,KAAKmI,cAC9BnI,KAAK+J,YAAY5C,QACjBnH,KAAKoH,QAEPpH,KAAK+J,YAAY3C,OAAUpH,KAAKmI,cAC9BnI,KAAK8J,YAAY3C,QACjBnH,KAAKoH,kBAKKoO,GACd1L,EACAC,EACAzF,GAEA,OAAO,IAAIiR,GAAgBzL,EAAaC,EAAazF,YCrFvCmR,GAAKrT,GACnB,OAAO,IAAIuD,aAAavD,GAAMkD,KAAK,YAGrBoQ,GAAOvP,EAAeD,GACpC,MAAMhD,EAAS,IAAIkC,MAAMc,GACzB,IAAK,IAAIV,EAAI,EAAGA,EAAIU,EAAQV,IAC1BtC,EAAOsC,GAAKiQ,GAAKtP,GAEnB,OAAOjD,QCHIyS,WAAapL,EACxBzK,YAAYwE,GACV6E,MAAM7E,GACNtE,KAAKoJ,WACLpJ,KAAKmH,QAAUuO,GAAO1V,KAAKmG,MAAOnG,KAAKkG,QACvClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,kBAI3BuP,GAAKnR,GACnB,OAAO,IAAIqR,GAAKrR,YCTF4M,GAEd9I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGpC4L,GAEd/I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGnD2E,GAEd/C,EACApB,GAEA,OAAOxG,EACL4H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACnCQ,EAAO/F,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAItB6L,GAEdjK,EACApB,GAEA,OAAOxG,EACL4H,EAAQnH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAClDQ,EAAO/F,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,UAIxCqQ,WAAa3M,EACxBnJ,eACME,KAAKkH,MAAQ,GACflH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCkH,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAWgN,GAAW,CACzC9K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCkH,UAAW,CAAC7O,GACZgH,WAAW,MAGbvG,KAAKkI,cAAgB9D,EAAW8M,GAAW,CACzC5K,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BkI,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAW8F,GAAW,CACzC5D,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,QAC1BkI,UAAW,CAAC7O,GACZgH,WAAW,KAKjBzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,SAElBhC,EAAMnF,KAAKoH,QAGbtH,UACEiF,EAAQ/E,KAAKkJ,WAAW9B,QACxBpH,KAAKkJ,WAAW9B,OAAUpH,KAAKmI,cAC7BnI,KAAKmH,QACLnH,KAAKoH,kBAKKxH,GAAKsJ,EAAoB5E,GACvC,OAAO,IAAIsR,GAAK1M,EAAY5E,SCtFjBuR,WAActL,EACzBzK,YAAYwE,GACV6E,MAAM7E,GACNtE,KAAKoJ,WACLpJ,KAAKmH,QAAU2B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QACxClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QAGzCpG,WAIAA,qBAKc+I,GAAMvE,GACpB,OAAO,IAAIuR,GAAMvR,GCVZ,MAAM2J,GAA2B,CACtC9G,QAAS,YAGE2O,WAAcxL,EAEzBxK,YAAYwE,GACV6E,MAAM,IAAK8E,MAAa3J,IAF1BtE,kBAA0C,KAGxCA,KAAKoJ,WACLpJ,KAAK+V,aAAe,KACpB/V,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,QAGzCpG,eACqB,IAAfE,KAAKmG,QACPnG,KAAKgP,QAAUhP,KAAKgW,UACpBhW,KAAK+V,aAAe3R,GAClB,SAAqC3E,GACnC,OAAOA,EAAMO,KAAKiK,OAAOzE,KAE3B,CACEc,OAAQ,CAAC,EAAGtG,KAAKkG,QACjBK,WAAW,KAMnBzG,aAAamI,GAEXjI,KAAK+V,aAAgB9N,EAAgB8N,aAGvCjW,QAAQsI,GACN,IACGhD,MAAMC,QAAQ+C,IAAWA,aAAkBzC,eACvB,iBAAdyC,EAAO,IACdA,EAAOzG,SAAW3B,KAAKkG,OAASlG,KAAKmG,MAErCpB,EAAQ/E,KAAKmH,SACbnH,KAAKmH,SvCkCiB1H,EuClCK2I,EvCkCYhG,EuClCQ,CAACpC,KAAKmG,MAAOnG,KAAKkG,QvCmC9D,IAAI4P,QAAMrW,EAAO2C,QuClCf,CAAA,IACLgD,MAAMC,QAAQ+C,IACdA,EAAOzG,SAAW3B,KAAKkG,UACtBd,MAAMC,QAAQ+C,EAAO,KAAOA,EAAO,aAAczC,eAClDyC,EAAO,GAAGzG,SAAW3B,KAAKmG,MAI1B,MAAM,IAAIjE,MAAM,qCAFhBlC,KAAKmH,QAAUzB,EAAM0C,OvC2BC3I,EAAiB2C,EuCvBzC+C,EAAMnF,KAAKoH,QAGbtH,UAAUsI,GACJpI,KAAKmH,SAASpC,EAAQ/E,KAAKmH,SAC3BnH,KAAK+V,aACP/V,KAAKmH,QAAUnH,KAAK+V,aAAa3N,GAEjCpI,KAAKmH,QAAUiB,EAEjBjD,EAAMnF,KAAKoH,QAGbtH,qBCtEcoR,GAEd9I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGpC4L,GAEd/I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGnD2E,GAEd/C,EACAC,GAEA,OAAO7H,EACL4H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACnC6B,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAItB6L,GAEdjK,EACAC,GAEA,OAAO7H,EACL4H,EAAQnH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAClD6B,EAAOpH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,UAIxC0Q,WAAkBhN,EAC7BnJ,eACE,MAAMqG,MAAEA,EAAKD,OAAEA,EAAMgB,MAAEA,GAAUlH,KAAKkJ,WAClClJ,KAAKkH,MAAQ,GACflH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACH,EAAOD,EAAQgB,GACxBkH,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAWgN,GAAW,CACzC9K,OAAQ,CAACH,EAAOD,EAAQgB,GACxBkH,UAAW,CAAC7O,GACZgH,WAAW,MAGbvG,KAAKkI,cAAgB9D,EAAW8M,GAAW,CACzC5K,OAAQ,CAACH,EAAOD,GAChBkI,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAW8F,GAAW,CACzC5D,OAAQ,CAACH,EAAOD,GAChBkI,UAAW,CAAC7O,GACZgH,WAAW,KAKjBzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,SAElBhC,EAAMnF,KAAKoH,QAGbtH,UACE,MAAMsH,OAAEA,GAAWpH,KACnBA,KAAKoH,OAAUpH,KAAKmI,cAClBnI,KAAKmH,QACLC,GAEFrC,EAAQqC,aCnEI8O,GAAWzW,GACzB,OAAOA,WAGO0W,GAAW1W,GACzB,OAAOA,WAQOuP,GAEd5G,GAEA,MAAM6J,EACJjS,KAAKiG,UAAU4L,SAAW7R,KAAKiK,OAAO1E,EAAIvF,KAAKiG,UAAUwL,QACrDS,EACJlS,KAAKiK,OAAO1E,EAAIvF,KAAKiG,UAAUwL,QAAUzR,KAAKiG,UAAU4L,SACpDM,EAAa9S,KAAKoO,IACtBzN,KAAKiG,UAAUsD,YACf0I,EAAejS,KAAKiG,UAAUmM,YAG1BC,EACJrS,KAAKiG,UAAU6L,SAAW9R,KAAKiK,OAAOzE,EAAIxF,KAAKiG,UAAUyL,QACrDY,EACJtS,KAAKiK,OAAOzE,EAAIxF,KAAKiG,UAAUyL,QAAU1R,KAAKiG,UAAU6L,SACpDS,EAAalT,KAAKoO,IACtBzN,KAAKiG,UAAUuD,aACf6I,EAAerS,KAAKiG,UAAUuM,aAGhC,IAAI4D,GAAgB,MAKpB,IACE,IAAI1D,EAAUrT,KAAKC,IAAI,EAAG+S,GAAeM,EAAStT,KAAKC,IAAI,EAAGgT,GAC9DI,EAAUH,EACVG,IAAWC,IAEX,IACE,IAAIC,EAAUvT,KAAKC,IAAI,EAAG2S,GACxBY,EAASxT,KAAKC,IAAI,EAAG4S,GACvBU,EAAUT,EACVS,IAAWC,IAEX,GACEF,GAAU,GACVA,EAAS3S,KAAKiG,UAAUuM,aACxBK,GAAU,GACVA,EAAS7S,KAAKiG,UAAUmM,WACxB,CACA,MAAM/G,EAAQjD,EAAOpI,KAAKiK,OAAOjB,GAAG2J,GAAQE,GACxCxH,EAAQ+K,IACVA,EAAe/K,GASvB,OAAO+K,WAWO5B,GAEdpN,EACAiP,EACAC,GAEA,MAAM/Q,EAAIlG,KAAKwC,MACZ7B,KAAKiK,OAAO1E,EAAIvF,KAAKsG,OAAOf,EAAKvF,KAAKiG,UAAUsQ,aAE7C/Q,EAAInG,KAAKwC,MACZ7B,KAAKiK,OAAOzE,EAAIxF,KAAKsG,OAAOd,EAAKxF,KAAKiG,UAAUuQ,cAGnD,IAAI/W,EAAQ,EAEZ,IAAK,IAAIgX,EAAU,EAAGA,EAAUzW,KAAKiG,UAAUuM,YAAaiE,IAC1D,IAAK,IAAIC,EAAU,EAAGA,EAAU1W,KAAKiG,UAAUmM,WAAYsE,IAAW,CACpE,MAAMC,EAAeL,EAAQG,GAASC,GAChCE,EAAeP,EAAQI,GAASC,GAClCC,IAAiBpR,GAAKqR,IAAiBpR,IACzC/F,GAAS2H,EAAOqP,GAASC,IAK/B,OAAOjX,EAsCF,MAAMwO,GAA0B,CACrC2D,QAAS,EACTJ,OAAQ,EACRjI,YAAa,EACbC,aAAc,EACdF,YAAa,SAGFuN,WAAaxN,EA6DxBvJ,YAAYwE,EAAyB4E,GACnCC,MAAM7E,EAAU4E,GAFlBlJ,sBAAmE,KAGjEA,KAAKsE,SAAW,IACXA,KACAiN,GAAUjN,EAAU2J,OACpB0D,GAAWrN,EAAU2J,KAG1BjO,KAAKmH,QAAU+I,GAASlQ,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACtDlH,KAAKoH,OAAS2B,EAAQ/I,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OAEpDlH,KAAKyJ,QAAUyG,GACblQ,KAAKuJ,YACLvJ,KAAKwJ,aACLxJ,KAAKsJ,aAEPtJ,KAAK0J,aAAeX,EAClB/I,KAAKuJ,YACLvJ,KAAKwJ,aACLxJ,KAAKsJ,aAEPtJ,KAAKoJ,WA/EPqI,cACE,OAAOzR,KAAKsE,SAASmN,QAGvBC,cACE,OAAO1R,KAAKsE,SAASoN,QAGvBG,eACE,OAAO7R,KAAKsE,SAASuN,SAGvBC,eACE,OAAO9R,KAAKsE,SAASwN,SAGvB3L,YACE,OAAO9G,KAAKwC,OACT7B,KAAKkJ,WAAW/C,MAAwB,EAAhBnG,KAAK6R,SAAe7R,KAAKuJ,aAChDvJ,KAAKyR,QACL,GAINvL,aACE,OAAO7G,KAAKwC,OACT7B,KAAKkJ,WAAWhD,OAAyB,EAAhBlG,KAAK8R,SAAe9R,KAAKwJ,cACjDxJ,KAAK0R,QACL,GAINxK,YACE,OAAOlH,KAAKsE,SAASgF,YAGvBA,kBAEE,OAAOtJ,KAAKsE,SAASgF,YAGvBgN,cACE,OAAOtW,KAAKsE,SAASgS,QAGvBA,YAAYA,GACVtW,KAAKsE,SAASgS,QAAUA,EAG1BD,cACE,OAAOrW,KAAKsE,SAAS+R,QAGvBA,YAAYA,GACVrW,KAAKsE,SAAS+R,QAAUA,EA4B1BvW,eACEE,KAAK4U,iBAAmBhQ,EAItB,CACE0R,QAASH,GACTE,QAASH,IAEXlH,GACA,CACE1I,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACvCjB,UAAW,CACTmM,WAAYpS,KAAKkJ,WAAW/C,MAC5BqM,YAAaxS,KAAKkJ,WAAWhD,OAC7B2L,SAAU7R,KAAK6R,SACfC,SAAU9R,KAAK8R,SACftI,aAAcxJ,KAAKwJ,aACnBD,YAAavJ,KAAKuJ,eAKxBvJ,KAAKmI,cAAgB/D,EAAWoQ,GAAS,CACvClO,OAAQ,CACNtG,KAAKkJ,WAAW/C,MAChBnG,KAAKkJ,WAAWhD,OAChBlG,KAAKkJ,WAAWhC,OAElBjB,UAAW,CACTmM,WAAYpS,KAAKkJ,WAAW/C,MAC5BqM,YAAaxS,KAAKkJ,WAAWhD,OAE7BqQ,YAAavW,KAAKmG,MAClBqQ,aAAcxW,KAAKkG,UAKzBpG,UACE,MAAQoD,OAAQiE,EAAOmP,QAAEA,EAAOD,QAAEA,GAAarW,KAC5C4U,iBACD5U,KAAKkJ,WAAW/B,SAElBnH,KAAKsW,QAAUA,EACftW,KAAKqW,QAAUA,EACfrW,KAAKmH,QAAUA,EAGjBrH,UAME,MAAMoV,EAAmBlV,KAAKkJ,WAAW9B,OACzCpH,KAAKkJ,WAAW9B,OAAUpH,KAAKmI,cAC7BnI,KAAKoH,OACLpH,KAAKsW,QACLtW,KAAKqW,SAEPtR,EAAQmQ,UCjTC4B,WAAuBnN,EAMlC7J,YAAYiX,GACV5N,QALFnJ,YAAyB,KACzBA,mBAAgB,KAChBA,mBAAgB,KAChBA,cAAW,GAGTA,KAAK+W,eAAiBA,EACtB/W,KAAKoJ,WAGPjD,YACE,OAAOnG,KAAK+W,eAAe5Q,MAG7BD,aACE,OAAOlG,KAAK+W,eAAe7Q,OAG7BgB,YACE,OAAOlH,KAAK+W,eAAe7P,MAG7BE,aACE,OAAOpH,KAAK+W,eAAe3P,OAG7BA,WAAWA,GACT,MAAM4P,EAAuBhX,KAAK+W,eAAe3P,OACjDpH,KAAK+W,eAAe3P,OAASA,EAC7BrC,EAAQiS,GAGV7P,cACE,OAAOnH,KAAK+W,eAAe5P,QAG7BA,YAAYA,GACV,MAAM8P,EAAwBjX,KAAK+W,eAAe5P,QAClDnH,KAAK+W,eAAe5P,QAAUA,EAC9BpC,EAAQkS,GAGVnX,WAEE,GADAyH,EAAU2P,UAAU9N,SAAS+N,KAAKnX,MAC9BA,KAAKmG,QAAUnG,KAAK+W,eAAe5Q,MACrC,MAAM,IAAIjE,MACR,GAAGlC,KAAK8H,YAAYC,oBAAoB/H,KAAKmG,aAAanG,KAAK+W,eAAejP,YAAYC,eAAe/H,KAAK+W,eAAe5Q,uBAIjI,GAAInG,KAAKkG,SAAWlG,KAAK+W,eAAe7Q,OACtC,MAAM,IAAIhE,MACR,GAAGlC,KAAK8H,YAAYC,qBAAqB/H,KAAKkG,cAAclG,KAAK+W,eAAejP,YAAYC,eAAe/H,KAAK+W,eAAe7Q,wBAKrIpG,cAAcqG,EAAeD,GAC3BlG,KAAK+W,eAAe5Q,MAAQA,EAC5BnG,KAAK+W,eAAe7Q,OAASA,EAG/BpG,WAIAA,WAIAA,SAIAA,gBAMAA,uBCrFWsX,WAAuBzN,EAMlC7J,YAAYwE,GACV6E,QANFnJ,YAAyB,KACzBA,cAAoC,GACpCA,mBAAgB,KAChBA,mBAAgB,KAIVsE,IACFtE,KAAKsE,SAAW,IAAKA,IAIzBxE,cAAcqG,EAAeD,GAC3BlG,KAAKqH,OAAS,KACdrH,KAAKsE,SAAW,IACXtE,KAAKsE,SACR6B,MAAAA,EACAD,OAAAA,EACAiB,QAAS2B,EAAQ3C,EAAOD,GACxBkB,OAAQ0B,EAAQ3C,EAAOD,IAI3BpG,gBAMAA,gBAMAA,WAIAA,WAIAA,MAAMwI,GACJ,MAAQnB,QAASoB,GAAevI,KAChCA,KAAKmH,QAAWnH,KAAKqH,OAAmBmB,IAAIxI,KAAMsI,GAElDvD,EAAQwD,GACRpD,EAAMnF,KAAKoH,kBAYCiQ,KACd,OAAO,IAAID,YC9DGlG,GAEd9I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGpC2E,GAEd/C,EACAC,GAEA,OAAO7H,EACL4H,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACnC6B,EAAOpH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAItB4L,GAEd/I,GAEA,OAAOjJ,EAASiJ,EAAOpI,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAGnD6L,GAEdjK,EACAC,GAEA,OAAO7H,EACL4H,EAAQnH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAClD6B,EAAOpH,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,UAIxC+R,WAAarO,EACxBnJ,eACE,MAAMqG,MAAEA,EAAKD,OAAEA,EAAMgB,MAAEA,GAAUlH,KAAKkJ,WAClChC,EAAQ,GACVlH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACH,EAAOD,EAAQgB,GACxBkH,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAWgN,GAAW,CACzC9K,OAAQ,CAACH,EAAOD,EAAQgB,GACxBkH,UAAW,CAAC7O,GACZgH,WAAW,MAGbvG,KAAKkI,cAAgB9D,EAAW8M,GAAW,CACzC5K,OAAQ,CAACH,EAAOD,GAChBkI,UAAW,CAACjP,GACZoH,WAAW,IAGbvG,KAAKmI,cAAgB/D,EAAW8F,GAAW,CACzC5D,OAAQ,CAACH,EAAOD,GAChBkI,UAAW,CAAC7O,GACZgH,WAAW,KAKjBzG,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,SAElBhC,EAAMnF,KAAKoH,QAGbtH,UACEiF,EAAQ/E,KAAKkJ,WAAW9B,QACxBpH,KAAKkJ,WAAW9B,OAAUpH,KAAKmI,cAC7BnI,KAAKmH,QACLnH,KAAKoH,kBAKKmQ,GAAKrO,EAAoB5E,GACvC,OAAO,IAAIgT,GAAKpO,EAAY5E,SCtFjBkT,WAAmBjQ,EAE9BzH,YAAYwE,EAA0B4E,GACpCC,MAAM7E,GACNtE,KAAKkJ,WAAaA,EAClBlJ,KAAKoJ,WAGPtJ,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAUzB,EAAM1F,KAAKkJ,WAAW/B,SAGvCrH,mBCgBc2X,GAEdrP,GAEA,IAAIsP,GAAYC,EAAAA,EAChB,IAAK,IAAInS,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAAK,CAClD,MAAM8F,EAAQjD,EAAO5C,GAAGD,GACpB8F,EAAQqM,IACVA,EAAWrM,GAIjB,OAAOqM,WAGOE,GAEdxP,GAEA,IAAIsP,GAAYC,EAAAA,EAChB,IAAK,IAAI3O,EAAI,EAAGA,EAAIhJ,KAAKiG,UAAUwM,WAAYzJ,IAC7C,IAAK,IAAIxD,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAAK,CAClD,MAAM8F,EAAQjD,EAAOY,GAAGxD,GAAGD,GACvB8F,EAAQqM,IACVA,EAAWrM,GAKnB,OAAOqM,WAcOG,GAEdzP,GAEA,IAAIpC,EAAM,EACV,IAAK,IAAIR,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAC7CS,GAAOoC,EAAO5C,GAAGD,GAGrB,OAAOS,WAGO8R,GAEd1P,GAEA,IAAIpC,EAAM,EACV,IAAK,IAAIgD,EAAI,EAAGA,EAAIhJ,KAAKiG,UAAUwM,WAAYzJ,IAC7C,IAAK,IAAIxD,EAAI,EAAGA,EAAIxF,KAAKiG,UAAUuM,YAAahN,IAC9C,IAAK,IAAID,EAAI,EAAGA,EAAIvF,KAAKiG,UAAUmM,WAAY7M,IAC7CS,GAAOoC,EAAOY,GAAGxD,GAAGD,GAI1B,OAAOS,WAGO+R,GAEd3P,EACAsP,GAEA,OAAOrY,KAAKK,IAAI0I,EAAOpI,KAAKiK,OAAO1E,GAAKmS,EAAS,aAWnCM,GAEd5P,EACAsP,GAEA,OAAOrY,KAAKK,IACV0I,EAAOpI,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAKmS,EAAS,aAYnDxG,GAEd+G,EACAC,GAEA,OAAOD,EAAajY,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAAK2S,EAAgB,YAGtD/G,GAEd8G,EACAC,GAEA,OACED,EAAajY,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GACvD2S,EAAgB,YAgBJhO,GAEdE,EACA6N,GAEA,IAAIE,EAAY,EAKhB,OAJcnY,KAAKiK,OAAO1E,EAAIvF,KAAKiK,OAAOzE,EAAIxF,KAAKsG,OAAOf,IAC5C6E,IACZ+N,EAAY,KAELA,EAAYF,EAAajY,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,aAG/C6L,GAEdhH,EACA6N,GAEA,IAAIE,EAAY,EAQhB,OANEnY,KAAKiK,OAAO1E,EACZvF,KAAKiK,OAAOzE,EAAIxF,KAAKsG,OAAOf,EAC5BvF,KAAKiK,OAAOjB,EAAIhJ,KAAKsG,OAAOf,EAAIvF,KAAKsG,OAAOd,IAChC4E,IACZ+N,EAAY,KAGZA,EAAYF,EAAajY,KAAKiK,OAAOjB,GAAGhJ,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,UAU1D6S,WAAgBxO,EAK3B9J,YAAYoJ,EAAoB5E,GAC9B6E,MAAMD,EAAY5E,GAFpBtE,YAA8B,KAG5BA,KAAKqY,sBAAwB,KAC7BrY,KAAKsY,kBAAoB,KACzBtY,KAAKuY,aAAe,KACpBvY,KAAKoJ,WAEDpJ,KAAKkH,MAAQ,GACflH,KAAKmH,QAAU+I,GAASlQ,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,OACtDlH,KAAKoH,OAAS2B,EAAQ/I,KAAKmG,MAAOnG,KAAKkG,OAAQlG,KAAKkH,QAC3ClH,KAAKkG,OAAS,GACvBlG,KAAKmH,QAAU8I,GAASjQ,KAAKmG,MAAOnG,KAAKkG,QACzClG,KAAKoH,OAAS0B,EAAQ9I,KAAKmG,MAAOnG,KAAKkG,UAEvClG,KAAKmH,QAAU6I,GAAOhQ,KAAKmG,OAC3BnG,KAAKoH,OAASyB,EAAM7I,KAAKmG,QAI7BrG,eACE,MAAMqG,MAAEA,EAAKD,OAAEA,EAAMgB,MAAEA,GAAUlH,KAC7BkH,EAAQ,GACVlH,KAAKqY,sBAAwBjU,EAAW4T,GAAmB,CACzD1R,OAAQ,CAACH,EAAOD,EAAQgB,KAE1BlH,KAAKsY,kBAAoBlU,EAAWwT,GAAe,CACjDtR,OAAQ,CAAC,EAAG,EAAG,GACfL,UAAW,CACTmM,WAAYjM,EACZqM,YAAatM,EACbuM,WAAYvL,KAGhBlH,KAAKuY,aAAenU,EAAW0T,GAAU,CACvCxR,OAAQ,CAAC,EAAG,EAAG,GACfL,UAAW,CACTmM,WAAYjM,EACZqM,YAAatM,EACbuM,WAAYvL,KAGhBlH,KAAKkI,cAAgB9D,EAAW+M,GAAW,CACzC7K,OAAQ,CAACH,EAAOD,EAAQgB,KAE1BlH,KAAKmI,cAAgB/D,EAAWgN,GAAW,CACzC9K,OAAQ,CAACH,EAAOD,EAAQgB,GACxBX,WAAW,MAGbvG,KAAKqY,sBAAwBjU,EAAW2T,GAAiB,CACvDzR,OAAQ,CAACH,EAAOD,KAElBlG,KAAKsY,kBAAoBlU,EAAWqT,GAAe,CACjDnR,OAAQ,CAAC,EAAG,GACZL,UAAW,CACTmM,WAAYjM,EACZqM,YAAatM,KAGjBlG,KAAKuY,aAAenU,EAAWyT,GAAU,CACvCvR,OAAQ,CAAC,EAAG,GACZL,UAAW,CACTmM,WAAYjM,EACZqM,YAAatM,KAGjBlG,KAAKkI,cAAgB9D,EAAW8M,GAAW,CACzC5K,OAAQ,CAACH,EAAOD,KAElBlG,KAAKmI,cAAgB/D,EAAW8F,GAAW,CACzC5D,OAAQ,CAACH,EAAOD,GAChBK,WAAW,KAKjBzG,UACE,MAAM0Y,EAAYxY,KAAKsY,kBACrBtY,KAAKkJ,WAAW/B,SAEZ8Q,EAAgBjY,KAAKqY,sBACzBrY,KAAKkJ,WAAW/B,QAChBqR,GAEIN,EAAmBlY,KAAKuY,aAC5BN,GAEFjY,KAAKmH,QAAWnH,KAAKkI,cACnB+P,EACAC,GAIJpY,QAAQuI,GACN,MAAMjB,OAAEA,EAAMrB,OAAEA,GAAW/F,KAC3BA,KAAK+F,OAAU/F,KAAKmI,cACjBE,EAA0B,GAC3BjB,GAEFpH,KAAKoH,OAAS1B,EAAM1F,KAAK+F,QACzBhB,EAAQqC,GACRrC,EAAQgB,GAER,MAAMmP,EAAmBlV,KAAKkJ,WAAW9B,OACzCpH,KAAKkJ,WAAW9B,OAAS1B,EAAM1F,KAAKoH,QACpCrC,EAAQmQ,UC1TCuD,WAAYlR,EAEvBzH,YAAYoJ,EAAoB5E,GAC9B6E,MAAM7E,GACNtE,KAAKkJ,WAAaA,EAGpBpJ,UACEiF,EAAQ/E,KAAKmH,SACbnH,KAAKmH,QAAUzB,EAAM1F,KAAKkJ,WAAW/B,SACrCnH,KAAKoJ,WAGPtJ,mBCbckP,GAAmCvP,GACjD,OAAOA,EAAMO,KAAKiK,OAAO1E,GAAGvF,KAAKiK,OAAOzE,GAG1C,MAAMgP,GAAUxF,SAEH0J,WAAkB9O,EAC7BzD,YACE,OAAOnG,KAAKkJ,WAAWhD,OAGzBA,aACE,OAAOlG,KAAKkJ,WAAW/C,MAGzBrG,YAAYoJ,GACVC,MAAMD,GACNlJ,KAAKoJ,WAGPtJ,eACEE,KAAKkI,cAAgB9D,EAAW4K,GAAS,CACvC1I,OAAQ,CAACtG,KAAKkG,OAAQlG,KAAKmG,SAE7BnG,KAAKmI,cAAgB/D,EAAWoQ,GAAS,CACvClO,OAAQ,CAACtG,KAAKmG,MAAOnG,KAAKkG,UAI9BpG,UACEE,KAAKmH,QAAWnH,KAAKkI,cACnBlI,KAAKkJ,WAAW/B,SAElBhC,EAAMnF,KAAKoH,QAGbtH,UACEE,KAAKkJ,WAAW9B,OAAUpH,KAAKmI,cAC7BnI,KAAKoH,eCMEuR,GAAa,CACxB1P,WAAAA,EACAU,SAAAA,EACAU,cAAAA,EACAC,WAAAA,EACAjB,OAAAA,EACAkB,MAAAA,EACAX,SAAAA,EACAC,SAAAA,EACAM,OAAAA,+FC9BA7F,EACA4E,GAEA,MAAMhD,OAAEA,GAAW5B,EAiBbyI,EAAejL,GAAO,CAC1B2F,GAAI,UACJvB,OAAAA,EACAC,MAAO+C,EAAWhD,OAClByB,WApBF,SACEsE,EACA3H,GAEA,MAAM+C,EAAS+F,EAAuBnB,EAAe3H,GAErD,OADA+C,EAAOuR,eACAvR,KAiBHwR,EAAc/W,GAAO,CACzB2F,GAAI,SACJvB,OAAAA,EACAyB,WAlBF,SACEsE,EACA3H,GAEA,MAAM+C,EAASiF,EAAsBL,EAAe3H,GAEpD,OADA+C,EAAOuR,eACAvR,KAiBHyR,EAAexH,GADJ1K,GADKqK,GAASlE,EAAc7D,GACT2P,IAG9BE,EAAgBhM,EAAa1F,OAInC,OAHA0R,EAAchM,aAAeA,EAC7BgM,EAAc/L,cAAgB9D,EAC9B6P,EAAc9L,WAAa6L,EACpBA,8EpBkZPxU,EACA4E,GAEA,OAAO,IAAI2K,GAAYvP,EAAU4E,gCCxWjCA,EACA5E,GAEA,OAAO,IAAIqQ,GAAQzL,EAAY5E,yBoB/GLA,EAA0B+G,GACpD,MAAMnF,OAAEA,EAAMoB,WAAEA,EAAa,MAAShD,EAChC6C,EAAUrF,GAAO,CACrB2F,GAAI,UACJvB,OAAAA,EACAC,MAAOkF,EAAMnF,OACboB,WAAAA,IAEI0K,EAASlQ,GAAO,CAAE2F,GAAI,SAAUvB,OAAAA,EAAQoB,WAAAA,IAC9C,OAAOgK,GACL1K,GAAIqK,GAAS9J,EAASkE,EAAO,CAAE/D,WAAAA,IAAe0K,EAAQ,CAAE1K,WAAAA,IACxD,CAAEA,WAAAA,+CnB6RJhD,EACA4E,GAEA,OAAO,IAAI8L,GAAe1Q,EAAU4E,iBoBpSpC5E,EACAyS,EACA1L,GAEA,MAAMnF,OAAEA,GAAW5B,EACb0U,EAAoBlX,GAAO,CAAEoE,OAAAA,EAAQC,MAAOkF,EAAMnF,SAClD+S,EAAsBnX,GAAO,CAAEqE,MAAOD,EAAQA,OAAAA,IAC9CgT,EAAiBrQ,GAAM,CAAE3C,OAAAA,IACzBiT,EAAa7H,GACjB1K,GACEA,GACEqK,GAAS+H,EAAmB3N,GAC5B4F,GAASgI,EAAqBlC,IAEhCmC,IAIEE,EAAmBtX,GAAO,CAAEoE,OAAAA,EAAQC,MAAOkF,EAAMnF,SACjDmT,EAAqBvX,GAAO,CAAEqE,MAAOD,EAAQA,OAAAA,IAC7CoT,EAAgBzQ,GAAM,CAAE3C,OAAAA,IACxBqT,EAAYjI,GAChB1K,GACEA,GACEqK,GAASmI,EAAkB/N,GAC3B4F,GAASoI,EAAoBtC,IAE/BuC,IAIEE,EAAc1X,GAAO,CAAEoE,OAAAA,EAAQC,MAAOkF,EAAMnF,SAC5CuT,EAAgB3X,GAAO,CAAEqE,MAAOD,EAAQA,OAAAA,IACxCwT,EAAW7Q,GAAM,CAAE3C,OAAAA,IACnByT,EAAO/Z,GACXgH,GACEA,GACEqK,GAASuI,EAAanO,GACtB4F,GAASwI,EAAejE,GAAgB+D,EAAWxC,KAErD2C,IAMJ,OAAO9S,GACL4O,GACE5O,GACE6O,GAAK,CAAEtP,MAAOgT,EAAWhT,MAAOD,OAAQiT,EAAWjT,SACnDkP,GAAS+D,IAEXQ,GAEFnE,GAAgBuB,EAAgBoC,6Bbcd7U,GACpB,OAAO,IAAIwR,GAAMxR,oCCSjB4E,EACA5E,GAEA,OAAO,IAAI2R,GAAU/M,EAAY5E,sBanFjCA,EACA+G,EACA0L,GAEA,MAAM7Q,OAAEA,GAAW5B,EAEnB,GAAsB,iBAAX4B,EACT,MAAM,IAAIhE,MAAM,4BAEd6U,EAAe6C,eACjB7C,EAAe6C,cAAc,EAAG1T,GAGlC,MAAM2T,EAAmB/X,GAAO,CAC9BoE,OAAAA,EACAC,MAAOkF,EAAMnF,OACb6J,IAAK,IACLtI,GAAI,qBAEAqS,EAAqBhY,GAAO,CAChCqE,MAAOD,EACPA,OAAAA,EACA6J,IAAK,IACLtI,GAAI,uBAEAsS,EAAgBlR,GAAM,CAAE3C,OAAAA,EAAQuB,GAAI,kBACpCuS,EAAY1I,GAChB1K,GACEA,GACEqK,GAAS4I,EAAkBxO,GAC3B4F,GAAS6I,EAAoB/C,IAE/BgD,GAEF,CAAEtS,GAAI,cAGFwS,EAAoBnY,GAAO,CAC/BoE,OAAAA,EACAC,MAAOkF,EAAMnF,OACb6J,IAAK,IACLtI,GAAI,sBAEAyS,EAAsBpY,GAAO,CACjCqE,MAAOD,EACPA,OAAAA,EACA6J,IAAK,IACLtI,GAAI,wBAEA0S,EAAiBtR,GAAM,CAAE3C,OAAAA,EAAQuB,GAAI,mBACrC2S,EAAa9I,GACjB1K,GACEA,GACEqK,GAASgJ,EAAmB5O,GAC5B4F,GAASiJ,EAAqBnD,IAEhCoD,GAEF,CAAE1S,GAAI,eAGF4S,EAAoBvY,GAAO,CAC/BoE,OAAAA,EACAC,MAAOkF,EAAMnF,OACb6J,IAAK,IACLtI,GAAI,sBAEA6S,EAAsBxY,GAAO,CACjCqE,MAAOD,EACPA,OAAAA,EACA6J,IAAK,IACLtI,GAAI,wBAEA8S,EAAiB1R,GAAM,CAAE3C,OAAAA,EAAQuB,GAAI,mBACrC+S,EAAalJ,GACjB1K,GACEA,GACEqK,GAASoJ,EAAmBhP,GAC5B4F,GAASqJ,EAAqBvD,IAEhCwD,GAEF,CAAE9S,GAAI,eAGFgT,EAAgB3Y,GAAO,CAC3BoE,OAAAA,EACAC,MAAOkF,EAAMnF,OACb6J,IAAK,IACLtI,GAAI,kBAEAiT,EAAkB5Y,GAAO,CAC7BqE,MAAOD,EACPA,OAAAA,EACA6J,IAAK,IACLtI,GAAI,oBAEAkT,EAAa9R,GAAM,CAAE3C,OAAAA,EAAQuB,GAAI,eACjCmT,EAAShb,GACbgH,GACEA,GACEqK,GAASwJ,EAAepP,GACxB4F,GAASyJ,EAAiB3D,IAE5B4D,GAEF,CAAElT,GAAI,WAIFoT,EAAarF,GAAgB4E,EAAYrD,EAAgB,CAC7DtP,GAAI,eAEAqT,EAAYtF,GAAgBwE,EAAWY,EAAQ,CAAEnT,GAAI,cAI3D,OAAO+N,GAAgBgF,EAAY5a,GAHtBgH,GAAIiU,EAAYC,EAAW,CAAErT,GAAI,UAGC,CAAEA,GAAI,uIC1HhCnD,EAA0B4E,GAC/C,MAAMhD,OAAEA,GAAW5B,EACbkW,EAAa1Y,GAAO,CACxBoE,OAAAA,EACAC,MAAO+C,EAAWhD,OAClBuB,GAAI,aACJsI,IAAK,MAEDzJ,EAASxE,GAAO,CAAEoE,OAAAA,EAAQuB,GAAI,SAAUsI,IAAK,MAC7CgL,EAAsB9J,GAASuJ,EAAYtR,EAAY,CAC3DzB,GAAI,wBAEN,OAAO2C,EACL,CAAE3C,GAAI,YAAanD,GACnBsC,GAAImU,EAAqBzU,2BbgTRhC,EAAyB4E,GAC5C,OAAO,IAAI2N,GAAKvS,EAAU4E,6Ec5T1B5E,EACA+G,EACA0L,GAEA,MAAM7Q,OAAEA,GAAW5B,EAEnB,GAAsB,iBAAX4B,EAAqB,MAAM,IAAIhE,MAAM,kBAC5C6U,EAAe6C,eACjB7C,EAAe6C,cAAc,EAAG1T,GAIlC,MAAM9G,EAAS0C,GAAO,CACpB2F,GAAI,SACJvB,OAAAA,EACAC,MAAOkF,EAAMnF,OACb6J,IAAK,MAGDiL,EAAalZ,GAAO,CACxB2F,GAAI,aACJvB,OAAAA,EACAC,MAAOD,EACP6J,IAAK,MAGD6D,EAAO/K,GAAM,CAAEpB,GAAI,OAAQvB,OAAAA,IAEjC,OAAOqR,GACL3Q,GACEA,GAAIqK,GAAS7R,EAAQiM,GAAQ4F,GAAS+J,EAAYjE,IAClDnD,uCVNJtP,EACA4E,GAEA,OAAO,IAAIsO,GAAWlT,EAAU4E,sEC+RhCA,EACA5E,GAEA,OAAO,IAAI8T,GAAQlP,EAAY5E,wBCnSb4E,EAAoB5E,GACtC,OAAO,IAAImU,GAAIvP,EAAY5E,sECWH4E,GACxB,OAAO,IAAIwP,GAAUxP,wBQvCvB,MAAM+R,GAAiB5X,OAAOkI,KAAKtD,aAEnBiT,GACdC,EACArR,EACAC,GAEA,IACGkR,GAAeG,KAAMC,GAAkBA,IAAkBF,EAAUxS,MAEpE,OAAO,KAET,MAAM2S,EAAUrT,GAQbkT,EAAUxS,MACb,GAAI2S,EAAMpE,qBAAqByB,GAAWtP,OAAQ,CAChD,IAAKS,EAAa,MAAM,IAAI5H,MAAM,sBAClC,OAAO,IAAKoZ,EAAqBH,EAAWrR,GACvC,GACLwR,EAAMpE,qBAAqByB,GAAW1P,YACtCqS,EAAMpE,qBAAqByB,GAAW/O,SACtC,CACA,IAAKE,EAAa,MAAM,IAAI5H,MAAM,sBAClC,OAAO,IAAKoZ,EAAyBxR,EAAaqR,GAC7C,GAAIG,EAAMpE,qBAAqByB,GAAWhP,SAC/C,OAAO,IAAK2R,EAAuBH,GAC9B,GAAIG,EAAMpE,qBAAqByB,GAAW9O,SAAU,CACzD,IAAKC,EAAa,MAAM,IAAI5H,MAAM,uBAClC,IAAK6H,EAAa,MAAM,IAAI7H,MAAM,uBAClC,OAAO,IAAKoZ,EAAuBxR,EAAaC,EAAaoR,GACxD,GACLG,EAAMpE,qBAAqByB,GAAWtO,eACtCiR,EAAMpE,qBAAqByB,GAAWrO,YACtCgR,EAAMpE,qBAAqByB,GAAWpO,MAEtC,OAAO,IAAK+Q,EAAwBH,GAC/B,GAAIG,IAAUnR,EAAQ,CAC3B,IAAKL,EAAa,MAAM,IAAI5H,MAAM,sBAClC,OAAO,IAAKoZ,EAAqBH,EAAWrR,GAE9C,OAAO,WCpDIyR,GAIXzb,YACEkC,EACAwZ,GAJFxb,UAA+B,KAC/BA,WAAqB,GAKnBA,KAAK2B,OAAS,EACd,MAAMmJ,EAAQ9K,KAAK8K,MACnB,GAAI0Q,EAAM,CACRxb,KAAKwb,KAAOA,EACZ,IAAK,IAAI9Z,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MACMuJ,EADSjJ,EAA0BN,GACpB8Z,GACrB,IAAK,MAAMtQ,KAAKD,EACTA,EAAO7H,eAAe8H,KACvBJ,EAAM1H,eAAe8H,KACzBJ,EAAMI,GAAKlL,KAAK2B,iBAGf,GAAIyD,MAAMC,QAAQrD,IAASoD,MAAMC,QAAQrD,EAAK,IACnD,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMD,EAASO,EAA8BN,GAC7C,IAAK,IAAIE,EAAI,EAAGA,EAAIH,EAAME,OAAQC,IAAK,CACrC,MAAMqJ,EAASxJ,EAAMG,GACrB,IAAK,MAAMsJ,KAAKD,EACTA,EAAO7H,eAAe8H,KACvBJ,EAAM1H,eAAe8H,KACzBJ,EAAMI,GAAKlL,KAAK2B,iBAKtB,IAAK,IAAID,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMuJ,EAAUjJ,EAAuBN,GACvC,IAAK,MAAMwJ,KAAKD,EACTA,EAAO7H,eAAe8H,KACvBJ,EAAM1H,eAAe8H,KACzBJ,EAAMI,GAAKlL,KAAK2B,aCiCnB,MAAMsM,GAAgC,CAC3C3F,aAAc,GACdmT,aAAc,GACd9T,WAAY,CACVsE,EACA3H,WAEA,OAAAoX,GACEzP,YACAA,EAAc3H,SAASgD,0BAAchD,KAI9BqX,GAA6C,CACxDzb,WAAY,IACZ0b,YAAa,KACb/L,KAAK,EACLgM,UAAW,GACXvT,aAAc,GACdwT,eAAgB,GAChBC,mBAAoB,IACpBC,QAASrE,EAAAA,SAWEsE,GA0FXnc,YAAYoc,EAA+B,IAZ3Clc,eAAkD,GAElDA,YAA0B,KAC1BA,iBAA6B,KAC7BA,mBAAiC,KACjCA,kBAA8B,KAC9BA,YAA0B,KAC1BA,sBAA4C,KAC5CA,iBAAkC,KAClCA,uBAAmC,KACnCA,kBAAmC,KACnCA,wBAAoC,KAElCA,KAAKkc,QAAU,IAAKjO,MAAaiO,GACjClc,KAAKmc,uBAAuB,IACvBR,MACAO,IA1FPpc,gCACEoc,GAEA,MAAMhc,WACJA,EAAU0b,YACVA,EAAW/L,IACXA,EAAGgM,UACHA,EAASvT,aACTA,EAAY8T,SACZA,EAAQN,eACRA,EAAcE,QACdA,GACEE,EAIEG,EAA2B,CAC/Bnc,WAAY,IAA4B,iBAAfA,GAA2BA,EAAa,EACjE0b,YAAa,IACY,iBAAhBA,GAA4BA,EAAc,GAAKA,EAAc,EACtE/L,IAAK,IAAqB,mBAARA,GAAqC,kBAARA,EAC/CgM,UAAW,IAA2B,iBAAdA,GAA0BA,EAAY,EAC9DvT,aAAc,IACY,iBAAjBA,GACPA,EAAe,GACfA,EAAe,EACjB8T,SAAU,IAA0B,mBAAbA,GAAwC,OAAbA,EAClDN,eAAgB,IACY,iBAAnBA,GAA+BA,EAAiB,EACzDE,QAAS,IAAyB,iBAAZA,GAAwBA,EAAU,GAE1D3Y,OAAOkI,KAAKoQ,IAAeW,QAASC,IAClC,GAAIF,EAAYjZ,eAAemZ,KAASF,EAAYE,KAAQ,CAC1D,MAAMC,EAAMN,EAAQK,GACpB,MAAM,IAAIra,MACR,IAAIqa,OACFC,MAAAA,EAAAA,EAAO,aACPC,yFAUV3c,cAAc+P,GAEV7P,KAAKU,UAAUmP,IADE,mBAARA,EACYA,IACZA,GAEY6M,QAAQ7M,IAMjC/P,uBAAuB6c,SACrB3c,KAAKU,UAAY,IAAKib,MAAkB3b,KAAKU,aAAcic,GAC3DV,GAAYW,yBAAyB5c,KAAKU,WAC1CV,KAAK6c,wBAAcF,EAAK9M,mBAAO7P,KAAKU,UAAUmP,KAC9C,MAAMuM,SAAEA,EAAQN,eAAEA,EAAcC,mBAAEA,GAAuB/b,KAAKU,UAC1D0b,GAAYN,IAAmBC,GACjCW,QAAQI,KACN,yCACEhB,MAAAA,EAAAA,EAAkB,aAClBW,uEACAV,MAAAA,EAAAA,EAAsB,aACtBU,iFAyBR3c,wBACE,MAAMid,gBAAEA,EAAeC,iBAAEA,EAAgBrO,OAAEA,GAAW3O,KAAKkc,QAC3D,IAAKvN,EAAQ,MAAM,IAAIzM,MAAM,2CAC7B,GAA+B,iBAApB6a,EACT,MAAM,IAAI7a,MAAM,gCAClB,GAAgC,iBAArB8a,EACT,MAAM,IAAI9a,MAAM,gCAClB,MAAMgH,EAAayF,EAAOoO,GAC1B,IAAK7T,EACH,MAAM,IAAIhH,MAAM,+CAElB,MAAM+a,EAActO,EAAOqO,GAC3B,IAAKC,EACH,MAAM,IAAI/a,MAAM,gDAQlB,OANAlC,KAAKkd,YAAchU,EACnBlJ,KAAKmd,cAAgBxO,EAAO3L,MAC1B+Z,EACAC,EAAmBD,GAErB/c,KAAKod,aAAeH,EACbtO,EAGT7O,oBACE,MAAMoJ,WAAEA,EAAU+T,YAAEA,GAAgBjd,KAAKkc,QACzC,IAAKhT,EAAY,MAAM,IAAIhH,MAAM,0BACjC,MAAMyM,EAAmB,GACzB3O,KAAKkd,YAAchU,IACnB,MAAMmU,EAAerd,KAAKsd,qBAAqBtd,KAAKkd,aAEpD,IAAKD,EAAa,MAAM,IAAI/a,MAAM,2BAQlC,OAPAlC,KAAKod,aAAeH,EAClBI,EAAaA,EAAa1b,OAAS,GACnC0b,EAAa1b,QAEfgN,EAAOlL,KAAKzD,KAAKkd,aACjBvO,EAAOlL,QAAQ4Z,GACf1O,EAAOlL,KAAKzD,KAAKod,cACV1O,GAAcC,GAGvB7O,qBAAqByd,GACnBvd,KAAKmd,cAAgB,GACrB,MAAMja,EAAmB,IACnBma,aAAEA,GAAiBrd,KAAKkc,QAE9B,IAAKmB,EAAc,MAAM,IAAInb,MAAM,4BAEnC,IAAK,IAAIR,EAAI,EAAGA,EAAI2b,EAAa1b,OAAQD,IAAK,CAC5C,MAAM8b,EAAcH,EAAa3b,GAAG6b,EAAe7b,GACnDwB,EAAOO,KAAK+Z,GACZxd,KAAKmd,cAAc1Z,KAAK+Z,GACxBD,EAAgBC,EAGlB,OAAOta,EAGTpD,aACEE,KAAK2O,OAAS3O,KAAKkc,QAAQvN,OACvB3O,KAAKyd,wBACLzd,KAAK0d,oBACT1d,KAAK2d,iBAAiB3d,KAAK2O,QAC3B3O,KAAK4d,OAAS5d,KAAK2O,OAAOkP,OAAQC,GAAMA,aAAavT,GAGvDzK,iBAAiB6O,WACf,IAAK,IAAIjN,EAAI,EAAGA,EAAIiN,EAAOhN,OAAQD,IAAK,CACtC,MAAMuG,EAAQ0G,EAAOjN,GAErBuG,EAAM2Q,cAAa,GAEjB3Q,aAAiBsC,GACA,OAAjBtC,EAAMZ,QAC6B,mBAA5BrH,KAAKkc,QAAQvU,aAEpBM,EAAMZ,OAASrH,KAAKkc,QAAQvU,WAC1BM,sBACAA,EAAM3D,SAASgD,0BAActH,KAAKkc,QAAQ5U,0BAAc,IAE1DW,EAAMZ,OAAOuR,gBAIjB,MAAMmF,EAAYpP,EAAOA,EAAOhN,OAAS,GACzC3B,KAAKge,iBAAmB,IAAI5X,EAAiB,CAC3CD,MAAO4X,EAAU5X,MACjBD,OAAQ6X,EAAU7X,SAItBpG,IAAIuL,GACF,IAAI4S,EACJ,GAAI7Y,MAAMC,QAAQgG,IAAWA,EAAuBQ,OAClDoS,EAAgB5S,MACX,CACL,IAAIrL,KAAKke,YAOP,MAAM,IAAIhc,MAAM,kCANhB+b,EAAgBzT,EAAO/B,QACrBzI,KAAKke,YACL7S,EACArL,KAAKme,mBAOX,IAAI7X,EAAStG,KAAKoe,SAASH,GAK3B,OAJI3X,aAAkBrB,YACpBqB,EAASA,EAAOmC,WAGdzI,KAAKqe,aACA7T,EAAO8T,SACZte,KAAKqe,aACL/X,GAGGA,EAGTxG,SAASuL,GACP,IAAKrL,KAAK2O,OAAQ,MAAM,IAAIzM,MAAM,mBAClClC,KAAK2O,OAAO,GAAGK,QAAQ3D,GACvB,IAAK,IAAI3J,EAAI,EAAGA,EAAI1B,KAAK2O,OAAOhN,OAAQD,IACtC1B,KAAK2O,OAAOjN,GAAGsN,UAEjB,OAAOhP,KAAK2O,OAAO3O,KAAK2O,OAAOhN,OAAS,GAAGwF,QAG7CrH,MACEkC,EACAka,EAAgD,IAEhD,MAAMqC,aAAEA,EAAYC,OAAEA,EAAMC,QAAEA,GAAYze,KAAK0e,cAAc1c,EAAMka,GACnE,IAAIyC,GAAkB,EACtB,MAAMC,EAAiB,IACrB5e,KAAK6e,wBAAwBN,GACzBO,EAAe,IAAY9e,KAAK+e,eAAeR,GACrD,KAAOI,GACLA,EAAkB3e,KAAKgf,cACrBR,EACAC,EACAG,EACAE,GAGJ,OAAON,EAGT1e,cACE0e,EACAC,EACAG,EACAK,GAEA,MAAMve,UAAEA,GAAcV,KACtB,QACEwe,EAAOte,YAAeQ,EAAUR,YAChCse,EAAO7e,OAAUe,EAAUkb,aAC3B7a,KAAKC,OAASyd,KAMW,mBAAlB/d,EAAUmP,KACjB2O,EAAOte,WAAcQ,EAAUmb,WAAyB,GAExD2C,EAAO7e,MAAQif,IACfle,EAAUmP,IACR,eAAe2O,EAAOte,+BAA+Bse,EAAO7e,UAG9D6e,EAAOte,WAAcQ,EAAUqb,oBAC/B,EAEAyC,EAAO7e,MAAQif,IAEfK,IAIAve,EAAU0b,UACVoC,EAAOte,WAAcQ,EAAUob,gBAA8B,GAE7Dpb,EAAU0b,SAAS/Y,OAAOC,OAAOkb,IAGnCA,EAAOte,cACA,GAGTJ,cACEkC,EACAka,GAEAlc,KAAKmc,uBAAuBD,GAE5B,MAAMgD,EAAgBlf,KAAKmf,WAAWnd,GAChCyc,EAAUze,KAAKU,UAAUsb,QAC3Bjb,KAAKC,MAAQhB,KAAKU,UAAUsb,QAC5B,EASJ,OAFAhc,KAAKof,sBAEE,CACLb,aAAcve,KAAKqf,aAAaH,GAChCV,OATa,CACb7e,MAAO,EACPO,WAAY,GAQZue,QAAAA,GAIJ3e,sBACOE,KAAK4d,QACR5d,KAAKsf,aAITxf,wBAAwBye,GACtB,IAAIvY,EAAmC,IAAIL,aAAa,CAAC,IACzD,MAAMqY,EAAmBhe,KAAKge,iBAC9B,IAAK,IAAItc,EAAI,EAAGA,EAAI6c,EAAa5c,SAAUD,EAAG,CAC5C,MAAM6d,EAAUvZ,EACVrG,EAAQK,KAAKwf,cACjBjB,EAAa7c,GAAG2J,MAChBkT,EAAa7c,GAAG4E,QAChB,GAEFN,EAAMgY,EAAiBpX,IAAIZ,EAAKrG,GAChCoF,EAAQpF,GACRoF,EAAQwa,GAEV,MAAMrc,EAAS8a,EAAiBjX,OAAOwX,EAAa5c,OAAQqE,GAE5D,GADAjB,EAAQiB,GACJ9C,aAAkB+B,UAAS,CAC7B,MAAMwa,EAAwBvc,EAAOuF,UAErC,OADA1D,EAAQ7B,GACDuc,EAAY,GAErB,OAAQvc,EAAoB,GAO9BpD,eAAekC,GACb,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EACjC1B,KAAKwf,cAAcxd,EAAKN,GAAG2J,MAAOrJ,EAAKN,GAAG4E,QAAQ,GAItDxG,cACEuL,EACAjB,EACAsV,SASA,GANA1f,KAAKoe,SAAS/S,GAGdrL,KAAK2f,iBAAiBvV,GACtBpK,KAAK4f,gBAEDF,EAAc,CAChB,eAAK1f,KAAKod,mCAAcrX,QACtB,MAAM,IAAI7D,MAAM,kCAElB,OAAQlC,KAAKge,iBAAsC3X,UACjDrG,KAAKod,aAAarX,QAGtB,OAAO,KAGTjG,iBAAiBsK,GACf,MAAMuE,EAAS3O,KAAK2O,OACpB,IAAK,IAAIjN,EAAIiN,EAAOhN,OAAS,EAAGD,GAAK,EAAGA,IACtCiN,EAAOjN,GAAG8S,QAAQpK,GAOtBtK,gBACE,MAAM8d,EAAS5d,KAAK4d,OACpB,IAAK,IAAIlc,EAAI,EAAGA,EAAIkc,EAAOjc,OAAQD,IACjCkc,EAAOlc,GAAGme,MAAM7f,KAAKU,UAAU4H,cASnCxI,WACEkC,GAIA,IAAKoD,MAAMC,QAAQrD,GAAO,CAExB,MAAM8d,EAAM,GACZA,EAAIrc,KAAKzB,GACTA,EAAO8d,EAIT,MAAMC,EAAkB/d,EAAK,GAAGqJ,MAChC,IAAI6T,EACJ,IACE9Z,MAAMC,QAAQrD,IACboD,MAAMC,QAAQ0a,IACbA,aAA2Bpa,aAkB7BuZ,EAAgBld,MAjBhB,CACA,IAAKhC,KAAKke,YAAa,CACrB,MAAM8B,EAAc,IAAIzE,GAAYvZ,EAAM,SAC1ChC,KAAKke,YAAc8B,EAAYlV,MAC/B9K,KAAKme,kBAAoB6B,EAAYre,OAEvCud,EAAgBld,EAAK6C,IAAKob,IAQjB,CAAE5U,MALKb,EAAO/B,QACnBzI,KAAKke,YACL+B,EAAW5U,MACXrL,KAAKme,qBAGNne,MAKL,MAAMkgB,EAAmBle,EAAK,GAAGsE,OACjC,KACGlB,MAAMC,QAAQ6a,IACbA,aAA4Bva,cAC9B,CACA,IAAK3F,KAAKqe,aAAc,CACtB,MAAM2B,EAAc,IAAIzE,GAAYvZ,EAAM,UAC1ChC,KAAKqe,aAAe2B,EAAYlV,MAChC9K,KAAKmgB,mBAAqBH,EAAYre,OAExCud,EAAgBld,EAAK6C,IACnB,CAACob,EAAY3U,KACX,MAAM7J,EAAQ+I,EAAO/B,QACnBzI,KAAKqe,aACL4B,EAAW3Z,OACXtG,KAAKme,mBAEP,MAAO,CACL9S,MAAO6T,EAAc5T,GAAOD,MAC5B/E,OAAQ7E,IAGZzB,MAGJ,OAAOkf,EAGTpf,aACEof,GAEA,MAAMkB,EAAkB,IAAIhb,MAAM8Z,EAAcvd,QAC1C0e,EAAgBjc,GACpB,SAAU3E,GACR,OAAOA,EAAMO,KAAKiK,OAAO1E,KAE3B,CACEe,OAAQ,CAAC4Y,EAAc,GAAG7T,MAAM1J,QAChC4E,WAAW,IAGT+Z,EAAiBlc,GACrB,SAAqC3E,GACnC,OAAOA,EAAMO,KAAKiK,OAAO1E,KAE3B,CACEe,OAAQ,CAAC4Y,EAAc,GAAG5Y,OAAO3E,QACjC4E,WAAW,IAIf,IAAK,IAAI7E,EAAI,EAAGA,EAAIwd,EAAcvd,OAAQD,IAAK,CAC7C,MAAM6e,EAAiBrB,EAAcxd,GACrC0e,EAAgB1e,GAAK,CACnB2J,MAAOgV,EAAcE,EAAelV,OACpC/E,OAAQga,EAAeC,EAAeja,SAG1C,OAAO8Z,EAaTtgB,OACE,MAAM,IAAIoC,MAASlC,KAAK8H,YAAYC,KAApB,gCAMlBjI,eAIE,GAHKE,KAAK2O,QACR3O,KAAKsf,eAGJtf,KAAK4d,QACL5d,KAAK2O,QACL3O,KAAKkd,aACLld,KAAKmd,eACLnd,KAAKod,cAEN,MAAM,IAAIlb,MAAM,8BAElB,MAAMse,EAAa,GACnB,IAAK,IAAI9e,EAAI,EAAGA,EAAI1B,KAAK2O,OAAOhN,OAAQD,IAAK,CAC3C,MAAMuG,EAAQjI,KAAK2O,OAAOjN,GACpByZ,EAAYlT,EAAMzG,SACpByG,EAAM7E,eAAe,cACvB+X,EAAU4B,gBAAkB/c,KAAK2O,OAAO8R,QACtCxY,EAAMiB,YAGRjB,EAAM7E,eAAe,gBACrB6E,EAAM7E,eAAe,iBAErB+X,EAAUuF,iBAAmB1gB,KAAK2O,OAAO8R,QACvCxY,EAAM6B,aAERqR,EAAUwF,iBAAmB3gB,KAAK2O,OAAO8R,QACvCxY,EAAM8B,cAGVyW,EAAW/c,KAAK0X,GAGlB,MAAO,CACLxS,KAAM3I,KAAK8H,YAAYC,KACvB6Y,gBACE5gB,KAAKkc,QAAQ0E,qBACb,CAAC5gB,KAAKkd,YAAYhX,QACf2a,OAAO7gB,KAAKmd,cAActY,IAAKiZ,GAAMA,EAAE5X,SACvC2a,OAAO,CAAC7gB,KAAKod,aAAalX,SAC/B8W,iBAAkBhd,KAAK2O,OAAO8R,QAAQzgB,KAAKod,cAC3CzO,OAAQ6R,EACRzD,gBAAiB/c,KAAK2O,OAAO8R,QAAQzgB,KAAKkd,cAI9Cpd,gBACE4D,EACAod,eAMA,MAAMN,EAAa9c,EAAKiL,OAClBA,EAAmB,GACnBzF,EAAa4X,YACf5F,GAAcsF,EAAW,mBAAOM,EAASN,EAAW,IACpDtF,GAAcsF,EAAW,IAE7B,IAAKtX,EAAY,MAAM,IAAIhH,MAAM,wBAEjCyM,EAAOlL,KAAKyF,GAEZ,IAAK,IAAIxH,EAAI,EAAGA,EAAI8e,EAAW7e,OAAQD,IAAK,CAC1C,MAAMyZ,EAAYqF,EAAW9e,GAC7B,QACuC,IAA9ByZ,EAAU4B,sBACqB,IAA/B5B,EAAUuF,uBACqB,IAA/BvF,EAAUwF,iBACjB,CACA,MAAM1Y,EAAQ6Y,YACV5F,GAAcC,kBAAc2F,EAAS3F,GACrCD,GAAcC,GAClB,IAAKlT,EAAO,MAAM,IAAI/F,MAAM,wBAC5ByM,EAAOlL,KAAKwE,QACP,GAAyC,iBAA9BkT,EAAU4B,gBAA8B,CACxD,MAAM7T,EAAayF,EAAOwM,EAAU4B,iBACpC,IAAK7T,EACH,MAAM,IAAIhH,MAAM,yBAElB,MAAM+F,EAAQ6Y,YACV5F,GAAcC,EAAWjS,kBACzB4X,EAAS3F,EAAWjS,GACpBgS,GAAcC,EAAWjS,GAC7B,IAAKjB,EAAO,MAAM,IAAI/F,MAAM,wBAC5ByM,EAAOlL,KAAKwE,OACP,CACL,GAA0C,iBAA/BkT,EAAUuF,iBACnB,MAAM,IAAIxe,MACR,2EAGJ,GAA0C,iBAA/BiZ,EAAUwF,iBACnB,MAAM,IAAIze,MACR,2EAGJ,MAAM4H,EAAc6E,EAAOwM,EAAUuF,kBAC/B3W,EAAc4E,EAAOwM,EAAUwF,kBAErC,QAAoB1c,IAAhB6F,EACF,MAAM,IAAI5H,MACR,4DAA4DiZ,EAAUuF,+BAE1E,QAAoBzc,IAAhB8F,EACF,MAAM,IAAI7H,MACR,4DAA4DiZ,EAAUwF,+BAG1E,MAAM1Y,EAAQ6Y,YACV5F,GAAcC,EAAWrR,EAAaC,kBACtC+W,EAAS3F,EAAWrR,EAAaC,GACjCmR,GAAcC,EAAWrR,EAAaC,GAE1C,IAAK9B,EAAO,MAAM,IAAI/F,MAAM,wBAC5ByM,EAAOlL,KAAKwE,IAIhB,OAAO,IAAIjI,KAAK,IAAK0D,EAAMiL,OAAAA,IAO7B7O,aACE,MAAM,IAAIoC,MACLlC,KAAK8H,YAAYC,KAApB,sCASJjI,oBACE,MAAM,IAAIoC,MACLlC,KAAK8H,YAAYC,KAApB,qbChwBN,IAAIgZ,EAAY/gB,IAAQA,GAAK+gB,UAAa,WAStC,OARAA,EAAW1d,OAAOC,QAAU,SAAS0d,GACjC,IAAK,IAAIC,EAAGvf,EAAI,EAAGwf,EAAIC,UAAUxf,OAAQD,EAAIwf,EAAGxf,IAE5C,IAAK,IAAIwJ,KADT+V,EAAIE,UAAUzf,GACO2B,OAAO6T,UAAU9T,eAAe+T,KAAK8J,EAAG/V,KACzD8V,EAAE9V,GAAK+V,EAAE/V,IAEjB,OAAO8V,IAEKI,MAAMphB,KAAMmhB,YAEhC9d,OAAOge,eAAeC,EAAS,aAAc,CAAE7hB,OAAO,IACtD6hB,OAAeA,QAAgBA,YAAe,EAI9C,IAAIC,EAAsB,WACtB,SAASA,EAAKC,EAAOtF,GACjB,IAAIuF,EAAQzhB,UACI,IAAZkc,IAAsBA,EAAU,IACpC,IAAIwF,EAAKX,EAASA,EAAS,GAAIQ,EAAKnV,iBAAkB8P,GAAUyF,EAAOD,EAAGC,KAAMC,EAAOF,EAAGE,KAC1F5hB,KAAK0B,EAAI,EACT1B,KAAK6hB,WAAY,EACjB7hB,KAAKwhB,MAAQA,EACbxhB,KAAKkc,QAAUA,EACflc,KAAK8hB,KAAO,WACR,IAAIL,EAAMI,YAEVJ,EAAMzF,QAAU+F,WAAWN,EAAMK,KAAM,IACnCP,EAAKS,SAAT,CAEA,IAAIC,EAAOR,EAAMD,MAAMC,EAAM/f,GAC7B,GAAI+f,EAAM/f,GAAK+f,EAAMD,MAAM7f,OAQvB,OAPa,OAATigB,IACAL,EAAKS,SAAU,EACfJ,IACAL,EAAKS,SAAU,GAEnBP,EAAMI,WAAY,OAClBK,aAAaT,EAAMzF,SAGV,OAAT2F,GACAJ,EAAKS,SAAU,EACfL,EAAKM,EAAMR,EAAM/f,GACjB6f,EAAKS,SAAU,QAED/d,IAATge,GACLA,IAEJR,EAAM/f,MAEV6f,EAAKY,MAAM1e,KAAKzD,MACXkc,EAAQkG,OACTpiB,KAAK8hB,OA0Fb,OAvFAze,OAAOge,eAAeE,EAAM,YAAa,CAIrCc,IAAK,WACD,OAAOd,EAAKS,SAEhBM,YAAY,EACZC,cAAc,IAKlBhB,EAAKiB,QAAU,WACX,IAAK,IAAI9gB,EAAI,EAAGA,EAAI6f,EAAKY,MAAMxgB,OAAQD,IACnC6f,EAAKY,MAAMzgB,GAAG+gB,QAMtBlB,EAAKrK,UAAUwL,UAAY,WACvB,QAAI1iB,KAAK6hB,YACL7hB,KAAK6hB,WAAY,GACV,IAOfN,EAAKrK,UAAUtQ,IAAM,SAAUqb,GAK3B,OAJAjiB,KAAKwhB,MAAM/d,KAAKwe,GACZjiB,KAAK0iB,aACL1iB,KAAK8hB,OAEF9hB,MAKXuhB,EAAKrK,UAAUyL,OAAS,SAAUV,GAK9B,OAJAjiB,KAAKwhB,MAAMve,OAAOjD,KAAK0B,EAAG,EAAGugB,GACzBjiB,KAAK0iB,aACL1iB,KAAK8hB,OAEF9hB,MAKXuhB,EAAKrK,UAAU0L,SAAW,SAAUpB,GAKhC,OAJAxhB,KAAKwhB,MAAQxhB,KAAKwhB,MAAMX,OAAOW,GAC3BxhB,KAAK0iB,aACL1iB,KAAK8hB,OAEF9hB,MAKXuhB,EAAKrK,UAAU2L,YAAc,SAAUrB,GACnC,IAAIsB,EAAS9iB,KAAKwhB,MAAMve,OAAO,EAAGjD,KAAK0B,GACnCqhB,EAAQ/iB,KAAKwhB,MAKjB,OAJAxhB,KAAKwhB,MAAQsB,EAAOjC,OAAOW,EAAOuB,GAC9B/iB,KAAK0iB,aACL1iB,KAAK8hB,OAEF9hB,MAKXuhB,EAAKrK,UAAUuL,KAAO,WAMlB,OALAziB,KAAK6hB,WAAY,EACjBK,aAAaliB,KAAKgc,SACdhc,KAAKkc,QAAQ0F,MACb5hB,KAAKkc,QAAQ0F,OAEV5hB,MAEXuhB,EAAKS,SAAU,EACfT,EAAKY,MAAQ,GACbZ,EAAKnV,gBAAkB,CACnBuV,KAAM,KACNC,KAAM,MAEHL,KAMX,SAASyB,EAAKxB,EAAOtF,GACjB,OAAO,IAAIqF,EAAKC,EAAOtF,GAL3BoF,OAAeC,EAOfD,OAAe0B,EACf,IAAIC,EAAuB,WACvB,SAASA,EAAM/G,EAASgH,QACN,IAAVA,IAAoBA,EAAQ,KAChCljB,KAAKsL,MAAQ,EACbtL,KAAKmiB,MAAQ,GACbniB,KAAKkjB,MAAQA,EACbljB,KAAKkc,QAAUA,EA8DnB,OAzDA+G,EAAM/L,UAAUtQ,IAAM,SAAUqb,GAG5B,OAFWjiB,KAAKmjB,OACXvc,IAAIqb,GACFjiB,MAKXijB,EAAM/L,UAAU0L,SAAW,SAAUpB,GAGjC,OAFWxhB,KAAKmjB,OACXP,SAASpB,GACPxhB,MAKXijB,EAAM/L,UAAUyL,OAAS,SAAUV,GAG/B,OAFWjiB,KAAKmjB,OACXR,OAAOV,GACLjiB,MAKXijB,EAAM/L,UAAU2L,YAAc,SAAUrB,GAGpC,OAFWxhB,KAAKmjB,OACXN,YAAYrB,GACVxhB,MAKXijB,EAAM/L,UAAUuL,KAAO,WACnB,IAAK,IAAI/gB,EAAI,EAAGA,EAAI1B,KAAKmiB,MAAMxgB,OAAQD,IACnC1B,KAAKmiB,MAAMzgB,GAAG+gB,OAElB,OAAOziB,MAKXijB,EAAM/L,UAAUiM,KAAO,WACnB,IAAIH,EACAb,EAAQniB,KAAKmiB,MAYjB,OAXIA,EAAMxgB,OAAS3B,KAAKkjB,OACpBF,EAAO,IAAIzB,EAAK,GAAIvhB,KAAKkc,SACzBiG,EAAM1e,KAAKuf,IAGXA,EAAOb,EAAMniB,KAAKsL,QAAU,KAEhCtL,KAAKsL,QACDtL,KAAKsL,OAAStL,KAAKkjB,QACnBljB,KAAKsL,MAAQ,GAEV0X,GAEJC,KAEX3B,QAAgB2B,EACM,oBAAXG,SAEPA,OAAO7B,KAAOA,EAEd6B,OAAOJ,KAAOA,EAEdI,OAAO7B,KAAK0B,MAAQA,eCxORI,GAAsBC,GACpC,MAAMpgB,EAAyB,GAC/B,IAAK,IAAIxB,EAAI,EAAGA,EAAI4hB,EAAO3hB,OAAQD,IACjCwB,EAAOO,KAAKkC,aAAaiD,KAAK0a,EAAO5hB,KAEvC,OAAOwB,WAGOqgB,GACdlY,EACA/E,GAEA,MAAMpD,EAAyB,GAC/B,IAAK,IAAIxB,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCwB,EAAOO,KAAKkC,aAAaiD,KAAKyC,EAAM3J,KAEtC,IAAK,IAAIA,EAAI,EAAGA,EAAI4E,EAAO3E,OAAQD,IACjCwB,EAAOO,KAAKkC,aAAaiD,KAAKtC,EAAO5E,KAEvC,OAAOwB,WAGOsgB,GAAqB/hB,GACnC,MAAMyB,EAAyB,GAC/B,IAAK,IAAIxB,EAAI,EAAGA,EAAID,EAAME,OAAQD,IAChCwB,EAAOO,KAAKkC,aAAaiD,KAAK,CAACnH,EAAMC,MAEvC,OAAOwB,WAGOugB,GACdpY,EACA/E,GAEA,MAAMpD,EAAyB,GAC/B,IAAK,IAAIxB,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCwB,EAAOO,KAAKkC,aAAaiD,KAAK,CAACyC,EAAM3J,MAEvC,IAAK,IAAIA,EAAI,EAAGA,EAAI4E,EAAO3E,OAAQD,IACjCwB,EAAOO,KAAKkC,aAAaiD,KAAK,CAACtC,EAAO5E,MAExC,OAAOwB,WAGOwgB,GAAoBjiB,GAClC,OAAOkE,aAAaiD,KAAKnH,YAsBXkiB,GACdtY,EACA/E,EACAsd,EACAC,EACAC,EACAC,GAEA,MAAMlhB,EAA0B,GAChC,IAAK,IAAInB,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAAK,CACrC,MAAMuJ,EAASI,EAAM3J,GACfwB,EAAS,IAAIyC,aAAame,GAChC,IAAK,MAAM5Y,KAAKD,EACVA,EAAO7H,eAAe8H,KACxBhI,EAAO0gB,EAAW1Y,IAAMD,EAAOC,IAGnCrI,EAAQY,KAAKP,GAEf,IAAK,IAAIxB,EAAI,EAAGA,EAAI4E,EAAO3E,OAAQD,IAAK,CACtC,MAAMuJ,EAAS3E,EAAO5E,GAChBwB,EAAS,IAAIyC,aAAaoe,GAChC,IAAK,MAAM7Y,KAAKD,EACVA,EAAO7H,eAAe8H,KACxBhI,EAAO2gB,EAAY3Y,IAAMD,EAAOC,IAGpCrI,EAAQY,KAAKP,GAEf,OAAOL,WAGOmhB,GACd/Y,GAEA,MAAM/H,EAAyB,GAC/B,IAAK,MAAMgI,KAAKD,EACTA,EAAO7H,eAAe8H,IAC3BhI,EAAOO,KAAKkC,aAAaiD,KAAK,CAACqC,EAAOC,MAExC,OAAOhI,WAGO+gB,GACd5Y,EACA/E,GAEA,MAAMpD,EAAyB,GAC/B,IAAK,MAAMgI,KAAKG,EACTA,EAAMjI,eAAe8H,IAC1BhI,EAAOO,KAAKkC,aAAaiD,KAAK,CAACyC,EAAMH,MAEvC,IAAK,MAAMA,KAAK5E,EACTA,EAAOlD,eAAe8H,IAC3BhI,EAAOO,KAAKkC,aAAaiD,KAAK,CAACtC,EAAO4E,MAExC,OAAOhI,WAGOghB,GACdjZ,EACAH,EACAnJ,GAEA,MAAMuB,EAAS,IAAIyC,aAAahE,GAChC,IAAK,MAAMuJ,KAAKD,EACVA,EAAO7H,eAAe8H,KACxBhI,EAAO4H,EAAMI,IAAMD,EAAOC,IAG9B,OAAOhI,WCzIO5D,GACdyS,GAMA,OAAI3M,MAAMC,QAAQ0M,IAAWA,aAAkBpM,aACtCtG,KAAKC,OAAOyS,GAEZ1S,KAAKC,OAAO+D,OAAO0O,OAAOA,aCVrBoS,GAAIpe,GAElB,IAAIC,EAAM,EACV,IAAK,IAAItE,EAAI,EAAGA,EAAIqE,EAAOpE,OAAQD,IACjCsE,GAAOD,EAAOrE,IAAM,EAEtB,OAAOsE,EAAMD,EAAOpE,OCatB,SAASyiB,GACP3kB,EACAqL,GAEA,GAAKrL,EAAuBoM,kBAAkBwY,YAC5C,OAAO,KAET,GAAIjf,MAAMC,QAAQ5F,GAChB,OAAOikB,GAET,IAAK5Y,EAAO,MAAM,IAAI5I,MAAM,uBAC5B,MAAMP,OAAEA,GAAW0B,OAAOkI,KAAKT,GAC/B,OAAQ4E,IACN,MAAMjO,EAAQ,IAAIkE,aAAahE,GAC/B,IAAK,MAAMuJ,KAAKJ,EACTA,EAAM1H,eAAe8H,KAC1BzJ,EAAMqJ,EAAMI,IAAMwE,EAAExE,IAAM,GAE5B,OAAOzJ,SAkHE6iB,GA6CXxkB,YACEoc,EAAuE,IA1CzElc,aAnFO,CACLukB,UAAW,EACXC,WAAY,EACZ/I,aAAc,IAiFhBzb,eAnCO,CACLykB,WAAY,UACZvkB,WAAY,IACZ0b,YAAa,KACb/L,KAAK,EACLgM,UAAW,GACX6I,eAAgB,IAChBpc,aAAc,GACdwE,SAAU,GACVgP,eAAgB,GAChBE,QAASrE,EAAAA,EACTgN,MAAO,GACPC,MAAO,KACPC,QAAS,MAuBX7kB,WAAkB,GAClBA,kBAAe,EACfA,YAAyB,GACzBA,aAA4B,GAC5BA,aAA0B,GAE1BA,YAAyB,GACzBA,aAA4B,GAC5BA,YAAyB,GAEzBA,wBAAqB,EAErBA,iBAAkC,KAClCA,uBAAoB,EACpBA,kBAAmC,KACnCA,wBAAqB,EAErBA,kBAA8C,KAC9CA,mBAA+C,KAE/CA,cAAmDqL,IACjDrL,KAAK8kB,gBACE9kB,KAAKoe,SAAS/S,IAGvBrL,qBACEsG,IAEAtG,KAAK8kB,gBACE9kB,KAAK+kB,gBAAgBze,IAI9BtG,oBAAiC,GACjCA,qBAAkC,GAClCA,gBAA+B,GAC/BA,iBAAgC,GAChCA,gBAAa,EAKXA,KAAKkc,QAAU,IAAKlc,KAAKkc,WAAYA,GACrClc,KAAKglB,sBAAsB9I,GAE3B,MAAMqI,UAAEA,EAASlH,aAAEA,EAAYmH,WAAEA,GAAexkB,KAAKkc,QACjDqI,GAAaC,IACfxkB,KAAK4gB,MAAQ,CAAC2D,GAAW1D,OAAOxD,MAAAA,EAAAA,EAAgB,IAAIwD,OAAO,CAAC2D,KAQhE1kB,aACE,IAAKE,KAAK4gB,MAAMjf,OACd,MAAM,IAAIO,MAAM,yCAGlBlC,KAAKid,YAAcjd,KAAK4gB,MAAMjf,OAAS,EACvC3B,KAAKgS,OAAS,IAAI5M,MAAMpF,KAAKid,aAC7Bjd,KAAKmH,QAAU,IAAI/B,MAAMpF,KAAKid,aAC9Bjd,KAAKilB,QAAU,IAAI7f,MAAMpF,KAAKid,aAG9Bjd,KAAKoH,OAAS,IAAIhC,MAAMpF,KAAKid,aAC7Bjd,KAAKwM,QAAU,IAAIpH,MAAMpF,KAAKid,aAC9Bjd,KAAK+F,OAAS,IAAIX,MAAMpF,KAAKid,aAE7B,IAAK,IAAIiI,EAAa,EAAGA,GAAcllB,KAAKid,YAAaiI,IAAc,CACrE,MAAM9iB,EAAOpC,KAAK4gB,MAAMsE,GAKxB,GAJAllB,KAAKoH,OAAO8d,GAAcrc,EAAMzG,GAChCpC,KAAK+F,OAAOmf,GAAcrc,EAAMzG,GAChCpC,KAAKilB,QAAQC,GAAcrc,EAAMzG,GAE7B8iB,EAAa,EAAG,CAClBllB,KAAKgS,OAAOkT,GAAclV,GAAO5N,GACjCpC,KAAKmH,QAAQ+d,GAAc,IAAI9f,MAAMhD,GACrCpC,KAAKwM,QAAQ0Y,GAAc,IAAI9f,MAAMhD,GAErC,IAAK,IAAI+iB,EAAY,EAAGA,EAAY/iB,EAAM+iB,IAAa,CACrD,MAAMC,EAAWplB,KAAK4gB,MAAMsE,EAAa,GACzCllB,KAAKmH,QAAQ+d,GAAYC,GAAanV,GAAOoV,GAC7CplB,KAAKwM,QAAQ0Y,GAAYC,GAAatc,EAAMuc,KAKlDplB,KAAK8kB,gBACyB,SAA1B9kB,KAAKU,UAAU2G,QACjBrH,KAAKqlB,aAITvlB,cAAc2kB,GACZ,MAAMhlB,EAAQglB,MAAAA,EAAAA,EAAczkB,KAAKU,UAAU+jB,WAC3C,OAAQhlB,GACN,IAAK,UACHO,KAAKoe,SAAWpe,KAAKslB,iBACrBtlB,KAAK+kB,gBAAkB/kB,KAAKulB,wBAC5B,MACF,IAAK,OACHvlB,KAAKoe,SAAWpe,KAAKwlB,cACrBxlB,KAAK+kB,gBAAkB/kB,KAAKylB,qBAC5B,MACF,IAAK,aACHzlB,KAAKoe,SAAWpe,KAAK0lB,mBACrB1lB,KAAK+kB,gBAAkB/kB,KAAK2lB,0BAC5B,MACF,IAAK,OACH3lB,KAAKoe,SAAWpe,KAAK4lB,cACrB5lB,KAAK+kB,gBAAkB/kB,KAAK6lB,qBAC5B,MACF,QACE,MAAM,IAAI3jB,MACR,sBAAsBzC,0EAK9BqmB,iBACE,OAAO9lB,KAAK4gB,MAAMjf,OAAS,EAG7B7B,IAAIuL,GACF,IAAKrL,KAAK8lB,WACR,MAAM,IAAI5jB,MAAM,wBAElB,IAAI6jB,EAUJ,GAREA,EADE/lB,KAAKke,YACU1T,EAAO/B,QACtBzI,KAAKke,YACJ7S,EACDrL,KAAKme,mBAGW9S,EAEhB0a,EAAepkB,SAAW3B,KAAK4gB,MAAM,GACvC,MAAM,IAAI1e,MAAM,qCAAqClC,KAAK4gB,MAAM,IAElE,MAAMta,EAAStG,KAAKoe,SAAS2H,GAAgB/iB,MAAM,GACnD,OAAIhD,KAAKqe,aACC7T,EAAO8T,SACbte,KAAKqe,aACL/X,GAGIA,EAGVxG,iBAAiBuL,GACfrL,KAAKilB,QAAQ,GAAK5Z,EAElB,IAAI/E,EAAS,KACb,IAAK,IAAI2B,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAM+d,EAAchmB,KAAK4gB,MAAM3Y,GACzBge,EAAgBjmB,KAAKmH,QAAQc,GAC7Bie,EAAelmB,KAAKgS,OAAO/J,GAC3Bke,EAAgBnmB,KAAKilB,QAAQhd,GACnC,IAAK,IAAIme,EAAO,EAAGA,EAAOJ,EAAaI,IAAQ,CAC7C,MAAMjf,EAAU8e,EAAcG,GAE9B,IAAIpgB,EAAMkgB,EAAaE,GACvB,IAAK,IAAInkB,EAAI,EAAGA,EAAIkF,EAAQxF,OAAQM,IAClC+D,GAAOmB,EAAQlF,GAAKoJ,EAAMpJ,GAG5BkkB,EAAcC,GAAQ,GAAK,EAAI/mB,KAAKK,KAAKsG,IAE3CM,EAAS+E,EAAQ8a,EAEnB,IAAK7f,EACH,MAAM,IAAIpE,MAAM,oBAElB,OAAOoE,EAGTxG,cAAcuL,GACZrL,KAAKilB,QAAQ,GAAK5Z,EAElB,IAAI/E,EAAS,KACb,IAAK,IAAI2B,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAMoe,EAAarmB,KAAK4gB,MAAM3Y,GACxBge,EAAgBjmB,KAAKmH,QAAQc,GAC7Bie,EAAelmB,KAAKgS,OAAO/J,GAC3Bke,EAAgBnmB,KAAKilB,QAAQhd,GACnC,IAAK,IAAIme,EAAO,EAAGA,EAAOC,EAAYD,IAAQ,CAC5C,MAAMjf,EAAU8e,EAAcG,GAE9B,IAAIpgB,EAAMkgB,EAAaE,GACvB,IAAK,IAAInkB,EAAI,EAAGA,EAAIkF,EAAQxF,OAAQM,IAClC+D,GAAOmB,EAAQlF,GAAKoJ,EAAMpJ,GAG5BkkB,EAAcC,GAAQpgB,EAAM,EAAI,EAAIA,EAEtCM,EAAS+E,EAAQ8a,EAEnB,IAAK7f,EACH,MAAM,IAAIpE,MAAM,oBAElB,OAAOoE,EAGTxG,mBAAmBuL,GACjBrL,KAAKilB,QAAQ,GAAK5Z,EAClB,MAAMqZ,eAAEA,GAAmB1kB,KAAKU,UAChC,IAAI4F,EAAS,KACb,IAAK,IAAI2B,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAMoe,EAAarmB,KAAK4gB,MAAM3Y,GACxBge,EAAgBjmB,KAAKmH,QAAQc,GAC7Bie,EAAelmB,KAAKgS,OAAO/J,GAC3Bke,EAAgBnmB,KAAKilB,QAAQhd,GACnC,IAAK,IAAIme,EAAO,EAAGA,EAAOC,EAAYD,IAAQ,CAC5C,MAAMjf,EAAU8e,EAAcG,GAE9B,IAAIpgB,EAAMkgB,EAAaE,GACvB,IAAK,IAAInkB,EAAI,EAAGA,EAAIkF,EAAQxF,OAAQM,IAClC+D,GAAOmB,EAAQlF,GAAKoJ,EAAMpJ,GAG5BkkB,EAAcC,GAAQ/mB,KAAKC,IAAI0G,EAAK0e,EAAiB1e,GAEvDM,EAAS+E,EAAQ8a,EAEnB,IAAK7f,EACH,MAAM,IAAIpE,MAAM,oBAElB,OAAOoE,EAGTxG,cAAcuL,GACZrL,KAAKilB,QAAQ,GAAK5Z,EAElB,IAAI/E,EAAS,KACb,IAAK,IAAI2B,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAMoe,EAAarmB,KAAK4gB,MAAM3Y,GACxBge,EAAgBjmB,KAAKmH,QAAQc,GAC7Bie,EAAelmB,KAAKgS,OAAO/J,GAC3Bke,EAAgBnmB,KAAKilB,QAAQhd,GACnC,IAAK,IAAIme,EAAO,EAAGA,EAAOC,EAAYD,IAAQ,CAC5C,MAAMjf,EAAU8e,EAAcG,GAE9B,IAAIpgB,EAAMkgB,EAAaE,GACvB,IAAK,IAAInkB,EAAI,EAAGA,EAAIkF,EAAQxF,OAAQM,IAClC+D,GAAOmB,EAAQlF,GAAKoJ,EAAMpJ,GAG5BkkB,EAAcC,GAAQ/mB,KAAKO,KAAKoG,GAElCM,EAAS+E,EAAQ8a,EAEnB,IAAK7f,EACH,MAAM,IAAIpE,MAAM,oBAElB,OAAOoE,EAQTxG,oBACEye,GAEIve,KAAK4gB,MAAMjf,SAEf3B,KAAK4gB,MAAQ,GACb5gB,KAAK4gB,MAAMnd,KAAK8a,EAAa,GAAGlT,MAAM1J,QACjC3B,KAAKkc,QAAQmB,aAKhBrd,KAAKkc,QAAQmB,aAAaf,QAASla,IACjCpC,KAAK4gB,MAAMnd,KAAKrB,KALlBpC,KAAK4gB,MAAMnd,KACTpE,KAAKC,IAAI,EAAGD,KAAKwC,MAAM0c,EAAa,GAAGlT,MAAM1J,OAAS,KAO1D3B,KAAK4gB,MAAMnd,KAAK8a,EAAa,GAAGjY,OAAO3E,QAEvC3B,KAAKsf,cAGPxf,sBAAsBY,GACpB,MAAM4lB,EAAS,IAAKtmB,KAAKU,aAAcA,GACvCV,KAAKumB,wBAAwBD,GAC7BtmB,KAAKU,UAAY4lB,EACjBtmB,KAAKwmB,aAAaxmB,KAAKU,UAAUmP,KAGnC/P,wBAAwBoc,GACtB,MAAMG,EAAmD,CACvDoI,WAAY,IACH,CAAC,UAAW,OAAQ,aAAc,QAAQ7V,SAC/CsN,EAAQuI,YAGZvkB,WAAY,KACV,MAAMsc,EAAMN,EAAQhc,WACpB,MAAsB,iBAARsc,GAAoBA,EAAM,GAE1CZ,YAAa,KACX,MAAMY,EAAMN,EAAQN,YACpB,MAAsB,iBAARY,GAAoBA,EAAM,GAAKA,EAAM,GAErD3M,IAAK,KACH,MAAM2M,EAAMN,EAAQrM,IACpB,MAAsB,mBAAR2M,GAAqC,kBAARA,GAE7CX,UAAW,KACT,MAAMW,EAAMN,EAAQL,UACpB,MAAsB,iBAARW,GAAoBA,EAAM,GAE1CkI,eAAgB,KACd,MAAMlI,EAAMN,EAAQwI,eACpB,MAAsB,iBAARlI,GAAoBA,EAAM,GAAKA,EAAM,GAErDlU,aAAc,KACZ,MAAMkU,EAAMN,EAAQ5T,aACpB,MAAsB,iBAARkU,GAAoBA,EAAM,GAAKA,EAAM,GAErD1P,SAAU,KACR,MAAM0P,EAAMN,EAAQpP,SACpB,MAAsB,iBAAR0P,GAAoBA,EAAM,GAAKA,EAAM,GAErDJ,SAAU,KACR,MAAMI,EAAMN,EAAQE,SACpB,MAAsB,mBAARI,QAA8BvY,IAARuY,GAEtCV,eAAgB,KACd,MAAMU,EAAMN,EAAQJ,eACpB,MAAsB,iBAARU,GAAoBA,EAAM,GAE1CR,QAAS,KACP,MAAMQ,EAAMN,EAAQF,QACpB,MAAsB,iBAARQ,GAAoBA,EAAM,GAE1CnV,OAAQ,KACN,MAAMmV,EAAMN,EAAQ7U,OACpB,OAAQmV,GAAe,SAARA,GAEjBmI,MAAO,KACL,MAAMnI,EAAMN,EAAQyI,MACpB,OAAOnI,EAAM,GAAKA,EAAM,GAE1BoI,MAAO,KACL,MAAMpI,EAAMN,EAAQ0I,MACpB,OAAOpI,EAAM,GAAKA,EAAM,GAE1BqI,QAAS,KACP,MAAMrI,EAAMN,EAAQ2I,QACpB,OAAOrI,EAAM,GAAKA,EAAM,IAG5B,IAAK,MAAMtR,KAAKmR,EAAa,CAC3B,MAAM3M,EAAKwM,EACX,IAAKG,EAAYnR,KACf,MAAM,IAAIhJ,MACR,IAAIgJ,MAAMwE,EAAExE,+EAWpBpL,mBACE,MAAM2kB,WACJA,EAAUvkB,WACVA,EAAU0b,YACVA,EAAW/L,IACXA,EAAGgM,UACHA,EAAS6I,eACTA,EAAcpc,aACdA,EAAYwE,SACZA,EAAQgP,eACRA,EAAcE,QACdA,EAAO3U,OACPA,EAAMsd,MACNA,EAAKC,MACLA,EAAKC,QACLA,GACE7kB,KAAKU,UACT,MAAO,CACL+jB,WAAAA,EACAvkB,WAAAA,EACA0b,YAAAA,EACA/L,IACiB,mBAARA,GAEY,kBAARA,GACPA,EAENgM,UAAAA,EACA6I,eAAAA,EACApc,aAAAA,EACAwE,SAAAA,EACAgP,eAAAA,EACAE,QAASA,IAAYrE,EAAAA,EAAW,WAAaqE,EAC7C3U,OAAAA,EACAsd,MAAAA,EACAC,MAAAA,EACAC,QAAAA,GAIJ/kB,aAAa+P,GAET7P,KAAKU,UAAUmP,IADE,mBAARA,EACYA,IACZA,GACY7P,KAAKymB,kBAM9B3mB,kBAAkB0e,GAChB9B,QAAQ7M,IACN,eAAe2O,EAAOte,+BAA+Bse,EAAO7e,SAIhEG,uBACEkC,GAEA,IAAIgE,EAAM,EACV,IAAK,IAAItE,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EACjCsE,GAAOhG,KAAK0mB,aAAa1kB,EAAKN,IAAI,GAEpC,OAAOsE,EAAMhE,EAAKL,OAGpB7B,cAAckC,GACZ,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EACjC1B,KAAK0mB,aAAa1kB,EAAKN,IAI3B5B,aACEkC,EACAwc,EACAC,GAEA,MAAMrC,SACJA,EAAQN,eACRA,EAAcF,YACdA,EAAW1b,WACXA,EAAU2P,IACVA,EAAGgM,UACHA,GACE7b,KAAKU,UAET,QACE8d,EAAOte,YAAcA,GACrBse,EAAO7e,OAASic,GAChB7a,KAAKC,OAASyd,KAKhBD,EAAOte,aAEH2P,GAAO2O,EAAOte,WAAa2b,GAAc,GAC3C2C,EAAO7e,MAAQK,KAAK2mB,uBAAuB3kB,GAC1C6N,EAA6C2O,IACrCA,EAAOte,WAAaF,KAAK+b,oBAAuB,EACzDyC,EAAO7e,MAAQK,KAAK2mB,uBAAuB3kB,GAE3ChC,KAAKif,cAAcjd,GAGjBoa,GAAYoC,EAAOte,WAAa4b,GAAmB,GACrDM,EAAS,CACPlc,WAAYse,EAAOte,WACnBP,MAAO6e,EAAO7e,SAGX,GAGTG,aACEkC,EACAka,EAA+C,IAE/Clc,KAAKglB,sBAAsB9I,GAC3B,MAAMqC,EAAeve,KAAKmf,WAAWnd,GAC/Byc,EAAU1d,KAAKC,MAAQhB,KAAKU,UAAUsb,QAS5C,OAFAhc,KAAKof,oBAAoBb,GAElB,CACLA,aAAAA,EACAC,OATa,CACb7e,MAAO,EACPO,WAAY,GAQZue,QAAAA,GAIJ3e,MACEkC,EACAka,EAA+C,IAE/C,MAAMqC,aAAEA,EAAYC,OAAEA,EAAMC,QAAEA,GAAYze,KAAK4mB,aAC7C5kB,EACAka,GAGF,KACOlc,KAAK6mB,aAAatI,EAAcC,EAAQC,KAI/C,OAAOD,EAGT1e,iBACEkC,EACAka,EAA+C,IAE/C,MAAMqC,aAAEA,EAAYC,OAAEA,EAAMC,QAAEA,GAAYze,KAAK4mB,aAAa5kB,EAAMka,GAElE,aAAa,IAAI4K,QAAQ,CAACC,EAASC,KACjC,IACE,MAAMC,EAAoB,IAAI1F,QAC5B,IAAInc,MAAMpF,KAAKU,UAAUR,YACzB,CACEkiB,OAAO,EACPT,KAAM,IACJ3hB,KAAK6mB,aAAatI,EAAcC,EAAQC,IACxCwI,EAAYxE,OACdb,KAAM,IAAMmF,EAAQvI,KAGxByI,EAAYnF,OACZ,MAAOoF,GACPF,EAAOE,MAKbpnB,aACEL,EACAigB,GASA,OANA1f,KAAKoe,SAAS3e,EAAM4L,OAGpBrL,KAAK+kB,gBAAgBtlB,EAAM6G,QAC3BtG,KAAK4f,gBAEDF,EACKyE,GAAInkB,KAAK+F,OAAO/F,KAAKid,cAEvB,KAGTnd,wBAAwBsK,GACtB,IAAK,IAAInC,EAAQjI,KAAKid,YAAahV,GAAS,EAAGA,IAAS,CACtD,MAAMoe,EAAarmB,KAAK4gB,MAAM3Y,GACxBkf,EAAennB,KAAKilB,QAAQhd,GAC5Bmf,EAAcpnB,KAAK+F,OAAOkC,GAC1Bof,EAAernB,KAAKoH,OAAOa,GAC3Bqf,EAAYtnB,KAAKmH,QAAQc,EAAQ,GAEvC,IAAK,IAAIme,EAAO,EAAGA,EAAOC,EAAYD,IAAQ,CAC5C,MAAM9f,EAAS6gB,EAAaf,GAE5B,IAAIzmB,EAAQ,EACZ,GAAIsI,IAAUjI,KAAKid,YACjBtd,EAAQyK,EAAOgc,GAAQ9f,MAClB,CACL,MAAMc,EAASpH,KAAKoH,OAAOa,EAAQ,GACnC,IAAK,IAAIhG,EAAI,EAAGA,EAAImF,EAAOzF,OAAQM,IACjCtC,GAASyH,EAAOnF,GAAKqlB,EAAUrlB,GAAGmkB,GAGtCgB,EAAYhB,GAAQzmB,EACpB0nB,EAAajB,GAAQzmB,EAAQ2G,GAAU,EAAIA,KAKjDxG,qBAAqBsK,GACnB,IAAK,IAAInC,EAAQjI,KAAKid,YAAahV,GAAS,EAAGA,IAAS,CACtD,MAAMsf,EAAcvnB,KAAK4gB,MAAM3Y,GACzBuf,EAAiBxnB,KAAKilB,QAAQhd,GAC9Bwf,EAAcznB,KAAKmH,QAAQc,EAAQ,GACnCyf,EAAa1nB,KAAKoH,OAAOa,EAAQ,GACjC0f,EAAgB3nB,KAAK+F,OAAOkC,GAC5B2f,EAAgB5nB,KAAKoH,OAAOa,GAElC,IAAK,IAAIme,EAAO,EAAGA,EAAOmB,EAAanB,IAAQ,CAC7C,MAAM9f,EAASkhB,EAAepB,GAE9B,IAAIzmB,EAAQ,EACZ,GAAIsI,IAAUjI,KAAKid,YACjBtd,EAAQyK,EAAOgc,GAAQ9f,OAEvB,IAAK,IAAIrE,EAAI,EAAGA,EAAIylB,EAAW/lB,OAAQM,IACrCtC,GAAS+nB,EAAWzlB,GAAKwlB,EAAYxlB,GAAGmkB,GAG5CuB,EAAcvB,GAAQzmB,EACtBioB,EAAcxB,GAAQ9f,EAAS,EAAI3G,EAAQ,IAKjDG,0BAA0BsK,GACxB,MAAMyd,EAAQ7nB,KAAKU,UAAUgkB,eAC7B,IAAK,IAAIzc,EAAQjI,KAAKid,YAAahV,GAAS,EAAGA,IAAS,CACtD,MAAMsf,EAAcvnB,KAAK4gB,MAAM3Y,GACzBuf,EAAiBxnB,KAAKilB,QAAQhd,GAC9Byf,EAAa1nB,KAAKoH,OAAOa,EAAQ,GACjCwf,EAAcznB,KAAKmH,QAAQc,EAAQ,GACnC0f,EAAgB3nB,KAAK+F,OAAOkC,GAC5B2f,EAAgB5nB,KAAKoH,OAAOa,GAElC,IAAK,IAAIme,EAAO,EAAGA,EAAOmB,EAAanB,IAAQ,CAC7C,MAAM9f,EAASkhB,EAAepB,GAE9B,IAAIzmB,EAAQ,EACZ,GAAIsI,IAAUjI,KAAKid,YACjBtd,EAAQyK,EAAOgc,GAAQ9f,OAEvB,IAAK,IAAIrE,EAAI,EAAGA,EAAIylB,EAAW/lB,OAAQM,IACrCtC,GAAS+nB,EAAWzlB,GAAKwlB,EAAYxlB,GAAGmkB,GAG5CuB,EAAcvB,GAAQzmB,EACtBioB,EAAcxB,GAAQ9f,EAAS,EAAI3G,EAAQkoB,EAAQloB,IAKzDG,qBAAqBsK,GACnB,IAAK,IAAInC,EAAQjI,KAAKid,YAAahV,GAAS,EAAGA,IAAS,CACtD,MAAMsf,EAAcvnB,KAAK4gB,MAAM3Y,GACzBuf,EAAiBxnB,KAAKilB,QAAQhd,GAC9Byf,EAAa1nB,KAAKoH,OAAOa,EAAQ,GACjCwf,EAAcznB,KAAKmH,QAAQc,EAAQ,GACnC0f,EAAgB3nB,KAAK+F,OAAOkC,GAC5B2f,EAAgB5nB,KAAKoH,OAAOa,GAElC,IAAK,IAAIme,EAAO,EAAGA,EAAOmB,EAAanB,IAAQ,CAC7C,MAAM9f,EAASkhB,EAAepB,GAE9B,IAAIzmB,EAAQ,EACZ,GAAIsI,IAAUjI,KAAKid,YACjBtd,EAAQyK,EAAOgc,GAAQ9f,OAEvB,IAAK,IAAIrE,EAAI,EAAGA,EAAIylB,EAAW/lB,OAAQM,IACrCtC,GAAS+nB,EAAWzlB,GAAKwlB,EAAYxlB,GAAGmkB,GAG5CuB,EAAcvB,GAAQzmB,EACtBioB,EAAcxB,IAAS,EAAI9f,EAASA,GAAU3G,IASpDG,gBACE,MAAMwI,aAAEA,EAAYwE,SAAEA,GAAa9M,KAAKU,UACxC,IAAK,IAAIuH,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAM4E,EAAW7M,KAAKilB,QAAQhd,EAAQ,GAChCoe,EAAarmB,KAAK4gB,MAAM3Y,GACxB6f,EAAc9nB,KAAKoH,OAAOa,GAC1B8f,EAAgB/nB,KAAKwM,QAAQvE,GAC7Bge,EAAgBjmB,KAAKmH,QAAQc,GAC7Bie,EAAelmB,KAAKgS,OAAO/J,GAEjC,IAAK,IAAIme,EAAO,EAAGA,EAAOC,EAAYD,IAAQ,CAC5C,MAAM5mB,EAAQsoB,EAAY1B,GAE1B,IAAK,IAAInkB,EAAI,EAAGA,EAAI4K,EAASlL,OAAQM,IAAK,CACxC,IAAI+lB,EAASD,EAAc3B,GAAMnkB,GAEjC+lB,EAAS1f,EAAe9I,EAAQqN,EAAS5K,GAAK6K,EAAWkb,EAEzDD,EAAc3B,GAAMnkB,GAAK+lB,EACzB/B,EAAcG,GAAMnkB,IAAM+lB,EAE5B9B,EAAaE,IAAS9d,EAAe9I,IAK3CM,aACEE,KAAKioB,eAAiB,GACtBjoB,KAAKkoB,gBAAkB,GACvBloB,KAAKmoB,WAAa,GAClBnoB,KAAKooB,YAAc,GACnBpoB,KAAKE,WAAa,EAElB,IAAK,IAAI+H,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAM7F,EAAOpC,KAAK4gB,MAAM3Y,GACxB,GAAIA,EAAQ,EAAG,CACbjI,KAAKioB,eAAehgB,GAASY,EAAMzG,GACnCpC,KAAKkoB,gBAAgBjgB,GAASY,EAAMzG,GACpCpC,KAAKmoB,WAAWlgB,GAAS,IAAI7C,MAAMhD,GACnCpC,KAAKooB,YAAYngB,GAAS,IAAI7C,MAAMhD,GAEpC,IAAK,IAAIgkB,EAAO,EAAGA,EAAOhkB,EAAMgkB,IAAQ,CACtC,MAAMhB,EAAWplB,KAAK4gB,MAAM3Y,EAAQ,GACpCjI,KAAKmoB,WAAWlgB,GAAOme,GAAQvd,EAAMuc,GACrCplB,KAAKooB,YAAYngB,GAAOme,GAAQvd,EAAMuc,KAK5CplB,KAAK4f,cAAgB5f,KAAKqoB,mBAG5BvoB,qBACEE,KAAKE,aAEL,MAAMA,WAAEA,GAAeF,MACjB2kB,MAAEA,EAAKC,MAAEA,EAAKC,QAAEA,EAAOvc,aAAEA,GAAiBtI,KAAKU,UAErD,IAAK,IAAIuH,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAM4E,EAAW7M,KAAKilB,QAAQhd,EAAQ,GAChCsf,EAAcvnB,KAAK4gB,MAAM3Y,GACzB2f,EAAgB5nB,KAAKoH,OAAOa,GAC5BqgB,EAAoBtoB,KAAKmoB,WAAWlgB,GACpCsgB,EAAqBvoB,KAAKooB,YAAYngB,GACtCugB,EAAiBxoB,KAAKmH,QAAQc,GAC9BwgB,EAAgBzoB,KAAKgS,OAAO/J,GAC5BygB,EAAwB1oB,KAAKioB,eAAehgB,GAC5C0gB,EAAyB3oB,KAAKkoB,gBAAgBjgB,GAEpD,IAAK,IAAIme,EAAO,EAAGA,EAAOmB,EAAanB,IAAQ,CAC7C,MAAM5mB,EAAQooB,EAAcxB,GAE5B,IAAK,IAAInkB,EAAI,EAAGA,EAAI4K,EAASlL,OAAQM,IAAK,CACxC,MAAM2mB,EAAWppB,EAAQqN,EAAS5K,GAC5B4mB,EACJP,EAAkBlC,GAAMnkB,GAAK0iB,GAAS,EAAIA,GAASiE,EAC/CE,EACJP,EAAmBnC,GAAMnkB,GAAK2iB,GAC7B,EAAIA,GAASgE,EAAWA,EAErBG,EACJF,GAAa,EAAIxpB,KAAK2pB,IAAIrE,EAAOzkB,IAC7B+oB,EACJH,GAAc,EAAIzpB,KAAK2pB,IAAIpE,EAAO1kB,IAEpCooB,EAAkBlC,GAAMnkB,GAAK4mB,EAC7BN,EAAmBnC,GAAMnkB,GAAK6mB,EAC9BN,EAAepC,GAAMnkB,IAClBqG,EAAeygB,GACf1pB,KAAKyO,KAAKmb,GAAsBpE,GAGrC,MAAMqE,EAAetB,EAAcxB,GAC7B+C,EACJT,EAAsBtC,GAAQzB,GAAS,EAAIA,GAASuE,EAChDE,EACJT,EAAuBvC,GAAQxB,GAC9B,EAAIA,GAASsE,EAAeA,EAEzBG,EACJX,EAAsBtC,IAAS,EAAI/mB,KAAK2pB,IAAIrE,EAAOzkB,IAC/CopB,EACJX,EAAuBvC,IAAS,EAAI/mB,KAAK2pB,IAAIpE,EAAO1kB,IAEtDwoB,EAAsBtC,GAAQ+C,EAC9BR,EAAuBvC,GAAQgD,EAC/BX,EAAcrC,IACX9d,EAAe+gB,GACfhqB,KAAKyO,KAAKwb,GAA0BzE,KAK7C/kB,WACEkC,GAEA,IAAKoD,MAAMC,QAAQrD,EAAK,GAAGqJ,OACzB,GAAIrL,KAAKke,YACPle,KAAKme,kBAAoB9a,OAAOkI,KAAKvL,KAAKke,aAAavc,WAClD,CACL,MAAMuc,EAAc,IAAI3C,GAAYvZ,EAAM,SAC1ChC,KAAKke,YAAcA,EAAYpT,MAC/B9K,KAAKme,kBAAoBD,EAAYvc,OAIzC,IAAKyD,MAAMC,QAAQrD,EAAK,GAAGsE,QACzB,GAAItG,KAAKqe,aACPre,KAAKmgB,mBAAqB9c,OAAOkI,KAAKvL,KAAKqe,cAAc1c,WACpD,CACL,MAAM6I,EAAS,IAAI+Q,GAAYvZ,EAAM,UACrChC,KAAKqe,aAAe7T,EAAOM,MAC3B9K,KAAKmgB,mBAAqB3V,EAAO7I,OAarC,GATK3B,KAAKupB,eACRvpB,KAAKupB,aAAenF,GAAgBpiB,EAAK,GAAGqJ,MAAOrL,KAAKke,cAGrDle,KAAKwpB,gBACRxpB,KAAKwpB,cAAgBpF,GAAgBpiB,EAAK,GAAGsE,OAAQtG,KAAKqe,eAIxDre,KAAKupB,cAAgBvpB,KAAKwpB,cAAe,CAC3C,MAAMtmB,EAA4D,GAClE,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK,CACV4H,MAAQrL,KAAKupB,aACVvnB,EAAKN,GAAG2J,OAEX/E,OAAStG,KAAKwpB,cACXxnB,EAAKN,GAAG4E,UAIf,OAAOpD,EAET,GAAIlD,KAAKupB,aAAc,CACrB,MAAMrmB,EAA4D,GAClE,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK,CACV4H,MAAQrL,KAAKupB,aACVvnB,EAAKN,GAAG2J,OAEX/E,OAAStE,EAAKN,GAAG4E,SAGrB,OAAOpD,EAET,GAAIlD,KAAKwpB,cAAe,CACtB,MAAMtmB,EAA4D,GAClE,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK,CACV4H,MAAQrJ,EAAKN,GAAG2J,MAChB/E,OAAStG,KAAKwpB,cACXxnB,EAAKN,GAAG4E,UAIf,OAAOpD,EAET,OAAQlB,EAKVlC,UAAUkC,WACHoD,MAAMC,QAAQrD,EAAKqJ,QAAmC,iBAAlBrJ,EAAKqJ,MAAM,KAClDrL,KAAKke,YAAc1T,EAAOif,QACvBznB,EAAKqJ,gBACNrL,KAAKke,2BAAe,IAElBle,KAAKke,cACPle,KAAKme,kBAAoB9a,OAAOkI,KAAKvL,KAAKke,aAAavc,SAGtDyD,MAAMC,QAAQrD,EAAKsE,SAAqC,iBAAnBtE,EAAKsE,OAAO,KACpDtG,KAAKqe,aAAe7T,EAAOif,QACxBznB,EAAKsE,iBACNtG,KAAKqe,4BAAgB,IAEnBre,KAAKqe,eACPre,KAAKmgB,mBAAqB9c,OAAOkI,KAAKvL,KAAKqe,cAAc1c,SAK/D7B,KACEkC,GAEA,MAAMuc,aAAEA,GAAiBve,KAAK4mB,aAC5B5kB,GAKI0nB,EAAa,GAGnB,IAAIC,EAAW,EACf,GANmD,IAAlCpL,EAAa,GAAGjY,OAAO3E,OAM1B,CACZ,IAAIa,EAAW,EACXC,EAAW,EACXH,EAAU,EACVC,EAAU,EAEd,IAAK,IAAIb,EAAI,EAAGA,EAAI6c,EAAa5c,OAAQD,IAAK,CAC5C,MAAM4E,EAAStG,KAAKoe,SAASG,EAAa7c,GAAG2J,OACvCjB,EAASmU,EAAa7c,GAAG4E,OACzBsjB,EAAStjB,EAAO,GAAKtG,KAAKkc,QAAQT,aAAe,EAAI,EACrDoO,EAAWzf,EAAO,GAExB,GAAIwf,IAAWC,EAAU,CACvB,MAAMC,EAAWvL,EAAa7c,GAC9BgoB,EAAWjmB,KAAK,CACd4H,MAAOye,EAASze,MAChB/E,OAAQwjB,EAASxjB,OACjBsjB,OAAAA,EACAC,SAAAA,IAIW,IAAXD,GAA6B,IAAbC,EAClBtnB,IACoB,IAAXqnB,GAA6B,IAAbC,EACzBvnB,IACoB,IAAXsnB,GAA6B,IAAbC,EACzBpnB,IACoB,IAAXmnB,GAA6B,IAAbC,GACzBrnB,IAGFmnB,GAAYxF,GACV7d,EAAOzB,IAAI,CAACpF,EAAOiC,IACV0I,EAAO1I,GAAKjC,IAKzB,MAAO,CACLE,MAAOgqB,EAAWpL,EAAa5c,OAC/B+nB,WAAAA,EACAppB,MAAOie,EAAa5c,OACpBY,QAAAA,EACAD,QAAAA,EACAG,SAAAA,EACAD,SAAAA,EACAE,UAAWJ,EAAU,EAAIA,GAAWA,EAAUE,GAAY,EAC1DG,OAAQL,EAAU,EAAIA,GAAWA,EAAUG,GAAY,EACvDG,UAAWL,EAAUD,GAAWic,EAAa5c,QAIjD,IAAK,IAAID,EAAI,EAAGA,EAAI6c,EAAa5c,OAAQD,IAAK,CAC5C,MAAM4E,EAAStG,KAAKoe,SAASG,EAAa7c,GAAG2J,OACvCjB,EAASmU,EAAa7c,GAAG4E,OACzBsjB,EAAStjB,EAAOma,QAAQnhB,GAAIgH,IAC5BujB,EAAWzf,EAAOqW,QAAQnhB,GAAI8K,IAEpC,GAAIwf,IAAWC,EAAU,CACvB,MAAMC,EAAWvL,EAAa7c,GAC9BgoB,EAAWjmB,KAAK,CACd4H,MAAOye,EAASze,MAChB/E,OAAQwjB,EAASxjB,OACjBsjB,OAAAA,EACAC,SAAAA,IAIJF,GAAYxF,GACV7d,EAAOzB,IAAI,CAACpF,EAAOiC,IACV0I,EAAO1I,GAAKjC,IAIzB,MAAO,CACLE,MAAOgqB,EAAWpL,EAAa5c,OAC/B+nB,WAAAA,EACAppB,MAAOie,EAAa5c,QAIxB7B,iBACOE,KAAK8lB,YACR9lB,KAAKsf,aAGP,MAAMyK,EAAmB/pB,KAAKmH,QAAQtC,IAAKmlB,GAClCA,EAAanlB,IAAKmlB,GAAiB5kB,MAAMwD,KAAKohB,KAEjDC,EAAkBjqB,KAAKgS,OAAOnN,IAAKqlB,GACvC9kB,MAAMwD,KAAKshB,IAEP1J,EAA2B,GAC3BuD,EAAe/jB,KAAK4gB,MAAMjf,OAAS,EACzC,IAAK,IAAID,EAAI,EAAGA,GAAKqiB,EAAcriB,IACjC8e,EAAW/c,KAAK,CACd0D,kBAAS4iB,EAAiBroB,kBAAM,GAChCsQ,iBAAQiY,EAAgBvoB,kBAAM,KAGlC,MAAO,CACLiH,KAAM,gBACNiY,MAAO,IAAI5gB,KAAK4gB,OAChBjS,OAAQ6R,EACRtC,YAAale,KAAKke,YAAc,IAAKle,KAAKke,aAAgB,KAC1DC,kBAAmBne,KAAKme,kBACxBE,aAAcre,KAAKqe,aAAe,IAAKre,KAAKqe,cAAiB,KAC7D8B,mBAAoBngB,KAAKmgB,mBACzBjE,QAAS,IAAKlc,KAAKkc,SACnBxb,UAAWV,KAAKmqB,oBAIpBrqB,SAAS4D,GAEP,GADA1D,KAAKkc,QAAU,CAzkCfqI,UAAW,EACXC,WAAY,EACZ/I,aAAc,MAukCqB/X,EAAKwY,SACpCxY,EAAKN,eAAe,aAAc,CACpC,MAAM1C,EAAY,IACbgD,EAAKhD,UACRsb,QAC6B,aAA3BtY,EAAKhD,UAAUsb,QACXrE,EAAAA,EACAjU,EAAKhD,UAAUsb,SAEvBhc,KAAKglB,sBAAsBtkB,GAE7BV,KAAK4gB,MAAQld,EAAKkd,MAClB5gB,KAAKsf,aAELtf,KAAKke,YAAcxa,EAAKwa,YAAc,IAAKxa,EAAKwa,aAAgB,KAChEle,KAAKme,kBAAoBza,EAAKya,kBAC9Bne,KAAKqe,aAAe3a,EAAK2a,aAAe,IAAK3a,EAAK2a,cAAiB,KACnEre,KAAKmgB,mBAAqBzc,EAAKyc,mBAE/B,MAAMK,EAAa9c,EAAKiL,OAClBqb,EAAehqB,KAAKmH,QAAQtC,IAAI,CAACmlB,EAAc9E,IAC5C1E,EAAW0E,GAAY/d,QAAQtC,IAAKmlB,GACzCrkB,aAAaiD,KAAKohB,KAGhBE,EAAclqB,KAAKgS,OAAOnN,IAAI,CAACqlB,EAAahF,IAChDvf,aAAaiD,KAAK4X,EAAW0E,GAAYlT,SAE3C,IAAK,IAAItQ,EAAI,EAAGA,GAAK1B,KAAKid,YAAavb,IACrC1B,KAAKmH,QAAQzF,GAAKsoB,EAAatoB,IAAM,GACrC1B,KAAKgS,OAAOtQ,GAAKwoB,EAAYxoB,IAAM,GAErC,OAAO1B,KAGTF,WACE2O,GAEA,MAAMgW,WAAEA,EAAUC,eAAEA,GAAmB1kB,KAAKU,UAC5C,IAAI0pB,GAAW,EACf,MAAMC,EAAa,CAACnF,EAAoBC,KACtC,GAAmB,IAAfD,EACF,MAAO,UAAUC,SAGnB,MAAMhe,EAAwBnH,KAAKmH,QAAQ+d,GAAYC,GACjDvR,EAAe5T,KAAKgS,OAAOkT,GAAYC,GAC7C,IAAKhe,EACH,MAAM,IAAIjF,MACR,yBAAyBgjB,iBAA0BC,eAGvD,IAAKvR,EACH,MAAM,IAAI1R,MACR,sBAAsBgjB,iBAA0BC,eAGpD,MAAMmF,EAAyB,GAC/BnjB,EAAQmV,QAAQ,CAACld,EAAgBmrB,KAC3BnrB,EAAS,EACXkrB,EAAa7mB,KACX,GAAGrE,KAAUirB,EAAWnF,EAAa,EAAGqF,MAG1CD,EAAa7mB,KACX,IAAIrE,KAAUirB,EAAWnF,EAAa,EAAGqF,QAI/C,MAAMrnB,EAAS,IAAI0Q,EAAK6I,aAAa6N,EAAaE,KAAK,OAEvD,OAAQ/F,GACN,IAAK,UACH,MAAO,mBAAmBvhB,MAC5B,IAAK,OAEH,OADAknB,GAAW,EACJ,OAAOlnB,YAEhB,IAAK,aAEH,OADAknB,GAAW,EACJ,eAAelnB,MAAWwhB,OAEnC,IAAK,OACH,MAAO,aAAaxhB,KACtB,QACE,MAAM,IAAIhB,MACR,sBAAsBuiB,2EAK9B,SAASgG,EAAUlf,GACjB,GAAIA,EAAK6P,KAAM1L,GAAMA,EAAEd,SAAS,MAC9B,MAAM,IAAI1M,MAAM,8CAIpB,MAAMwoB,EAAyB,GAC/B,IAAIxnB,EAEAgb,EAAc,GAClB,GAAIle,KAAKke,YAAa,CAEpBuM,EADapnB,OAAOkI,KAAKvL,KAAKke,cAE9BA,EAAc,6BAA6B7a,OAAOkI,KAAKvL,KAAKke,aACzDrZ,IAAK0X,GAAQ,UAAUA,OACvBiO,KAAK,UAEV,GAAIxqB,KAAK4gB,MAAMjf,OAAS,EAAG,MAAM,IAAIO,MAAM,aAC3C,IACE,IAAIijB,EAAY,EAChBA,EAAYnlB,KAAK4gB,MAAM5gB,KAAKid,aAC5BkI,IAEAuF,EAAajnB,KAAK4mB,EAAWrqB,KAAKid,YAAakI,IAEjD,GAAInlB,KAAKqe,aAAc,CACrB,MAAM9S,EAAOlI,OAAOkI,KAAKvL,KAAKqe,cAC9BoM,EAAUlf,GAIVrI,EAAS,IAHMqI,EACZ1G,IAAI,CAAC0X,EAAK7a,IAAM,IAAI6a,MAAQmO,EAAahpB,MACzC8oB,KAAK,aAGRtnB,EAAS,IAAIwnB,EAAaF,KAAK,QAGjC,MAAMG,EAAS,GAAGzM,IAAckM,EAAW,SAAW,YAAYlnB,KAElE,OAAO,IAAI0nB,SAAS,QAASnc,EAAKA,EAAGkc,GAAUA,IC1uCnD,SAASE,GAEP1jB,EACA6K,EACA5J,GAEA,IAAIpC,EAAMgM,EAAOhS,KAAKiK,OAAO1E,GAC7B,IAAK,IAAItD,EAAI,EAAGA,EAAIjC,KAAKiG,UAAU7D,KAAMH,IACvC+D,GAAOmB,EAAQnH,KAAKiK,OAAO1E,GAAGtD,GAAKmG,EAAOnG,GAG5C,OAAO,GAAK,EAAI5C,KAAKK,KAAKsG,IAG5B,SAAS8kB,GAEP3jB,EACA6K,EACA5J,GAEA,IAAIpC,EAAMgM,EAAOhS,KAAKiK,OAAO1E,GAC7B,IAAK,IAAItD,EAAI,EAAGA,EAAIjC,KAAKiG,UAAU7D,KAAMH,IACvC+D,GAAOmB,EAAQnH,KAAKiK,OAAO1E,GAAGtD,GAAKmG,EAAOnG,GAG5C,OAAO+D,EAAM,EAAI,EAAIA,EAGvB,SAAS+kB,GAEP5jB,EACA6K,EACA5J,GAEA,IAAIpC,EAAMgM,EAAOhS,KAAKiK,OAAO1E,GAC7B,IAAK,IAAItD,EAAI,EAAGA,EAAIjC,KAAKiG,UAAU7D,KAAMH,IACvC+D,GAAOmB,EAAQnH,KAAKiK,OAAO1E,GAAGtD,GAAKmG,EAAOnG,GAG5C,OAAO+D,EAAM,EAAI,EAAI,IAAOA,EAG9B,SAASglB,GAEP7jB,EACA6K,EACA5J,GAEA,IAAIpC,EAAMgM,EAAOhS,KAAKiK,OAAO1E,GAC7B,IAAK,IAAItD,EAAI,EAAGA,EAAIjC,KAAKiG,UAAU7D,KAAMH,IACvC+D,GAAOmB,EAAQnH,KAAKiK,OAAO1E,GAAGtD,GAAKmG,EAAOnG,GAG5C,OAAO5C,KAAKO,KAAKoG,GAGnB,SAASilB,GAAgB3kB,EAAgB8D,GACvC,OAAOA,EAAS9D,EAGlB,SAAS4kB,GAAkBvrB,EAAe2G,GAExC,OAAO3G,EAAQ2G,GAAU,EAAIA,GAG/B,SAAS6kB,GAAexrB,EAAe2G,GAErC,OAAOA,EAAS,EAAI3G,EAAQ,EAG9B,SAASyrB,GAAoBzrB,EAAe2G,GAE1C,OAAOA,EAAS,EAAI3G,EAAQ,IAAOA,EAGrC,SAAS0rB,GAAe1rB,EAAe2G,GAErC,OAAQ,EAAIA,EAASA,GAAU3G,EAGjC,SAAS2rB,GACP/lB,EACAnD,EACAqlB,EACAC,GAEA,IAAI/nB,EAAQ,EACZ,IAAK,IAAIsC,EAAI,EAAGA,EAAIG,EAAMH,IACxBtC,GAAS+nB,EAAWzlB,GAAKwlB,EAAYxlB,GAAGsD,GAE1C,OAAO5F,EAUT,SAAS4rB,GACPjjB,EACAwE,EACA0e,EACAhsB,EACAisB,GAEA,OAAOnjB,EAAe9I,EAAQisB,EAAiB3e,EAAW0e,EAG5D,SAASE,GAAW1D,EAAgB5oB,GAClC,OAAO4oB,EAAS5oB,EAGlB,SAASusB,GAEP3Z,EACA5K,GAEA,OACE4K,EAAOhS,KAAKiK,OAAO1E,GAAK6B,EAAOpH,KAAKiK,OAAO1E,GAAKvF,KAAKiG,UAAUqC,aAKnE,SAAS6b,GAA4Bpe,GACnC,IAAIC,EAAM,EACV,IAAK,IAAItE,EAAI,EAAGA,EAAI1B,KAAKiG,UAAU7D,KAAMV,IACvCsE,GAAOD,EAAOrE,IAAM,EAEtB,OAAOsE,EAAMhG,KAAKiG,UAAU7D,WAoBjBwpB,WAAgDtH,GAsE3DxkB,YAAYoc,EAA6C,IACvD/S,MAAM+S,GAjERlc,wBAA4D,KAC1D,MAAM,IAAIkC,MAAM,kBAGlBlC,sBAMI,GAEJA,uBAAqE,GAErEA,sBAaI,GAEJA,qBAEI,GAEJA,YAAgD,KAC9C,MAAM,IAAIkC,MAAM,kBAGlBlC,aAAoE,KAClE,MAAM,IAAIkC,MAAM,kBAGlBlC,mBAAqE,KACnE,MAAM,IAAIkC,MAAM,kBAKlBlC,aAA0B,GAG1BA,YAAyB,GAGzBA,YAAyB,GAGzBA,aAA0B,GAG1BA,aAA0B,GAG1BA,YAAyB,GA0GzBA,cAAYqL,IACV,IAAI/E,EACJtG,KAAKilB,QAAQ,GAAK5Z,EAClB,IAAK,IAAIpD,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAC7ClD,EAAQ/E,KAAKilB,QAAQhd,IACrBjI,KAAKilB,QAAQhd,GAASjI,KAAK6rB,iBAAiB5jB,GAC1CjI,KAAKmH,QAAQc,GACbjI,KAAKgS,OAAO/J,GACZoD,GAEF/E,EAAS+E,EAAQrL,KAAKilB,QAAQhd,GAEhC,OAAO3B,GA6FTtG,qBAAmBoK,IACjB,IAAK,IAAInC,EAAQjI,KAAKid,YAAahV,EAAQ,EAAGA,IAAS,CAIrD,IAAI3B,EAHJvB,EAAQ/E,KAAKoH,OAAOa,IACpBlD,EAAQ/E,KAAK+F,OAAOkC,IAMlB3B,EAHE2B,IAAUjI,KAAKid,YAGRjd,KAAK8rB,kBAAkB7jB,GAAOjI,KAAKilB,QAAQhd,GAAQmC,GAInDpK,KAAK8rB,kBAAkB7jB,GAC9BjI,KAAKmH,QAAQc,EAAQ,GACrBjI,KAAKilB,QAAQhd,GACbjI,KAAKoH,OAAOa,EAAQ,IAGxBjI,KAAKoH,OAAOa,GAAS3B,EAAOpD,OAC5BlD,KAAK+F,OAAOkC,GAAS3B,EAAO3G,QAnO9BK,KAAK+b,mBAAqB,IAC1B/b,KAAK+rB,IAAM,IAAIvnB,MAAI,CAAEC,KAAMyX,EAAQzX,OAGrC3E,aACEqJ,MAAMmW,aACNtf,KAAKgsB,gBACLhsB,KAAKisB,uBACLjsB,KAAKksB,kBACLlsB,KAAKmsB,oBACLnsB,KAAKosB,cAGPtsB,iBAIAA,aACEL,EACAigB,GASA,OANA1f,KAAKoe,SAAS3e,EAAM4L,OAGpBrL,KAAK+kB,gBAAgBtlB,EAAM6G,QAC3BtG,KAAK4f,gBAEDF,EACK1f,KAAKqsB,OAAOrsB,KAAK+F,OAAO/F,KAAKid,cAE/B,KAGTnd,uBAAuBkC,GACrB,IAAIgE,EAAM,IAAIL,aAAa,CAAC,IAC5B,IAAK,IAAIjE,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EAAG,CACpC,MAAM6d,EAAUvZ,EACVrG,EAAQK,KAAK0mB,aAAa1kB,EAAKN,IAAI,GACzCsE,EAAMhG,KAAKssB,QAAQtmB,EAAKrG,GACxBoF,EAAQpF,GACRoF,EAAQwa,GAEV,MAAMrc,EAASlD,KAAKusB,cAAcvqB,EAAKL,OAAQqE,GAE/C,OADAjB,EAAQiB,IACA9C,aAAkB+B,UACrB/B,EAAOuF,UACPvF,GAAqB,GAG5BpD,gBACEE,KAAKwsB,aACLxsB,KAAKysB,eAGP3sB,gBACE,IAAI4sB,EAAc,KAElB,OAAQ1sB,KAAKU,UAAU+jB,YACrB,IAAK,UACHiI,EAAc7B,GACd,MACF,IAAK,OACH6B,EAAc5B,GACd,MACF,IAAK,aACH4B,EAAc3B,GACd,MACF,IAAK,OACH2B,EAAc1B,GACd,MACF,QACE,MAAM,IAAI9oB,MACR,sBAAsBlC,KAAKU,UAAU+jB,kFAI3C,IAAK,IAAIxc,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAC7CjI,KAAK6rB,iBAAiB5jB,GAASjI,KAAK+rB,IAAIrnB,aAAagoB,EAAa,CAChEpmB,OAAQ,CAACtG,KAAK4gB,MAAM3Y,IACpB0kB,UAAU,EACV1mB,UAAW,CACT7D,KAAMpC,KAAK4gB,MAAM3Y,EAAQ,IAE3B1B,WAAW,IAIfvG,KAAK4sB,mBAAqB5sB,KAAK+rB,IAAIrnB,cACjC,SAAUjF,GACR,OAAOA,EAAMO,KAAKiK,OAAO1E,KAE3B,CACEe,OAAQ,CAACtG,KAAK4gB,MAAM,IACpB+L,UAAU,EACVpmB,WAAW,IAsBjBzG,uBACE,IAAI+sB,EACJ,OAAQ7sB,KAAKU,UAAU+jB,YACrB,IAAK,UACHoI,EAAa3B,GACb,MACF,IAAK,OACH2B,EAAa1B,GACb,MACF,IAAK,aACH0B,EAAazB,GACb,MACF,IAAK,OACHyB,EAAaxB,GACb,MACF,QACE,MAAM,IAAInpB,MACR,sBAAsBlC,KAAKU,UAAU+jB,kFAI3CoI,EAAaC,QACXC,QAAMC,kBAAkB,IAAMH,GAC9BA,GAEF7sB,KAAK+rB,IAAIkB,YAAYJ,GACrB,IAAK,IAAI5kB,EAAQjI,KAAKid,YAAahV,EAAQ,EAAGA,IACxCA,IAAUjI,KAAKid,YAGjBjd,KAAK8rB,kBAAkB9rB,KAAKid,aAAejd,KAAK+rB,IAAIjnB,gBAClD,CACEnF,MAAOsrB,KAET,SAEEhG,EACAiI,GAEA,MAAM5mB,EAAS2e,EAAQjlB,KAAKiK,OAAO1E,GAC7B6E,EAAS8iB,EAAQltB,KAAKiK,OAAO1E,GAGnC,OAAOsnB,EAAW5B,GAAgB3kB,EAAQ8D,GAAS9D,KAErD,CACEA,OAAQ,CAACtG,KAAK4gB,MAAM5gB,KAAKid,cACzB0P,UAAU,EACVpmB,WAAW,IAMfvG,KAAK8rB,kBAAkB7jB,GAASjI,KAAK+rB,IAAIjnB,gBACvC,CACEnF,MAAO2rB,KAET,SAEE7D,EACAxC,EACAyC,GAEA,MAAMphB,EAAS2e,EAAQjlB,KAAKiK,OAAO1E,GAGnC,OAAOsnB,EACLvB,GACEtrB,KAAKiK,OAAO1E,EACZvF,KAAKiG,UAAU7D,KACfqlB,EACAC,GAEFphB,KAGJ,CACEA,OAAQ,CAACtG,KAAK4gB,MAAM3Y,IACpB0kB,UAAU,EACV1mB,UAAW,CACT7D,KAAMpC,KAAK4gB,MAAM3Y,EAAQ,IAE3B1B,WAAW,IA+BrBzG,kBACE,IAAK,IAAImI,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAG7CjI,KAAKmtB,iBAAiBllB,GAASjI,KAAK+rB,IAAIjnB,gBACtC,CACEqC,QAASukB,GACTlf,QAAS+e,KAEX,SAME6B,EACAhmB,EACAD,EACAkmB,GASA,OAAO3B,GAPQH,GACbvrB,KAAKiG,UAAUqC,aACftI,KAAKiG,UAAU6G,SACfugB,EAAgBrtB,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,GAC3C6B,EAAOpH,KAAKiK,OAAOzE,GACnB4nB,EAAgBptB,KAAKiK,OAAO1E,IAEJ4B,EAAQnH,KAAKiK,OAAOzE,GAAGxF,KAAKiK,OAAO1E,MAE/D,CACEe,OAAQ,CAACtG,KAAK4gB,MAAM3Y,EAAQ,GAAIjI,KAAK4gB,MAAM3Y,IAC3C0kB,UAAU,EACV1mB,UAAW,CACT7D,KAAMpC,KAAK4gB,MAAM3Y,EAAQ,GACzBK,aAActI,KAAKU,UAAU4H,aAC7BwE,SAAU9M,KAAKU,UAAUoM,UAE3BvG,WAAW,IAMnBzG,aACE,IAAK,IAAImI,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAMd,EAAUnH,KAAKmH,QAAQc,GACvBuE,EAAUxM,KAAKwM,QAAQvE,GACvB3B,EAAStG,KAAKmtB,iBAAiBllB,GACnCjI,KAAKilB,QAAQhd,EAAQ,GACrBjI,KAAKoH,OAAOa,GACZd,EACAqF,GAEFzH,EAAQoC,GACRpC,EAAQyH,GACRxM,KAAKmH,QAAQc,GAAS3B,EAAOa,QAC7BnH,KAAKwM,QAAQvE,GAAS3B,EAAOkG,QAC7BzH,EAAQuB,EAAOpD,SAInBpD,oBACE,IAAK,IAAImI,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAC7CjI,KAAKstB,gBAAgBrlB,GAASjI,KAAK+rB,IAAIrnB,aAAainB,GAAW,CAC7DrlB,OAAQ,CAACtG,KAAK4gB,MAAM3Y,IACpB0kB,UAAU,EACV1mB,UAAW,CACTqC,aAActI,KAAKU,UAAU4H,cAE/B/B,WAAW,IAKjBzG,eACE,IAAK,IAAImI,EAAQ,EAAGA,GAASjI,KAAKid,YAAahV,IAAS,CACtD,MAAM+J,EAAShS,KAAKgS,OAAO/J,GAC3BjI,KAAKgS,OAAO/J,GAASjI,KAAKstB,gBAAgBrlB,GACxC+J,EACAhS,KAAKoH,OAAOa,IAEdlD,EAAQiN,IAIZlS,cACEE,KAAKqsB,OAASrsB,KAAK+rB,IAAIrnB,aAAayf,GAAK,CACvC7d,OAAQ,CAAC,GACTL,UAAW,CACT7D,KAAMpC,KAAK4gB,MAAM5gB,KAAKid,cAExB0P,UAAU,EACVpmB,WAAW,IAEbvG,KAAKssB,QAAUtsB,KAAK+rB,IAAIrnB,cACtB,SAAUmC,EAAkBC,GAC1B,OAAOD,EAAO,GAAKC,EAAO,KAE5B,CACER,OAAQ,CAAC,GACTqmB,UAAU,EACVpmB,WAAW,IAGfvG,KAAKusB,cAAgBvsB,KAAK+rB,IAAIrnB,cAC5B,SAAU/C,EAAgBqF,GACxB,MAAMvH,EAAQuH,EAAO,GACrB,OAAIvH,EAAQ,EACHA,EAAQkC,EAEV,IAET,CACE2E,OAAQ,CAAC,KAKfxG,IAAIuL,GACF,IAAKrL,KAAK8lB,WACR,MAAM,IAAI5jB,MAAM,wBAElB,IAAI6jB,EAEFA,EADE/lB,KAAKke,YACU1T,EAAO/B,QACtBzI,KAAKke,YACJ7S,EACDrL,KAAKme,mBAGW9S,EAEpB,MAAMkiB,EAAiBvtB,KAAKoe,SAAS2H,GAC/Bzf,EACJinB,aAA0BtoB,UACtBsoB,EAAe9kB,UACf8kB,EAEN,OAAIvtB,KAAKqe,aACC7T,EAAO8T,SACbte,KAAKqe,aACL/X,GAIIA,EAIVxG,aACEkC,EACAka,EAA+C,IAE/Clc,KAAKglB,sBAAsB9I,GAC3B,MAAMqC,EAAeve,KAAKmf,WAAWnd,GAC/Byc,EAAU1d,KAAKC,MAAQhB,KAAKU,UAAUsb,QAO5Chc,KAAKof,oBAAoBb,GAEzB,MAAMiP,EAAsBxtB,KAAK+rB,IAAIrnB,cACnC,SAAUjF,GACR,OAAOA,EAAMO,KAAKiK,OAAO1E,KAE3B,CACEe,OAAQ,CAACiY,EAAa,GAAGjY,OAAO3E,QAChCgrB,UAAU,EACVpmB,WAAW,IAGf,MAAO,CACLgY,aAAcA,EAAa1Z,IAAK4oB,KAC9BpiB,MAAOrL,KAAK4sB,mBAAmBa,EAAIpiB,OACnC/E,OAAQknB,EAAoBC,EAAInnB,WAElCkY,OAtBa,CACb7e,MAAO,EACPO,WAAY,GAqBZue,QAAAA,GAMJ3e,aACE,MAAM,IAAIoC,MACLlC,KAAK8H,YAAYC,KAApB,sCAIJjI,iBACqB,OAAfE,KAAK4gB,OACP5gB,KAAKsf,aAGP,MAAMyK,EAAmB/pB,KAAKmH,QAAQtC,IAAKmlB,IACjCA,aAAwB/kB,UAC3B+kB,EAAavhB,UACbuhB,GACHnlB,IAAKmlB,GAAiB5kB,MAAMwD,KAAKohB,KAE/BC,EAAkBjqB,KAAKgS,OAAOnN,IAAKqlB,GACvC9kB,MAAMwD,KACJshB,aAAuBjlB,UAClBilB,EAAYzhB,UACZyhB,IAGH1J,EAA2B,GACjC,IAAK,IAAI9e,EAAI,EAAGA,GAAK1B,KAAKid,YAAavb,IACrC8e,EAAW/c,KAAK,CACd0D,kBAAS4iB,EAAiBroB,kBAAM,GAChCsQ,iBAAQiY,EAAgBvoB,kBAAM,KAGlC,MAAO,CACLiH,KAAM,mBACNiY,MAAO,IAAI5gB,KAAK4gB,OAChBjS,OAAQ6R,EACRtC,YAAale,KAAKke,YAAc,IAAKle,KAAKke,aAAgB,KAC1DC,kBAAmBne,KAAKme,kBACxBE,aAAcre,KAAKqe,aAAe,IAAKre,KAAKqe,cAAiB,KAC7D8B,mBAAoBngB,KAAKmgB,mBACzBjE,QAAS,IAAKlc,KAAKkc,SACnBxb,UAAWV,KAAKmqB,2BC1sBTuD,WAA4B/jB,EAAzC7J,kCACEE,cAA2B,GAC3BA,WAAuB,KACvBF,SAASmI,GACPjI,KAAKiI,MAAQA,EAGf9B,YACE,IAAKnG,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC,OAAOlC,KAAKiI,MAAM9B,MAGpBA,UAAU1G,GACR,MAAM,IAAIyC,MAASlC,KAAK8H,YAAYC,KAApB,iCAGlB7B,aACE,IAAKlG,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC,OAAOlC,KAAKiI,MAAM/B,OAGpBA,WAAWzG,GACT,MAAM,IAAIyC,MAASlC,KAAK8H,YAAYC,KAApB,kCAGlBX,aACE,IAAKpH,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC,OAAOlC,KAAKiI,MAAMb,OAGpBA,WAAWA,GACT,IAAKpH,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC6C,EAAQ/E,KAAKiI,MAAMb,QACnBpH,KAAKiI,MAAMb,OAASA,EAGtBD,cACE,IAAKnH,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC,OAAOlC,KAAKiI,MAAMd,QAGpBA,YAAYA,GACV,IAAKnH,KAAKiI,MAAO,MAAM,IAAI/F,MAAM,iBACjC6C,EAAQ/E,KAAKiI,MAAMd,SACnBnH,KAAKiI,MAAMd,QAAUA,EAGvBrH,WAIAA,WAIAA,QACE,MAAM,IAAIoC,MAAM,mBAGlBpC,gBAMAA,uBCfW6tB,WAAkB1R,GAW7Bnc,YACEoc,EAAkE,IAIlE/S,MAAM+S,GAfRlc,eAAuC,GAIvCA,uBAAgD,KAChDA,gBAAyB,GACzBA,+BAAsC,GACtCA,YAA0B,KAW1BF,iBAKE,IAAKE,KAAKkc,QAAQhT,WAChB,MAAM,IAAIhH,MAAM,wBAElB,IAAKlC,KAAKkc,QAAQe,YAChB,MAAM,IAAI/a,MAAM,yBAElB,MAAMgH,EAAalJ,KAAKkc,QAAQhT,aAC1BmU,EAAerd,KAAKsd,qBAAqBpU,GAK/C,MAAO,CACLA,WAAAA,EACAmU,aAAAA,EACAJ,YAPkBjd,KAAKkc,QAAQe,YAC/BI,EAAaA,EAAa1b,OAAS,IAClC,IASL7B,qBACE,MAAM6O,EAAmB,GACnBif,EAAiB5tB,KAAK6tB,WAAW7tB,KAAK6tB,WAAWlsB,OAAS,GAChE,IAAImsB,EAA6B,EAEjC,SAASC,EAAe7kB,GACtB,MAAMoC,EAAQsiB,EAAenN,QAAQvX,GACrC,GAAIoC,EAAQ,EAAG,MAAM,IAAIpJ,MAAM,wBAC/B,OAAOyM,EAAOrD,GAGhB,SAAS0iB,EAAc/lB,GACrB,MAAO,IACFA,EAAM3D,SACT6C,QAAS,KACTC,OAAQ,KACRC,OAAQ,MAIZ,IAAK,IAAI3F,EAAI,EAAGA,EAAIksB,EAAejsB,OAAQD,IAAK,CAC9C,MAAM6b,EAAgBqQ,EAAelsB,GACrC,IAAIuG,EAEJ,GAAIsV,aAAyBtU,EAC3BhB,EAAQ,IAAKsV,EAAczV,YACzBimB,EAAexQ,EAAcrU,YAC7B8kB,EAAczQ,SAEX,GAAIA,aAAyBjT,EAClCrC,EAAQ,IAAKsV,EAAczV,YACzBkmB,EAAczQ,SAEX,GAAIA,aAAyBlU,EAClCpB,EAAQ,IAAKsV,EAAczV,YACzBkmB,EAAczQ,EAAcrU,YAC5B6kB,EAAexQ,EAAcrU,kBAE1B,GAAIqU,aAAyB5T,EAAU,CAC5C,MAAMskB,EACJL,EACE5tB,KAAKkuB,0BAA0BJ,MAEnC,GAAIvQ,aAAyBmQ,GAC3B,MAAM,IAAIxrB,MAAM,cACX,GAAIqb,aAAyBzG,GAClC7O,EAAQ,IAAI6O,GAAemX,OACtB,CAAA,KAAI1Q,aAAyBnG,IAGlC,MAAM,IAAIlV,MACR,gBAAgBqb,EAAczV,YAAYC,qCAH5CE,EAAQ,IAAI6O,GAAemX,SAMxB,GACL1Q,aAAyBlT,GACzBkT,aAAyBhT,EAEzBtC,EAAQsV,OACH,GAAIA,aAAyB3T,EAClC3B,EAAQ,IAAKsV,EAAczV,YACzBimB,EAAexQ,EAAcrU,YAC7B8kB,EAAczQ,EAAcrU,kBAEzB,GAAIqU,aAAyB1T,EAClC5B,EAAQ,IAAKsV,EAAczV,YACzBimB,EAAexQ,EAAczT,aAC7BikB,EAAexQ,EAAcxT,aAC7BikB,EAAczQ,QAEX,CAAA,KAAIA,aAAyBpT,GAMlC,MAAM,IAAIjI,MACR,gBAAgBqb,EAAczV,YAAYC,qCAN5CE,EAAQ,IAAKsV,EAAczV,YACzBkmB,EAAczQ,GACdwQ,EAAexQ,EAAcrU,aAOjCyF,EAAOlL,KAAKwE,GAGd,OAAO0G,EAGT7O,qBAAqByd,GACnB,MAAMF,EAAe,GAErB,IAAKrd,KAAKkc,QAAQmB,aAAc,MAAM,IAAInb,MAAM,4BAEhD,IAAK,IAAIR,EAAI,EAAGA,EAAI1B,KAAKkc,QAAQmB,aAAa1b,OAAQD,IAAK,CACzD,MAAMqV,EAAiB,IAAIK,GACrBoG,EAAcxd,KAAKkc,QAAQmB,aAAa3b,GAC5C6b,EACAxG,EACArV,GAEF6b,EAAgBC,EAChBH,EAAa5Z,KAAK+Z,GAGpB,OAAOH,EAGTvd,aAEE,IAAIquB,EACJ,GAFAnuB,KAAKouB,kBAAoB,IAAIV,GAEzB1tB,KAAKkc,QAAQvN,OACfwf,EAAWnuB,KAAKyd,4BACX,CACL,MAAMvU,WAAEA,EAAUmU,aAAEA,EAAYJ,YAAEA,GAAgBjd,KAAKquB,iBACvDF,EAAWzf,GAAc,CAACxF,KAAemU,EAAcJ,IACvDjd,KAAKkuB,0BAA4B7Q,EAAaxY,IAAKiZ,GACjDqQ,EAAS1N,QAAQ3C,IAEnB9d,KAAKkd,YAAchU,EACnBlJ,KAAKmd,cAAgBE,EACrBrd,KAAKod,aAAeH,EAEtBjd,KAAK2O,OAASwf,EACdnuB,KAAK6tB,WAAa,CAACM,GACnBnuB,KAAK4d,OAASuQ,EAAStQ,OACpBC,GAAMA,aAAavT,GAASuT,aAAazT,GAE5CrK,KAAK2d,iBAAiBwQ,GAGxBruB,iBACE,MAAM6O,EAAS3O,KAAKsuB,qBACpB,IAAK,IAAI5sB,EAAI,EAAGA,EAAIiN,EAAOhN,OAAQD,IAAK,CACxBiN,EAAOjN,GACfkX,cAAa,GAIrB5Y,KAAK6tB,WAAWpqB,KAAKkL,GAKvB7O,IAAIsI,GACF,KAAOpI,KAAK6tB,WAAWlsB,QAAUyG,EAAOzG,QACtC3B,KAAKuuB,iBAEP,MAAMrrB,EAASlD,KAAKwuB,UAAUpmB,GAC9B,OAAIlF,aAAkB+B,UAAgB/B,EAAOuF,UACtCvF,EAGTpD,SAASuL,GACP,MAAM,IAAInJ,MAAM,oBAGlBpC,UAAUsI,GACR,KAAOpI,KAAK6tB,WAAWlsB,OAASyG,EAAOzG,QACrC3B,KAAKuuB,iBAEP,MAAMjvB,EAAM8I,EAAOzG,OAAS,EAC5B,IAAK,IAAI4D,EAAI,EAAGA,GAAKjG,EAAKiG,IAAK,CAC7B,MAAM4oB,EAAWnuB,KAAK6tB,WAAWtoB,GACjC4oB,EAAS,GAAGnf,QAAQ5G,EAAO7C,IAC3B,IAAK,IAAI7D,EAAI,EAAGA,EAAIysB,EAASxsB,OAAQD,IACnCysB,EAASzsB,GAAGsN,UAGhB,MAAMyf,EAAgBzuB,KAAK6tB,WAAWvuB,GAChC4D,EAASurB,EAAcA,EAAc9sB,OAAS,GAAGwF,QAEvD,OADAnH,KAAK0uB,MACExrB,EAKTpD,MACEkC,EACAka,EAA8C,IAE9C,MAAMqC,aAAEA,EAAYC,OAAEA,EAAMC,QAAEA,GAAYze,KAAK0e,cAAc1c,EAAMka,GACnE,IAAIyC,GAAkB,EACtB,MAAMC,EAAiB,IACrB5e,KAAK6e,wBAAwBN,GACzBO,EAAe,IAAY9e,KAAK+e,eAAeR,GACrD,KAAOI,GACLA,EAAkB3e,KAAKgf,cACrBR,EACAC,EACAG,EACAE,GAGJ,OAAON,EAGT1e,MACE,MAAMyF,EAAIvF,KAAK6tB,WAAWlsB,OAAS,EAC7BgtB,EAAe3uB,KAAK6tB,WAAWtoB,GACrCopB,EAAa,GAAG3f,QAAQ,CAAC,IAAIrJ,aAAa,CAAC,MAC3C,IAAK,IAAIjE,EAAI,EAAGA,EAAIitB,EAAahtB,OAAQD,IACvCitB,EAAajtB,GAAGsN,UAMpBlP,aAAaof,GACX,OAAOA,EAKTpf,cACEkC,EACAka,GAEAlc,KAAKmc,uBAAuBD,GAC5B,MAAMuC,EAAUze,KAAKU,UAAUsb,QAC3Bjb,KAAKC,MAAQhB,KAAKU,UAAUsb,QAC5B,EASJ,OAFAhc,KAAKof,sBAEE,CACLb,aAAcve,KAAKqf,aAAard,GAChCwc,OATa,CACb7e,MAAO,EACPO,WAAY,GAQZue,QAAAA,GAMJ3e,wBAAwBkC,GACtB,IAAKhC,KAAKge,iBACR,MAAM,IAAI9b,MAAM,mCAElB,IAAI8D,EAAoB,IAAIL,aAAa,GACzC,IAAK,IAAIjE,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EAAG,CACpC,MAAM6d,EAAUvZ,EACVrG,EAAQK,KAAKwf,cAAcxd,EAAKN,IAAI,GAC1CsE,EAAMhG,KAAKge,iBAAiBpX,IAAIZ,EAAKrG,GACrCoF,EAAQpF,GACRoF,EAAQwa,GAEV,MAAMrc,EAASlD,KAAKge,iBAAiBjX,OAAO/E,EAAKL,OAAQqE,GAEzD,GADAjB,EAAQiB,GACJ9C,aAAkB+B,UAAS,CAE7B,OADoB/B,EAAOuF,UACR,GAErB,OAAQvF,EAAoB,GAM9BpD,WAAWkC,GACT,OAAOA,EAKTlC,iBAAiBsK,GACf,MAAMukB,EAAe3uB,KAAK6tB,WAAW7tB,KAAK6tB,WAAWlsB,OAAS,GAE9D,IAAK,IAAID,EAAIitB,EAAahtB,OAAS,EAAGD,GAAK,EAAGA,IAC5CitB,EAAajtB,GAAG8S,UAGlB,IAAK,IAAIjP,EAAI6E,EAAOzI,OAAS,EAAG4D,GAAK,EAAGA,IAAK,CAC3C,MAAM4oB,EAAWnuB,KAAK6tB,WAAWtoB,GACjC4oB,EAASA,EAASxsB,OAAS,GAAG6S,QAAQpK,EAAO7E,EAAI,IACjD,IAAK,IAAI7D,EAAIysB,EAASxsB,OAAS,EAAGD,GAAK,EAAGA,IACxCysB,EAASzsB,GAAG8S,WAKlB1U,sBACE,MAAM8d,EAAS5d,KAAK4d,OACpB,IAAK,IAAIlc,EAAI,EAAGA,EAAIkc,EAAOjc,OAAQD,IACjCkc,EAAOlc,GAAGme,gBAAM7f,KAAKkc,QAAQ5T,4BAAgB,GAMjDxI,eAAekC,GACb,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAKL,SAAUD,EACjC1B,KAAKwf,cAAcxd,EAAKN,IAAI,GAMhC5B,cACEsI,EACAsX,GASA,GANA1f,KAAKwuB,UAAUpmB,GAGfpI,KAAK2f,iBAAiBvX,GACtBpI,KAAK4f,gBAEDF,EAAc,CAChB,IAAK1f,KAAKge,iBACR,MAAM,IAAI9b,MAAM,mCAElB,IAAIvC,EAAsB,IAAIgG,aAAa,GAC3C,IAAK,IAAIjE,EAAI,EAAGpC,EAAM8I,EAAOzG,OAAS,EAAGD,GAAKpC,EAAKoC,IAAK,CACtD,MAAMysB,EAAWnuB,KAAK6tB,WAAWnsB,GAC3Bqc,EAAYoQ,EAASA,EAASxsB,OAAS,GACvC8E,EAA0B9G,EAChCA,EAAQK,KAAKge,iBAAiBxX,YAC5BC,EACAsX,EAAUhY,QAEZhB,EAAQ0B,GAEV,OAAOf,EAAM1F,KAAKge,iBAAiBjX,OAAOqB,EAAOzG,OAAQhC,IAE3D,OAAO,YChaEivB,GAMX9uB,YAAY+uB,EAAeC,GAL3B9uB,UAAO,EACPA,aAAU,EAKJ6uB,IAAM7uB,KAAK6uB,KAAOA,GAClBC,IAAS9uB,KAAK8uB,QAAUA,GAE5B9uB,KAAKmH,QAAU0B,EAAM7I,KAAK6uB,KAAO7uB,KAAK8uB,SACtC9uB,KAAKoH,OAASyB,EAAM7I,KAAK6uB,KAAO7uB,KAAK8uB,SAGvChvB,UAAU2F,EAAaspB,GAGrB,MAAMC,EAAKhvB,KAAK8uB,QAAUrpB,EAAMspB,EAEhC,GAAIC,EAAK,GAAKA,GAAMhvB,KAAKmH,QAAQxF,OAC/B,MAAM,IAAIO,MAAM,0BAGlB,OAAOlC,KAAKmH,QAAQ6nB,GAGtBlvB,UAAU2F,EAAaspB,EAAarf,GAElC,MAAMsf,EAAKhvB,KAAK8uB,QAAUrpB,EAAMspB,EAEhC,GAAIC,EAAK,GAAKA,GAAMhvB,KAAKmH,QAAQxF,OAC/B,MAAM,IAAIO,MAAM,0BAKlB,OAFAlC,KAAKmH,QAAQ6nB,GAAMtf,EAEZ1P,KAGTF,SAAS2F,EAAaspB,GAGpB,MAAMC,EAAKhvB,KAAK8uB,QAAUrpB,EAAMspB,EAEhC,GAAIC,EAAK,GAAKA,GAAMhvB,KAAKoH,OAAOzF,OAC9B,MAAM,IAAIO,MAAM,0BAGlB,OAAOlC,KAAKoH,OAAO4nB,GAGrBlvB,SAAS2F,EAAaspB,EAAarf,GAEjC,MAAMsf,EAAKhvB,KAAK8uB,QAAUrpB,EAAMspB,EAEhC,GAAIC,EAAK,GAAKA,GAAMhvB,KAAKmH,QAAQxF,OAC/B,MAAM,IAAIO,MAAM,0BAKlB,OAFAlC,KAAKoH,OAAO4nB,GAAMtf,EAEX1P,KAGTF,SACE,MAAO,CACL+uB,KAAM7uB,KAAK6uB,KACXC,QAAS9uB,KAAK8uB,QACd3nB,QAAS/B,MAAMwD,KAAK5I,KAAKmH,QAAQnE,MAAM,KAI3ClD,gBAAgB4D,GACd,MAAMkC,EAAS,IAAIgpB,GAAOlrB,EAAKmrB,KAAMnrB,EAAKorB,SAE1C,IAAK,IAAIptB,EAAI,EAAGpC,EAAMoE,EAAKmrB,KAAOnrB,EAAKorB,QAASptB,EAAIpC,EAAKoC,IACvDkE,EAAOuB,QAAQzF,GAAKgC,EAAKyD,QAAQzF,GAGnC,OAAOkE,EAGT9F,iBAAiBqH,GACf,MAAMvB,EAAS,IAAIgpB,GAAOznB,EAAQxF,OAAQwF,EAAQ,GAAGxF,QAErD,OADAiE,EAAOqpB,UAAU9nB,GACVvB,EAGT9F,gBACE,OAAOE,KAAKyI,QAAQ,UAGtB3I,iBACE,OAAOE,KAAKyI,QAAQ,WAGtB3I,QAAQ0b,EAA6B,WACnC,MAAMtY,EAAqB,IAAIkC,MAAMpF,KAAK6uB,MAa1C,OAZA7uB,KAAKkvB,QAAQ,CACXzpB,IAAM0pB,IACJjsB,EAAOisB,GAAY,IAAI/pB,MAAMpF,KAAK8uB,UAEpCM,OAAQ,CAACD,EAAUE,KACJ,YAAT7T,EACFtY,EAAOisB,GAAUE,GAAervB,KAAKsvB,UAAUH,EAAUE,GACvC,WAAT7T,IACTtY,EAAOisB,GAAUE,GAAervB,KAAKuvB,SAASJ,EAAUE,OAIvDnsB,EAGTpD,UACE2B,EACA+Z,EAA6B,WAE7B,GAAI/Z,EAAME,SAAW3B,KAAK6uB,KACxB,MAAM,IAAI3sB,MAAM,qBAElB,GAAIT,EAAM,GAAGE,SAAW3B,KAAK8uB,QAC3B,MAAM,IAAI5sB,MAAM,wBAelB,OAbAlC,KAAKkvB,QAAQ,CACXE,OAAQ,CAACD,EAAUE,KACjB,MAAM5vB,EAAQgC,EAAM0tB,GAAUE,GAC9B,GAAqB,iBAAV5vB,EACT,MAAM,IAAIyC,MAAM,oBAEL,YAATsZ,EACFxb,KAAKwvB,UAAUL,EAAUE,EAAa5vB,GACpB,WAAT+b,GACTxb,KAAKyvB,SAASN,EAAUE,EAAa5vB,MAIpCO,KAGTF,QAAQ4vB,GAIN,MAAMb,EAAO7uB,KAAK6uB,KACZC,EAAU9uB,KAAK8uB,QACrB,IAAK,IAAIK,EAAW,EAAGA,EAAWN,EAAMM,IAAY,CAC9CO,EAAUjqB,KACZiqB,EAAUjqB,IAAI0pB,GAEhB,IAAK,IAAIE,EAAc,EAAGA,EAAcP,EAASO,IAC3CK,EAAUN,QACZM,EAAUN,OAAOD,EAAUE,GAIjC,OAAOrvB,YChKE2vB,WAAqBf,GAGhC9uB,YAAY+uB,EAAcC,EAAiB/e,GACzC5G,MAAM0lB,EAAMC,GAEZ9uB,KAAK+P,IAAMA,EAEX,IAAK,IAAIrO,EAAI,EAAGpC,EAAMU,KAAKmH,QAAQxF,OAAQD,EAAIpC,EAAKoC,IAClD1B,KAAKmH,QAAQzF,GAAK2N,IAAaU,EAAKA,UCG7B6f,GAOX9vB,YAAoBiS,EAAmC8d,EAAe,GAAlD7vB,YAAA+R,EANpB/R,gBAA+D,GAC/DA,oBAA4D,GAC5DA,gBAAqC,GACrCA,oBAA2B,GAC3BA,cAAU,OAGOiE,IAAX8N,GAEJ/R,KAAKmE,MAAM4N,EAAQ8d,GAGrB/vB,MAAMiS,EAAkC8d,EAAe,GACrD,GAAI7vB,KAAK8vB,QAAS,MAAM,IAAI5tB,MAAM,kCAClClC,KAAK+R,OAASA,EAId/R,KAAK+vB,4BAA4Bhe,GACjC/R,KAAKgwB,YAAYH,GACZ9d,EAAO,GAAiB1G,OAC3BrL,KAAKiwB,iBAEPjwB,KAAKkwB,kBACLlwB,KAAK8vB,SAAU,EAGjBhwB,4BAA4BiS,GAC1B,MAAMoe,EAAwD,GAC9D,IACE,IAAIC,EAAqB,EAAGC,EAAsBte,EAAOpQ,OACzDyuB,EAAqBC,EACrBD,IACA,CACA,MAAME,EAAave,EAAOqe,GAO1B,GAAIE,EAAWltB,eAAe,UAAW,CACvC,MAAMmtB,EAAaD,EACnB,IACE,IAAIE,EAAiB,EAAGC,EAAmBF,EAAW5uB,OACtD6uB,EAAiBC,EACjBD,IACA,CACA,MAAME,EAAYH,EAAWC,GACzBL,EAAoB/sB,eAAestB,KACvCP,EAAoBO,IAAa,EACjC1wB,KAAKswB,WAAW7sB,KAAKitB,UAElB,GAA0B,iBAAfJ,EAAyB,CACzC,GAAIH,EAAoB/sB,eAAektB,GAAa,SACpDH,EAAoBG,IAAc,EAClCtwB,KAAKswB,WAAW7sB,KAAK6sB,QAChB,GAA0B,kBAAfA,EAA0B,CAC1C,MAAMI,EAAYJ,EAAW7T,WAC7B,GAAI0T,EAAoB/sB,eAAestB,GAAY,SACnDP,EAAoBO,IAAa,EACjC1wB,KAAKswB,WAAW7sB,KAAKitB,QAChB,GACLtrB,MAAMC,QAAQirB,IACW,iBAAlBA,EAAW,GAElB,IAAK,IAAI5uB,EAAI,EAAGA,EAAI4uB,EAAW3uB,OAAQD,IAAK,CAC1C,MAAMgvB,EAAYJ,EAAW5uB,GACzByuB,EAAoB/sB,eAAestB,KACvCP,EAAoBO,IAAa,EACjC1wB,KAAKswB,WAAW7sB,KAAKitB,SAElB,IACLtrB,MAAMC,QAAQirB,IACY,iBAAlBA,EAAW,IACQ,kBAAlBA,EAAW,GAQf,CAAA,IACLA,EAAWltB,eAAe,WAC1BktB,EAAWltB,eAAe,UAe1B,MAAM,IAAIlB,MAAM,mBAdhB,CACA,MAAMmJ,MAAEA,EAAK/E,OAAEA,GAAYgqB,EACvBlrB,MAAMC,QAAQgG,GAChBrL,KAAK2wB,cAActlB,EAAO8kB,GAE1BnwB,KAAK2wB,cAActlB,EAAMoR,WAAY0T,GAGnC/qB,MAAMC,QAAQiB,GAChBtG,KAAK2wB,cAAcrqB,EAAQ6pB,GAE3BnwB,KAAK2wB,cAAcrqB,EAAOmW,WAAY0T,SApBxC,IAAK,IAAIzuB,EAAI,EAAGA,EAAI4uB,EAAW3uB,OAAQD,IAAK,CAC1C,MAAMgvB,EAAYJ,EAAW5uB,GAAG+a,WAC5B0T,EAAoB/sB,eAAegtB,KACvCD,EAAoBO,IAAa,EACjC1wB,KAAKswB,WAAW7sB,KAAKitB,MAwB7B5wB,cACEwwB,EACAM,GAEA,IAAK,IAAIlvB,EAAI,EAAGA,EAAI4uB,EAAW3uB,OAAQD,IAAK,CAC1C,MAAMgvB,EAAYJ,EAAW5uB,GAAG+a,WAC5BmU,EAAgBxtB,eAAestB,KACnCE,EAAgBF,IAAa,EAC7B1wB,KAAKswB,WAAW7sB,KAAKitB,KAIzB5wB,YAAY+vB,GAEV,MAAMY,EAAmBzwB,KAAKswB,WAAW3uB,OACzC,IACE,IAAI6uB,EAAiB,EACrBA,EAAiBC,EACjBD,IACA,CACA,MAAME,EAAY1wB,KAAKswB,WAAWE,GAC9BA,GAAkBX,IAEpB7vB,KAAK6wB,WAAWH,GAAaF,EAC7BxwB,KAAK8wB,eAAeN,GAAkBE,IAK5C5wB,UAAUL,EAAcowB,EAAe,GACrC,MAAM3sB,EAAS,IACT2tB,WAAEA,GAAe7wB,KAEvB,cAAeP,GACb,IAAK,SACL,IAAK,UACHA,EAAQA,EAAMgd,WAGlB,IAAK,IAAI/a,EAAI,EAAGpC,EAAMG,EAAMkC,OAAQD,EAAIpC,EAAKoC,IAAK,CAChD,MAAMgvB,EAAYjxB,EAAMiC,GAAG+a,WAC3B,IAAInR,EAAQulB,EAAWH,GACvB,QAAczsB,IAAVqH,EAAqB,CACvB,IAAIulB,EAAWE,aAGb,MAAM,IAAI7uB,MAAM,2BAA2BwuB,MAF3CplB,EAAQulB,EAAWE,aAKnBzlB,EAAQukB,GACZ3sB,EAAOO,KAAK6H,GAEd,OAAOpI,EAGTpD,qBACEuL,EACA/E,EACAupB,EAAe,GAEf,MAAM3sB,EAAmBlD,KAAKgxB,eAAe3lB,EAAOwkB,GAAc,GAElE,YAAsB,IAAXvpB,EAA+BpD,EACnCA,EAAO2d,OAAO7gB,KAAKgxB,eAAe1qB,EAAQupB,GAAc,IAGjE/vB,eACEL,EACAowB,EACAoB,GAEA,GAAqB,iBAAVxxB,EACTA,EAAQA,EAAMyxB,MAAM,SACf,GAAqB,iBAAVzxB,GAAuC,kBAAVA,EAC7CA,EAAQA,EAAMgd,WAAWyU,MAAM,QAC1B,CAAA,IACL9rB,MAAMC,QAAQ5F,IACqB,iBAA1BA,EAAmB,IACS,kBAA3BA,EAAoB,IACM,iBAA1BA,EAAmB,GAI7B,MAAM,IAAIyC,MAAM,sBAFhBzC,EAASA,EAAmBoF,IAAK6K,GAAMA,EAAE+M,YAO3C,OAHIwU,IACFxxB,EAAQA,EAAMohB,OAAO,CAAC,aAAc,kBAE/B7gB,KAAKmxB,UAAU1xB,EAAOowB,GAG/B/vB,aAAasxB,EAAmBvB,EAAe,GAC7C,MAAM3sB,EAAmB,IACnB2tB,WAAEA,EAAUC,eAAEA,GAAmB9wB,KAEvC,IAAK,IAAI0B,EAAI,EAAGpC,EAAM8xB,EAAQzvB,OAAQD,EAAIpC,EAAKoC,IAAK,CAClD,MAAM4J,EAAQ8lB,EAAQ1vB,GACtB,GAAI4J,EAAQukB,EAAc,SAC1B,IAAIa,EAAYI,EAAexlB,GAC/B,QAAkBrH,IAAdysB,EAAyB,CAC3B,IAAIG,EAAWE,aAGb,MAAM,IAAI7uB,MAAM,uBAAuBoJ,MAFvColB,EAAYI,EAAeD,EAAWE,mBAIjB,OAAdL,GACTxtB,EAAOO,KAAKitB,EAAUjU,YAI1B,OAAOvZ,EAGTpD,SAASsxB,EAAmBvB,GAC1B,OAAO7vB,KAAKqxB,aAAaD,EAASvB,GAAcrF,KAAK,IAGvD1qB,iBACEE,KAAKsxB,WAAW,cAChBtxB,KAAKsxB,WAAW,gBAGlBxxB,kBACEE,KAAKsxB,WAAW,gBAGlBxxB,wBACE+vB,EACA9d,EAAS,CAAC,OAEV,IAAK,IAAIrQ,EAAI,GAAIA,GAAK,IAAKA,IACzBqQ,EAAOtO,KAAK8tB,OAAOC,aAAa9vB,IAElC,OAAO,IAAIkuB,GAAc7d,EAAQ8d,GAGnC/vB,mCACE+vB,EACA9d,EAAS,CAAC,OAEV,MAAM0f,EAAgB7B,GAAc8B,iBAAiB7B,EAAc9d,GAGnE,OAFA0f,EAAcxB,iBACdwB,EAAcvB,kBACPuB,EAGT3xB,6BACE6xB,EACA9B,GAEA,MAAM9d,EAAS3M,MAAMwD,KAAK,IAAIgpB,IAAID,IAASnH,KAAK,IAC1CiH,EAAgB,IAAI7B,GAAc7d,EAAOmf,MAAM,IAAKrB,GAI1D,OAHA4B,EAAcxB,iBACdwB,EAAcvB,kBACduB,EAAc3B,SAAU,EACjB2B,EAGT3xB,4BACEkC,EACA6tB,GAEA,MAAM9d,EAAmC,GAEzC,IAAK,IAAIrQ,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMmwB,EAAQ7vB,EAAKN,GACnBqQ,EAAOtO,KAAKquB,GAAgBD,EAAMxmB,OAAQymB,GAAgBD,EAAMvrB,SAElE,MAAMyrB,EAAsB3sB,MAAMC,QAAQ0M,GACrCA,EAAsBigB,OACvBjgB,EACE0f,EAAgB,IAAI7B,GACxBxqB,MAAMwD,KAAK,IAAIgpB,IAAIG,IACnBlC,GAKF,OAHA4B,EAAcxB,iBACdwB,EAAcvB,kBACduB,EAAc3B,SAAU,EACjB2B,EAGT3xB,kBAAkB6xB,EAAgB9B,EAAe,GAC/C,MAAM9d,EAAS3M,MAAMwD,KAAK,IAAIgpB,IAAID,IAASnH,KAAK,IAChD,OAAO,IAAIoF,GAAc7d,EAAOmf,MAAM,IAAKrB,GAG7C/vB,SACE,MAAO,CACL+wB,WAAY7wB,KAAK6wB,WACjBC,eAAgB9wB,KAAK8wB,eACrB/e,OAAQ/R,KAAK+R,OACbue,WAAYtwB,KAAKswB,WACjB2B,eAAgBjyB,KAAKiyB,gBAOzBnyB,gBAAgB4D,GACd,MAAM+tB,EAAgB,IAAI7B,GAM1B,OALA6B,EAAcZ,WAAantB,EAAKmtB,WAChCY,EAAcX,eAAiBptB,EAAKotB,eACpCW,EAAc1f,OAASrO,EAAKqO,OAC5B0f,EAAcnB,WAAa5sB,EAAK4sB,WAChCmB,EAAcQ,eAAiBvuB,EAAKuuB,eAC7BR,EAGT3xB,WAAWoyB,EAA0BxB,EAAY,MAC/C,MAAMyB,EAAgBnyB,KAAK6wB,WAAWqB,GAAWlyB,KAAKswB,WAAW3uB,OACjE3B,KAAK8wB,eAAeqB,GAAgBzB,EACpC1wB,KAAKiyB,eAAexuB,KAAKzD,KAAKswB,WAAW3uB,QACzC3B,KAAKswB,WAAW7sB,KAAKyuB,GAGvBpyB,mBACE,MAAO,0BACYsyB,KAAKC,UAAUryB,KAAK8wB,sCACxBsB,KAAKC,UAAUryB,KAAK6wB,kCACpBuB,KAAKC,UAAUryB,KAAKswB,8DAEftwB,KAAKmxB,UAAU1U,iDACJzc,KAAKsyB,qBAAqB7V,yCAClCzc,KAAKqxB,aAAa5U,2CAChBzc,KAAKgxB,eAAevU,kBAI/C3c,aAAauL,EAAe/E,SAC1B,YAAcrC,IAAVoH,EAA4B,GAC5BjG,MAAMC,QAAQgG,IAA8B,iBAAbA,EAAM,GAChCA,aAELrL,KAAK6wB,iCAAYztB,eAAe,eAC3BpD,KAAKsyB,qBAAqBjnB,EAAO/E,GAEnCtG,KAAKmxB,UAAU9lB,GAGxBvL,cAAcuL,EAAiB/E,GAC7B,OAAOtG,KAAKqxB,aAAa/qB,GAAQkkB,KAAK,IAGxC1qB,OAAOkC,GACL,KACqB,iBAAZA,EAAK,IACXoD,MAAMC,QAAQrD,EAAK,KAClBA,EAAK,GAAGoB,eAAe,UAAapB,EAAK,GAAGoB,eAAe,WAE7D,OAAOpB,EAET,MAAMkB,EAAqB,GAC3B,GACqB,iBAAZlB,EAAK,IACO,iBAAZA,EAAK,IACZoD,MAAMC,QAAQrD,EAAK,IAEnB,GAAKhC,KAAK8vB,QAMR,IAAK,IAAIpuB,EAAI,EAAGpC,EAAM0C,EAAKL,OAAQD,EAAIpC,EAAKoC,IAC1CwB,EAAOO,KAAKzD,KAAKuyB,aAAavwB,EAAKN,SAPpB,CACjB1B,KAAKmE,MAAMnC,GACX,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAKzD,KAAKuyB,aAAaT,GAAgB9vB,EAAKN,UAOlD,CAAA,IAAKM,EAAK,GAAiBqJ,QAAUrJ,EAAK,GAAiBsE,OAahE,MAAM,IAAIpE,MAAM,qBAZXlC,KAAK8vB,SACR9vB,KAAKmE,MAAMnC,GAEb,IAAK,IAAIN,EAAI,EAAGpC,EAAM0C,EAAKL,OAAQD,EAAIpC,EAAKoC,IAC1CwB,EAAOO,KACLzD,KAAKuyB,aACHT,GAAiB9vB,EAAKN,GAAiB2J,OACvCymB,GAAiB9vB,EAAKN,GAAiB4E,UAO/C,OAAOpD,GAIX,SAAS4uB,GAAgBryB,GACvB,GAAqB,iBAAVA,EAAoB,OAAOA,EACtC,GAAqB,iBAAVA,EAAoB,OAAOA,EAAMgd,WAC5C,GAAqB,kBAAVhd,EAAqB,OAAOA,EAAMgd,WAC7C,GAAIrX,MAAMC,QAAQ5F,IAA8B,iBAAbA,EAAM,GACvC,OAAOA,EACT,GAAwB,kBAAbA,EAAM,GACf,OAAQA,EAAoBoF,IAAK6K,GAAeA,EAAE+M,YAEpD,GAAwB,iBAAbhd,EAAM,GACf,OAAQA,EAAmBoF,IAAK6K,GAAcA,EAAE+M,YAElD,MAAM,IAAIva,MACR,mGClaY0E,GAAI4rB,EAAiBC,EAAcC,GACjD,IAAK,IAAIhxB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC8wB,EAAQrrB,QAAQzF,GAAK+wB,EAAKtrB,QAAQzF,GAAKgxB,EAAMvrB,QAAQzF,GACrD8wB,EAAQprB,OAAO1F,GAAK,WCHRixB,GAAKH,EAAiBC,EAAcC,GAClD,IAAK,IAAIhxB,EAAI,EAAGA,EAAI8wB,EAAQprB,OAAOzF,OAAQD,IACzC+wB,EAAKrrB,OAAO1F,GAAK8wB,EAAQprB,OAAO1F,GAChCgxB,EAAMtrB,OAAO1F,GAAK8wB,EAAQprB,OAAO1F,YCHrBkxB,GAAQJ,GACtB,IAAK,IAAI9wB,EAAI,EAAGA,EAAI8wB,EAAQrrB,QAAQxF,OAAQD,IAC1C8wB,EAAQrrB,QAAQzF,GAAK,EACrB8wB,EAAQprB,OAAO1F,GAAK,WCNRmxB,GAAcL,EAAiBC,GAC7CD,EAAQ3D,KAAO4D,EAAK5D,KACpB2D,EAAQ1D,QAAU2D,EAAK3D,QACvB0D,EAAQrrB,QAAUsrB,EAAKtrB,QAAQnE,MAAM,GACrCwvB,EAAQprB,OAASqrB,EAAKrrB,OAAOpE,MAAM,GAEnC,IAAK,IAAItB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC8wB,EAAQrrB,QAAQzF,IAAM+wB,EAAKtrB,QAAQzF,GACnC8wB,EAAQprB,OAAO1F,GAAK,WCLRuP,GAASuhB,EAAiBC,EAAcC,GACtD,MAAMI,EAAWL,EAAK5D,KAChBkE,EAAcN,EAAK3D,QACnBkE,EAAeN,EAAM5D,QAG3B,IAAK,IAAImE,EAAU,EAAGA,EAAUH,EAAUG,IAAW,CACnD,MAAMC,EAAcH,EAAcE,EAC5BE,EAAeH,EAAeC,EAGpC,IAAK,IAAIG,EAAc,EAAGA,EAAcJ,EAAcI,IAAe,CAEnE,IAAIC,EAAM,EAGV,IAAK,IAAIC,EAAa,EAAGA,EAAaP,EAAaO,IAAc,CAC/D,MACMC,EAAYL,EAAcI,EAC1BE,EAFkBR,EAAeM,EAEFF,EACrCC,GAAOZ,EAAKtrB,QAAQosB,GAAab,EAAMvrB,QAAQqsB,GAC/Cf,EAAKrrB,OAAOmsB,GAAa,EACzBb,EAAMtrB,OAAOosB,GAAc,EAG7BhB,EAAQrrB,QAAQgsB,EAAeC,GAAeC,aCzBpCI,GAAUjB,EAAiBC,EAAcC,GACvD,MAAMI,EAAWL,EAAK5D,KAChBkE,EAAcN,EAAK3D,QACnBkE,EAAeN,EAAM5D,QAG3B,IAAK,IAAI4E,EAAc,EAAGA,EAAcZ,EAAUY,IAAe,CAC/D,MAAMR,EAAcH,EAAcW,EAC5BP,EAAeH,EAAeU,EAGpC,IAAK,IAAIN,EAAc,EAAGA,EAAcJ,EAAcI,IAEpD,IAAK,IAAIE,EAAa,EAAGA,EAAaP,EAAaO,IAAc,CAC/D,MACML,EAAUC,EAAcI,EACxBK,EAFkBX,EAAeM,EAEJF,EAC7BQ,EAAqBpB,EAAQprB,OAAO+rB,EAAeC,GACzDX,EAAKrrB,OAAO6rB,IAAYP,EAAMvrB,QAAQwsB,GAAYC,EAClDlB,EAAMtrB,OAAOusB,IAAalB,EAAKtrB,QAAQ8rB,GAAWW,aCtB1Cpe,GACdgd,EACAC,EACAC,GAEA,MAAMvrB,QAAEA,GAAYsrB,EAEpB,IAAK,IAAI/wB,EAAI,EAAGA,EAAIyF,EAAQxF,OAAQD,IAClC8wB,EAAQrrB,QAAQzF,GAAK+wB,EAAKtrB,QAAQzF,GAAKgxB,EAAMvrB,QAAQzF,GACrD8wB,EAAQprB,OAAO1F,GAAK,WCNRmyB,GACdrB,EACAC,EACAC,GAEA,IAAK,IAAIhxB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC+wB,EAAKrrB,OAAO1F,GAAKgxB,EAAMvrB,QAAQzF,GAAK8wB,EAAQprB,OAAO1F,GACnDgxB,EAAMtrB,OAAO1F,GAAK+wB,EAAKtrB,QAAQzF,GAAK8wB,EAAQprB,OAAO1F,YCNvC6V,GAAKib,EAAiBC,GACpC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC8wB,EAAQrrB,QAAQzF,GAAKrC,KAAKC,IAAI,EAAGmzB,EAAKtrB,QAAQzF,IAC9C8wB,EAAQprB,OAAO1F,GAAK,WCJRoyB,GAAMtB,EAAiBC,GACrC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI8wB,EAAQprB,OAAOzF,OAAQD,IACzC+wB,EAAKrrB,OAAO1F,GAAK+wB,EAAKtrB,QAAQzF,GAAK,EAAI8wB,EAAQprB,OAAO1F,GAAK,WCL/CqyB,GACdvB,EACAC,EACAuB,GAEA,MAAMlF,QAAEA,GAAY2D,EACdwB,EAAUnF,EAAUkF,EAE1B,IAAK,IAAI5E,EAAS,EAAGA,EAASN,EAASM,IACrCoD,EAAQrrB,QAAQioB,GAAUqD,EAAKtrB,QAAQ8sB,EAAU7E,GACjDoD,EAAQprB,OAAOgoB,GAAU,WCPb8E,GACd1B,EACAC,EACAtD,GAEA,MAAML,QAAEA,GAAY2D,EACdwB,EAAUnF,EAAUK,EAE1B,IAAK,IAAIC,EAAS,EAAGA,EAASN,EAASM,IACrCqD,EAAKrrB,OAAO6sB,EAAU7E,GAAUoD,EAAQprB,OAAOgoB,YCZnC9d,GAAQkhB,EAAiBC,GAEvC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC8wB,EAAQrrB,QAAQzF,GAAK,GAAK,EAAIrC,KAAKK,KAAK+yB,EAAKtrB,QAAQzF,KACrD8wB,EAAQprB,OAAO1F,GAAK,WCJRyyB,GAAS3B,EAAiBC,GACxC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI8wB,EAAQprB,OAAOzF,OAAQD,IAAK,CAC9C,MAAM0yB,EAAM5B,EAAQrrB,QAAQzF,GAC5B+wB,EAAKrrB,OAAO1F,GAAK0yB,GAAO,EAAIA,GAAO5B,EAAQprB,OAAO1F,aCHtC2yB,GAAQzuB,GAEtB,MAAM1C,EAAS,IAAI0rB,GAAOhpB,EAAOipB,KAAMjpB,EAAOkpB,SAC9C,IAAIwF,GAAU,OAEd,IAAK,IAAI5yB,EAAI,EAAGA,EAAIkE,EAAOuB,QAAQxF,OAAQD,IACrCkE,EAAOuB,QAAQzF,GAAK4yB,IACtBA,EAAS1uB,EAAOuB,QAAQzF,IAI5B,IAAIuf,EAAI,EACR,IAAK,IAAIvf,EAAI,EAAGA,EAAIkE,EAAOuB,QAAQxF,OAAQD,IACzCwB,EAAOiE,QAAQzF,GAAKrC,KAAKK,IAAIkG,EAAOuB,QAAQzF,GAAK4yB,GACjDrT,GAAK/d,EAAOiE,QAAQzF,GAGtB,IAAK,IAAIA,EAAI,EAAGA,EAAIkE,EAAOuB,QAAQxF,OAAQD,IACzCwB,EAAOiE,QAAQzF,IAAMuf,EAMvB,OAAO/d,WCxBOtD,GAAK4yB,EAAiBC,GAEpC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI+wB,EAAKtrB,QAAQxF,OAAQD,IACvC8wB,EAAQrrB,QAAQzF,GAAKrC,KAAKO,KAAK6yB,EAAKtrB,QAAQzF,IAC5C8wB,EAAQprB,OAAO1F,GAAK,WCJR6yB,GAAM/B,EAAiBC,GACrC,IAAK,IAAI/wB,EAAI,EAAGA,EAAI8wB,EAAQprB,OAAOzF,OAAQD,IAAK,CAE9C,MAAM0yB,EAAM5B,EAAQrrB,QAAQzF,GAC5B+wB,EAAKrrB,OAAO1F,IAAM,EAAI0yB,EAAMA,GAAO5B,EAAQprB,OAAO1F,UCoCzC8yB,GAAb10B,cACEE,YAAmB,GAEnBA,cAAW,EAEXF,IAAI2yB,EAAcC,GAChB,GAAID,EAAKtrB,QAAQxF,SAAW+wB,EAAMvrB,QAAQxF,OACxC,MAAM,IAAIO,MAAM,uBAGlB,MAAMswB,EAAU,IAAI5D,GAAO6D,EAAK5D,KAAM4D,EAAK3D,SAW3C,OATA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,MACNyqB,QAAAA,EACAC,KAAAA,EACAC,MAAAA,EACAgC,UAAW9tB,GACX+tB,kBAAmBhC,KAGdH,EAGT1yB,QAAQ+uB,EAAcC,GACpB,MAAM0D,EAAU,IAAI5D,GAAOC,EAAMC,GAUjC,OARA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,UACNyqB,QAAAA,EACAC,KAAMD,EACNkC,UAAW9B,GACX+B,kBAAmB,SAGdnC,EAGT1yB,cAAc8F,GACZ,MAAM4sB,EAAU,IAAI5D,GAAOhpB,EAAOipB,KAAMjpB,EAAOkpB,SAU/C,OARA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,gBACNyqB,QAAAA,EACAC,KAAM7sB,EACN8uB,UAAW7B,GACX8B,kBAAmB,SAGdnC,EAMT1yB,SAAS2yB,EAAcC,GACrB,GAAID,EAAKtrB,QAAQxF,SAAW+wB,EAAMvrB,QAAQxF,OACxC,MAAM,IAAIO,MAAM,uBAGlB,OAAOlC,KAAK4G,IACV5G,KAAK4G,IAAI5G,KAAK4yB,QAAQH,EAAK5D,KAAM4D,EAAK3D,SAAU9uB,KAAK6yB,cAAcJ,IACnEC,GAOJ5yB,SAAS2yB,EAAcC,GACrB,GAAID,EAAK3D,UAAY4D,EAAM7D,KACzB,MAAM,IAAI3sB,MAAM,uBAGlB,MAAMswB,EAAU,IAAI5D,GAAO6D,EAAK5D,KAAM6D,EAAM5D,SAW5C,OATA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,WACNyqB,QAAAA,EACAC,KAAAA,EACAC,MAAAA,EACAgC,UAAWzjB,GACX0jB,kBAAmBlB,KAGdjB,EAMT1yB,gBAAgB2yB,EAAcC,GAC5B,GAAID,EAAKtrB,QAAQxF,SAAW+wB,EAAMvrB,QAAQxF,OACxC,MAAM,IAAIO,MAAM,uBAGlB,MAAMswB,EAAU,IAAI5D,GAAO6D,EAAK5D,KAAM4D,EAAK3D,SAW3C,OATA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,kBACNyqB,QAAAA,EACAC,KAAAA,EACAC,MAAAA,EACAgC,UAAWlf,GACXmf,kBAAmBd,KAGdrB,EAMT1yB,KAAK8F,GACH,MAAM4sB,EAAU,IAAI5D,GAAOhpB,EAAOipB,KAAMjpB,EAAOkpB,SAU/C,OARA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,OACNyqB,QAAAA,EACAC,KAAM7sB,EACN8uB,UAAWnd,GACXod,kBAAmBb,KAGdtB,EAMT1yB,MAAMuL,GAcJ,OAbArL,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,QACNyqB,QAASnnB,EACTqpB,UAAYlC,IACV,GAAKxyB,KAAK40B,WAAV,CACA,GAAI50B,KAAK40B,WAAWjzB,SAAW6wB,EAAQrrB,QAAQxF,OAC7C,MAAM,IAAIO,MAAM,0CAElBswB,EAAQrrB,QAAUkE,EAAMlE,QAAUnH,KAAK40B,aAEzCD,kBAAmB,SAGdtpB,EAMTvL,iBAAiB8F,GAEf,MAAMivB,EAAO70B,KACPwyB,EAAU,IAAI5D,GAAOhpB,EAAOkpB,QAAS,GAa3C,OAXA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,mBACNyqB,QAAAA,EACAC,KAAM7sB,EACN8sB,YACE,OAAQmC,EAAKC,UAEfJ,UAAWX,GACXY,kBAAmBT,KAGd1B,EAMT1yB,QAAQ8F,GACN,MAAM4sB,EAAU,IAAI5D,GAAOhpB,EAAOipB,KAAMjpB,EAAOkpB,SAU/C,OARA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,UACNyqB,QAAAA,EACAC,KAAM7sB,EACN8uB,UAAWpjB,GACXqjB,kBAAmBR,KAGd3B,EAMT1yB,KAAK8F,GACH,MAAM4sB,EAAU,IAAI5D,GAAOhpB,EAAOipB,KAAMjpB,EAAOkpB,SAU/C,OARA9uB,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,OACNyqB,QAAAA,EACAC,KAAM7sB,EACN8uB,UAAW90B,GACX+0B,kBAAmBJ,KAGd/B,EAOT1yB,QAAQ8F,GAQN,OAPA5F,KAAKy0B,OAAOhxB,KAAK,CACfsE,KAAM,UACNyqB,QAAS,IAAI5D,GACb8F,UAAW,OACXC,kBAAmB,SAGd/uB,EAMT9F,SAASqvB,EAAW,GAClBnvB,KAAK80B,SAAW3F,EAChB,IAAI4F,EAAQ/0B,KAAKy0B,OAAO,GAExB,IAAK,IAAI/yB,EAAI,EAAGpC,EAAMU,KAAKy0B,OAAO9yB,OAAQD,EAAIpC,EAAKoC,IACjDqzB,EAAQ/0B,KAAKy0B,OAAO/yB,GAEfqzB,EAAM3xB,eAAe,cACzB2xB,EAAML,UACLK,EAAMvC,QACNuC,EAAMtC,KACNsC,EAAMrC,OAIV,OAAOqC,EAAMvC,QAMf1yB,SAAS80B,GACP50B,KAAK40B,WAAaA,EAClB,IAAIG,EAAQ/0B,KAAKy0B,OAAO,GAExB,IAAK,IAAI/yB,EAAI,EAAGpC,EAAMU,KAAKy0B,OAAO9yB,OAAQD,EAAIpC,EAAKoC,IACjDqzB,EAAQ/0B,KAAKy0B,OAAO/yB,GAEfqzB,EAAM3xB,eAAe,cACzB2xB,EAAML,UACLK,EAAMvC,QACNuC,EAAMtC,KACNsC,EAAMrC,OAIV,OAAOqC,EAAMvC,QAMf1yB,gBACE,IAAI4B,EAAI1B,KAAKy0B,OAAO9yB,OAChBozB,EAAQ/0B,KAAKy0B,OAAO,GAExB,KAAO/yB,KAAM,GACXqzB,EAAQ/0B,KAAKy0B,OAAO/yB,GAEfqzB,EAAM3xB,eAAe,sBACzB2xB,EAAMJ,kBACLI,EAAMvC,QACNuC,EAAMtC,KACNsC,EAAMrC,OAIV,OAAOqC,EAAMvC,QAMf1yB,mBAAmBqvB,EAAW,GAC5BnvB,KAAK80B,SAAW3F,EAEhB,IAAIztB,EAAI1B,KAAKy0B,OAAO9yB,OAChBozB,EAAQ/0B,KAAKy0B,OAAO,GAExB,KAAO/yB,KAAM,GACXqzB,EAAQ/0B,KAAKy0B,OAAO/yB,GAEfqzB,EAAM3xB,eAAe,sBACzB2xB,EAAMJ,kBACLI,EAAMvC,QACNuC,EAAMtC,KACNsC,EAAMrC,OAIV,OAAOqC,EAAMvC,QAMf1yB,cAAcuL,EAAqBjB,GACjC,IAAIuf,EAAW,EACf,MAAMrjB,EAAStG,KAAKoe,SAAS/S,GAE7B,IAAK,IAAI3J,EAAI,EAAGA,EAAI4E,EAAOa,QAAQxF,OAAQD,IAAK,CAC9C,MAAM/B,EAAQ2G,EAAOa,QAAQzF,GAAK0I,EAAO1I,GAEzCioB,GAAYtqB,KAAKsH,IAAIhH,GAErB2G,EAAOc,OAAO1F,GAAK/B,EAGrB,OAAOgqB,EAMT7pB,mBAAmBuL,EAAejB,GAChC,MAAM9D,EAAStG,KAAKg1B,SAAS3pB,GAEvB4pB,EAAmB3uB,EACnB4uB,EAAgBb,GAAQ/tB,GAO9B,OAJA2uB,EAAiB7tB,OAAS8tB,EAAc/tB,QAAQnE,MAAM,GACtDiyB,EAAiB7tB,OAAOgD,IAAW,GAG3B/K,KAAK81B,KAAKD,EAAc/tB,QAAQiD,cCxX5BgrB,GAAKxvB,GAEnB,MAAMuB,QAAEA,GAAYvB,EACpB,IAAIyvB,EAAOluB,EAAQ,GACfmuB,EAAQ,EAEZ,IAAK,IAAI5zB,EAAI,EAAGA,EAAIyF,EAAQxF,OAAQD,IAAK,CACvC,MAAMgO,EAAIvI,EAAQzF,GACdgO,EAAI2lB,IAERC,EAAQ5zB,EACR2zB,EAAO3lB,GAGT,OAAO4lB,WCbOC,GAAQ3vB,GAGtB,MAAM+J,EAAIN,GAAY,EAAG,GACnBmmB,EAAI5vB,EAAOuB,QACjB,IAAI5B,EAAI,EACJ7D,EAAI,EAER,OAAa,CAGX,GAFA6D,GAAKiwB,EAAE9zB,GAEH6D,EAAIoK,EACN,OAAOjO,EAGTA,KC4DG,MAAMia,GAAqC,CAChDzb,WAAY,IACZ0b,YAAa,KACb/L,KAAK,EACLgM,UAAW,GACXvT,aAAc,IACdwT,eAAgB,GAChBE,QAASrE,EAAAA,GAgBE1J,GAAW,KACf,CACLsW,UAAW,GACXkR,WAAY,GACZpY,aAAc,CAAC,GAAI,IACnBmH,WAAY,GACZ3W,UAAW,KACXE,UAAW,KACX2nB,KAAM,KACNC,QAAS,EACTC,oBAAqB,IACrBnE,cAAe,IAAI7B,WAeViG,GAmBX/1B,YAAYoc,EAAsD,IAlBlElc,aAAuB,IAAKiO,MAC5BjO,eAAiC,IAAK2b,IACtC3b,eAA+C,GAC/CA,UAAO,EACPA,kBAAe,EACfA,WAAmBqD,OAAOyyB,KAAK,CAC7BC,eAAe,EACf1qB,MAAO,IAAIujB,GAAO,EAAG,GACrBvR,aAAc,GACd/W,OAAQ,IAAIsoB,GAAO,EAAG,GACtBoH,UAAW,GACXC,YAAa,GACbC,oBAAqB,GACrBC,gBAAiB,IAAIxG,GAAa,EAAG,EAAG,OAG1C3vB,wBAA+B,GAG7BA,KAAKkc,QAAU,IAAKlc,KAAKkc,WAAYA,GACrClc,KAAKglB,sBAAsB,IACtBrJ,KAIDO,EAAQxY,MACV1D,KAAK2D,SAASuY,EAAQxY,MAI1B5D,aACE,MAAM2xB,cAAEA,GAAkBzxB,KAAKkc,SAC3BuV,MAAAA,SAAAA,EAAenB,WAAW3uB,UAC5B3B,KAAKkc,QAAQqI,UAAYvkB,KAAKkc,QAAQuZ,WAAaz1B,KAAKkc,QAAQsI,WAC9DiN,EAAcnB,WAAW3uB,QAE7B3B,KAAKo2B,MAAQp2B,KAAKq2B,WAGpBv2B,qBACE,MAAMud,aAAEA,EAAYkH,UAAEA,GAAcvkB,KAAKkc,QACnCoa,EAAuC,GAE7CA,EAAkB7yB,KAAKzD,KAAKu2B,eAAelZ,EAAa,GAAIkH,IAC5D,IAAIa,EAAW/H,EAAa,GAE5B,IAAK,IAAImZ,EAAI,EAAGA,EAAInZ,EAAa1b,OAAQ60B,IAAK,CAE5C,MAAMC,EAAapZ,EAAamZ,GAChCF,EAAkB7yB,KAAKzD,KAAKu2B,eAAeE,EAAYrR,IACvDA,EAAWqR,EAEb,OAAOH,EAGTx2B,eAAe22B,EAAoBrR,GACjC,MAAO,CAELhmB,OAAQ,IAAIuwB,GAAa8G,EAAYrR,EAAU,KAE/CpK,WAAY,IAAI2U,GAAa8G,EAAYA,EAAY,KAErD7iB,KAAM,IAAIgb,GAAO6H,EAAY,IAIjC32B,YACE42B,EACAC,EACAC,EACApZ,GAEA,IAAKA,EAAYpe,SAAWoe,EAAYxC,aAAewC,EAAY5J,KACjE,MAAM,IAAI1R,MAAM,iDAElB,MAAMqV,EAAOmf,EAASnf,KAAKsf,KAAKH,GAC1B9vB,EAAM8vB,EAAS9vB,IAAIiwB,KAAKH,GACxBzlB,EAAWylB,EAASzlB,SAAS4lB,KAAKH,GAExC,OAAOnf,EACL3Q,EACEA,EACEqK,EAASuM,EAAYpe,OAAQu3B,GAC7B1lB,EAASuM,EAAYxC,WAAY4b,IAEnCpZ,EAAY5J,OAKlB9T,oBACE,MAAM21B,WAAEA,EAAUlR,UAAEA,GAAcvkB,KAAKkc,QACvC,GAAIuZ,EAAa,EACf,MAAM,IAAIvzB,MAAM,kDAClB,GAAIqiB,EAAY,EACd,MAAM,IAAIriB,MAAM,iDAGlB,OAAO,IAAIytB,GAAa8F,EAAa,EAAGlR,EAAW,KAGrDzkB,uBACE,MAAM0kB,WAAEA,EAAUnH,aAAEA,GAAiBrd,KAAKkc,QACpC4a,EAAiBC,GAAK1Z,GAG5B,MAAO,CAEL8Y,gBAAiB,IAAIxG,GAAanL,EAAa,EAAGsS,EAAgB,KAGlExwB,OAAQ,IAAIsoB,GAAOpK,EAAa,EAAG,IAIvC1kB,eACE,MAAMs2B,MAAEA,GAAUp2B,MACZqd,aAAEA,GAAiBrd,KAAKkc,QACxBwa,EAAW,IAAIlC,GACfvP,EAAoB,GACpB+R,EACJZ,EAAMF,oBAAoBv0B,OAAS,EAC/Bo1B,GAAKX,EAAMF,qBACXl2B,KAAKi3B,mBAEX,IAAI3wB,EAAStG,KAAKk3B,YAChBR,EACAA,EAASS,iBAAiBf,EAAM/qB,OAChC2rB,EAAmB,GACnBZ,EAAM/Y,aAAa,IAErB4H,EAAQxhB,KAAK6C,GAEb,IAAK,IAAI5E,EAAI,EAAGpC,EAAM+d,EAAa1b,OAAQD,EAAIpC,EAAKoC,IAAK,CACvD,IAAKs1B,EAAmBt1B,GACtB,MAAM,IAAIQ,MAAM,iCAAiCR,GAEnD4E,EAAStG,KAAKk3B,YACZR,EACApwB,EACA0wB,EAAmBt1B,GACnB00B,EAAM/Y,aAAa3b,IAErBujB,EAAQxhB,KAAK6C,GAGf8vB,EAAMF,oBAAoBzyB,KAAKwhB,GAC/ByR,EAAS9vB,IACP8vB,EAASzlB,SAASmlB,EAAMD,gBAAiB7vB,GACzC8vB,EAAM9vB,QAER8vB,EAAMJ,UAAUvyB,KAAKizB,GAGvB52B,WACE,MAAMm2B,EAAwB,GAC9Bj2B,KAAKi3B,mBAAqBj3B,KAAKkc,QAAQmB,aAAaxY,IACjDzC,GAAS,IAAIwsB,GAAOxsB,EAAM,IAG7B,MAAMiJ,EAAQrL,KAAKo3B,oBACnBnB,EAAYxyB,KAAK4H,GAEjB,MAAMgS,EAAerd,KAAKq3B,qBAC1B,IAAKha,EAAa1b,OAAQ,MAAM,IAAIO,MAAM,4BAC1C,IAAK,IAAIR,EAAI,EAAGpC,EAAM+d,EAAa1b,OAAQD,EAAIpC,EAAKoC,IAAK,CACvD,MAAM41B,EAAqCja,EAAa3b,GACxD,IAAK,MAAM61B,KAAYD,EAChBA,EAAal0B,eAAem0B,IACjCtB,EAAYxyB,KAAK6zB,EAAaC,IAIlC,MAAMjxB,OAAEA,EAAM6vB,gBAAEA,GAAoBn2B,KAAKw3B,uBAIzC,OAHAvB,EAAYxyB,KAAK0yB,GACjBF,EAAYxyB,KAAK6C,GAEVjD,OAAOyyB,KAAK,CACjBC,eAAe,EACf1qB,MAAAA,EACAgS,aAAAA,EACA/W,OAAAA,EACA0vB,UAAW,GACXC,YAAAA,EACAC,oBAAqB,GACrBC,gBAAAA,IAIJr2B,WAAWuL,GACTrL,KAAKy3B,OACL,MAAMrB,MAAEA,GAAUp2B,KACZV,EAAM+L,EAAM1J,OAClB,IACI+0B,EADAgB,EAAU,EAEd,KAAOtB,EAAMJ,UAAUr0B,QAAU0J,EAAM1J,OAAS,GAE9C3B,KAAK23B,eAEP,IACE,IAAIC,GAAc,EAAGC,EAAWxsB,EAAM1J,OACtCi2B,EAAaC,EACbD,IACA,CAEA,MAAME,EAAgBF,EAAa,EACnClB,EAAWN,EAAMJ,UAAU8B,GAE3B,MAAMnN,GAAyB,IAAhBiN,EAAoB,EAAIvsB,EAAMusB,GAAc,EACrDxtB,EAASwtB,IAAet4B,EAAM,EAAI,EAAI+L,EAAMusB,EAAa,GAAK,EACpEF,GAAWhB,EAASqB,mBAAmBpN,EAAQvgB,GAEjD,OAAO/K,KAAK2pB,IAAI,EAAG0O,GAAWp4B,EAAM,IAAM,IAG5CQ,cAAcuL,GACZ,IAAI3J,EAAI2J,EAAM1J,OACd,MAAMy0B,MAAEA,GAAUp2B,MACZg2B,UAAEA,GAAcI,EACtB,KAAO10B,EAAI,GACTs0B,EAAUt0B,GAAGs2B,mBAAmB3sB,EAAM3J,EAAI,GAAK,GAC/CA,IAEFs0B,EAAU,GAAGgC,mBAAmB,GAGlCl4B,gBACE,MAAM41B,KAAEA,EAAIC,QAAEA,EAAO9nB,UAAEA,EAASE,UAAEA,GAAc/N,KAAKkc,SAC/Cxb,UAAEA,EAAS01B,MAAEA,EAAK6B,UAAEA,GAAcj4B,MAClCsI,aAAEA,GAAiB5H,GACnBu1B,YAAEA,GAAgBG,EACxB,IAAI8B,EAAa,EACbC,EAAS,EACb,IAAK,IAAIC,EAAc,EAAGA,EAAcnC,EAAYt0B,OAAQy2B,IAAe,CACzE,MAAMxyB,EAASqwB,EAAYmC,IACrBjxB,QAAEA,EAAOC,OAAEA,GAAWxB,EACtBwyB,KAAeH,IACnBA,EAAUG,GAAevvB,EAAMjD,EAAOipB,KAAOjpB,EAAOkpB,UAEtD,MAAMuJ,EAAQJ,EAAUG,GACxB,IAAK,IAAI12B,EAAI,EAAGA,EAAIyF,EAAQxF,OAAQD,IAAK,CACvC,IAAIiO,EAAIvI,EAAO1F,GACf,MAAM8zB,EAAIruB,EAAQzF,GAElB22B,EAAM32B,GAAK22B,EAAM32B,GAAKmM,GAAa,EAAIA,GAAa8B,EAAIA,EAEpDA,EAAIgmB,GACNhmB,EAAIgmB,EACJuC,KACSvoB,GAAKgmB,IACdhmB,GAAKgmB,EACLuC,KAEFC,IAEAhxB,EAAQzF,GACN8zB,GAAMltB,EAAeqH,EAAKtQ,KAAKyO,KAAKuqB,EAAM32B,GAAKqM,GAAa2nB,EAAOF,GAGzEx1B,KAAKs4B,aAAeJ,EAAaC,EAGnCrS,iBACE,OAAI9lB,KAAKo2B,OAAyC,IAAhCp2B,KAAKo2B,MAAMJ,UAAUr0B,SACrC+a,QAAQ/c,MAAM,6CACP,GAMXG,gBACE,IAAKE,KAAK8lB,WACR,MAAM,IAAI5jB,MAAM,wBAIpBpC,IAAIy4B,EAAkB,GAAIC,GAAY,EAAOC,EAAc,GACzD,MAAM7C,EACJ51B,KAAKkc,QAAQ0Z,qBACC,OAAb2C,EAAqBA,EAAoB52B,OAAS,IAClD3B,KAAKkc,QAAQuV,cACVzxB,KAAKkc,QAAQuV,cAAcQ,eAAetwB,OAC1C,GAEN3B,KAAK04B,gBAEL,MAAMrtB,EACJrL,KAAKkc,QAAQuV,eAAkB8G,EAAoB52B,OAAS,EACxD3B,KAAKkc,QAAQuV,cAAcc,aAAagG,GACvCA,GACDnC,MAAEA,GAAUp2B,KACZsG,EAAS,GACf,IAAI5E,EAAI,EACR,OAAa,CACX,MAAMi3B,EACE,IAANj3B,EAAU,EAAIA,EAAI2J,EAAM1J,OAAS0J,EAAM3J,EAAI,GAAK,EAAI4E,EAAO5E,EAAI,GACjE,KAAO00B,EAAMJ,UAAUr0B,QAAUD,GAC/B1B,KAAK23B,eAEP,MAEMiB,EAFWxC,EAAMJ,UAAUt0B,GAEHszB,SAAS2D,GACjC1D,EAAmB,IAAIrG,GAC3BwH,EAAM9vB,OAAOuoB,KACbuH,EAAM9vB,OAAOwoB,SAGf,GClbgC2D,EDibTmG,GCjbRpG,EDibVyC,GChbDpG,KAAO4D,EAAK5D,KACpB2D,EAAQ1D,QAAU2D,EAAK3D,QACvB0D,EAAQrrB,QAAUsrB,EAAKtrB,QAAQnE,MAAM,GACrCwvB,EAAQprB,OAASqrB,EAAKrrB,OAAOpE,MAAM,GD8aX,IAAhBy1B,GAAqBD,EAOvB,IAAK,IAAI52B,EAAI,EAAGtC,EAAM21B,EAAiB9tB,QAAQxF,OAAQC,EAAItC,EAAKsC,IAC9DqzB,EAAiB9tB,QAAQvF,IAAM62B,EAInC,MAAMI,EAAQxE,GAAQY,GAChB6D,EAAYN,EAAYjD,GAAQsD,GAASzD,GAAKyD,GAGpD,GADAn3B,IACkB,IAAdo3B,EAEF,MAEF,GAAIp3B,GAAKk0B,EAEP,MAGFtvB,EAAO7C,KAAKq1B,OC3cGtG,EAAiBC,EDydlC,OAAOzyB,KAAKkc,QAAQuV,cAAcsH,cAChC1tB,EACA/E,EAAOtD,MAAMqI,EAAM1J,QAAQkD,IAAKpF,GAAUA,EAAQ,IAStDK,sBACOE,KAAKo2B,MAAML,eACd/1B,KAAKsf,aAaTxf,sBAAsBoc,SACpBlc,KAAKU,UAAY,IAAKib,MAAkBO,GACxClc,KAAKumB,wBAAwBvmB,KAAKU,WAClCV,KAAKwmB,uBAAatK,EAAQrM,mBAAO7P,KAAKU,UAAUmP,KAKlD/P,wBAAwBoc,GACtB,MAAMG,EAAmD,CACvDnc,WAAY,KACV,MAAMsc,EAAMN,EAAQhc,WACpB,MAAsB,iBAARsc,GAAoBA,EAAM,GAE1CZ,YAAa,KACX,MAAMY,EAAMN,EAAQN,YACpB,MAAsB,iBAARY,GAAoBA,EAAM,GAAKA,EAAM,GAErD3M,IAAK,KACH,MAAM2M,EAAMN,EAAQrM,IACpB,MAAsB,mBAAR2M,GAAqC,kBAARA,GAE7CX,UAAW,KACT,MAAMW,EAAMN,EAAQL,UACpB,MAAsB,iBAARW,GAAoBA,EAAM,GAE1ClU,aAAc,KACZ,MAAMkU,EAAMN,EAAQ5T,aACpB,MAAsB,iBAARkU,GAAoBA,EAAM,GAAKA,EAAM,GAErDJ,SAAU,KACR,MAAMI,EAAMN,EAAQE,SACpB,MAAsB,mBAARI,QAA8BvY,IAARuY,GAEtCV,eAAgB,KACd,MAAMU,EAAMN,EAAQJ,eACpB,MAAsB,iBAARU,GAAoBA,EAAM,GAE1CR,QAAS,KACP,MAAMQ,EAAMN,EAAQF,QACpB,MAAsB,iBAARQ,GAAoBA,EAAM,IAG5C,IAAK,MAAMtR,KAAKmR,EAAa,CAC3B,MAAM3M,EAAKwM,EACX,IAAKG,EAAYnR,KACf,MAAM,IAAIhJ,MACR,IAAIgJ,MAAMwE,EAAExE,+EAMpBpL,aAAa+P,GAET7P,KAAKU,UAAUmP,IADE,mBAARA,EACYA,IACZA,GACY6M,QAAQ7M,IAMvB/P,aACRkC,EACAka,SAEAlc,KAAKglB,sBAAsB9I,GAC3B,MAAMqC,EAAeve,KAAKkc,QAAQuV,cAAcuH,OAAOh3B,GACjDyc,EAAU1d,KAAKC,iBAAShB,KAAKU,UAAUsb,uBAAW,GASxD,OAFAhc,KAAKof,sBAEE,CACLb,aAAAA,EACAC,OATa,CACb7e,MAAO,EACPO,WAAY,GAQZue,QAAAA,GAIJ3e,MACEkC,EACAtB,EAA0C,UAE1CV,KAAKU,UAAYA,EAAY,IACxBib,MACAjb,GAEL,MAAMR,WACJA,EAAU0b,YACVA,EAAWC,UACXA,EAASO,SACTA,EAAQN,eACRA,GACE9b,KAAKU,UACHmP,GAAwB,IAAlBnP,EAAUmP,IAAe6M,QAAQ7M,IAAMnP,EAAUmP,IAC7D,IACInO,EAEA0G,EAHAzI,EAAQgY,EAAAA,EAIZ,aAAI3X,KAAKkc,8BAASuV,cAChBrpB,EAASpI,KAAKkc,QAAQuV,cAAcuH,OAAOh3B,OACtC,CAAA,IACLoD,MAAMC,QAAQrD,KACdoD,MAAMC,QAAQrD,EAAK,KACmB,iBAA9BA,EAAoB,GAAG,GAI/B,MAAM,IAAIE,MAAM,iDAFhBkG,EAASpG,EAOX,IAFAhC,KAAKof,sBAEA1d,EAAI,EAAGA,EAAIxB,GAAcP,EAAQic,EAAala,IAAK,CACtD,IAAIsE,EAAM,EACV,IAAK,IAAIpE,EAAI,EAAGA,EAAIwG,EAAOzG,OAAQC,IAAK,CAEtCoE,GADYhG,KAAK0mB,aAAate,EAAOxG,IAAI,GAK3C,GAFAjC,EAAQqG,EAAMhE,EAAKL,OAEfkG,MAAMlI,GACR,MAAM,IAAIuC,MACR,gKAGA2N,GAAOnO,EAAIma,GAAc,GAC3BhM,EAAI,eAAenO,sBAAsB/B,KAEvCyc,GAAY1a,EAAIoa,GAAmB,GACrCM,EAAS,CAAEzc,MAAAA,EAAOO,WAAYwB,IAIlC,MAAO,CACL/B,MAAAA,EACAO,WAAYwB,GAIhB5B,YACE,MAAM,IAAIoC,MAAM,uBAGlBpC,SACOE,KAAKo2B,MAAML,eACd/1B,KAAKsf,aAEP,MAAM8W,MAAEA,EAAKla,QAAEA,GAAYlc,KAE3B,MAAO,CACL2I,KAAM3I,KAAK8H,YAAYC,KACvBmU,QAAS,IAAKA,EAASuV,cAAevV,EAAQuV,cAAcjwB,UAC5Dd,UAAW,IACNV,KAAKU,UACRsb,QACEhc,KAAKU,UAAUsb,UAAYrE,EAAAA,EACvB,WACA3X,KAAKU,UAAUsb,SAEvB3Q,MAAO+qB,EAAM/qB,MAAM7J,SACnB6b,aAAc+Y,EAAM/Y,aAAaxY,IAAK2Y,IACpC,MAAM7O,EAA2C,GACjD,IAAK,MAAMzD,KAAKsS,EACTA,EAAYpa,eAAe8H,KAChCyD,EAAOzD,GAAKsS,EAAYtS,GAAG1J,UAE7B,OAAOmN,IAETwnB,gBAAiBn2B,KAAKo2B,MAAMD,gBAAgB30B,SAC5C8E,OAAQtG,KAAKo2B,MAAM9vB,OAAO9E,UAI9B1B,SAAS4D,GACP,MAAMwY,QAAEA,GAAYxY,EACduyB,EAAc,GACd5qB,EAAQujB,GAAOjrB,SAASD,EAAK2H,OACnC4qB,EAAYxyB,KAAK4H,GACjB,MAAMgS,EAAuC,GAE7C3Z,EAAK2Z,aAAaf,QAASkB,IACzB,MAAM7O,EAAsC,GAC5C,IAAK,MAAMzD,KAAKsS,EACd7O,EAAOzD,GAAK0jB,GAAOjrB,SAAS6Z,EAAYtS,IACxC+qB,EAAYxyB,KAAKkL,EAAOzD,IAE1BmS,EAAa5Z,KAAKkL,KAGpB,MAAMwnB,EAAkBvH,GAAOjrB,SAASD,EAAKyyB,iBAC7CF,EAAYxyB,KAAK0yB,GACjB,MAAM7vB,EAASsoB,GAAOjrB,SAASD,EAAK4C,QA+BpC,OA9BA2vB,EAAYxyB,KAAK6C,GAEb4V,EAAQuV,cACVzxB,KAAKkc,QAAU,IACVjO,QACAiO,EACHuV,cAAe7B,GAAcjsB,SAASuY,EAAQuV,gBAGhDzxB,KAAKkc,QAAU,IACVjO,QACAiO,EACHuV,cAAe,IAAI7B,IAIvB5vB,KAAKo2B,MAAQ/yB,OAAOyyB,KAAK,CACvBC,eAAe,EACf1qB,MAAAA,EACAgS,aAAAA,EACA/W,OAAAA,EACA2vB,YAAAA,EACAE,gBAAAA,EACAH,UAAW,GACXE,oBAAqB,KAEvBl2B,KAAKi3B,mBAAqBj3B,KAAKkc,QAAQmB,aAAaxY,IACjDzC,GAAS,IAAIwsB,GAAOxsB,EAAM,IAE7BpC,KAAK23B,eACE33B,KAGTF,WAAW2O,GACT,MAAM2nB,MAAEA,GAAUp2B,MACZg2B,UAAEA,GAAch2B,KAAKo2B,MACrBM,EAAWV,EAAU,IACrBvB,OAAEA,GAAWiC,EACbuC,EAAa7G,KAAKC,UAAUryB,KAAKwB,UAEvC,SAAS03B,EAAwBC,GAC/B,MAAMC,EAAahD,EAAMF,oBAAoB,IACvCzB,OAAEA,GAAWuB,EAAU,GAC7B,IAAK,IAAIt0B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAC5C,GAAI+yB,EAAO/yB,GAAG8wB,UAAY2G,EACxB,OAAOz3B,EAGX,OAAO03B,EAAW3Y,QAAQ0Y,GAsB5B,SAASE,EAAeF,EAAWG,GACjC,IAAKH,IAAMA,EAAEtK,OAASsK,EAAErK,QAAS,MAAO,OAExC,GAAIqK,IAAM/C,EAAM/qB,MAAO,MAAO,aAC9B,GAAI8tB,IAAM/C,EAAMD,gBAAiB,MAAO,uBACxC,GAAIgD,IAAM/C,EAAM9vB,OAAQ,MAAO,cAE/B,IAAK,IAAI5E,EAAI,EAAGpC,EAAM82B,EAAM/Y,aAAa1b,OAAQD,EAAIpC,EAAKoC,IAAK,CAC7D,MAAM8b,EAAc4Y,EAAM/Y,aAAa3b,GACvC,IAAK,MAAMwJ,KAAKsS,EACd,GAAKA,EAAYpa,eAAe8H,IAC5BsS,EAAYtS,KAAOiuB,EACvB,MAAO,qBAAqBz3B,MAAMwJ,IAItC,OAnCF,SAAsBiuB,EAAWG,GAC/B,IAAK,IAAI53B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAAK,CACjD,MAAMqzB,EAAQN,EAAO/yB,GAErB,GAAIA,IAAM43B,EAAY,CACpB,MAAM13B,EAAIs3B,EAAwBC,GAClC,OAAIv3B,GAAK,IAAMu3B,IAAMpE,EAAMtC,MAAQ0G,IAAMpE,EAAMrC,OACtC,qBAAqB9wB,gCAAgCA,2BAA2Bu3B,EAAEtK,SAASsK,EAAErK,WAE/F,cAAcqK,EAAEtK,SAASsK,EAAErK,WAGpC,GAAIqK,IAAMpE,EAAMvC,QAAS,MAAO,UAAU9wB,aAC1C,GAAIy3B,IAAMpE,EAAMrC,MAAO,MAAO,UAAUhxB,WACxC,GAAIy3B,IAAMpE,EAAMtC,KAAM,MAAO,UAAU/wB,UAEzC,MAAO,GAmBA63B,CAAaJ,EAAGG,GAGzB,SAASE,EAAQC,GAGf,MAAMC,EAAUD,EAAShd,WAAWyU,MAAM,KAC1CwI,EAAQC,QAER,MACMC,EADeF,EAAQlP,KAAK,KACD0G,MAAM,KAGvC,OAFA0I,EAAYC,MAELD,EACJpP,KAAK,KACL0G,MAAM,MACN1G,KAAK,cACLsP,QAAQ,yBAA0B,IAClCA,QAAQ,8BAA+B,IACvCA,QAAQ,8BAA+B,IACvCA,QAAQ,gCAAiC,IACzCA,QAAQ,yCAA0C,IAGvD,SAASC,EAASC,GAChB,MAAO,wBAAwBA,EAAOF,QAAQ,UAAU,SAAUr6B,GAChE,MAAO,IAAIA,EAAMw6B,sBAIrB,MAAMC,EAAY,GACZC,EAAuD,GACvDC,EAAuB,GAC7B,IAAK,IAAI14B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAAK,CACjD,MAAMqzB,EAAQN,EAAO/yB,GACrBw4B,EAAUz2B,KAAK,UAAU/B,wBAChBqzB,EAAML,UAAU3sB,uBACjBgtB,EAAMtC,KAAO4G,EAAetE,EAAMtC,KAAM/wB,GAAK,8BAC5CqzB,EAAMrC,MAAQ2G,EAAetE,EAAMrC,MAAOhxB,GAAK,gCAC7C23B,EAAetE,EAAMvC,QAAS9wB,aAGzC,MAAMs4B,EAASjF,EAAML,UAAU3sB,KAC1BoyB,EAAkBH,KACrBG,EAAkBH,IAAU,EAC5BI,EAAqB32B,KACnB,iBAAiBu2B,uBAA4BD,EAASC,iBACpDR,EAAQzE,EAAML,UAAUjY,kCAMhC,MAAM4d,EAAM,iMAIDpB,SAEXj5B,KAAKkc,QAAQuV,cACNzxB,KAAKkc,QAAQuV,cAAc6I,mBAA9B,iEAEA,SAGJt6B,KAAKkc,QAAQuV,eACsC,mBAA5CzxB,KAAKkc,QAAQuV,cAAcc,aAC9B,mDAAmDiH,EACjDx5B,KAAKkc,QAAQuV,cAAcc,aAAa9V,qCAE1C,SAG2B,OAA/Bzc,KAAKkc,QAAQuV,eACuC,mBAA7CzxB,KAAKkc,QAAQuV,cAAcsH,cAC9B,iEAAiES,EAC/Dx5B,KAAKkc,QAAQuV,cAAcsH,cAActc,qCAE3C,wCAGFzc,KAAKkc,QAAQ0Z,qDAGb51B,KAAKkc,QAAQuV,cACTzxB,KAAKkc,QAAQuV,cAAcQ,eAAetwB,OAC1C,qBAGN3B,KAAKkc,QAAQuV,eACsC,mBAA5CzxB,KAAKkc,QAAQuV,cAAcc,aAC9B,yBACA,0VAgBF2H,EAAU1P,KAAK,wDAEf0P,EAAUv4B,yNAOdy4B,EAAqB5P,KAAK,+gBAyBxBxqB,KAAKkc,QAAQuV,eACuC,mBAA7CzxB,KAAKkc,QAAQuV,cAAcsH,cAC9B,qGACA,8NAOJlwB,EAAM4T,iBACN4X,GAAQ5X,WAAWqd,QAAQ,YAAa,gBACxCzqB,GAAYoN,iBACZ8Y,GAAQ9Y,iBACR2Y,GAAK3Y,aAEL,OAAO,IAAImO,SACT,WACA,YACA,cACAnc,EAAKA,EAAG4rB,GAAOA,GAInBv6B,aAAauL,EAAiBqU,GAC5B,MAAM/f,EAAQK,KAAKu6B,WAAWlvB,GAI9B,OAHArL,KAAKw6B,cAAcnvB,GACnBrL,KAAK4f,gBAEDF,EACK/f,EAEF,YAcKo3B,GAAQhlB,GACtB,OAAOA,EAAOA,EAAOpQ,OAAS,SE97BnB84B,WAAY5E,GACvB/1B,eAAe22B,EAAoBrR,GACjC,OAAOsV,GAAkBjE,EAAYrR,GAGvCtlB,YACE42B,EACAC,EACAC,EACApZ,GAEA,OAAOmd,GACLjE,EACAC,EACAC,EACApZ,aAKUkd,GACdjE,EACArR,GAEA,MAAO,CAGLwV,sBAAuB,IAAIjL,GAAa8G,EAAYrR,EAAU,KAC9DyV,uBAAwB,IAAIlL,GAAa8G,EAAYA,EAAY,KACjEvd,eAAgB,IAAI0V,GAAO6H,EAAY,GAGvCqE,qBAAsB,IAAInL,GAAa8G,EAAYrR,EAAU,KAC7D2V,sBAAuB,IAAIpL,GAAa8G,EAAYA,EAAY,KAChEnd,cAAe,IAAIsV,GAAO6H,EAAY,GAGtCuE,qBAAsB,IAAIrL,GAAa8G,EAAYrR,EAAU,KAC7D6V,sBAAuB,IAAItL,GAAa8G,EAAYA,EAAY,KAChEyE,cAAe,IAAItM,GAAO6H,EAAY,aAI1BkE,GACdjE,EACAC,EACAC,EACApZ,GAEA,KACGA,EAAYod,uBACZpd,EAAYqd,wBACZrd,EAAYtE,gBACZsE,EAAYsd,sBACZtd,EAAYud,uBACZvd,EAAYlE,eACZkE,EAAYwd,sBACZxd,EAAYyd,uBACZzd,EAAY0d,eAEb,MAAM,IAAIh5B,MAAM,iDAGlB,MAAMoP,EAAUolB,EAASplB,QAAQulB,KAAKH,GAChC9vB,EAAM8vB,EAAS9vB,IAAIiwB,KAAKH,GACxBzlB,EAAWylB,EAASzlB,SAAS4lB,KAAKH,GAClClhB,EAAkBkhB,EAASlhB,gBAAgBqhB,KAAKH,GAChD92B,EAAO82B,EAAS92B,KAAKi3B,KAAKH,GAC1B9D,EAAU8D,EAAS9D,QAAQiE,KAAKH,GAChC7D,EAAgB6D,EAAS7D,cAAcgE,KAAKH,GAG5Cvd,EAAa7H,EACjB1K,EACEA,EACEqK,EAASuM,EAAYod,sBAAuBjE,GAC5C1lB,EAASuM,EAAYqd,uBAAwBjE,IAE/CpZ,EAAYtE,iBAKVK,EAAYjI,EAChB1K,EACEA,EACEqK,EAASuM,EAAYsd,qBAAsBnE,GAC3C1lB,EAASuM,EAAYud,sBAAuBnE,IAE9CpZ,EAAYlE,gBAKVK,EAAO/Z,EACXgH,EACEA,EACEqK,EAASuM,EAAYwd,qBAAsBrE,GAC3C1lB,EACEuM,EAAYyd,sBACZzlB,EAAgB+D,EAAWqd,KAG/BpZ,EAAY0d,gBAMhB,OAAOt0B,EACL4O,EACE5O,EACEgsB,EAAQzZ,EAAW0V,KAAM1V,EAAW2V,SACpC+D,EAAc1Z,IAEhBQ,GAEFnE,EAAgBohB,EAAgBzd,UCtIvBgiB,GAIXr7B,YACEkC,EAIOwZ,GAAAxb,UAAAwb,EARTxb,YAAS,EACTA,WAAmC,GASjC,IAAK,IAAI0B,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MACM05B,EADQp5B,EAAKN,GACG8Z,GACtB,IAAK,IAAI5Z,EAAI,EAAGA,EAAIw5B,EAAQz5B,OAAQC,IAAK,CACvC,MAAMnC,EAAQ27B,EAAQx5B,GACtB,IAAK,MAAMsJ,KAAKzL,EACTA,EAAM2D,eAAe8H,KACtBlL,KAAK8K,MAAM1H,eAAe8H,KAC9BlL,KAAK8K,MAAMI,GAAKlL,KAAK2B,cCmFxB,MAAMsM,GAAW,KACf,IACFotB,KACH9W,UAAW,EACXlH,aAAc,CAAC,IACfmH,WAAY,EACZiR,WAAY,UAIH6F,WAAoBzF,GAqB/B/1B,YACEoc,EAA8D,IAE9D/S,QAvBFnJ,uBAAoB,EACpBA,iBAAkC,KAClCA,kBAAmC,KACnCA,wBAAqB,EAIrBA,WAA2BqD,OAAOyyB,KAAK,CACrCC,eAAe,EACf1Y,aAAc,GACd/W,OAAQ,IAAIsoB,GAAO,EAAG,GACtBoH,UAAW,GACXC,YAAa,GACbC,oBAAqB,GACrBC,gBAAiB,IAAIxG,GAAa,EAAG,EAAG,OAK1C3vB,aAA+BiO,KAK7BjO,KAAKkc,QAAU,IAAKlc,KAAKkc,WAAYA,GACrClc,KAAKglB,sBAAsB,IACtBrJ,MACAO,IAGDA,EAAQxY,MACV1D,KAAK2D,SAASuY,EAAQxY,MAI1B5D,oBACE,MAAM,IAAIoC,MAAM,8CAGlBpC,uBACE,MAAM0kB,WAAEA,GAAexkB,KAAKkc,QACtB4a,EAAiBC,GAAK/2B,KAAKkc,QAAQmB,cAGnC8Y,EAAkB,IAAIxG,GAAanL,EAAYsS,EAAgB,KAGrE,MAAO,CAAExwB,OADM,IAAIqpB,GAAanL,EAAY,EAAG,KAC9B2R,gBAAAA,GAGnBr2B,eACE,MAAMs2B,MAAEA,EAAKla,QAAEA,GAAYlc,MACrBqd,aAAEA,EAAYkH,UAAEA,GAAcrI,EAC9BvN,EAASynB,EAAM/Y,aACfqZ,EAAW,IAAIlC,GACfvP,EAAU,GACV+R,EACJZ,EAAMF,oBAAoBv0B,OAAS,EAC/By0B,EAAMF,oBAAoBE,EAAMF,oBAAoBv0B,OAAS,GAC7D3B,KAAKi3B,mBAEX,IAAI3wB,EAAStG,KAAKk3B,YAChBR,EACAA,EAASrrB,MAAM,IAAIujB,GAAOrK,EAAW,IACrCyS,EAAmB,GACnBroB,EAAO,IAETsW,EAAQxhB,KAAK6C,GAEb,IAAK,IAAI5E,EAAI,EAAGpC,EAAM+d,EAAa1b,OAAQD,EAAIpC,EAAKoC,IAClD4E,EAAStG,KAAKk3B,YACZR,EACApwB,EACA0wB,EAAmBt1B,GACnBiN,EAAOjN,IAETujB,EAAQxhB,KAAK6C,GAGf8vB,EAAMF,oBAAoBzyB,KAAKwhB,GAC/ByR,EAAS9vB,IACP8vB,EAASzlB,SAASmlB,EAAMD,gBAAiB7vB,GACzC8vB,EAAM9vB,QAER8vB,EAAMJ,UAAUvyB,KAAKizB,GAGvB52B,aACEE,KAAKo2B,MAAQp2B,KAAKq2B,WAKpBv2B,WACE,MAAMm2B,EAAwB,GAC9Bj2B,KAAKi3B,mBAAqBj3B,KAAKkc,QAAQmB,aAAaxY,IACjDzC,GAAS,IAAIwsB,GAAOxsB,EAAM,IAG7B,MAAMib,EAAerd,KAAKq3B,qBAC1B,IAAK,IAAI31B,EAAI,EAAGpC,EAAM+d,EAAa1b,OAAQD,EAAIpC,EAAKoC,IAAK,CACvD,MAAM41B,EAAeja,EAAa3b,GAClC,IAAK,MAAM61B,KAAYD,EAChBA,EAAal0B,eAAem0B,IACjCtB,EAAYxyB,KAAK6zB,EAAaC,IAIlC,MAAMpB,gBAAEA,EAAe7vB,OAAEA,GAAWtG,KAAKw3B,uBAIzC,OAFAvB,EAAYxyB,KAAK0yB,GACjBF,EAAYxyB,KAAK6C,GACVjD,OAAOyyB,KAAK,CACjBC,eAAe,EACf1Y,aAAAA,EACA/W,OAAAA,EACA0vB,UAAW,GACXC,YAAAA,EACAC,oBAAqB,GACrBC,gBAAAA,IAIJr2B,gBACE,IAAK,IAAI4B,EAAI1B,KAAKo2B,MAAMJ,UAAUr0B,OAAS,EAAGD,GAAK,EAAGA,IACpD1B,KAAKo2B,MAAMJ,UAAUt0B,GAAG84B,gBAM5B16B,IACEy4B,GAEA,MAAM5sB,EAAQnB,EAAO+wB,UAAUhD,GAAU/N,KAAK,KAC9C,OAAQ7e,GACN,IAAK,eAGH,OAAO3L,KAAKw7B,SAASjD,GACvB,IAAK,qBAGH,OAAOv4B,KAAKy7B,gBAAgBlD,GAC9B,IAAK,gBAGH,OAAOv4B,KAAK07B,UAAUnD,GACxB,IAAK,sBAGH,OAAOv4B,KAAK27B,iBAAiBpD,GAC/B,QACE,MAAM,IAAIr2B,MAAM,2BAA2ByJ,IAIjD7L,SACEy4B,EACArV,EAAQ,GAER,MAAMvX,EAAQnB,EAAO+wB,UAAUhD,GAAU/N,KAAK,KAC9C,OAAQ7e,GACN,IAAK,eAGH,OAAO3L,KAAK47B,cAAcrD,EAA0BrV,GACtD,IAAK,qBAGH,OAAOljB,KAAK67B,qBAAqBtD,EAA4BrV,GAC/D,IAAK,gBAGH,OAAOljB,KAAK07B,UAAUnD,GACxB,IAAK,sBAGH,OAAOv4B,KAAK87B,sBAAsBvD,EAA2BrV,GAC/D,QACE,MAAM,IAAIhhB,MAAM,2BAA2ByJ,IAIjD7L,cAAcuL,EAAqB6X,EAAQ,GACzCljB,KAAK04B,gBACL,MAAMtC,MAAEA,GAAUp2B,MACZg2B,UAAEA,GAAcI,EAChBz0B,EAAS0J,EAAM1J,OAASuhB,EAC9B,KAAO8S,EAAUr0B,QAAUA,GACzB3B,KAAK23B,eAEP,IAAIoE,EACAjE,EAAgB,EACpB,GAA+B,IAA3B93B,KAAKkc,QAAQqI,UACf,IAAK,IAAI7iB,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCq6B,EAAa/F,EAAU8B,KAAiB1Z,SACtCzY,aAAaiD,KAAK,CAACyC,EAAM3J,WAI7B,IAAK,IAAIA,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCq6B,EAAa/F,EAAU8B,KAAiB1Z,SAASzY,aAAaiD,KAAK,KAGvE,IAAKmzB,EACH,MAAM,IAAI75B,MAAM,sBAElB,MAAMgB,EAAS,CAAC64B,EAAW50B,QAAQ,IACnC,IAAK,IAAIzF,EAAI,EAAGpC,EAAM4jB,EAAQ,EAAGxhB,EAAIpC,EAAKoC,IACxCq6B,EAAa/F,EAAU8B,KAAiB1Z,SAAS2d,EAAW50B,SAC5DjE,EAAOO,KAAKs4B,EAAW50B,QAAQ,IAGjC,OADAnH,KAAK0uB,MACE/oB,aAAaiD,KAAK1F,GAG3BpD,qBAAqBuL,EAAuB6X,EAAQ,GAClDljB,KAAK04B,gBACL,MAAMtC,MAAEA,GAAUp2B,MACZg2B,UAAEA,GAAcI,EAChBz0B,EAAS0J,EAAM1J,OAASuhB,EAC9B,KAAO8S,EAAUr0B,QAAUA,GACzB3B,KAAK23B,eAEP,IAAIoE,EACAjE,EAAgB,EACpB,IAAK,IAAIp2B,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCq6B,EAAa/F,EAAU8B,KAAiB1Z,SAAS/S,EAAM3J,IAEzD,IAAKq6B,EACH,MAAM,IAAI75B,MAAM,sBAElB,MAAMgB,EAAS,CAACyC,aAAaiD,KAAKmzB,EAAW50B,UAC7C,IAAK,IAAIzF,EAAI,EAAGpC,EAAM4jB,EAAQ,EAAGxhB,EAAIpC,EAAKoC,IACxCq6B,EAAa/F,EAAU8B,KAAiB1Z,SAAS2d,EAAW50B,SAC5DjE,EAAOO,KAAKkC,aAAaiD,KAAKmzB,EAAW50B,QAAQnE,MAAM,KAGzD,OADAhD,KAAK0uB,MACExrB,EAGTpD,sBAAsBuL,EAAsB6X,EAAQ,GAClD,IAAKljB,KAAKke,YACR,MAAM,IAAIhc,MAAM,4BAElB,IAAKlC,KAAKqe,aACR,MAAM,IAAInc,MAAM,6BAElB,MAAMgd,EAAgB7T,EAAMxG,IAAKpF,GAC/B+K,EAAO/B,QACLzI,KAAKke,YACLze,EACAO,KAAKme,oBAGT,OAAOne,KAAK67B,qBAAqB3c,EAAegE,GAAOre,IAAKpF,GAC1D+K,EAAO8T,SAASte,KAAKqe,aAA6B5e,IAMtDK,MACEkC,EACAtB,EAA0C,IAE1CV,KAAKU,UAAYA,EAAY,IACxBs7B,MACAt7B,GAG0B,IAA3BV,KAAKkc,QAAQqI,WAA+C,IAA5BvkB,KAAKkc,QAAQsI,YAC/CxkB,KAAKi8B,QAAQj6B,GAEfhC,KAAKk8B,aAEL,MAAMhd,EAAgBlf,KAAKmf,WAAWnd,GACtC,IACIN,EADA/B,EAAQgY,EAAAA,EAGZ3X,KAAKof,sBACL,MAAMlf,WACJA,EAAU0b,YACVA,EAAWC,UACXA,EAASO,SACTA,EAAQN,eACRA,GACE9b,KAAKU,UACHmP,GAAwB,IAAlBnP,EAAUmP,IAAe6M,QAAQ7M,IAAMnP,EAAUmP,IAC7D,IAAKnO,EAAI,EAAGA,EAAIxB,GAAcP,EAAQic,EAAala,IAAK,CACtD,IAAIsE,EAAM,EACV,IAAK,IAAIpE,EAAI,EAAGA,EAAIsd,EAAcvd,OAAQC,IAAK,CAE7CoE,GADYhG,KAAK0mB,aAAaxH,EAActd,IAAI,GAKlD,GAFAjC,EAAQqG,EAAMkZ,EAAcvd,OAExBkG,MAAMlI,GACR,MAAM,IAAIuC,MACR,gKAEA2N,GAAOnO,EAAIma,GAAc,GAC3BhM,EAAI,eAAenO,sBAAsB/B,KAEvCyc,GAAY1a,EAAIoa,GAAmB,GACrCM,EAAS,CAAEzc,MAAAA,EAAOO,WAAYwB,IAIlC,MAAO,CACL/B,MAAAA,EACAO,WAAYwB,GAIhB5B,kBAAkBuL,GAChB,GAAIA,EAAM1J,OAAS,EACjB,MAAM,IAAIO,MAAM,uCAElB,MAAM8zB,UAAEA,GAAch2B,KAAKo2B,MAC3B,KAAOJ,EAAUr0B,OAAS0J,EAAM1J,QAC9B3B,KAAK23B,eAEP,IAAIhO,EAAW,EACf,IAAK,IAAIjoB,EAAI,EAAGpC,EAAM+L,EAAM1J,OAAS,EAAGD,EAAIpC,EAAKoC,IAC/CioB,GAAYqM,EAAUt0B,GAAGy6B,cAAc9wB,EAAM3J,GAAI2J,EAAM3J,EAAI,IAG7D,OADA1B,KAAK0uB,MACE/E,EAAWte,EAAM1J,OAK1B7B,aAAauL,EAAuBqU,GAClC,MAAM/f,EAAQK,KAAKo8B,kBAAkB/wB,GAIrC,OAHArL,KAAKw6B,gBACLx6B,KAAK4f,gBAEDF,EACK/f,EAEF,EAGTG,QAAQkC,GACN,IAAII,EAAO,EAEX,OADkBoI,EAAO+wB,UAAUv5B,GAAMwoB,KAAK,MAE5C,IAAK,qBACL,IAAK,sBACL,IAAK,2BACL,IAAK,4BACHpoB,EAAO,EAEP,MACF,IAAK,2BACHA,EAAQJ,EAAsB,GAAG,GAAGL,OACpC,MACF,IAAK,4BAEHS,EAAOiB,OAAOkI,KAAKf,EAAO6xB,UAAUr6B,IAA0BL,OAC9D,MACF,IAAK,iCACHS,EAASJ,EAEL,GAAGqJ,MAAM,GAAG1J,OAChB,MACF,IAAK,kCACHS,EAAOiB,OAAOkI,KACZf,EAAO8xB,eACLt6B,IAEFL,OACF,MACF,QACE,MAAM,IAAIO,MAAM,uCAEpBlC,KAAKkc,QAAU7Y,OAAOyyB,KAAK,IACtB91B,KAAKkc,QACRqI,UAAWniB,EACXoiB,WAAYpiB,IAIhBtC,aACE,IAAIE,KAAKkc,QAAQqI,WAAavkB,KAAKkc,QAAQsI,aACrCxkB,KAAKkc,QAAQqI,YAAcvkB,KAAKkc,QAAQsI,WAC1C,MAAM,IAAItiB,MAAM,kDAKtBpC,SAASuL,GACPrL,KAAK04B,gBACL,MAAM1C,UAAEA,GAAch2B,KAAKo2B,MAC3B,KAAOJ,EAAUr0B,QAAU0J,EAAM1J,QAC/B3B,KAAK23B,eAEP,IAAIoE,EACJ,IAAK,IAAIr6B,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAChCq6B,EAAa/F,EAAUt0B,GAAG0c,SAAS,IAAIzY,aAAa,CAAC0F,EAAM3J,MAG7D,OADA1B,KAAK0uB,MACGqN,EAAsB50B,QAAQ,GAGxCrH,gBAAgBuL,GACdrL,KAAK04B,gBACL,MAAMtC,MAAEA,GAAUp2B,MACZg2B,UAAEA,GAAcI,EACtB,KAAOJ,EAAUr0B,QAAU0J,EAAM1J,QAC/B3B,KAAK23B,eAEP,IAAIoE,EACJ,IAAK,IAAIr6B,EAAI,EAAGA,EAAI2J,EAAM1J,OAAQD,IAAK,CAErCq6B,EADqB/F,EAAUt0B,GAAG0c,SAAS/S,EAAM3J,IACvByF,QAG5B,OADAnH,KAAK0uB,MACEqN,MAAAA,EAAAA,EAAcp2B,aAAaiD,KAAK,IAGzC9I,UAAUuL,GACR,IAAKrL,KAAKke,YACR,MAAM,IAAIhc,MAAM,4BAElB,IAAKlC,KAAKqe,aACR,MAAM,IAAInc,MAAM,6BAElB,IAAKlC,KAAKmgB,mBACR,MAAM,IAAIje,MAAM,mCAElB,GAAIlC,KAAKke,cAAgBle,KAAKqe,aAAc,CAC1C,MAAMke,EAAa/xB,EAAOgyB,aAAax8B,KAAKke,YAAa7S,GACzD,OAAOb,EAAOiyB,gBACZz8B,KAAKqe,aACLre,KAAK47B,cACHW,EACAv8B,KAAKmgB,mBAAqBoc,EAAW56B,QAEvC46B,EAAW56B,QAGf,OAAO6I,EAAO8T,SACZte,KAAKqe,aACLre,KAAK47B,cACHpxB,EAAO/B,QAAQzI,KAAKke,YAAa7S,EAAOrL,KAAKme,mBAC7Cne,KAAKmgB,qBAKXrgB,iBAAiBuL,GACf,GAAyB,OAArBrL,KAAKke,YACP,MAAM,IAAIhc,MAAM,4BAElB,GAA0B,OAAtBlC,KAAKqe,aACP,MAAM,IAAInc,MAAM,6BAElB,MAAM6jB,EAAiB1a,EAAMxG,IAAKpF,GAChC+K,EAAO/B,QACLzI,KAAKke,YACLze,EACAO,KAAKme,oBAGT,OAAOne,KAAK67B,qBAAqB9V,EAAgB,GAAGlhB,IAAKpF,GACvD+K,EAAO8T,SAASte,KAAKqe,aAA6B5e,IAClD,GAGJK,wBAAwBuL,GACtB,IAAKrL,KAAKke,YACR,MAAM,IAAIhc,MAAM,4BAElB,IAAKlC,KAAKqe,aACR,MAAM,IAAInc,MAAM,6BAElB,OAAOsI,EAAO8T,SACZte,KAAKqe,aACLre,KAAKy7B,gBACHjxB,EAAOkyB,SAAS18B,KAAKke,YAAa7S,EAAOrL,KAAKme,qBAKpDre,MACEE,KAAKo2B,MAAMJ,UAAUh2B,KAAKo2B,MAAMJ,UAAUr0B,OAAS,GAAGyc,SACpD,IAAIzY,aAAa3F,KAAKkc,QAAQsI,aAIlC1kB,0BACE,GAA+B,IAA3BE,KAAKkc,QAAQqI,UACf,MAAM,IAAIriB,MAAM,0CAElB,GAAgC,IAA5BlC,KAAKkc,QAAQsI,WACf,MAAM,IAAItiB,MAAM,2CAKpBpC,YAAYkC,GACV,MAAMkB,EAAS,GACflD,KAAK28B,0BACL,IAAK,IAAIj7B,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAKkC,aAAaiD,KAAK,CAAC5G,EAAKN,MAEtC,MAAO,CAACwB,GAIVpD,mBAAmBkC,GACjB,MAAMkB,EAAS,IACTqhB,UAAEA,EAASC,WAAEA,GAAexkB,KAAKkc,QACvC,GAAkB,IAAdqI,GAAkC,IAAfC,EAAkB,CACvC,IAAK,IAAI9iB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK+f,GAAqBxhB,EAAKN,KAExC,OAAOwB,EAET,GAAIqhB,IAAcviB,EAAK,GAAGL,OACxB,MAAM,IAAIO,MAAM,wCAElB,GAAIsiB,IAAexiB,EAAK,GAAGL,OACzB,MAAM,IAAIO,MAAM,0CAElB,IAAK,IAAIR,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAKkC,aAAaiD,KAAK5G,EAAKN,KAErC,MAAO,CAACwB,GAIVpD,oBAAoBkC,GAElB,GADAhC,KAAK28B,2BACA38B,KAAKke,YAAa,CACrB,MAAM8B,EAAc,IAAIzE,GAAYvZ,GACpChC,KAAKke,YAAcle,KAAKqe,aAAe2B,EAAYlV,MACnD9K,KAAKme,kBAAoBne,KAAKmgB,mBAAqBH,EAAYre,OAEjE,MAAMuB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAKugB,GAAsBhiB,EAAKN,KAEzC,OAAOwB,EAITpD,yBAAyBkC,GACvB,IAAKhC,KAAKke,YAAa,CACrB,MAAM8B,EAAc,IAAIzE,GAAYvZ,GACpChC,KAAKke,YAAcle,KAAKqe,aAAe2B,EAAYlV,MACnD9K,KAAKme,kBAAoBne,KAAKmgB,mBAAqBH,EAAYre,OAEjE,MAAMuB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK,CACVygB,GAAqBliB,EAAKN,GAAI1B,KAAKke,YAAale,KAAKme,qBAGzD,OAAOjb,EAITpD,0BAA0BkC,GACxB,MAAMkB,EAAS,GACflD,KAAK28B,0BACL,IAAK,IAAIj7B,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMmwB,EAAQ7vB,EAAKN,GACnBwB,EAAOO,KACLggB,GACEoO,EAAMxmB,MACNwmB,EAAMvrB,SAIZ,OAAOpD,EAITpD,2BAA2BkC,GAEzB,GADAhC,KAAK28B,2BACA38B,KAAKke,YAAa,CACrB,MAAMA,EAAc,IAAI3C,GAAYvZ,EAAM,SAC1ChC,KAAKke,YAAcA,EAAYpT,MAC/B9K,KAAKme,kBAAoBD,EAAYvc,OAEvC,IAAK3B,KAAKqe,aAAc,CACtB,MAAMA,EAAe,IAAI9C,GAAYvZ,EAAM,UAC3ChC,KAAKqe,aAAeA,EAAavT,MACjC9K,KAAKmgB,mBAAqB9B,EAAa1c,OAEzC,MAAMuB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMmwB,EAAQ7vB,EAAKN,GACnBwB,EAAOO,KACLwgB,GACE4N,EAAMxmB,MACNwmB,EAAMvrB,SAIZ,OAAOpD,EAITpD,0BAA0BkC,GACxB,MAAMkB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAC/BwB,EAAOO,KAAK4f,GAAsBrhB,EAAKN,KAEzC,OAAOwB,EAITpD,2BAA2BkC,GACzB,IAAKhC,KAAKke,YAAa,CACrB,MAAM8B,EAAc,IAAIzE,GAAYvZ,GACpChC,KAAKke,YAAcle,KAAKqe,aAAe2B,EAAYlV,MACnD9K,KAAKme,kBAAoBne,KAAKmgB,mBAAqBH,EAAYre,OAEjE,MAAMuB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMD,EAAQ,GACd,IAAK,IAAIG,EAAI,EAAGA,EAAII,EAAKN,GAAGC,OAAQC,IAClCH,EAAMgC,KACJygB,GACEliB,EAAKN,GAAGE,GACR5B,KAAKke,YACLle,KAAKme,oBAIXjb,EAAOO,KAAKhC,GAEd,OAAOyB,EAITpD,iCAAiCkC,GAC/B,MAAMkB,EAAS,IACTqhB,UAAEA,EAASC,WAAEA,GAAexkB,KAAKkc,QACvC,GAAIqI,IAAeviB,EAAK,GAAGqJ,MAA2B,GAAG1J,OACvD,MAAM,IAAIO,MAAM,wCAElB,GAAIsiB,IAAgBxiB,EAAK,GAAGsE,OAA4B,GAAG3E,OACzD,MAAM,IAAIO,MAAM,0CAElB,IAAK,IAAIR,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMmwB,EAAQ7vB,EAAKN,GACnBwB,EAAOO,KACL8f,GACEsO,EAAMxmB,MACNwmB,EAAMvrB,SAIZ,OAAOpD,EAITpD,kCACEkC,GAKA,IAAKhC,KAAKke,YAAa,CACrB,MAAMA,EAAc,IAAIid,GAAiBn5B,EAAM,SAC/ChC,KAAKke,YAAcA,EAAYpT,MAC/B9K,KAAKme,kBAAoBD,EAAYvc,OAEvC,IAAK3B,KAAKqe,aAAc,CACtB,MAAMA,EAAe,IAAI8c,GAAiBn5B,EAAM,UAChDhC,KAAKqe,aAAeA,EAAavT,MACjC9K,KAAKmgB,mBAAqB9B,EAAa1c,OAEzC,IAAK3B,KAAKmgB,mBACR,MAAM,IAAIje,MAAM,oDAElB,MAAMgB,EAAS,GACf,IAAK,IAAIxB,EAAI,EAAGA,EAAIM,EAAKL,OAAQD,IAAK,CACpC,MAAMmwB,EAAQ7vB,EAAKN,GACnBwB,EAAOO,KACLkgB,GACEkO,EAAMxmB,MACNwmB,EAAMvrB,OACNtG,KAAKke,YACLle,KAAKqe,aACLre,KAAKme,kBACLne,KAAKmgB,qBAIX,OAAOjd,EAGTpD,WAAWkC,GAET,OADkBwI,EAAO+wB,UAAUv5B,GAAMwoB,KAAK,MAE5C,IAAK,eACH,OAAOxqB,KAAK48B,YAAY56B,GAC1B,IAAK,qBACH,OAAOhC,KAAK68B,mBAAmB76B,GACjC,IAAK,sBACH,OAA+B,IAA3BhC,KAAKkc,QAAQqI,UACRvkB,KAAK88B,oBAAoB96B,GAEzBhC,KAAK+8B,yBAAyB/6B,GAEzC,IAAK,2BACH,OAAOhC,KAAKg9B,0BAA0Bh7B,GACxC,IAAK,4BACH,OAAOhC,KAAKi9B,2BAA2Bj7B,GACzC,IAAK,2BACH,OAAOhC,KAAKk9B,0BAA0Bl7B,GACxC,IAAK,4BACH,OAAOhC,KAAKm9B,2BAA2Bn7B,GACzC,IAAK,iCACH,OAAOhC,KAAKo9B,iCAAiCp7B,GAC/C,IAAK,kCACH,OAAOhC,KAAKq9B,kCACVr7B,GAKJ,QACE,MAAM,IAAIE,MAAM,wCAItBpC,KAAKkC,GAEH,MAAM0nB,EAAa,GAGnB,IAAIC,EAAW,EACf,MAAMzK,EAAgBlf,KAAKmf,WAAWnd,GACtC,IAAK,IAAIN,EAAI,EAAGA,EAAIwd,EAAcvd,OAAQD,IAAK,CAC7C,MAAM2J,EAAQ6T,EAAcxd,GACtB4E,EAAStG,KAAKwI,IAAI6C,EAAMpI,OAAO,EAAGoI,EAAM1J,OAAS,IACjDyI,EAASiB,EAAMA,EAAM1J,OAAS,GACpC,IAAIoE,EAAS,EACTu3B,EAAa,EACjB,IAAK,IAAI17B,EAAI,EAAGA,EAAI0E,EAAO3E,OAAQC,IAAK,CACtC07B,IACA,MAAM39B,EAAQyK,EAAOxI,GAAK0E,EAAO1E,GAEjCmE,GAAUpG,EAAQA,EAEpBgqB,GAAY5jB,EAASu3B,EAErB,GADkBj+B,KAAKsH,IAAIZ,GACX/F,KAAKU,UAAUkb,YAAa,CAC1C,MAAMkO,EAAY9nB,EAAsBN,GACxCgoB,EAAWjmB,KAAK,CACdhE,MAAOqqB,EACPF,OAAQtjB,KAId,MAAO,CACL3G,MAAOgqB,EAAWzK,EAAcvd,OAChC+nB,WAAAA,EACAppB,MAAO4e,EAAcvd,QAMzB7B,UAAUL,mBAER,OADkB+K,EAAO+wB,UAAU97B,GAAO+qB,KAAK,MAE7C,IAAK,qBACL,IAAK,2BACL,IAAK,eACL,IAAK,qBACH,OACF,IAAK,sBACHxqB,KAAKke,YAAc1T,EAAOif,QACvBhqB,EAAyB4L,gBAC1BrL,KAAKke,2BAAe,IAElBle,KAAKke,cACPle,KAAKme,kBAAoB9a,OAAOkI,KAAKvL,KAAKke,aAAavc,QAEzD3B,KAAKqe,aAAe7T,EAAOif,QACxBhqB,EAAyB6G,iBAC1BtG,KAAKqe,4BAAgB,IAEnBre,KAAKqe,eACPre,KAAKmgB,mBAAqB9c,OAAOkI,KAAKvL,KAAKqe,cAAc1c,QAE3D,MAEF,IAAK,gBACH3B,KAAKke,YAAcle,KAAKqe,aAAe7T,EAAOif,QAC5ChqB,YACAO,KAAKke,2BAAe,IAElBle,KAAKke,cACPle,KAAKme,kBAAoBne,KAAKmgB,mBAAqB9c,OAAOkI,KACxDvL,KAAKke,aACLvc,QAEJ,MAEF,IAAK,sBAAuB,CAC1B,MAAM47B,EAAa99B,EACnB,IAAK,IAAIiC,EAAI,EAAGA,EAAI67B,EAAW57B,OAAQD,IACrC1B,KAAKke,YAAcle,KAAKqe,aAAe7T,EAAOif,QAC5C8T,EAAW77B,aACX1B,KAAKke,2BAAe,IAElBle,KAAKke,cACPle,KAAKme,kBAAoBne,KAAKmgB,mBAAqB9c,OAAOkI,KACxDvL,KAAKke,aACLvc,QAGN,MAEF,IAAK,4BAA6B,CAChC,MAAM47B,EAAa99B,EACb+9B,EAAaD,EAAWlyB,MAC9B,IAAK,IAAI3J,EAAI,EAAGA,EAAI87B,EAAW77B,OAAQD,IACrC1B,KAAKke,YAAc1T,EAAOif,QACxB+T,EAAW97B,aACX1B,KAAKke,2BAAe,IAElBle,KAAKke,cACPle,KAAKme,kBAAoB9a,OAAOkI,KAAKvL,KAAKke,aAAavc,QAG3D,MAAM87B,EAAcF,EAAWj3B,OAC/B,IAAK,IAAI5E,EAAI,EAAGA,EAAI+7B,EAAY97B,OAAQD,IACtC1B,KAAKqe,aAAe7T,EAAOif,QACzBgU,EAAY/7B,aACZ1B,KAAKqe,4BAAgB,IAEnBre,KAAKqe,eACPre,KAAKmgB,mBAAqB9c,OAAOkI,KAAKvL,KAAKqe,cAAc1c,QAG7D,MAGF,QACE,MAAM,IAAIO,MAAM,wCAMtBpC,SACOE,KAAKo2B,OACRp2B,KAAKsf,aAEP,MAAM8W,MAAEA,GAAUp2B,KACZkc,EAAU,IAAKlc,KAAKkc,WAAYmf,IAEtC,MAAO,CACL1yB,KAAM3I,KAAK8H,YAAYC,KACvBmU,QAAAA,EACAmB,aAAc+Y,EAAM/Y,aAAaxY,IAAK2Y,IACpC,MAAM7O,EAA2C,GACjD,IAAK,MAAMzD,KAAKsS,EACTA,EAAYpa,eAAe8H,KAChCyD,EAAOzD,GAAKsS,EAAYtS,GAAG1J,UAE7B,OAAOmN,IAETwnB,gBAAiBC,EAAMD,gBAAgB30B,SACvC8E,OAAQ8vB,EAAM9vB,OAAO9E,SACrB0c,YAAale,KAAKke,YAClBC,kBAAmBne,KAAKme,kBACxBE,aAAcre,KAAKqe,aACnB8B,mBAAoBngB,KAAKmgB,oBAM7BrgB,SAAS4D,GACP,MAAMwY,QAAEA,GAAYxY,EACduyB,EAAc,GACd5Y,EAAuC,GAG7C3Z,EAAK2Z,aAAaf,QAASkB,IACzB,MAAM7O,EAAsC,GAC5C,IAAK,MAAMzD,KAAKsS,EACd7O,EAAOzD,GAAK0jB,GAAOjrB,SAAS6Z,EAAYtS,IACxC+qB,EAAYxyB,KAAKkL,EAAOzD,IAE1BmS,EAAa5Z,KAAKkL,KAGpB,MAAMwnB,EAAkBvH,GAAOjrB,SAASD,EAAKyyB,iBAC7CF,EAAYxyB,KAAK0yB,GACjB,MAAM7vB,EAASsoB,GAAOjrB,SAASD,EAAK4C,QAwBpC,OAvBA2vB,EAAYxyB,KAAK6C,GAIjBtG,KAAKkc,QAAU,IAAKjO,QAAeiO,GACnClc,KAAKke,YAAcxa,EAAKwa,YACxBle,KAAKme,kBAAoBza,EAAKya,kBAC9Bne,KAAKqe,aAAe3a,EAAK2a,aACzBre,KAAKmgB,mBAAqBzc,EAAKyc,mBAE/BngB,KAAKo2B,MAAQ/yB,OAAOyyB,KAAK,CACvBC,eAAe,EACf1Y,aAAAA,EACA/W,OAAAA,EACA2vB,YAAAA,EACAE,gBAAAA,EACAH,UAAW,GACXE,oBAAqB,KAEvBl2B,KAAKi3B,mBAAqB/a,EAAQmB,aAAaxY,IAC5CzC,GAAS,IAAIwsB,GAAOxsB,EAAM,IAE7BpC,KAAK23B,eACE33B,KAKTF,WAAW2O,GACT,MAAM2nB,MACJA,EAAKlY,YACLA,EAAWC,kBACXA,EAAiBE,aACjBA,EAAY8B,mBACZA,GACEngB,MACEukB,UAAEA,GAAcvkB,KAAKkc,SACrB8Z,UAAEA,GAAcI,EAChBM,EAAWV,EAAU,IACrBvB,OAAEA,GAAWiC,EACbuC,EAAa7G,KAAKC,UAAUryB,KAAKwB,UAEvC,SAAS03B,EAAwBC,GAC/B,MAAMC,EAAahD,EAAMF,oBAAoB,IACvCzB,OAAEA,GAAWuB,EAAU,GAC7B,IAAK,IAAIt0B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAC5C,GAAI+yB,EAAO/yB,GAAG8wB,UAAY2G,EACxB,OAAOz3B,EAGX,OAAO03B,EAAW3Y,QAAQ0Y,GAkC5B,SAASE,EAAeF,EAAWG,GACjC,IAAKH,IAAMA,EAAEtK,OAASsK,EAAErK,QAAS,MAAO,OACxC,GAAIqK,IAAM/C,EAAMD,gBAAiB,MAAO,uBACxC,GAAIgD,IAAM/C,EAAM9vB,OAAQ,MAAO,cAE/B,IAAK,IAAI5E,EAAI,EAAGpC,EAAM82B,EAAM/Y,aAAa1b,OAAQD,EAAIpC,EAAKoC,IAAK,CAC7D,MAAM8b,EAAc4Y,EAAM/Y,aAAa3b,GACvC,IAAK,MAAMwJ,KAAKsS,EACd,GAAKA,EAAYpa,eAAe8H,IAC5BsS,EAAYtS,KAAOiuB,EACvB,MAAO,qBAAqBz3B,MAAMwJ,IAItC,OA7CF,SAAsBiuB,EAAWG,GAC/B,IAAK,IAAI53B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAAK,CACjD,MAAMqzB,EAAQN,EAAO/yB,GAErB,GAAIA,IAAM43B,EAAY,CACpB,MAAM13B,EAAIs3B,EAAwBC,GAClC,OAAQA,GACN,KAAKpE,EAAMtC,KACT,GAAI7wB,GAAK,EACP,MAAO,qBAAqBA,gCAAgCA,2BAA2Bu3B,EAAEtK,SAASsK,EAAErK,WAGxG,KAAKiG,EAAMrC,MACT,GAAI9wB,GAAK,EACP,MAAO,qBAAqBA,gCAAgCA,2BAA2Bu3B,EAAEtK,SAASsK,EAAErK,WAGxG,KAAKiG,EAAMvC,QACT,MAAO,cAAc2G,EAAEtK,SAASsK,EAAErK,WACpC,QACE,MAAM5sB,MAAM,kBAIlB,GAAIi3B,IAAMpE,EAAMvC,QAAS,MAAO,UAAU9wB,aAC1C,GAAIy3B,IAAMpE,EAAMrC,MAAO,MAAO,UAAUhxB,WACxC,GAAIy3B,IAAMpE,EAAMtC,KAAM,MAAO,UAAU/wB,UAEzC,MAAO,GAiBA63B,CAAaJ,EAAGG,GA4EzB,SAASE,EAAQC,GAKf,MAAMC,EAAUD,EAAShd,WAAWyU,MAAM,KAC1CwI,EAAQC,QAER,MACMC,EADeF,EAAQlP,KAAK,KACD0G,MAAM,KAGvC,OAFA0I,EAAYC,MAELD,EACJpP,KAAK,KACL0G,MAAM,MACN1G,KAAK,cACLsP,QAAQ,yBAA0B,IAClCA,QAAQ,8BAA+B,IACvCA,QAAQ,8BAA+B,IACvCA,QAAQ,gCAAiC,IACzCA,QAAQ,yCAA0C,IAGvD,SAASC,EAASC,GAChB,MAAO,wBAAwBA,EAAOF,QAAQ,UAAU,SAAUr6B,GAChE,MAAO,IAAIA,EAAMw6B,sBAIrB,MAAMC,EAAY,GACZC,EAAuD,GACvDC,EAAuB,GAC7B,IAAK,IAAI14B,EAAI,EAAGpC,EAAMm1B,EAAO9yB,OAAQD,EAAIpC,EAAKoC,IAAK,CACjD,MAAMqzB,EAAQN,EAAO/yB,GACrBw4B,EAAUz2B,KAAK,UAAU/B,wBAChBqzB,EAAML,UAAU3sB,uBACjBgtB,EAAMtC,KAAO4G,EAAetE,EAAMtC,KAAM/wB,GAAK,8BAC5CqzB,EAAMrC,MAAQ2G,EAAetE,EAAMrC,MAAOhxB,GAAK,gCAC7C23B,EAAetE,EAAMvC,QAAS9wB,aAGzC,MAAMs4B,EAASjF,EAAML,UAAU3sB,KAC1BoyB,EAAkBH,KACrBG,EAAkBH,IAAU,EACT,UAAfjF,EAAMhtB,MACRqyB,EAAqB32B,KAAK,SAASu2B,OACnCI,EAAqB32B,KACnBya,GAA6B,IAAdqG,EACX,sGACc,IAAdA,EACA,iCACA,gCAEN6V,EAAqB32B,KAAK,WAE1B22B,EAAqB32B,KACnB,iBAAiBu2B,MACJ,cAAXA,EACI,oBAAoBD,EAASC,GAC7B,iBAENR,EAAQzE,EAAML,UAAUjY,kCAOhC,MAAMihB,EAA8B,IAAdnZ,GAAmBvkB,KAAKqe,aACxCgc,EAAM,mBACAr6B,KAAKke,YAAc,wBAA0B,6BAC9C+a,4FAMXyE,EACIxf,IAAgBG,EACdF,EACA,mBAAkBgC,EAAqB,GACzC,0GAKF+Z,EAAU1P,KAAK,wDAEf0P,EAAUv4B,uNAQdy4B,EAAqB5P,KAAK,8BAIR,IAAdjG,GAAmBrG,EACf,sEACA,6CAING,EACIA,IAAiBH,EACf,4CACA,8BACY,IAAdqG,EACA,mBACA,uBAxLGrG,EACa,IAAdqG,EACErG,IAAgBG,EACX,0DACS+T,KAAKC,UAAUnU,+OAS1B,wDACSkU,KAAKC,UAAUnU,+KAQ1B,0DACSkU,KAAKC,UAAUnU,uKAIIC,6MA3BV,SAsCpBE,EACa,IAAdkG,EACErG,IAAgBG,EACX,0EACS+T,KAAKC,UAAUhU,oSAW1B,0DACS+T,KAAKC,UAAUhU,oKAQ1B,wDACS+T,KAAKC,UAAUhU,qJAzBL,mJA4J5BxV,EAAM4T,iBACN4X,GAAQ5X,WAAWqd,QAAQ,aAAc,gBACzCzqB,GAAYoN,iBACZ8Y,GAAQ9Y,iBACR2Y,GAAK3Y,aAEL,OAAO,IAAImO,SAAS,WAAYnc,EAAKA,EAAG4rB,GAAOA,IAY5C,MAAM1e,GAAgB,IAAKqgB,UC5yCrB2B,WAAoBrC,GAC/Bx7B,eAAe22B,EAAoBrR,GACjC,OAAOsV,GAAkBjE,EAAYrR,GAGvCtlB,YACE42B,EACAC,EACAC,EACApZ,GAEA,OAAOmd,GACLjE,EACAC,EACAC,EACApZ,UCDOogB,WAAa/H,GACxB/1B,eAAe22B,EAAoBrR,GACjC,OAAOyY,GAAmBpH,EAAYrR,GAGxCtlB,YACE42B,EACAC,EACAC,EACApZ,GAEA,OAAOsgB,GACLpH,EACAC,EACAC,EACApZ,aAKUqgB,GACdpH,EACArR,GAEA,MAAO,CAGLuR,YAAa,IAAIhH,GAAa8G,EAAYrR,EAAU,KACpD2Y,YAAa,IAAIpO,GAAa8G,EAAYA,EAAY,KACtDuH,UAAW,IAAIpP,GAAO6H,EAAY,GAElCwH,aAAc,IAAItO,GAAa8G,EAAYrR,EAAU,KACrD8Y,aAAc,IAAIvO,GAAa8G,EAAYA,EAAY,KACvD0H,WAAY,IAAIvP,GAAO6H,EAAY,GAEnCmC,aAAc,IAAIjJ,GAAa8G,EAAYrR,EAAU,KACrDgZ,aAAc,IAAIzO,GAAa8G,EAAYA,EAAY,KACvD4H,WAAY,IAAIzP,GAAO6H,EAAY,GAGnC6H,qBAAsB,IAAI3O,GAAa8G,EAAYrR,EAAU,KAC7DmZ,qBAAsB,IAAI5O,GAAa8G,EAAYA,EAAY,KAC/D+H,mBAAoB,IAAI5P,GAAO6H,EAAY,aAI/BqH,GACdpH,EACAC,EACAC,EACApZ,GAEA,KACGA,EAAYmZ,aACZnZ,EAAYugB,aACZvgB,EAAYwgB,WACZxgB,EAAYygB,cACZzgB,EAAY0gB,cACZ1gB,EAAY2gB,YACZ3gB,EAAYob,cACZpb,EAAY4gB,cACZ5gB,EAAY6gB,YACZ7gB,EAAY8gB,sBACZ9gB,EAAY+gB,sBACZ/gB,EAAYghB,oBAEb,MAAM,IAAIt8B,MAAM,iDAGlB,MAAMoP,EAAUolB,EAASplB,QAAQulB,KAAKH,GAChC9vB,EAAM8vB,EAAS9vB,IAAIiwB,KAAKH,GACxBzlB,EAAWylB,EAASzlB,SAAS4lB,KAAKH,GAClClhB,EAAkBkhB,EAASlhB,gBAAgBqhB,KAAKH,GAChD92B,EAAO82B,EAAS92B,KAAKi3B,KAAKH,GAE1B1c,EAAY1I,EAChB1K,EACEA,EACEqK,EAASuM,EAAYmZ,YAAaA,GAClC1lB,EAASuM,EAAYugB,YAAanH,IAEpCpZ,EAAYwgB,YAIV5jB,EAAa9I,EACjB1K,EACEA,EACEqK,EAASuM,EAAYygB,aAActH,GACnC1lB,EAASuM,EAAY0gB,aAActH,IAErCpZ,EAAY2gB,aAKV3jB,EAAalJ,EACjB1K,EACEA,EACEqK,EAASuM,EAAYob,aAAcjC,GACnC1lB,EAASuM,EAAY4gB,aAAcxH,IAErCpZ,EAAY6gB,aAKVI,EAAY7+B,EAChBgH,EACEA,EACEqK,EAASuM,EAAY8gB,qBAAsB3H,GAC3C1lB,EAASuM,EAAY+gB,qBAAsB3H,IAE7CpZ,EAAYghB,qBAKV3jB,EAAarF,EAAgB4E,EAAYwc,GACzC9b,EAAYtF,EAAgBwE,EAAWykB,GAI7C,OAAOjpB,EAAgBgF,EAAY5a,EAHtBgH,EAAIiU,EAAYC,WCtIlB4jB,WAAqBpD,GAChCx7B,eAAe22B,EAAoBrR,GACjC,OAAOyY,GAAmBpH,EAAYrR,GAGxCtlB,YACE42B,EACAC,EACAC,EACApZ,GAEA,OAAOsgB,GACLpH,EACAC,EACAC,EACApZ,aCkBUmhB,IAAUC,OACxBA,EAAMC,OACNA,EAAMC,OACNA,EAAM12B,OACNA,EAAM3C,IACNA,EAAGs5B,KACHA,EAAIC,SACJA,EAAQC,cACRA,IAEA,IAAIC,EAAM,2BACON,EAAS,EAAIE,wBACbD,EAAS,EAAIp5B,EAAMo5B,EAASC,4BACxB,EAAIA,6BACH,EAAIA,yFAGN12B,EAAO+2B,gCACN/2B,EAAOg3B,uDAEVR,EAAS,yBACTC,EAAS,EAAIp5B,EAAMo5B,yBACnBD,EAAS,EAAIE,yBACbD,EAAS,EAAIp5B,EAAMo5B,mCACTE,EAAKI,sBAAsBJ,EAAK54B,gCACvC44B,EAAKK,gBAS1B,OARIh3B,EAAOi3B,SACTH,GAAO,2BACQN,EAAS,wBACTC,EAAS,EAAIp5B,EAAMo5B,EAAS,4DAEpBG,4BACJC,MAAkB72B,EAAOi3B,OAAO55B,aAE9Cy5B,WAQOI,IAAWV,OACzBA,EAAMC,OACNA,EAAMp5B,IACNA,EAAG2pB,OACHA,EAAM0P,OACNA,EAAMS,OACNA,IAEA,MAAO,4BACSX,EAAS,EAAIxP,EAASwP,uBACtBC,EAAS,EAAIp5B,EAAMo5B,sBACpBC,mFAGGS,EAAOJ,8BACNI,EAAOH,yBASZI,IAAWZ,OACzBA,EAAMC,OACNA,EAAMp5B,IACNA,EAAG2pB,OACHA,EAAM2P,KACNA,EAAI9Z,QACJA,EAAO6Z,OACPA,IAEA,MAAO,4BACSF,EAAS,EAAIxP,EAASwP,uBACtBC,EAAS,EAAIp5B,EAAMo5B,sBACpBC,mFAGG7Z,EAAQka,8BACPla,EAAQma,mDAEXR,EAAS,EAAIxP,EAASwP,EAASE,uBAC/BD,EAAS,EAAIp5B,EAAMo5B,uBACnBD,EAAS,EAAIxP,EAASwP,EAASA,EAAS,uBACxCC,EAAS,EAAIp5B,EAAMo5B,iCACTE,EAAKI,sBAAsBJ,EAAK54B,8BACvC44B,EAAKK,yBAUVK,IAAwBb,OACtCA,EAAMC,OACNA,EAAMp5B,IACNA,EAAG2pB,OACHA,EAAM0P,OACNA,EAAMY,MACNA,EAAKX,KACLA,EAAI7F,wBACJA,IAEA,MAAO,0BACS0F,EAAS,GAAKxP,EAAS,GAAKwP,EAASE,uBACrCY,EAAQ,EAAIxG,EAA0BwG,uBACtCd,EAAS,EAAIxP,EAASwP,EAASE,uBAC/BD,EAAS,EAAIp5B,EAAMo5B,iCACTE,EAAKI,sBAAsBJ,EAAK54B,8BACvC44B,EAAKK,yBAgBVO,GACdzjB,GAEA,MAAM0E,MAAEA,EAAK1a,OAAEA,EAAMC,MAAEA,GAAU+V,EACjC,IAAIgjB,EAAM,GACV,MAAMN,EAASz4B,EAAQya,EAAMjf,OAC7B,IAAK,IAAIytB,EAAS,EAAGA,EAASxO,EAAMjf,OAAQytB,IAAU,CACpD,MAAMhtB,EAAOwe,EAAMwO,GACbyP,EAAS34B,EAAS9D,EACxB,IAAK,IAAIqD,EAAM,EAAGA,EAAMrD,EAAMqD,IAC5B,GAAe,IAAX2pB,EACF8P,GAAOP,GAAU,CAAEC,OAAAA,EAAQC,OAAAA,EAAQp5B,IAAAA,EAAK2pB,OAAAA,KAAWlT,QAC9C,CACDkT,IAAWxO,EAAMjf,OAAS,EAC5Bu9B,GAAOM,GAAW,CAAEZ,OAAAA,EAAQC,OAAAA,EAAQp5B,IAAAA,EAAK2pB,OAAAA,KAAWlT,IAEpDgjB,GAAOI,GAAW,CAAEV,OAAAA,EAAQC,OAAAA,EAAQp5B,IAAAA,EAAK2pB,OAAAA,KAAWlT,IAEtD,MAAM0jB,EAAehf,EAAMwO,EAAS,GAC9BsQ,EAAQx5B,EAAS05B,EACvB,IACE,IAAI1G,EAA0B,EAC9BA,EAA0B0G,EAC1B1G,IAEAgG,GAAOO,GAAwB,CAC7Bb,OAAAA,EACAC,OAAAA,EACAp5B,IAAAA,EACA2pB,OAAAA,EACAsQ,MAAAA,EACAxG,wBAAAA,KACGhd,KAMb,OAAOgjB,WAQOW,IAAyBjB,OACvCA,EAAMC,OACNA,EAAMp5B,IACNA,EAAG2pB,OACHA,EAAM0P,OACNA,EAAMgB,cACNA,IAEA,MAAMC,EAAQnB,EAAS,EAAIxP,EAASwP,EAASE,EAAS,EAChDkB,EAAQnB,EAAS,EAAIp5B,EAAMo5B,EAC3Bt5B,EAAIw6B,EAAiB,EAATjB,EAAa,EAM/B,MAAO,6BACYiB,KAASC,OALjBz6B,EAAI,OADLy6B,EAEK,OACJD,EAAQ,OACRC,EAAQ,OAE8Cz6B,KANvDy6B,6BAOYF,EAAcX,uCACRW,EAAc35B,gJAIrB25B,EAAcV,yBAQrBa,GACd/jB,GAEA,MAAM/V,MAAEA,EAAKD,OAAEA,EAAM45B,cAAEA,EAAalf,MAAEA,EAAKke,OAAEA,GAAW5iB,EAClD0iB,EAASz4B,EAAQya,EAAMjf,OAC7B,IAAIu9B,EAAM,4LAEuCY,EAAcX,0DAG/DD,GAAOS,GAAwBzjB,GAC/B,IAAK,IAAIkT,EAAS,EAAGA,EAASxO,EAAMjf,OAAQytB,IAAU,CACpD,MAAMhtB,EAAOwe,EAAMwO,GACbyP,EAAS34B,EAAS9D,EACxB,IAAK,IAAIqD,EAAM,EAAGA,EAAMrD,EAAMqD,IAC5By5B,GAAOW,GAAyB,CAC9BjB,OAAAA,EACAC,OAAAA,EACAp5B,IAAAA,EACA2pB,OAAAA,EACA0P,OAAAA,EACAgB,cAAAA,IAIN,OAAOZ,WAgEOgB,GACdC,EACAh6B,EACAD,GAGA,MAAO,+JAIYC,2BACCD,MAAWi6B,mBAgCjBC,GACdC,GAEA,MAAMnkB,QAAEA,GAAYmkB,GACd9b,UAAEA,EAASC,WAAEA,EAAUnH,aAAEA,GAAiBnB,EAChD,MAAO,CAACqI,GAAW1D,OAAOxD,GAAcwD,OAAO,CAAC2D,aA8KlC8b,GACd1f,EACAye,GAEA,IAAKze,EACH,MAAM,IAAI1e,MAAM,iBAElB,GAAI0e,EAAM2f,KAAMn+B,GAAiBA,EAAO,GACtC,MAAM,IAAIF,MAAM,2BAElB,GAAIm9B,GAAUA,EAAO19B,SAAWif,EAAM,GACpC,MAAM,IAAI1e,MAAM,gCAElB,OAAO0e,QC9hBH4f,GAAY,CAChBlF,YAAAA,GACAoD,aAAAA,GACAf,YAAAA,GACA9H,IAAAA,GACA+H,KAAAA,GACAnD,IAAAA,IAGIgG,GAAY,CAChBnhC,IAAAA,OACA6kB,QACA1O,GACAC,OAAAA,UACA5T,GACAsN,aAAAA,GACAY,OAAAA,GACA0wB,eCxCoBC,EAAejS,GACnC,MAAMxrB,EAAmB,GACzB,KAAOy9B,EAAQjS,EAAKiS,IAClBz9B,EAAOO,KAAKk9B,GAEd,OAAOz9B,GDoCPuF,iBE9CAsJ,GAEA,OAAI3M,MAAMC,QAAQ0M,GACTpM,aAAaiD,KAAKmJ,GAGpBpM,aAAaiD,KAAKvF,OAAO0O,OAAOA,KFyCvC6d,cAAAA,SACA/mB,EACA+3B,eDiZAP,EACAnkB,GAIA,MAAM2kB,EAAgB,CAnEpB9B,KAAM,CACJ54B,MAAO,GACPg5B,MAAO,QACPC,UAAW,cAEbU,cAAe,CACb35B,MAAO,EACPg5B,MAAO,MACPC,UAAW,cAEbh3B,OAAQ,CACN+2B,MAAO,uBACPE,OAAQ,KACRD,UAAW,SAEbna,QAAS,CACPka,MAAO,2BACPC,UAAW,UAEbG,OAAQ,CACNJ,MAAO,0BACPC,UAAW,iBAEbJ,SAAU,OACVC,cAAe,QACfH,OAAQ,EACR34B,MAAO,IACPD,OAAQ,IACR0a,MAAO,MAuCuC1E,IAC1C/V,MAAEA,EAAKD,OAAEA,EAAMkC,OAAEA,GAAWy4B,EAGlC,IAAIjgB,EAAkB,GACtB,GAAIyf,aAAe/b,IAAiB+b,aAAezU,GACjDhL,WA3GFyf,GAIA,MAAMnkB,QAAEA,EAAO0E,MAAEA,GAAUyf,GACrB9b,UAAEA,EAASC,WAAEA,EAAUnH,aAAEA,GAAiBnB,EAChD,IAAK0E,EAAO,CACV,GAAyB,iBAAd2D,GAA0BA,EAAY,EAC/C,MAAM,IAAIriB,MAAM,qBAElB,GAA0B,iBAAfsiB,GAA2BA,EAAa,EACjD,MAAM,IAAItiB,MAAM,sBAElB,GAAImb,MAAAA,SAAAA,EAAckjB,KAAM7wB,GAAMA,EAAI,GAChC,MAAM,IAAIxN,MAAM,wBAGpB,MAA4B,iBAAdqiB,GACZnf,MAAMC,QAAQgY,IACQ,iBAAfmH,EACL,CAACD,GAAW1D,OAAOxD,GAAcwD,OAAO,CAAC2D,IACzC5D,EAsFMkgB,CAAsBT,QAG3B,GAAIA,aAAe1S,GAAW,CACjC,MAAMpJ,UAAEA,EAASlH,aAAEA,EAAYmH,WAAEA,YA7JFjjB,GACjC,MAAM8b,EAAyB,IACzBnB,QAAEA,GAAY3a,EACpB,IAAK2a,EAAQhT,WACX,MAAM,IAAIhH,MAAM,0BAElB,IAAKga,EAAQe,YACX,MAAM,IAAI/a,MAAM,2BAElB,MAAMgH,EAAagT,EAAQhT,aAC3BmU,EAAa5Z,KAAKyY,EAAQmB,aAAa,GAAGnU,EAAYmO,KAAkB,IACxE,IAAK,IAAI3V,EAAI,EAAGA,EAAIwa,EAAQmB,aAAa1b,OAAQD,IAC/C2b,EAAa5Z,KACXyY,EAAQmB,aAAa3b,GAAG2b,EAAa3b,EAAI,GAAI2V,KAAkB3V,IAGnE,MAAMub,EAAcf,EAAQe,YAC1BI,EAAaA,EAAa1b,OAAS,IAClC,GAEH,MAAO,CACL4iB,UAAWrb,EAAWhD,OACtBmX,aAAcA,EAAaxY,IAAK2Y,GAAwBA,EAAYtX,QACpEse,WAAYvH,EAAY/W,QAsIwB66B,CAAmBV,GACnEzf,EAAQ,CAAC2D,GAAW1D,OAAOxD,GAAcwD,OAAO,CAAC2D,SAG9C,GAAI6b,aAAepkB,GAAa,CACnC,MAAMsI,UAAEA,EAASlH,aAAEA,EAAYmH,WAAEA,YApMAjjB,GACnC,MAAM2a,QAAEA,GAAY3a,EACpB,IAAK2a,EACH,MAAM,IAAIha,MAAM,uBAElB,IAAKga,EAAQhT,WACX,MAAM,IAAIhH,MAAM,kCAElB,IAAKga,EAAQmB,aACX,MAAM,IAAInb,MAAM,oCAElB,GAAIga,EAAQmB,aAAa1b,OAAS,EAChC,MAAM,IAAIO,MAAM,iCAElB,IAAKga,EAAQe,YACX,MAAM,IAAI/a,MAAM,mCAElB,MAAMgH,EAAagT,EAAQhT,aACrBmU,EAAe,GACrBA,EAAa5Z,KAAKyY,EAAQmB,aAAa,GAAGnU,EAAY,IACtD,IAAK,IAAIxH,EAAI,EAAGA,EAAIwa,EAAQmB,aAAa1b,OAAQD,IAC/C2b,EAAa5Z,KAAKyY,EAAQmB,aAAa3b,GAAG2b,EAAa3b,EAAI,GAAIA,IAEjE,MAAMub,EAAcf,EAAQe,YAC1BI,EAAaA,EAAa1b,OAAS,GACnC0b,EAAa1b,QAEf,MAAO,CACL4iB,UAAWrb,EAAWhD,OACtBmX,aAAcA,EAAaxY,IAAK2Y,GAAwBA,EAAYtX,QACpEse,WAAYvH,EAAY/W,QAsKwB86B,CAAqBX,GACrEzf,EAAQ,CAAC2D,GAAW1D,OAAOxD,GAAcwD,OAAO,CAAC2D,QAG9C,CAAA,GACH6b,aAAexK,IACfwK,aAAezC,IACfyC,aAAe5F,IACf4F,aAAe/E,IACf+E,aAAe3B,IACf2B,aAAe1C,GAEf,OAAOuC,GACLD,GAAc,IACTY,EACHjgB,MAAO0f,GACLF,GACGC,GAQHj4B,EAAOi3B,UAGXl5B,EACAD,GAIC,GAAIm6B,EAAIj9B,eAAe,QAC1B,OAASi9B,EAA2B13B,MAClC,IAAK,gBACL,IAAK,mBACH,OAAOu3B,GACLP,GAAwB,IACnBkB,EACHjgB,MAAO0f,IAjKuB58B,EAkKF28B,EAjK/B38B,EAAKkd,OAkKAxY,EAAOi3B,UAGXl5B,EACAD,GAEJ,IAAK,MACL,IAAK,MACL,IAAK,OACL,IAAK,cACL,IAAK,cACL,IAAK,eACH,OAAOg6B,GACLD,GAAc,IACTY,EACHjgB,MAAO0f,GAAWF,GAAYC,GAAkBj4B,EAAOi3B,UAEzDl5B,EACAD,GAEJ,QACE,MAAM,IAAIhE,MAAM,6BAEf,GACLm+B,EAAIj9B,eAAe,cACnBi9B,EAAIj9B,eAAe,iBACnBi9B,EAAIj9B,eAAe,cACnB,CACA,MAAMmhB,UAAEA,EAASlH,aAAEA,EAAYmH,WAAEA,GAAe6b,EAChDzf,EAAQ,CAAC2D,KAAclH,EAAcmH,OAChC,CAAA,IAAI6b,EAAIj9B,eAAe,SAG5B,MAAM,IAAIlB,MAAM,wBAFhB0e,EAASyf,EAAezf,WAlMcld,EAsMxC,OAAOw8B,GACLP,GAAwB,IACnBkB,EACHjgB,MAAO0f,GAAW1f,EAAOxY,EAAOi3B,UAElCl5B,EACAD,4JIhiBFmF,EACAg1B,GAEA,IAAKA,EACH,MAAM,IAAIY,UACR,8CAA8CZ,4CAIlD,MAAM/5B,EAAS+5B,EAAI73B,IAAI6C,GACvB,IAAI61B,EAAU,KACV1oB,GAAY,EAahB,OAXAnV,OAAO89B,QAAQ76B,GAAQgW,QAAQ,EAAEC,EAAK9c,WAEjB,IAAVA,GACU,iBAAVA,GACPA,EAAQ+Y,IAER0oB,EAAU3kB,EACV/D,EAAW/Y,KAIRyhC"}