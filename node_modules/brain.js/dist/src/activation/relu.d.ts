/**
 * Relu Activation, aka Rectified Linear Unit Activation
 * @description https://en.wikipedia.org/wiki/Rectifier_(neural_networks)
 */
export declare function activate(weight: number): number;
/**
 * Relu derivative
 */
export declare function measure(weight: number, delta: number): number;
//# sourceMappingURL=relu.d.ts.map